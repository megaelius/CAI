We analyze three different post-processing methods applied to a single-shot qubit readout: the
average-signal (boxcar filter), peak-signal, and maximum-likelihood methods. In contrast to
previous work, we account for a stochastic turn-on time $t_i$ associated with the leading edge of
a pulse signaling one of the qubit states. This model is relevant to spin-qubit readouts based on
spin-to-charge conversion and would be generically reached in the limit of large signal-to-noise
ratio $r$ for several other physical systems, including fluorescence-based readouts of ion-trap
qubits and nitrogen-vacancy center spins. We derive analytical closed-form expressions for the
conditional probability distributions associated with the peak-signal and boxcar filters. For
the boxcar filter, we find an asymptotic scaling of the single-shot error rate $\varepsilon \sim
\ln r/\sqrt{r}$ when $t_i$ is stochastic, in contrast to the result $\varepsilon \sim \ln r/ r$ for
deterministic $t_i$. Consequently, the peak-signal method outperforms the boxcar filter significantly
when $t_i$ is stochastic, but is only marginally better for deterministic $t_i$ (a result that is
consistent with the widespread use of the boxcar filter for fluorescence-based readouts and the
peak-signal for spin-to-charge conversion). We generalize the theoretically optimal maximum-likelihood
method to stochastic $t_i$ and show numerically that a stochastic turn-on time $t_i$ will always
result in a larger single-shot error rate. Based on this observation, we propose a general strategy
to improve the quality of single-shot readouts by forcing $t_i$ to be deterministic. 