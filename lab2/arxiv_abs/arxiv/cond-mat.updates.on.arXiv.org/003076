Fluctuations in biochemical networks, e.g., in a living cell, have a complex origin that precludes
a description of such systems in terms of bipartite or multipartite processes, as is usually done
in the framework of stochastic and/or information thermodynamics. This means that fluctuations
in each subsystem are not independent: subsystems jump simultaneously if the dynamics is modeled
as a Markov jump process, or noises are correlated for diffusion processes. In this paper, we consider
information and thermodynamic exchanges between a pair of coupled systems that do not satisfy the
bipartite property. The generalization of information-theoretic measures, such as learning
rates and transfer entropy rates, to this situation is non-trivial and also involves introducing
several additional rates. We describe how this can be achieved in the framework of general continuous-time
Markov processes, without restricting the study to the steady-state regime. We illustrate our
general formalism on the case of diffusion processes and derive an extension of the second law of
information thermodynamics in which the difference of transfer entropy rates in the forward and
backward time directions replaces the learning rate. As a side result, we also generalize an important
relation linking information theory and estimation theory. To further obtain analytical expressions
we treat in detail the case of Ornstein-Uhlenbeck processes, and discuss the ability of the various
information measures to detect a directional coupling in the presence of correlated noises. Finally,
we apply our formalism to the analysis of the directional influence between cellular processes
in a concrete example, which also requires considering the case of a non-bipartite and non-Markovian
process. 