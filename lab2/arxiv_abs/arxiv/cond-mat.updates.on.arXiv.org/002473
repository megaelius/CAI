Interest in the thermodynamics of computation has revived in recent years, driven by developments
in science, economics and technology. Given the consequences of the growing demand for computational
power, the idea of reducing the energy cost of computations has gained new importance. Simultaneously,
many biological networks are now interpreted as information-processing or computational systems
constrained by their underlying thermodynamics. Indeed, some suggest that low-cost, high-density
biological systems may help to mitigate the rising demand for computational power and the "end"
of Moore's law of exponential growth in the density of transistors. In this chapter we address widespread
misconceptions about thermodynamics and the thermodynamics of computation. In particular, we
will argue against the general perception that a measurement or copy operation can be performed
at no cost, against the emphasis placed on the significance of erasure operations, and against the
careless discussion of heat and work. While not universal, these misconceptions are sufficiently
prevalent (particularly within interdisciplinary contexts) to warrant a detailed discussion.
In the process, we will argue that explicitly representing fundamental processes is a useful tool,
serving to demystify key concepts. We first give a brief overview of thermodynamics, then the history
of the thermodynamics of computation - particularly in terms of copy and measurement operations
inherent to classic thought experiments. Subsequently, we analyse these ideas via an explicit
biochemical representation of the entire cycle of Szilard's engine. In doing so we show that molecular
computation is both a promising engineering paradigm, and a valuable tool in providing fundamental
understanding. 