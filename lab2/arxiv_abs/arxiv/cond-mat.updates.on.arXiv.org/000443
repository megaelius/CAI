In the quest for alternatives to traditional CMOS, it is being suggested that digital computing
efficiency and power can be improved by matching the precision to the application. Many applications
do not need the high precision that is being used today. In particular, large gains in area- and power
efficiency could be achieved by dedicated analog realizations of approximate computing engines.
In this work, we explore the use of memristor networks for analog approximate computation, based
on a machine learning framework called reservoir computing. Most experimental investigations
on the dynamics of memristors focus on their nonvolatile behavior. Hence, the volatility that is
present in the developed technologies is usually unwanted and it is not included in simulation models.
In contrast, in reservoir computing, volatility is not only desirable but necessary. Therefore,
in this work, we propose two different ways to incorporate it into memristor simulation models.
The first is an extension of Strukov's model and the second is an equivalent Wiener model approximation.
We analyze and compare the dynamical properties of these models and discuss their implications
for the memory and the nonlinear processing capacity of memristor networks. Our results indicate
that device variability, increasingly causing problems in traditional computer design, is an
asset in the context of reservoir computing. We conclude that, although both models could lead to
useful memristor based reservoir computing systems, their computational performance will differ.
Therefore, experimental modeling research is required for the development of accurate volatile
memristor models. 