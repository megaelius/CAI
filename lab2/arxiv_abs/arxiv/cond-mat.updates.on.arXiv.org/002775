Restricted Boltzmann machines (RBMs) constitute one of the main models for machine statistical
inference and they are widely employed in Artificial Intelligence as powerful tools for (deep)
learning. However, in contrast with countless remarkable practical successes, their mathematical
formalization has been largely elusive: from a statistical-mechanics perspective these systems
display the same (random) Gibbs measure of bi-partite spin-glasses, whose rigorous treatment
is notoriously difficult. In this work, beyond providing a brief review on RBMs from both the learning
and the retrieval perspectives, we aim to contribute to their analytical investigation, by considering
two distinct realizations of their weights (i.e., Boolean and Gaussian) and studying the properties
of their related free energies. More precisely, focusing on a RBM characterized by digital couplings,
we first extend the Pastur-Shcherbina-Tirozzi method (originally developed for the Hopfield
model) to prove the self-averaging property for the free energy, over its quenched expectation,
in the infinite volume limit, then we explicitly calculate its simplest approximation, namely
its annealed bound. Next, focusing on a RBM characterized by analogical weights, we extend Guerra's
interpolating scheme to obtain a control of the quenched free-energy under the assumption of replica
symmetry: we get self-consistencies for the order parameters (in full agreement with the existing
Literature) as well as the critical line for ergodicity breaking that turns out to be the same obtained
in AGS theory. As we discuss, this analogy stems from the slow-noise universality. Finally, glancing
beyond replica symmetry, we analyze the fluctuations of the overlaps for an estimate of the (slow)
noise affecting the retrieval of the signal, and by a stability analysis we recover the Aizenman-Contucci
identities typical of glassy systems. 