In this work we develop analytical techniques to address, in the high-storage regime, phase diagrams
for a broad class of neural networks (whose cost functions may include various, polynomial, contributions
both in the neurons and the patterns, hence {\em dense}). The techniques translate the original
statistical-mechanical problem into a pure analytical mechanical one which implies solving a
set of partial differential equations, rather than tackling the canonical probabilistic route.
We test the methods on the classical Hopfield model -- where the cost function includes only two-body
interactions (i.e., pairwise, quadratic terms) and on the ``relativistic'' Hopfield model, where
the (expansion of the) cost function includes (infinite) $p$-body (i.e., of degree $p$) contributions.
Interestingly, the latter shares deep similarities with the dense associative memories proposed
by Krotov $\&$ Hopfield as a benchmark to test the emerging capabilities of modern neural network
architectures. Under the replica symmetric assumption, we paint the phase diagrams of these models
by obtaining the explicit expression of their (quenched) free energy as a function of the natural
order parameters of the theory as the tunable one (e.g. noise level and memory storage) may vary.
Further, since for non-pairwise models ergodicity breaking is non necessarily a critical phenomenon,
we also develop a systematic fluctuation analysis to find out that standard criticality is yet preserved.
Aiming for overall global coherence, we finally check that -- in the proper limits -- classical scenarios
(e.g., the Amit-Gutfreund-Sompolinsky theory) are recovered as they should. 