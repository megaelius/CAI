Cosmological phase transitions in the early Universe may produce relics in the form of a network
of cosmic defects. Independently of the order of a phase transition, topology of the defects, and
their global or gauge nature, the defects are expected to emit gravitational waves (GWs) as the network
energy-momentum tensor adapts itself to maintaining {scaling}. We show that the evolution of any
defect network (and for that matter any scaling source) emits a GW background with spectrum $\Omega_{\rm
GW} \propto f^3$ for $f \ll f_0$, $\Omega_{\rm GW} \propto 1/f^2$ for $f_0 \lesssim f \lesssim f_{\rm
eq}$, and $\Omega_{\rm GW} \propto~const$ (i.e.~exactly scale-invariant) for $f \gg f_{\rm eq}$,
where $f_0$ and $ f_{\rm eq}$ denote respectively the frequencies corresponding to the present
and matter-radiation equality horizons. This background represents an irreducible emission
of GWs from any scaling network of cosmic defects, with its amplitude characterized only by the symmetry
breaking scale and the nature of the defects. Using classical lattice simulations we calculate
the GW signal emitted by defects created after the breaking of a global symmetry $O(N) \rightarrow
O(N-1)$. We obtain the GW spectrum for $N$ between 2 and 20 with two different techniques: integrating
over unequal time correlators of the energy momentum tensor, updating our previous work on smaller
lattices, and for the first time, comparing the result with the real time evolution of the tensor
perturbations sourced by the same defects. Our results validate the equivalence of the two techniques.
Using CMB upper bounds on the defects' energy scale, we discuss the difficulty of detecting this
GW background in the case of global defects. 