The problem of sampling from the stationary distribution of a Markov chain finds widespread applications
in a variety of fields. The time required for a Markov chain to converge to its stationary distribution
is known as the classical mixing time. In this article, we deal with analog quantum algorithms for
mixing. First, we provide an analog quantum algorithm that given a Markov chain, allows us to sample
from its stationary distribution in a time that scales as the sum of the square root of the classical
mixing time and the square root of the classical hitting time. Our algorithm makes use of the framework
of interpolated quantum walks and relies on Hamiltonian evolution in conjunction with von Neumann
measurements. There also exists a different notion for quantum mixing: the problem of sampling
from the limiting distribution of quantum walks, defined in a time-averaged sense. In this scenario,
the quantum mixing time is defined as the time required to sample from a distribution that is close
to this limiting distribution. Recently we provided an upper bound on the quantum mixing time for
Erd\"os-Renyi random graphs [Phys. Rev. Lett. 124, 050501 (2020)]. Here, we also extend and expand
upon our findings therein. Namely, we provide an intuitive understanding of the state-of-the-art
random matrix theory tools used to derive our results. In particular, for our analysis we require
information about macroscopic, mesoscopic and microscopic statistics of eigenvalues of random
matrices which we highlight here. Furthermore, we provide numerical simulations that corroborate
our analytical findings and extend this notion of mixing from simple graphs to any ergodic, reversible,
Markov chain. 