Over the past decade, machine learning techniques have revolutionized how research is done, from
designing new materials and predicting their properties to assisting drug discovery to advancing
cybersecurity. Recently, we added to this list by showing how a machine learning algorithm (a so-called
learner) combined with an optimization routine can assist experimental efforts in the realm of
tuning semiconductor quantum dot (QD) devices. Among other applications, semiconductor QDs are
a candidate system for building quantum computers. The present-day tuning techniques for bringing
the QD devices into a desirable configuration suitable for quantum computing that rely on heuristics
do not scale with the increasing size of the quantum dot arrays required for even near-term quantum
computing demonstrations. Establishing a reliable protocol for tuning that does not rely on the
gross-scale heuristics developed by experimentalists is thus of great importance. To implement
the machine learning-based approach, we constructed a dataset of simulated QD device characteristics,
such as the conductance and the charge sensor response versus the applied electrostatic gate voltages.
Here, we describe the methodology for generating the dataset, as well as its validation in training
convolutional neural networks. We show that the learner's accuracy in recognizing the state of
a device is ~96.5 % in both current- and charge-sensor-based training. We also introduce a tool that
enables other researchers to use this approach for further research: QFlow lite - a Python-based
mini-software suite that uses the dataset to train neural networks to recognize the state of a device
and differentiate between states in experimental data. This work gives the definitive reference
for the new dataset that will help enable researchers to use it in their experiments or to develop
new machine learning approaches and concepts. 