The yield of physical qubits fabricated in the laboratory is much lower than that of classical transistors
in production semiconductor fabrication. Actual implementations of quantum computers will be
susceptible to loss in the form of physically faulty qubits. Though these physical faults must negatively
affect the computation, we can deal with them by adapting error correction schemes. In this paper
We have simulated statically placed single-fault lattices and lattices with randomly placed faults
at functional qubit yields of 80%, 90% and 95%, showing practical performance of a defective surface
code by employing actual circuit constructions and realistic errors on every gate, including identity
gates. We extend Stace et al.'s superplaquettes solution against dynamic losses for the surface
code to handle static losses such as physically faulty qubits. The single-fault analysis shows
that a static loss at the periphery of the lattice has less negative effect than a static loss at the
center. The randomly-faulty analysis shows that 95% yield is good enough to build a large scale quantum
computer. The local gate error rate threshold is $\sim 0.3\%$, and a code distance of seven suppresses
the residual error rate below the original error rate at $p=0.1\%$. 90% yield is also good enough
when we discard badly fabricated quantum computation chips, while 80% yield does not show enough
error suppression even when discarding 90% of the chips. We evaluated several metrics for predicting
chip performance, and found that the average of the product of the number of data qubits and the cycle
time of a stabilizer measurement of stabilizers gave the strongest correlation with post-correction
residual error rates. Our analysis will help with selecting usable quantum computation chips from
among the pool of all fabricated chips. 