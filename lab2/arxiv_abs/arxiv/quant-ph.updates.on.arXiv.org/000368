Recent progress in building large-scale quantum devices for exploring quantum computing and simulation
paradigms has relied upon effective tools for achieving and maintaining good experimental parameters,
i.e. tuning up devices. In many cases, including in quantum-dot based architectures, the parameter
space grows substantially with the number of qubits, and may become a limit to scalability. Fortunately,
machine learning techniques for pattern recognition and image classification using so-called
deep neural networks have shown surprising successes for computer-aided understanding of complex
systems. In this work, we use deep and convolutional neural networks to characterize states and
charge configurations of semiconductor quantum dot arrays when one can only measure a current-voltage
characteristic of transport (here conductance) through such a device. For simplicity, we model
a semiconductor nanowire connected to leads and capacitively coupled to depletion gates using
the Thomas-Fermi approximation and Coulomb blockade physics. We then generate labelled training
data for the neural networks, and find at least $90\,\%$ accuracy for charge and state identification
for single and double dots purely from the dependence of the nanowire's conductance upon gate voltages.
Using these characterization networks, we can then optimize the parameter space to achieve a desired
configuration of the array, a technique we call `auto-tuning'. Finally, we show how such techniques
can be implemented in an experimental setting by applying our approach to an experimental data set,
and outline further problems in this domain, from using charge sensing data to extensions to full
one and two-dimensional arrays, that can be tackled with machine learning. 