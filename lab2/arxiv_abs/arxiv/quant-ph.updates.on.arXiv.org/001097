In quantum computation the target fidelity of the qubit gates is very high, with the admissible error
being in the range from $10^{-3}$ to $10^{-4}$ and even less, depending on the protocol. The direct
experimental determination of such an extremely small error is very challenging by standard quantum-process
tomography. Instead, the method of randomized benchmarking, which uses a random sequence of Clifford
gates, has become a standard tool for determination of the average gate error as the decay constant
in the exponentially decaying fidelity. In this paper, the task for determining a tiny error is addressed
by sequentially repeating the \emph{same} gate multiple times, which leads to the coherent amplification
of the error, until it reaches large enough values to be measured reliably. If the transition probability
is $p=1-\epsilon$ with $\epsilon \ll 1$ in the single process, then classical intuition dictates
that the probability after $N$ passes should be $P_N \approx 1 - N \epsilon$. However, this classical
expectation is misleading because it neglects interference effects. This paper presents a rigorous
theoretical analysis based on the SU(2) symmetry of the qubit propagator, resulting in explicit
analytic relations that link the $N$-pass propagator to the single-pass one in terms of Chebyshev
polynomials. In particular, the relations suggest that in some special cases the $N$-pass transition
probability degrades as $P_N = 1-N^2\epsilon$, i.e. dramatically faster than the classical probability
estimate. In the general case, however, the relation between the single-pass and $N$-pass propagators
is much more involved. Recipes are proposed for unambiguous determination of the gate errors in
the general case, and for both Clifford and non-Clifford gates. 