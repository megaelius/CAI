In cosmologies with massive neutrinos, the galaxy bias defined with respect to the total matter
field (cold dark matter, baryons, and non-relativistic neutrinos) depends on the sum of the neutrino
masses $M_{\nu}$, and becomes scale-dependent even on large scales. This effect has been usually
neglected given the sensitivity of current surveys, but becomes a severe systematic for future
surveys aiming to provide the first detection of non-zero $M_{\nu}$. The effect can be corrected
for by defining the bias with respect to the density field of cold dark matter and baryons instead
of the total matter field. In this work, we provide a simple prescription for correctly mitigating
the neutrino-induced scale-dependent bias effect in a practical way. We clarify a number of subtleties
regarding how to properly implement this correction in the presence of redshift-space distortions
and non-linear evolution of perturbations. We perform a MCMC analysis on simulated galaxy clustering
data that match the expected sensitivity of the \textit{Euclid} survey. We find that the neutrino-induced
scale-dependent bias can lead to important shifts in both the inferred mean value of $M_{\nu}$,
as well as its uncertainty. We show how these shifts propagate to other cosmological parameters
correlated with $M_{\nu}$, such as the cold dark matter physical density $\Omega_{cdm} h^2$ and
the scalar spectral index $n_s$. In conclusion, we find that correctly accounting for the neutrino-induced
scale-dependent bias will be of crucial importance for future galaxy clustering analyses. We encourage
the cosmology community to correctly account for this effect using the simple prescription we present
in our work. The tools necessary to easily correct for the neutrino-induced scale-dependent bias
will be made publicly available in an upcoming release of the Boltzmann solver \texttt{CLASS}.
