The technical breakthroughs of multiple detectors developed by Daya Bay and RENO collaborations
have gotten great attention. Yet the optimal determination of neutrino mixing parameters from
reactor data depends on the statistical method and demands equal attention. We find that a straightforward
method using a minimal parameters will generally outperform a multi-parameter method by delivering
more reliable values with sharper resolution. We review standard confidence levels and statistical
penalties for models using extra parameters, and apply those rules to our analysis. We find that
the methods used in recent work of the Daya Bay and RENO collaborations have several undesirable
properties. The existing work also uses non-standard measures of significance which we are unable
to explain. A central element of the current methods consists of variationally fitting many more
parameters than data points. As a result the experimental resolution of $\sin ^{2}(2\theta _{13})$
is degraded. The results also become extremely sensitive to certain model parameters that can be
adjusted arbitrarily. The number of parameters to include in evaluating significance is an important
issue that has generally been overlooked. The measures of significance applied previously would
be consistent if and only if all parameters but one were considered to have no physical relevance
for the experiment's hypothesis test. Simpler, more transparent methods can improve the determination
of the mixing angle $\theta _{13}$ from reactor data, and exploit the advantages from superb hardware
technique of the experiments. We anticipate that future experimental analysis will fully exploit
those advantages. 