We find an asymptotic limit for the integral scale dissipation length in strongly stratified stellar
convection; this is not adjustable, and we identify it with the "mixing length parameter", $\alpha
\sim 5/3$, a theoretical prediction which agrees to within 10% with the fitted empirical values
quoted by eight independent stellar evolutionary groups, as well as several 3D stellar atmosphere
groups. For strong stratification, the dissipation length approaches the density scale height;
in weak stratification it shrinks to the depth for such thin convective regions. Simulations with
different zoning give a monotonic decrease in resolution errors with added zones, down to barely
detectable for the most difficult case (lower boundary layer), and an estimate of the dissipation
due to the turbulent cascade. No explicit viscosity is required; stellar dissipation occurs from
nonlinear fluid effects (Taylor, Onsager). These implicit large eddy simulations of the Euler
equations, with simultaneous analysis by Reynolds averaging (RA-ILES), resolve the energy-containing
eddies, develop a turbulent cascade down to the grid scale, and produce surfaces of separation at
boundary layers. Like experiments (Warhaft), and direct numerical simulations of the Navier-Stokes
equations (DNS, Sreenivasan), our simulations develop "anomalous terms" for dissipation in the
turbulent cascade (due to intermittency, anisotropy, and interactions between coherent structures).
They have more realistic behavior at high order than the K41 theory of Kolmogorov. Mixing length
theory (MLT, Boehm-Vitense) overestimates the convective enthalpy flux for strong stratification,
which has consequences for the theory of luminous blue variables, for the solar metal abundance,
and deep solar convection. 