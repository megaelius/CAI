The understanding of (sub-)millimetre polarisation has made a leap forward since high-resolution
imaging with ALMA came available. Amongst other effects, self-scattering (i.e., scattering of
thermal dust emission on other grains) is thought to be the origin of millimetre polarisation. This
opens the first window to a direct measurement of dust grain sizes in regions of optically thick continuum
emission as it can be found in protoplanetary disks and star-forming regions. However, the newly
derived values of grain sizes are usually around ${\sim}100\,\mu$m and thus one order of magnitude
smaller than those obtained from more indirect measurements as well as those expected from theory
(${\sim}1\,$mm). We see the origin of this contradiction in the applied dust model of today's self-scattering
simulations: a perfect compact sphere. The aim of this study is to test our hypothesis by investigating
the impact of non-spherical grain shapes on the self-scattering signal. We apply discrete dipole
approximation simulations to investigate the influence of the grain shape on self-scattering
polarisation in three scenarios: an unpolarised and polarised incoming wave under a fixed as well
as a varying incident polarisation angle. We find significant deviations of the resulting self-scattering
polarisation when comparing non-spherical to spherical grains, in particular outside the Rayleigh
regime, i.e. for >100$\,\mu$m size grains observed at $870\,\mu$m wavelength. Self-scattering
by oblate grains produces higher polarisation degrees compared to spheres which challenges the
interpretation of the origin of observed millimetre polarisation. A (nearly) perfect alignment
of the non-spherical grains is required to account for the observed millimetre polarisation in
protoplanetary disks. Our findings point towards a necessary re-evaluation of the dust grain sizes
derived from (sub-)mm polarisation. 