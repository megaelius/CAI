Observations of gamma-ray burst (GRB) afterglows have long provided the most detailed information
about the origin of this spectacular phenomena. The model that is most commonly used to extract physical
properties of the event from the observations is the relativistic fireball model, where ejected
material moving at relativistic speeds creates a shock wave when it interacts with the surrounding
medium. Electrons are accelerated in the shock wave, generating the observed synchrotron emission
through interactions with the magnetic field in the downstream medium. It is usually assumed that
the accelerated electrons follow a simple power-law distribution in energy between specific energy
boundaries and that no electron exists outside these boundaries. This work explores the consequences
of adding a low-energy power-law segment to the electron distribution whose energy contributes
insignificantly to the total energy budget of the distribution. The low-energy electrons have
a significant impact on the radio emission, providing synchrotron absorption and emission at these
long wavelengths. Shorter wavelengths are affected through the normalization of the distribution.
The new model is used to analyze the light curves of GRB 990510 and the resulting parameters compared
to a model without the extra electrons. The quality of the fit and the best fit parameters are significantly
affected by the additional model component. The new component is in one case found to strongly affect
the X-ray light curves showing how changes to the model at radio frequencies can affect light curves
at other frequencies through changes in best fit model parameters. 