Post-processing algorithms play a key role in pushing the detection limits of high-contrast imaging
(HCI) instruments. State-of-the-art image processing approaches for HCI enable the production
of science-ready images relying on unsupervised learning techniques, such as low-rank approximations,
for generating a model PSF and subtracting the residual starlight and speckle noise. In order to
maximize the detection rate of HCI instruments and survey campaigns, advanced algorithms with
higher sensitivities to faint companions are needed, especially for the speckle-dominated innermost
region of the images. We propose a reformulation of the exoplanet detection task (for ADI sequences)
that builds on well-established machine learning techniques to take HCI post-processing from
an unsupervised to a supervised learning context. In this new framework, we present algorithmic
solutions using two different discriminative models: SODIRF (random forests) and SODINN (neural
networks). We test these algorithms on real ADI datasets from VLT/NACO and VLT/SPHERE HCI instruments.
We then assess their performances by injecting fake companions and using receiver operating characteristic
analysis. This is done in comparison with state-of-the-art ADI algorithms, such as ADI-PCA. This
study shows the improved sensitivity vs specificity trade-off of the proposed approach. At the
diffraction limit, SODINN improves the true positive rate by a factor ranging from ~2 to ~10 (depending
on the dataset and angular separation) with respect to ADI-PCA when working at the same false positive
level. The proposed supervised detection framework outperforms state-of-the-art techniques
in the task of discriminating planet signal from speckles. In addition, it offers the possibility
of re-processing existing HCI databases to maximize their scientific return and potentially improve
the demographics of directly imaged exoplanets. 