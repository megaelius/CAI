The Event Horizon Telescope recently observed the first shadow of a black hole. Images like this
can potentially be used to test or constrain theories of gravity and deepen the understanding in
plasma physics at event horizon scales, which requires accurate parameter estimations. In this
work, we present Deep Horizon, two convolutional deep neural networks that recover the physical
parameters from the images of black hole shadows. We investigate the effects of a limited telescope
resolution and of observations at different frequencies. We train two convolutional deep neural
networks on a large image library of simulated mock data. The first network is a Bayesian deep neural
regression network and is used to recover the viewing angle $i$ and the position angle $PA$, the mass
accretion rate $\dot{M}$, the electron heating prescription $R_{\rm high}$ and the black hole
mass $M_{\rm BH}$. The second network is a classification network that recovers the black hole spin
$a$. We find that with the current resolution of the Event Horizon Telescope, it is only possible
to accurately recover a limited amount of parameters of a static image, namely the mass and mass accretion
rate. Since potential future space-based observing missions will operate at frequencies above
$230$ GHz, we also investigated the applicability of our network at a frequency of $690$ GHz. The
expected resolution of space-based missions is higher than the current resolution of the Event
Horizon Telescope and we show that Deep Horizon can accurately recover the parameters of simulated
observations with a comparable resolution to such missions. 