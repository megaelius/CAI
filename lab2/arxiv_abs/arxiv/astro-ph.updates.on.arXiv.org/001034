Observations in radio have shown that galaxy clusters are giant reservoirs of cosmic rays (CR).
Although a gamma- ray signal from the cluster volume is expected to arise through interactions of
CR protons with the ambient plasma, a confirming observation is still missing. We search for a cumulative
gamma-ray emission in direction of galaxy clusters by analysing a collection of stacked Fermi-LAT
count maps. Additionally, we investigate possible systematic differences in the emission between
cool-core and non-cool core cluster populations. Making use of a sample of 53 clusters selected
from the HIFLUGCS catalog, we do not detect a significant signal from the stacked sample. The upper
limit on the average flux per cluster derived for the total stacked sample is at the level of a few 1e-11
ph cm-2 s-1 at 95% confidence level in the 1-300 GeV band, assuming power-law spectra with photon
indices 2.0, 2.4, 2.8 and 3.2. Separate stacking of the cool core and non-cool core clusters in the
sample lead to similar values of around 5e-11 ph cm-2 s-1 and 2e-11 ph cm-2 s-1, respectively. Under
the assumption that decaying pi0, produced in collisions between CRs and the ambient thermal gas,
are responsible for the gamma-ray emission, we set upper limits on the average CR content in galaxy
clusters. For the entire cluster population, our upper limit on the gamma-ray flux translates into
an upper limit on the average CR-to-thermal energy ratio of 4.6% for a photon index of 2.4, although
it is possible for individual systems to exceed this limit. Our 95% upper limits are at the level expected
from numerical simulations, which likely suggests that the injection of CR at cosmological shocks
is less efficient than previously assumed. 