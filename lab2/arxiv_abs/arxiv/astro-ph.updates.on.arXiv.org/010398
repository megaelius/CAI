The tidal disruption of stars by supermassive black holes (SMBHs) can be used to probe the SMBH mass
function, the properties of individual stars, and stellar dynamics in galactic nuclei. Upcoming
missions will detect thousands of TDEs, and accurate theoretical modeling is required to interpret
the data with precision. Here we analyze the influence of more realistic stellar structure on the
outcome of TDEs; in particular, we compare the fallback rates -- being the rate at which tidally-disrupted
debris returns to the black hole -- from progenitors generated with the stellar evolution code {\sc
mesa} to $\gamma = 4/3$ and $\gamma = 5/3$ polytropes. We find that {\sc mesa}-generated density
profiles yield qualitatively-different fallback rates as compared to polytropic approximations,
and that only the fallback curves from low-mass ($1M_{\odot}$ or less), zero-age main-sequence
stars are well fit by either a $\gamma = 4/3$ or $5/3$ polytrope. Stellar age has a strong affect on
the shape of the fallback curve, and can produce characteristic timescales (e.g., the time to the
peak of the fallback rate) that greatly differ from the polytropic values. We use these differences
to assess the degree to which the inferred black hole mass from the observed lightcurve can deviate
from the true value, and find that the discrepancy can be at the order of magnitude level. Accurate
stellar structure also leads to a substantial variation in the critical impact parameter at which
the star is fully disrupted, and can increase the susceptibility of the debris stream to fragmentation
under its own self-gravity. These results suggest that detailed modeling is required to accurately
interpret observed lightcurves of TDEs. 