Highly reddened type Ia Supernovae (SNe Ia) with low total-to-selective visual extinction ratio
values, $R_V$, also show peculiar linear polarization wavelength dependencies with peak polarizations
at short wavelengths ($\lambda_{max} \lesssim 0.4 \mu m$). It is not clear why sightlines to SNe
Ia display such different continuum polarization profiles from interstellar sightlines in the
Milky Way with similar $R_V$ values. We investigate polarization profiles of a sample of Galactic
stars with low $R_V$ values, along anomalous extinction sightlines, with the aim to find similarities
to the polarization profiles that we observe in SN Ia sightlines. We undertook spectropolarimetry
of 14 stars, and used archival data for three additional stars, and run dust extinction and polarization
simulations to infer a simple dust model that can reproduce the observed extinction and polarization
curves. Our sample of Galactic stars with low $R_V$ values and anomalous extinction sightlines
displays normal polarization profiles with an average $\lambda_{max} \sim 0.53 {\mu m}$, and is
consistent within 3$\sigma$ to a larger coherent sample of Galactic stars from literature. Despite
the low $R_V$ values of dust towards the stars in our sample, the polarization curves do not show any
similarity to the continuum polarization curves observed towards SNe Ia with low $R_V$ values.
There is a correlation between the best-fit Serkowski parameters $K$ and $\lambda_{max}$, but
we did not find any significant correlation between $R_V$ and $\lambda_{max}$. Our simulations
show that the $K-\lambda_{max}$ relationship is an intrinsic property of polarization. Furthermore,
we have shown that in order to reproduce polarization curves with normal $\lambda_{max}$ and low
$R_V$ values, a population of large (a $\geq 0.1 \mu m$) interstellar silicate grains must be contained
in the dust's composition. 