We consider delayed, volumetric heating in a magnetized outflow that has broken out of a confining
medium and expanded to a high Lorentz factor ($\Gamma \sim 10^2-10^3$) and low optical depth to scattering
($\tau_{\rm T} \sim 10^{-3}-10^{-2}$). The energy flux at breakout is dominated by the magnetic
field, with a modest contribution from quasi-thermal gamma rays whose spectrum was calculated
in Paper I. We focus on the case of extreme baryon depletion in the magnetized material, but allow
for a separate baryonic component that is entrained from a confining medium. Dissipation is driven
by relativistic motion between these two components, which develops once the photon compactness
drops below $ 4\times 10^3(Y_e/0.5)^{-1}$. We first calculate the acceleration of the magnetized
component following breakout, showing that embedded MHD turbulence provides significant inertia,
the neglect of which leads to unrealistically high estimates of flow Lorentz factor. After re-heating
begins, the pair and photon distributions are evolved self-consistently using a one-zone kinetic
code that incorporates an exact treatment of Compton scattering, pair production and annihilation,
and Coulomb scattering. Heating leads to a surge in pair creation, and the scattering depth saturates
at $\tau_{\rm T} \sim$ 1-4. The plasma maintains a very low ratio of particle to magnetic pressure,
and can support strong anisotropy in the charged particle distribution, with cooling dominated
by Compton scattering. High-energy power-law spectra with photon indices in the range observed
in GRBs ($-3 < \beta < -3/2$) are obtained by varying the ratio of heat input to the seed energy
in quasi-thermal photons. We contrast our results with those for continuous heating across an expanding
photosphere, and show that the latter model produces soft-hard evolution that is inconsistent
with observations of GRBs. 