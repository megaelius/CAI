To use strongly lensed Type Ia supernovae (LSNe Ia) for cosmology, a time-delay measurement between
the multiple supernova (SN) images is necessary. The sharp rise and decline of SN Ia light curves
make them promising for measuring time delays, but microlensing can distort these light curves
and therefore add large uncertainties to the measurements. An alternative approach is to use color
curves where uncertainties due to microlensing are significantly reduced for a certain period
of time known as the achromatic phase. In this work, we investigate in detail the achromatic phase,
testing four different SN Ia models with various microlensing configurations. We find on average
an achromatic phase of around three rest-frame weeks or longer for most color curves but the spread
in the duration of the achromatic phase (due to different microlensing maps and filter combinations)
is quite large and an achromatic phase of just a few days is also possible. Furthermore, the achromatic
phase is longer for smoother microlensing maps, lower macro-magnifications and larger mean Einstein
radii of microlenses. From our investigations, we do not find a strong dependency on the model or
on asymmetries in the SN ejecta. Further, we find that three independent LSST color curves exhibit
features such as extreme points or turning points within the achromatic phase, which make them promising
for time-delay measurements. These curves contain combinations of rest-frame bands $u$, $g$,
$r$, and $i$ and to observe them for typical LSN Ia redshifts, it would be ideal to cover (observer-frame)
filters $r$, $i$, $z$, $y$, $J$, and $H$. 