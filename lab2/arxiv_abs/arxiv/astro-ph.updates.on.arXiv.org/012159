X-ray telescopes are powerful tools for the study of neutron stars and black holes. Several methods
have already been developed (e.g., principal component analysis, nonlinear optimal filtering
or high-rate processing method) to analyze the pulses that result from X-rays absorbed in superconducting
transition-edge sensors. Our goal is to develop a lightweight, linear filter that will maximize
energy and time resolution when X-ray photons are detected by transition-edge sensors. Furthermore,
we find the minimal sampling rate that will not degrade the energy and time-resolution of these techniques.
Our method is designed for the widest range of photon energies (from $0.1$ keV to $30$ keV). Transition-edge
sensors exhibit a non-linear response that becomes more pronounced with increasing photon energy;
therefore, we need to treat high-energy photons differently from low-energy photons. In order
to retrieve the energy and the arrival time of the photon, we fit simulations of the evolution of the
current including the typical noise sources in a sensor with simulated theoretical models. The
curve-fitting parameters are interpolated to extract the energy and time resolution. For energies
from $0.1$ keV to $30$ keV and with a sampling rate of $195$ kHz, we successfully obtain a $2\sigma$-energy
resolution between $1.67$ eV and $6.43$ eV. Those results hold if the sampling rate decreases by
a factor two. About time resolution, with a sampling rate of $195$ kHz we get a $2\sigma$-time resolution
between $94$ ns and $0.55$ ns for a sensor with the physical parameters as those used in the HOLMES
experiment. In order to make this method useful on a larger scale, it will be essential to get a more
general description of the noise in a TES, and it will be necessary to develop a robust way to identify
pile-up events. 