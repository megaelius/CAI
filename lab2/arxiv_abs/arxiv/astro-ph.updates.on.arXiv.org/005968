Computer simulations of photon transport through an absorbing and/or scattering medium form an
important research tool in astrophysics. Nearly all software codes performing such simulations
for three-dimensional geometries employ the Monte Carlo radiative transfer method, including
various forms of biasing to accelerate the calculations. Because of the probabilistic nature of
the Monte Carlo technique, the outputs are inherently noisy, but it is often assumed that the average
values provide the physically correct result. We show that this assumption is not always justified.
Specifically, we study the intensity of radiation penetrating an infinite, uniform slab of material
that absorbs and scatters the radiation with equal probability. The basic Monte Carlo radiative
transfer method, without any biasing mechanisms, starts to break down for transverse optical depths
above ~20 because so few of the simulated photon packets reach the other side of the slab. When including
biasing techniques such as absorption/scattering splitting and path length stretching, the simulated
photon packets do reach the other side of the slab but the biased weights do not necessarily add up
to the correct solution. While the noise levels seem to be acceptable, the average values sometimes
severely underestimate the correct solution. Detecting these anomalies requires the judicious
application of statistical tests, similar to those used in the field of nuclear particle transport,
possibly in combination with convergence tests employing consecutively larger numbers of photon
packets. In any case, for transverse optical depths above ~75 the Monte Carlo methods used in our
study fail to solve the one-dimensional slab problem, implying the need for approximations such
as a modified random walk. 