When comparing nebular electron densities derived from collisionally excited lines (CELs) to
those estimated using the emission measure, significant discrepancies are common. The standard
solution is to view nebulae as aggregates of dense regions of constant density in an otherwise empty
void. This porosity is parametrized by a filling factor $f<1$. Similarly, abundance and temperature
discrepancies between optical recombination lines (ORLs) and CELs are often explained by invoking
a dual delta distribution of a dense, cool, metal-rich component immersed in a diffuse, warm, metal-poor
plasma. In this paper, we examine the possibility that the observational diagnostics that lead
to such discrepancies can be produced by a realistic distribution of density and temperature fluctuations,
such as might arise in plasma turbulence. We produce simulated nebulae with density and temperature
fluctuations described by various probability distribution functions (pdfs). Standard astronomical
diagnostics are applied to these simulated observations to derive estimates of nebular densities,
temperatures, and abundances. Our results show that for plausible density pdfs the simulated observations
lead to filling factors in the observed range. None of our simulations satisfactorily reproduce
the abundance discrepancy factors (ADFs) in planetary nebulae, although there is possible consistency
with \ion{H}{ii} regions. Compared to the case of density-only and temperature-only fluctuations,
a positive correlation between density and temperature reduces the filling factor and ADF (from
optical CELs), whereas a negative correlation increases both, eventually causing the filling
factor to exceed unity. This result suggests that real observations can provide constraints on
the thermodynamics of small scale fluctuations. 