The detection of gravitational waves (GWs) from binary black holes (BBHs) has allowed the theory
of general relativity to be tested in a previously unstudied regime: that of strong curvature and
high GW luminosities. One distinctive and measurable effect associated with this aspect of the
theory is the nonlinear GW memory effect. The GW memory effect is characterized by its effect on freely
falling observers: the proper distance between their locations differs before and after a burst
of GWs passes by their locations. Gravitational-wave interferometers, like the LIGO and Virgo
detectors, can measure features of this effect from a single BBH merger, but previous work has shown
that it will require an event that is significantly more massive and closer than any previously detected
GW event. Finding evidence for the GW memory effect within the entire population of BBH mergers detected
by LIGO and Virgo is more likely to occur sooner. A prior study has shown that the GW memory effect could
be detected in a population of BBHs consisting of binaries like the first GW150914 event after roughly
one-hundred events. In this paper, we compute forecasts of the time it will take the advanced LIGO
and Virgo detectors (when the detectors are operating at their design sensitivities) to find evidence
for the GW memory effect in a population of BBHs that is consistent with the measured population of
events in the first two observing runs of the LIGO detectors. We find that after five years of data
collected by the advanced LIGO and Virgo detectors the signal-to-noise ratio for the nonlinear
GW memory effect in the population will be about three (near a previously used threshold for detection).
We point out that the different approximation methods used to compute the GW memory effect can lead
to notably different signal-to-noise ratios. 