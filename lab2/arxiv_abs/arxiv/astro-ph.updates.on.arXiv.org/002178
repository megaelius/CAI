Both numerical hydrodynamic and semi-analytic cosmological models of galaxy formation struggle
to match observed star formation histories of galaxies in low-mass halos (M$_{\rm{H}} \lesssim
10^{11}$ \msun), predicting more star formation at high redshift and less star formation at low
redshift than observed. The fundamental problem is that galaxies' gas accretion and star formation
rates are too closely coupled in the models: the accretion rate largely drives the star formation
rate. Observations point to gas accretion rates that outpace star formation at high redshift, resulting
in a buildup of gas and a delay in star formation until lower redshifts. We present three empirical
adjustments of standard recipes in a semi-analytic model motivated by three physical scenarios
that could cause this decoupling: 1) the mass loading factors of outflows driven by stellar feedback
may have a steeper dependence on halo mass at earlier times, 2) the efficiency of star formation may
be lower in low mass halos at high redshift, and 3) gas may not be able to accrete efficiently onto the
disk in low mass halos at high redshift, delaying star formation. These new recipes, once tuned,
better reproduce the evolution of \fstar$\equiv M_\star/M _{\rm{H}}$ as a function of halo mass
as derived from abundance matching over redshifts $z=0$ to 3, though they have different effects
on cold gas fractions, star formation rates, and metallicities. Changes to gas accretion and stellar-driven
winds are promising, while direct modification of the star formation timescale requires drastic
measures that are not physically well-motivated. 