Spacecraft autonomy can be enhanced by vision-based navigation (VBN) techniques. Applications
range from manoeuvers around Solar System objects and landing on planetary surfaces, to in-orbit
servicing or space debris removal. The development and validation of VBN algorithms relies on the
availability of physically accurate relevant images. Yet archival data from past missions can
rarely serve this purpose and acquiring new data is often costly. The SurRender software is an image
simulator that addresses the challenges of realistic image rendering, with high representativeness
for space scenes. Images are rendered by raytracing, which implements the physical principles
of geometrical light propagation, in physical units. A macroscopic instrument model and scene
objects reflectance functions are used. SurRender is specially optimized for space scenes, with
huge distances between objects and scenes up to Solar System size. Raytracing conveniently tackles
some important effects for VBN algorithms: image quality, eclipses, secondary illumination,
subpixel limb imaging, etc. A simulation is easily setup (in MATLAB, Python, and more) by specifying
the position of the bodies (camera, Sun, planets, satellites) over time, 3D shapes and material
surface properties. SurRender comes with its own modelling tool enabling to go beyond existing
models for shapes, materials and sensors (projection, temporal sampling, electronics, etc.).
It is natively designed to simulate different kinds of sensors (visible, LIDAR, etc.). Tools are
available for manipulating huge datasets to store albedo maps and digital elevation models, or
for procedural (fractal) texturing that generates high-quality images for a large range of observing
distances (from millions of km to touchdown). We illustrate SurRender performances with a selection
of case studies, placing particular emphasis on a 900-km Moon flyby simulation. 