There are now hundreds of publicly available supernova spectral time series. Radiative transfer
modeling of this data gives insights into the physical properties of these explosions such as the
composition, the density structure, or the intrinsic luminosity---this is invaluable for understanding
the supernova progenitors, the explosion mechanism, or for constraining the supernova distance.
However, a detailed parameter study of the available data has been out of reach due to the high dimensionality
of the problem coupled with the still significant computational expense. We tackle this issue through
the use of machine-learning emulators, which are algorithms for high-dimensional interpolation.
These use a pre-calculated training dataset to mimic the output of a complex code but with run times
orders of magnitude shorter. We present the application of such an emulator to synthetic type II
supernova spectra generated with the TARDIS radiative transfer code. The results show that with
a relatively small training set of 780 spectra we can generate emulated spectra with interpolation
uncertainties of less than one percent. We demonstrate the utility of this method by automatic spectral
fitting of two well-known type IIP supernovae; as an exemplary application, we determine the supernova
distances from the spectral fits using the tailored-expanding-photosphere method. We compare
our results to previous studies and find good agreement. This suggests that emulation of TARDIS
spectra can likely be used to perform automatic and detailed analysis of many transient classes
putting the analysis of large data repositories within reach. 