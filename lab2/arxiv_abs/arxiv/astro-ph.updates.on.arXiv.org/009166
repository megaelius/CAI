One of the key questions in understanding the formation and evolution of galaxies is how starbursts
affect the assembly of stellar populations in galaxies over time. We define a burst indicator ($\eta$),
which compares a galaxy's star formation rates on short ($\sim10$ Myr) and long ($\sim100$ Myr)
timescales. To estimate $\eta$, we apply the detailed time-luminosity relationship for H$\alpha$
and near-ultraviolet emission to simulated star formation histories (SFHs) from semi-analytic
models and the Mufasa hydrodynamical cosmological simulations. The average of $\eta$ is not a good
indicator of star formation stochasticity (burstiness); indeed, we show that this average should
be close to zero unless the population has an average SFH which is rising or falling rapidly. Instead,
the width of the $\eta$ distribution characterizes the burstiness of a galaxy population's recent
star formation. We find this width to be robust to variations in stellar initial mass function and
metallicity. We apply realistic noise and selection effects to the models to generate mock HST and
JWST galaxy catalogs and compare these catalogs with 3D-HST observations of 956 galaxies at $0.65<z<1.5$
detected in H$\alpha$. Measurements of $\eta$ are unaffected by dust measurement errors under
the assumption that $E(B-V)_\mathrm{stars}=0.44\,E(B-V)_\mathrm{gas}$ (i.e., $Q_\mathrm{sg}=0.44$).
However, setting $Q_\mathrm{sg}=0.8^{+0.1}_{-0.2}$ removes an unexpected dependence of the
average value of $\eta$ upon dust attenuation and stellar mass in the 3D-HST sample while also resolving
disagreements in the distribution of star formation rates. However, even varying the dust law cannot
resolve all discrepancies between the simulated and the observed galaxies. 