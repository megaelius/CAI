In this paper we test the perturbative halo bias model at the field level. The advantage of this approach
is that any analysis can be done without sample variance if the same initial conditions are used in
simulations and perturbation theory calculations. We write the bias expansion in terms of modified
bias operators in Eulerian space, designed such that the large bulk flows are automatically resummed
and not treated perturbatively. Using these operators, the bias model accurately matches the Eulerian
density of halos in N-body simulations. The mean-square model error is close to the Poisson shot
noise for a wide range of halo masses and it is rather scale-independent, with scale-dependent corrections
becoming relevant at the nonlinear scale. In contrast, for linear bias the mean-square model error
can be higher than the Poisson prediction by factors of up to a few on large scales, and it becomes scale
dependent already in the linear regime. We show that by weighting simulated halos by their mass,
the mean-square error of the model can be further reduced by up to an order of magnitude, or by a factor
of two when including $60\%$ mass scatter. We also test the Standard Eulerian bias model using the
nonlinear matter field measured from simulations and show that it leads to a larger and more scale-dependent
model error than the bias expansion based on perturbation theory. These results may be of particular
relevance for cosmological inference methods that use a likelihood of the biased tracer at the field
level, or for initial condition and BAO reconstruction that requires a precise estimate of the large-scale
potential from the biased tracer density. 