We determine the cosmic expansion rate from supernovae of type Ia to set up a data-based distance
measure that does not make assumptions about the constituents of the universe, i.e. about a specific
parametrisation of a Friedmann cosmological model. The scale, determined by the Hubble constant
$H_0$, is the only free cosmological parameter left in the gravitational lensing formalism. We
investigate to which accuracy and precision the lensing distance ratio $D$ is determined from the
Pantheon sample. Inserting $D$ and its uncertainty into the lensing equations for given $H_0$,
esp. the time-delay equation between a pair of multiple images, allows to determine lens properties,
esp. differences in the lensing potential ($\Delta \phi$), without specifying a cosmological
model. We expand the luminosity distances into an analytic orthonormal basis, determine the maximum-likelihood
weights for the basis functions by a globally optimal $\chi^2$-parameter estimation, and derive
confidence bounds by Monte-Carlo simulations. For typical strong lensing configurations between
$z=0.5$ and $z=1.0$, $\Delta \phi$ can be determined with a relative imprecision of 1.7%, assuming
imprecisions of the time delay and the redshift of the lens on the order of 1%. With only a small, tolerable
loss in precision, the model-independent lens characterisation developed in this paper series
can be generalised by dropping the specific Friedmann model to determine $D$ in favour of a data-based
distance ratio. Moreover, for any astrophysical application, the approach presented here, provides
distance measures for $z\le2.3$ that are valid in any homogeneous, isotropic universe with general
relativity as theory of gravity. 