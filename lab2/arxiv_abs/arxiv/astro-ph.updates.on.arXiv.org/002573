(Abridged) Heating of the interstellar medium by multiple supernovae (SNe) explosions is at the
heart of producing galaxy-scale outflows. We use hydrodynamical simulations to study the efficiency
of multiple SNe in heating the interstellar medium (ISM) and filling the volume with gas of high temperatures.
We argue that it is important for SNe remnants to have a large filling factor {\it and} a large heating
efficiency. For this, they have to be clustered in space and time, and keep exploding until the hot
gas percolates through the whole region, in order to compensate for the radiative loss. In the case
of a limited number of SNe, we find that although the filling factor can be large, the heating efficiency
declines after reaching a large value. In the case of a continuous series of SNe, the hot gas ($T \ge
3 \times 10^6$ K) can percolate through the whole region after the total volume filling factor reaches
a threshold of $\sim 0.3$. The efficiency of heating the gas to X-ray temperatures can be $\ge 0.1$
after this percolation epoch, which occurs after a period of $\approx 10$ Myr for a typical starburst
SNe rate density of $\nu_{\rm SN} \approx 10^{-9}$ pc$^{-3}$ yr$^{-1}$ and gas density of $n\approx
10$ cm$^{-3}$ in starburst nuclei regions. This matches the recent observations of a time delay
of similar order between the onset of star formation and galactic outflows. The efficiency to heat
gas up to X-ray temperatures ($\ge 10^{6.5}$ K) roughly scales as $\nu_{\rm SN}^{0.2} n^{-0.6}$.
For a typical SNe rate density and gas density in starburst nuclei, the heating efficiency is $\sim
0.15$, also consistent with previous interpretations from X-ray observations. We discuss the
implications of our results with regard to observational diagnostics of ionic ratios and emission
measures in starburst nuclei regions. 