We study the spectral properties of the cosmic-ray spectrum in the interstellar medium within 1
kpc distance from the Sun. We used eight-year exposure data of molecular clouds of the Gould Belt
obtained with the Fermi/LAT telescope to precisely measure the cosmic-ray spectrum at different
locations in the local Galaxy. We compared this measurement with the direct measurements of the
cosmic-ray flux in and around the solar system obtained by Voyager and AMS-02 or PAMELA. We find that
the average cosmic-ray spectrum in the local Galaxy in the 1-100 GeV range is well described by a broken
power-law in rigidity with a low-energy slope of $2.33^{+0.06}_{-0.08}$ and a break at $18^{+7}_{-4}$
GV, with a slope change by $0.59\pm 0.11$. This result is consistent with an earlier analysis of the
gamma-ray signal from the Gould Belt clouds based on a shorter exposure of Fermi/LAT and with a different
event selection. The break at 10-20 GV is also consistent with the combined Voyager + AMS-02 measurements
in/around the solar system. The slope of the spectrum below the break agrees with the slope of the
average cosmic-ray spectrum in the inner part of the disk of the Milky Way that was previously derived
from the Fermi/LAT gamma-ray data. We conjecture that it is this slope of 2.33 and not the locally
measured softer slope of 2.7-2.8 that is determined by the balance between a steady-state injection
of cosmic rays with a power-law slope of 2-2.1 that is due to Fermi acceleration and the energy-dependent
propagation of cosmic-ray particles through the turbulent interstellar magnetic field with a
Kolmogorov turbulence spectrum. The approximation of a continuous-in-time injection of cosmic
rays at a constant rate breaks down, which causes the softening of the spectrum at higher energies.
