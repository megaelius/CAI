Because of vast volume of data being produced by today's scientific simulations and experiments,
lossy data compressor allowing user-controlled loss of accuracy during the compression is a relevant
solution for significantly reducing the data size. However, lossy compressor developers and users
are missing a tool to explore the features of scientific datasets and understand the data alteration
after compression in a systematic and reliable way. To address this gap, we have designed and implemented
a generic framework called Z-checker. On the one hand, Z-checker combines a battery of data analysis
components for data compression. On the other hand, Z-checker is implemented as an open-source
community tool to which users and developers can contribute and add new analysis components based
on their additional analysis demands. In this paper, we present a survey of existing lossy compressors.
Then we describe the design framework of Z-checker, in which we integrated evaluation metrics proposed
in prior work as well as other analysis tools. Specifically, for lossy compressor developers, Z-checker
can be used to characterize critical properties of any dataset to improve compression strategies.
For lossy compression users, Z-checker can detect the compression quality, provide various global
distortion analysis comparing the original data with the decompressed data and statistical analysis
of the compression error. Z-checker can perform the analysis with either coarse granularity or
fine granularity, such that the users and developers can select the best-fit, adaptive compressors
for different parts of the dataset. Z-checker features a visualization interface displaying all
analysis results in addition to some basic views of the datasets such as time series. To the best of
our knowledge, Z-checker is the first tool designed to assess lossy compression comprehensively
for scientific datasets. 