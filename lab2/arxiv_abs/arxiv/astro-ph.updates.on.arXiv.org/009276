Among stars in Galactic globular clusters the carbon abundance tends to decrease with increasing
luminosity on the upper red giant branch, particularly within the lowest metallicity clusters.
While such a phenomena is not predicted by canonical models of stellar interiors and evolution,
it is widely held to be the result of some extra mixing operating during red giant branch ascent which
transports material exposed to the CN(O)-cycle across the radiative zone in the stellar interior
and into the base of the convective envelope, whereupon it is brought rapidly to the stellar surface.
Here we present measurements of [C/Fe] abundances among 67 red giants in 19 globular clusters within
the Milky Way. Building on the work of Martell et al., we have concentrated on giants with absolute
magnitudes of $M_\mathrm{V} \sim -1.5$ within clusters encompassing a range of metallicity (-2.4
$<$ [Fe/H] $<$ -0.3). The Kitt Peak National Observatory (KPNO) 4 m and Southern Astrophysical Research
(SOAR) 4.1 m telescopes were used to obtain spectra covering the $\lambda$4300 CH and $\lambda$3883
CN bands. The CH absorption features in these spectra have been analyzed via synthetic spectra in
order to obtain [C/Fe] abundances. These abundances and the luminosities of the observed stars
were used to infer the rate at which C abundances change with time during upper red giant branch evolution
(i.e., the mixing efficiency). By establishing rates over a range of metallicity, the dependence
of deep mixing on metallicity is explored. We find that the inferred carbon depletion rate decreases
as a function of metallicity, although our results are dependent on the initial [C/Fe] composition
assumed for each star. 