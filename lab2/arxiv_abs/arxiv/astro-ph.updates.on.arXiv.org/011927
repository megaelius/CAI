The dissipation of turbulent magnetic fields is an appealing scenario to explain the origin of non-thermal
particles in high-energy astrophysical sources. However, it has been suggested that the particle
distribution may effectively thermalise when the radiative (synchrotron and/or Inverse Compton)
losses are severe. Inspired by recent PIC simulations of relativistic turbulence, which show that
electrons are impulsively heated in intermittent current sheets by a strong electric field aligned
with the local magnetic field, we instead argue that in plasmas where the particle number density
is dominated by the pairs (electron-positron and electron-positron-ion plasmas): (i) as an effect
of fast cooling and of different injection times, the electron energy distribution is ${\rm d}n_e/{\rm
d}\gamma\propto\gamma^{-2}$ for $\gamma\lesssim\gamma_{\rm heat}$ (the Lorentz factor $\gamma_{\rm
heat}$ being close to the equipartition value), while the distribution steepens at higher energies;
(ii) since the time scales for the turbulent fields to decay and for the photons to escape are of the
same order, the magnetic and the radiation energy densities in the dissipation region are comparable;
(iii) if the mass energy of the plasma is dominated by the ion component, the pairs with a Lorentz factor
smaller than a critical one (of the order of the proton-to-electron mass ratio) become isotropic,
while the pitch angle remains small otherwise. The outlined scenario is consistent with the typical
conditions required to reproduce the Spectral Energy Distribution of blazars, and allows one to
estimate the magnetisation of the emission site. Finally, we show that turbulence within the Crab
Nebula may power the observed gamma-ray flares if the pulsar wind is nearly charge-separated at
high latitudes. 