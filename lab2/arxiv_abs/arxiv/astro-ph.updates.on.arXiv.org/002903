We propose a simple analytic model to understand when star formation is time-steady versus bursty
in galaxies. Recent models explain the observed Kennicutt-Schmidt relation between star formation
rate and gas surface densities in galaxies as resulting from a balance between stellar feedback
and gravity. We argue that bursty star formation occurs when such an equilibrium cannot be stably
sustained, and identify two regimes in which galaxy-scale star formation should be bursty: i) at
high redshift (z>~1) for galaxies of all masses, and ii) at low masses (depending on gas fraction)
for galaxies at any redshift. At high redshift, characteristic galactic dynamical timescales
become too short for supernova feedback to effectively respond to gravitational collapse in galactic
discs (an effect recently identified for galactic nuclei), whereas in dwarf galaxies star formation
occurs in too few bright star-forming regions to effectively average out. Burstiness is also enhanced
at high redshift owing to elevated gas fractions in the early Universe. Our model can thus explain
the bursty star formation rates predicted in these regimes by recent high-resolution galaxy formation
simulations, as well as the bursty star formation histories observationally-inferred in both
local dwarf and high-redshift galaxies. In our model, bursty star formation is associated with
particularly strong spatio-temporal clustering of supernovae. Such clustering can promote the
formation of galactic winds and our model may thus also explain the much higher wind mass loading
factors inferred in high-redshift massive galaxies relative to their z~0 counterparts. 