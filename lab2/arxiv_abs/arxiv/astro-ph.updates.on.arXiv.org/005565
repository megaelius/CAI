The explosion of data in the recent years generated an increasing need of new analysis techniques
in order to extract knowledge from massive datasets. Machine learning proved particularly useful
to perform this task. Fully automatized methods have recently gathered great popularity, even
though those methods are often lacking physical interpretability. In contrast, feature based
approaches can provide both, well performing models as well as understandable causalities with
respect to the found correlations between features and physical processes. Efficient feature
selection is an essential tool to boost the performance of machine learning models. In this work,
we propose a forward selection method in order to compute, evaluate and characterize better performing
features for regression and classification problems. Given the importance of photometric redshift
estimation, we adopt it as use case. We synthetically created 4, 520 features, by combining magnitudes,
errors, radii and ellipticities of quasars, taken from the SDSS. We apply a forward selection process,
a recursive method in which a huge number of feature sets is tested via a kNN algorithm, leading to
a tree of feature sets. The branches of the feature tree are used to perform experiments with the random
forest, to validate the best set with an alternative model. We demonstrate that the sets of features
determined with our approach improve the performances of the regression models significantly
when compared to the performance of the classic features from the literature. The found features
are unexpected and surprising, being very different from the classic features. Therefore, a method
to interpret some of the found features in a physical context is presented. The feature selection
methodology described is very general and can be used to improve the performance of machine learning
models for any regression or classification task. 