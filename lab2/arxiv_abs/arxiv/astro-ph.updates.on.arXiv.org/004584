In this paper we examine to what extent the radio continuum can be used as an extinction free probe
of star formation in dwarf galaxies. To that aim we observe $40$ nearby dwarf galaxies with the Very
Large Array at 6 cm ($4$-$8$ GHz) in C-configuration. We obtained images with $3$-$8^{\prime\prime}$
resolution and noise levels of $3$-$15{\rm \,\mu Jy\,beam^{-1}}$. We detected emission associated
with $22$ of the $40$ dwarf galaxies, $8$ of which are new detections. The general picture is that
of an interstellar medium largely devoid of radio continuum emission, interspersed by isolated
pockets of emission associated with star formation. We find an average thermal fraction of $\sim
50$-$70$% and an average magnetic field strength of $\sim 5$-$8\,{\rm \mu G}$, only slightly lower
than that found in larger, spiral galaxies. At 100 pc scales, we find surprisingly high values for
the average magnetic field strength of up to 50$\,{\rm \mu G}$. We find that dwarf galaxies follow
the theoretical predictions of the radio continuum-star formation rate relation within regions
of significant radio continuum emission but that the non-thermal radio continuum is suppressed
relative to the star formation rate when considering the entire optical disk. We examine the far-infrared-star
formation rate relation for our sample and find that the far-infrared is suppressed compared to
the expected star formation rate. We discuss explanations for these observed relations and the
impact of our findings on the radio continuum-far-infrared relation. We conclude that radio continuum
emission at centimetre wavelengths has the promise of being a largely extinction-free star formation
rate indicator. We find that star formation rates of gas rich, low mass galaxies can be estimated
with an uncertainty of $\pm 0.2$ dex between the values of $2 \times 10^{-4}$ and $0.1 {\rm M_\odot\,yr^{-1}}$.
