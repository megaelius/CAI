The estimation and utilization of photometric redshift (photo-z) PDFs has become increasingly
important over the last few years. Primarily this is because of the prominent role photo-z PDFs play
in enabling photometric survey data to be used to make cosmological constraints, especially when
compared to single estimates. Currently there exist a wide variety of algorithms to compute photo-z's,
each with their own strengths and weaknesses. In this paper, we present a novel and efficient Bayesian
framework that combines the results from different photo-z techniques into a more powerful and
robust estimate by maximizing the information from the photometric data. To demonstrate this we
use a supervised machine learning technique based on prediction trees and a random forest, an unsupervised
method based on self organizing maps and a random atlas, and a standard template fitting method but
can be easily extend to other existing techniques. We use data from the DEEP2 survey and more than
$10^6$ galaxies from the SDSS to explore different methods for combining the photo-z predictions
from these techniques. In addition, we demonstrate that we can improve the accuracy of our final
photo-z estimate over the best input technique, that the fraction of outliers is reduced, and that
the identification of outliers is significantly improved when we apply a Na\"ive Bayes Classifier
to this combined information. Furthermore, we introduce a new approach to explore how different
techniques perform across the different areas within the information space supported by the photometric
data. Our more robust and accurate photo-z PDFs will allow even more precise cosmological constraints
to be made by using photometric surveys. These improvements are crucial as we move to analyze photometric
data that push to or even past the limits of the available training data, which will be the case with
the LSST. 