Compressing large data sets to a manageable number of summaries that are informative about the underlying
parameters vastly simplifies both frequentist and Bayesian inference. When only simulations
are available, these summaries are typically chosen heuristically, so they may inadvertently
miss important information. We introduce a simulation-based machine learning technique that
trains artificial neural networks to find non-linear functionals of data that maximise Fisher
information: information maximising neural networks (IMNNs). In test cases where the posterior
can be derived exactly, likelihood-free inference based on automatically derived IMNN summaries
produces nearly exact posteriors, showing that these summaries are good approximations to sufficient
statistics. In a series of numerical examples of increasing complexity and astrophysical relevance
we show that IMNNs are robustly capable of automatically finding optimal, non-linear summaries
of the data even in cases where linear compression fails: inferring the variance of Gaussian signal
in the presence of noise; inferring cosmological parameters from mock simulations of the Lyman-{\alpha}
forest in quasar spectra; and inferring frequency-domain parameters from LISA-like detections
of gravitational waveforms. In this final case, the IMNN summary outperforms linear data compression
by avoiding the introduction of spurious likelihood maxima. We anticipate that the automatic physical
inference method described in this paper will be essential to obtain both accurate and precise cosmological
parameter estimates from complex and large astronomical data sets, including those from LSST and
Euclid. 