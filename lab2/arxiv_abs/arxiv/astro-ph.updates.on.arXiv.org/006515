Compact object mergers can produce a thermal electromagnetic counterpart (a "kilonova") powered
by the decay of freshly synthesized radioactive isotopes. The luminosity of kilonova light curves
depends on the efficiency with which beta-decay electrons are thermalized in the ejecta. Here we
derive a simple analytic solution for thermalization by calculating how electrons accumulate
in the ejecta and lose energy adiabatically and via plasma losses. We find that the time-dependent
thermalization efficiency is well described by $f(t) \approx (1 + t/t_e)^{-n}$ where $n \approx
1$ and the timescale $t_e$ is a function of the ejecta mass and velocity. For a statistical distribution
of r-process isotopes with radioactive power $\dot{Q} \propto t^{-4/3}$, the late time kilonova
luminosity asymptotes to $L \propto t^{-7/3}$ and depends super-linearly on the ejecta mass, $L
\propto M^{5/3}$. If a kilonova is instead powered by a single dominate isotope, we show that the
late time luminosity can deviate substantially from the underlying exponential decay and eventually
become brighter than the instantaneous radioactivity due to the accumulation of trapped electrons.
Applied to the kilonova associated with the gravitational wave source GW170817, these results
imply that a possible steepening of the observed light curve at $\gtrsim 7$ days is unrelated to thermalization
effects and instead could mark the onset of translucency in a high opacity component of ejecta. The
analytic results should be convenient for estimating the properties of observed kilonovae and
assessing the potential late time detectability of future events. 