Detection of g-mode pulsations in subdwarf B (sdB) stars allows a rare test of how well stellar evolution
theory can predict the interior properties of stars. Asteroseismology suggests He-CO cores of
the order of $\sim 0.22-0.28\,M_\odot$, i.e.\ $\gtrsim$ 40\,\% of the total stellar mass. Using
mixing-length theory (MLT) without convective overshoot produces significantly smaller cores
($\sim 0.1 M_\odot$). We have used MESA (Modules for Experiments in Stellar Astrophysics) to explore
how well stellar observational data can be reproduced by standard algorithms. Using the same parameters
as previous investigators (not the MESA defaults), we show that our models can be made consistent
with earlier sdB models in terms of timescales, qualitative evolutionary paths and position in
the $\log g - T_{\rm{eff}}$ diagram. The sdB masses from our full stellar evolutionary sequences
fall within the range of the empirical mass distribution of sdB stars, but are nearly always lower
than the median. Also, the models are not completely consistent with observed atmospheric parameters.
To investigate the discrepancy in convective core masses, we varied the amount of overshoot within
standard formulations. Even with a very high value of $f_{\rm{ov}}= 0.08$, we could barely produce
He-CO core masses comparable to the lowest values suggested by the asteroseismological analyses.
The large amount of convective overshooting required would increase the sdB lifetime by a factor
of $2$ to $2.5$. These inconsistencies are most simply explained by a flaw in standard mixing algorithms
which diverts the {\it evolutionary} trajectories from the correct {\it structures}. 