Using a 1D Lagrangian code specifically designed to assess the impact of multiple, time-resolved
supernovae (SNe) from a single star cluster on the surrounding medium, we test three commonly used
feedback recipes: delayed cooling (e.g., used in the GASOLINE-2 code), momentum-energy injection
(a resolution-dependent transition between momentum-dominated feedback and energy-dominated
feedback used, e.g., in the FIRE-2 code), and simultaneous energy injection (e.g., used in the EAGLE
simulations). Our work provides an intermediary test for these recipes: we analyse a setting that
is more complex than the simplified scenarios for which many were designed, but one more controlled
than a full galactic simulation. In particular, we test how well these models reproduce the enhanced
momentum efficiency seen for an 11 SN cluster simulated at high resolution (0.6 pc; a factor of 12
enhancement relative to the isolated SN case) when these subgrid recipes are implemented in low
resolution (20 pc) runs. We find that: 1) the delayed cooling model performs well -- resulting in
9 times the momentum efficiency of the fiducial isolated SN value -- when SNe are clustered and $10^{51}$
erg are injected per SN, while clearly over-predicting the momentum efficiency in the single SN
test case; 2) the momentum-energy model always achieves good results, with a factor of 5 boost in
momentum efficiency; and 3) injecting the energy from all SNe simultaneously does little to prevent
over-cooling and greatly under-produces the momentum deposited by clustered SNe, resulting in
a factor of 3 decrease in momentum efficiency on the average. 