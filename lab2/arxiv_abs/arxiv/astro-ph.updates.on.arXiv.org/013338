Improving distance measurements in large imaging surveys is a major challenge to better reveal
the distribution of galaxies on a large scale and to link galaxy properties with their environments.
Photometric redshifts can be efficiently combined with the cosmic web (CW) extracted from overlapping
spectroscopic surveys to improve their accuracy. We apply a similar method using a new generation
of photometric redshifts based on a convolution neural network (CNN). The CNN is trained on the SDSS
images with the main galaxy sample (SDSS-MGS, $r \leq 17.8$) and the GAMA spectroscopic redshifts
up tor $\sim 19.8$. The mapping of the CW is obtained with 680,000 spectroscopic redshifts from the
MGS and BOSS surveys. The redshift probability distribution functions (PDF), which are well calibrated
(unbiased and narrow, $\leq 120$ Mpc), intercept a few CW structure along the line of sight. Combining
these PDFs with the density field distribution provides new photometric redshifts, $z_{web}$,
whose accuracy is improved by a factor of two (i.e.,${\sigma} \sim 0.004(1+z)$) for galaxies with
$r \leq 17.8$. For half of them, the distance accuracy is better than 10 cMpc. The narrower the original
PDF, the larger the boost in accuracy. No gain is observed for original PDFs wider than 0.03. The final
$z_{web}$ PDFs also appear well calibrated. The method performs slightly better for passive galaxies
than star-forming ones, and for galaxies in massive groups since these populations better trace
the underlying large-scale structure. Reducing the spectroscopic sampling by a factor of 8 still
improves the photometric redshift accuracy by 25%. Extending the method to galaxies fainter than
the MGS limit still improves the redshift estimates for 70% of the galaxies, with a gain in accuracy
of 20% at low $z$ where the resolution of the CW is the highest. 