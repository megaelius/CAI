The empirical upper luminosity boundary $L_{\rm max}$ of cool supergiants, often referred to as
the Humphreys-Davidson limit, is thought to encode information on the general mass-loss behaviour
of massive stars. Further, it delineates the boundary at which single stars will end their lives
stripped of their hydrogen-rich envelope, which in turn is a key factor in the relative rates of Type-II
to Type-Ibc supernovae from single star channels. In this paper we have revisited the issue of $L_{\rm
max}$ by studying the luminosity distributions of cool supergiants (SGs) in the Large and Small
Magellanic Clouds (LMC/SMC). We assemble samples of cool SGs in each galaxy which are highly-complete
above $\log L/L_{\odot}$=5.0, and determine their spectral energy distributions from the optical
to the mid-infrared using modern multi-wavelength survey data. We show that in both cases $L_{\rm
max}$ appears to be lower than previously quoted, and is in the region of $\log L/L_{\odot}$=5.5.
There is no evidence for $L_{\rm max}$ being higher in the SMC than in the LMC, as would be expected
if metallicity-dependent winds were the dominant factor in the stripping of stellar envelopes.
We also show that $L_{\rm max}$ aligns with the lowest luminosity of single nitrogen-rich Wolf-Rayet
stars, indicating of a change in evolutionary sequence for stars above a critical mass. From population
synthesis analysis we show that the Geneva evolutionary models greatly over-predict the numbers
of cool SGs in the SMC. We also argue that the trend of earlier average spectral types of cool SGs in
lower metallicity environments represents a genuine shift to hotter temperatures. Finally, we
use our new bolometric luminosity measurements to provide updated bolometric corrections for
cool supergiants. 