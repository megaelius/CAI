The material expelled by core-collapse supernova (SN) explosions absorbs X-rays from the central
regions. We use SN models based on three-dimensional neutrino-driven explosions to estimate optical
depths to the center of the explosion, compare different progenitor models, and investigate the
effects of explosion asymmetries. The optical depths below 2 keV for progenitors with a remaining
hydrogen envelope are expected to be high during the first century after the explosion due to photoabsorption.
A typical optical depth is $100 t_4^{-2} E^{-2}$, where $t_4$ is the time since the explosion in units
of 10 000 days (${\sim}$27 years) and $E$ the energy in units of keV. Compton scattering dominates
above 50 keV, but the scattering depth is lower and reaches unity already at ${\sim}$1000 days at
1 MeV. The optical depths are approximately an order of magnitude lower for hydrogen-stripped progenitors.
The metallicity of the SN ejecta is much higher than in the interstellar medium, which enhances photoabsorption
and makes absorption edges stronger. These results are applicable to young SN remnants in general,
but we explore the effects on observations of SN 1987A and the compact object in Cas A in detail. For
SN 1987A, the absorption is high and the X-ray upper limits of ${\sim}$100 Lsun on a compact object
are approximately an order of magnitude less constraining than previous estimates using other
absorption models. The details are presented in an accompanying paper. For the central compact
object in Cas A, we find no significant effects of our more detailed absorption model on the inferred
surface temperature. 