We construct the average radio spectral energy distribution (SED) of highly star-forming galaxies
(HSFGs) up to z~4. Infrared and radio luminosities are bound by a tight correlation that is defined
by the so-called q parameter. This infrared-radio correlation provides the basis for the use of
radio luminosity as a star-formation tracer. Recent stacking and survival analysis studies find
q to be decreasing with increasing redshift. It was pointed out that a possible cause of the redshift
trend could be the computation of rest-frame radio luminosity via a single power-law assumption
of the star-forming galaxies' (SFGs) SED.To test this, we constrained the shape of the radio SED
of a sample of HSFGs. To achieve a broad rest-frame frequency range, we combined previously published
VLA observations of the COSMOS field at 1.4 GHz and 3 GHz with unpublished GMRT observations at 325
MHz and 610 MHz by employing survival analysis to account for non-detections in the GMRT maps. We
selected a sample of HSFGs in a broad redshift range (0.3<z<4,SFR>100M0/yr) and constructed the
average radio SED. By fitting a broken power-law, we find that the spectral index changes from $\alpha_1=0.42\pm0.06$
below a rest-frame frequency of 4.3 GHz to $\alpha_2=0.94\pm0.06$ above 4.3 GHz. Our results are
in line with previous low-redshift studies of HSFGs (SFR>10M0/yr) that show the SED of HSFGs to differ
from the SED found for normal SFGs (SFR<10M0/yr). The difference is mainly in a steeper spectrum
around 10 GHz, which could indicate a smaller fraction of thermal free-free emission. Finally,
we also discuss the impact of applying this broken power-law SED in place of a simple power-law in
K-corrections of HSFGs and a typical radio SED for normal SFGs drawn from the literature. We find
that the shape of the radio SED is unlikely to be the root cause of the q-z trend in SFGs. 