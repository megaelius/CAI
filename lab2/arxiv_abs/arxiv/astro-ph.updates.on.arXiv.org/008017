Determining the cosmic expansion history from a sample of supernovae of type Ia, data-based cosmic
distance measures can be set up that make no assumptions about the constituents of the universe,
i.e. about a specific cosmological model. The overall scale, usually determined by the Hubble constant
$H_0$, is the only free parameter left. We investigate to which accuracy and precision the lensing
distance ratio D of our distance to the lens, to the source, and their relative distance can be determined
from the most recent Pantheon sample. Subsequently inserting D and its uncertainty into the gravitational
lensing equations for given $H_0$, esp. the time-delay equation between a pair of multiple images,
allows to determine lens properties, esp. differences in the lensing potential (\Delta \Phi),
without specifying a cosmological model. Alternatively, given \Delta \Phi$\,$ between multiple
images, e.g. by a lens model, $H_0$ can be determined. For typical strong gravitational lensing
configurations between z=0.5 and z=1.0, we find that \Delta \Phi$\,$ can be determined with a relative
imprecision of 1.7%, assuming imprecisions of the time delay and the redshift of the lens on the order
of 1%. Using a $\Lambda$CDM model, the relative imprecision of \Delta \Phi$\,$ is 1.4%. Minimum
relative imprecisions for $H_0$ amount to 20% and 10% for galaxy- and galaxy-cluster-scale lenses
when including measurements of velocity dispersions in a single-lens-plane model. With only a
small, tolerable loss in precision, the model-independent lens characterisation developed in
this paper series can be generalised by dropping the specific Friedmann model to determine D in favour
of a data-based distance ratio. For any astrophysical application, the approach presented here,
provides distance measures up to z=2.3 that are valid in any homogeneous, isotropic universe with
general relativity as theory of gravity. 