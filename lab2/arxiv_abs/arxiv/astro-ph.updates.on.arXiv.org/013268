Despite the utility of neural networks (NNs) for astronomical time-series classification, the
proliferation of learning architectures applied to diverse datasets has thus far hampered a direct
intercomparison of different approaches. Here we perform the first comprehensive study of variants
of NN-based learning and inference for astronomical time-series, aiming to provide the community
with an overview on relative performance and, hopefully, a set of best-in-class choices for practical
implementations. In both supervised and self-supervised contexts, we study the effects of different
time-series-compatible layer choices, namely the dilated temporal convolutional neural network
(dTCNs), Long-Short Term Memory (LSTM) NNs, Gated Recurrent Units (GRUs) and temporal convolutional
NNs (tCNNs). We also study the efficacy and performance of encoder-decoder (i.e., autoencoder)
networks compared to direct classification networks, different pathways to include auxiliary
(non-time-series) metadata, and different approaches to incorporate multi-passband data (i.e.,
multiple time-series per source). Performance---applied to a sample of 17,604 variable stars
from the MACHO survey across 10 imbalanced classes---is measured in training convergence time,
classification accuracy, reconstruction error, and generated latent variables. We find that
networks with Recurrent NN (RNNs) generally outperform dTCNs and, in many scenarios, yield to similar
accuracy as tCNNs. In learning time and memory requirements, convolution-based layers are more
performant. We conclude by discussing the advantages and limitations of deep architectures for
variable star classification, with a particular eye towards next-generation surveys such as LSST,
WFIRST and ZTF2. 