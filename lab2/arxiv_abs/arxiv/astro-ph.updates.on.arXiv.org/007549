We recently presented a new statistical method to constrain the physics of star formation and feedback
on the cloud scale. Fundamentally, this new method is only able to recover the relative durations
of different evolutionary phases. It therefore requires a "reference time-scale" to convert the
relative time-scales into absolute values. The phase over which the star formation rate (SFR) tracer
is visible is the logical choice to assign this reference time-scale to, since it can be characterised
using stellar population synthesis models. In this paper, we use hydrodynamical disc galaxy simulations
to produce synthetic emission maps of several SFR tracers and apply our statistical method to measure
the associated characteristic time-scale of each tracer. These cover 12 ultraviolet (UV) filters
(from GALEX, Swift, and HST) covering a wavelength range 150-350 nm, as well as H$\alpha$. For solar-metallicity
environments, we find the characteristic time-scales for H$\alpha$ with (without) continuum
subtraction to be ~4.3 (6-16) Myr and for the UV filters to be in the range 17-33 Myr, monotonically
increasing with wavelength. We find that the characteristic time-scale decreases towards higher
metallicities, as well as to lower star formation rate surface densities, if the stellar initial
mass function is not well-sampled. We provide fitting functions to the resulting reference time-scales
to facilitate observational applications of our statistical method across a wide range of galactic
environments. More generally, our results predict the time-scales over which photoionisation
and UV heating take place around star-forming regions. 