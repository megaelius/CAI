The design of methods for inference from time sequences has traditionally relied on statistical
models that describe the relation between a latent desired sequence and the observed one. A broad
family of model-based algorithms have been derived to carry out inference at controllable complexity
using recursive computations over the factor graph representing the underlying distribution.
An alternative model-agnostic approach utilizes machine learning (ML) methods. Here we propose
a framework that combines model-based inference algorithms and data-driven ML tools for stationary
time sequences. In the proposed approach, neural networks are developed to separately learn specific
components of a factor graph describing the distribution of the time sequence, rather than the complete
inference task. By exploiting stationary properties of this distribution, the resulting approach
can be applied to sequences of varying temporal duration. Additionally, this approach facilitates
the use of compact neural networks which can be trained with small training sets, or alternatively,
can be used to improve upon existing deep inference systems. We present an inference algorithm based
on learned stationary factor graphs, referred to as StaSPNet, which learns to implement the sum
product scheme from labeled data, and can be applied to sequences of different lengths. Our experimental
results demonstrate the ability of the proposed StaSPNet to learn to carry out accurate inference
from small training sets for sleep stage detection using the Sleep-EDF dataset, as well as for symbol
detection in digital communications with unknown channels. 