A group of transition probability functions form a Shannon's channel whereas a group of truth functions
form a semantic channel. Label learning is to let semantic channels match Shannon's channels and
label selection is to let Shannon's channels match semantic channels. The Channel Matching (CM)
algorithm is provided for multi-label classification. This algorithm adheres to maximum semantic
information criterion which is compatible with maximum likelihood criterion and regularized
least squares criterion. If samples are very large, we can directly convert Shannon's channels
into semantic channels by the third kind of Bayes' theorem; otherwise, we can train truth functions
with parameters by sampling distributions. A label may be a Boolean function of some atomic labels.
For simplifying learning, we may only obtain the truth functions of some atomic label. For a given
label, instances are divided into three kinds (positive, negative, and unclear) instead of two
kinds as in popular studies so that the problem with binary relevance is avoided. For each instance,
the classifier selects a compound label with most semantic information or richest connotation.
As a predictive model, the semantic channel does not change with the prior probability distribution
(source) of instances. It still works when the source is changed. The classifier changes with the
source, and hence can overcome class-imbalance problem. It is shown that the old population's increasing
will change the classifier for label "Old" and has been impelling the semantic evolution of "Old".
The CM iteration algorithm for unseen instance classification is introduced. 