Sequential Monte Carlo (SMC) methods, also known as particle filters, are simulation-based recursive
algorithms for the approximation of the a posteriori probability measures generated by state-space
dynamical models. At any given (discrete) time t, a particle filter produces a set of samples over
the state space of the system of interest. These samples are referred to as "particles" and can be
used to build a discrete approximation of the a posteriori probability distribution of the state,
conditional on a sequence of available observations. When new observations are collected, a recursive
stochastic procedure allows to update the set of particles to obtain an approximation of the new
posterior. In this paper, we address the problem of constructing kernel-based estimates of the
filtering probability density function. Kernel methods are the most widely employed techniques
for nonparametric density estimation using i.i.d. samples and it seems natural to investigate
their performance when applied to the approximate samples produced by particle filters. Here,
we show how to obtain asymptotic convergence results for the particle-kernel approximations of
the filtering density and its derivatives. In particular, we find convergence rates for the approximation
error that hold uniformly on the state space and guarantee that the error vanishes almost surely
(a.s.) as the number of particles in the filter grows. Based on this uniform convergence result,
we first show how to build continuous measures that converge a.s. (with known rate) toward the filtering
measure and then address a few applications. The latter include maximum a posteriori estimation
of the system state using the approximate derivatives of the posterior density and the approximation
of functionals of it, e.g., Shannon's entropy. 