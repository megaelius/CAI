We derive an efficient stochastic algorithm for computational inverse problems that present an
unknown linear forcing term and a set of nonlinear parameters to be recovered. It is assumed that
the data is noisy and that the linear part of the problem is ill-posed. The vector of nonlinear parameters
to be recovered is modeled as a random variable. This random vector is augmented by a random regularization
parameter for the linear part. A probability distribution function for this augmented random vector
knowing the measurements is derived. We explain how this derivation is related to the maximum likelihood
regularization parameter selection [Galatsanos and Katsaggelos, 1992], which we generalize
to the case where the underlying linear operator is rectangular and depends on a nonlinear parameter.
A major difference in our approach is that, unlike in [Galatsanos and Katsaggelos, 1992], we do not
limit ourselves to the most likely regularization parameter, instead we show that due to the dependence
of the problem on the nonlinear parameter, there is a great advantage in exploring all positive values
of the regularization parameter. Based on our new probability distribution function, we construct
a choice sampling algorithm to compute the posterior expected value and covariance of the nonlinear
parameter. This algorithm is greatly accelerated by using a parallel platform where we alternate
computing proposals in parallel and combining proposals to accept or reject them as in [Calderhead,
2014]. Finally, our new algorithm is illustrated by solving an inverse problem in seismology. We
show how our algorithm performs in that example and how it is able to compute marginal posterior probability
functions even in the presence of strong noise. We discuss why this problem can not be approached
by using the Generalized Cross Validation method or the discrepancy principle. 