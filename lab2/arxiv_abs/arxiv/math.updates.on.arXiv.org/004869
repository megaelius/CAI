The use of coordinate processes for the modelling of impulse control for {\em general}\ Markov processes
typically involves the construction of a probability measure on a countable product of copies of
the path space. In addition, admissibility of an impulse control policy requires that the random
times of the interventions be stopping times with respect to different filtrations arising from
the different component coordinate processes. When the underlying strong Markov process has {\em
continuous}\ paths, however, a simpler model can be developed which takes the single path space
as its probability space and uses the natural filtration with respect to which the intervention
times must be stopping times. Moreover, this model construction allows for uncertain impulse control
whereby the decision maker selects an impulse but the intervention may result in a different impulse
occurring. This paper gives the construction of the probability measure on the path space for an
admissible intervention policy subject to an uncertain impulse mechanism. An added feature is
that when the intervention policy results in deterministic distributions for each impulse, the
paths between interventions are independent and, moreover, if the same distribution is used for
each impulse, then the cycles following the initial cycle are identically distributed. This paper
also identifies a class of impulse policies under which the resulting controlled process is Markov.
The decision to use an $(s,S)$ ordering policy in inventory management provides an example of an
impulse policy for which the process is Markov and has i.i.d.~cycles so a benefit of the constructed
model is that one is allowed to use classical renewal arguments. 