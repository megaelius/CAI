We propose a new polynomial-time algorithm for linear programming. We further extend the ideas
used in this new linear programming algorithm for nonlinear programming problems. The new algorithm
is based on the idea of treating the objective function as a parameter. We form a matrix of coefficients,
made-up of the coefficients of the variables defined in the problem itself, and the coefficients
of variables defined newly, for converting inequalities into equations, namely, slack variables
if it is the maximization problem, or, surplus variables if it is the minimization problem. The system
of equations we use consist of the objective equation and equations obtained from inequalities
defining constraint imposed by the problem. We obtain reduced-row-echelon-form, R, for this matrix
containing only one unknown, namely, the objective function itself as an unknown parameter, d,
say. This matrix in the reduced-row-echelon-form contains columns (column vectors) corresponding
to basic variables and non-basic variables. If all the entries in the columns corresponding to non-basic
variables in R are already nonnegative then we will see that we have almost reached to the solution
and nothing much is left to be done. If there are columns corresponding to non-basic variables which
contain some negative entries then we will require to apply suitable row transformations, at most
$m$ in number if there are m rows in R, as we will see below, to make all the entries in the columns corresponding
to non-basic variables nonnegative. We then proceed to show that the method developed above for
linear programming naturally extends to nonlinear programming problems. For nonlinear programming
problems, we use the technique of Grobner bases, since Grobner basis is an equivalent of reduced
row echelon form for a system of nonlinear equations. 