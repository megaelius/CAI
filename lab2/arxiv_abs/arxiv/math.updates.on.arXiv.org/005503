We propose a new paradigm for robust geometric computations that complements the classical fixed
precision paradigm and the exact geometric computation paradigm. We provide a framework where
we study algorithmic problems under smoothed analysis of the input, the relaxation of the problem
requirements, or the witness of a recognition problem. Our framework specifies a widely applicable
set of prerequisites that make real RAM algorithms suitable for smoothed analysis. We prove that
suitable algorithms can (under smoothed analysis) be robustly executed with expected logarithmic
bit-precision. This shows in a formal way that inputs which need high bit-precision are contrived
and that these algorithms are likely robust for realistic input. Interestingly our techniques
generalize to problems with a natural notion of resource augmentation (geometric packing, the
art gallery problem) and recognition problems (recognition of realizable order types or disk intersection
graphs). Our results also have theoretical implications for some ER-hard problems: These problems
have input instances where their real verification algorithm requires at least exponential bit-precision
which makes it difficult to place these ER-hard problems in NP. Our results imply for a host of ER-complete
problems that this exponential bit-precision phenomenon comes from nearly degenerate instances.
It is not evident that problems that have a real verification algorithm belong to ER. Therefore,
we conclude with a real RAM analogue to the Cook-Levin Theorem. This gives an easy proof of ER-membership,
as real verification algorithms are much more versatile than ETR-formulas. 