In many statistical linear inverse problems, one needs to recover classes of similar curves from
their noisy images under an operator that does not have a bounded inverse. Problems of this kind appear
in many areas of application. Routinely, in such problems clustering is carried out at the pre-processing
step and then the inverse problem is solved for each of the cluster averages separately. As a result,
the errors of the procedures are usually examined for the estimation step only. The objective of
this paper is to examine, both theoretically and via simulations, the effect of clustering on the
accuracy of the solutions of general ill-posed linear inverse problems. In particular, we assume
that one observes $X_m = A f_m + \sigma n^{-1/2} \epsilon_m$, $m=1, \cdots, M$, where functions $f_m$
can be grouped into $K$ classes and one needs to recover a vector function ${\bf f}= (f_1,\cdots,
f_M)^T$. We construct an estimators for ${\bf f}$ as a solution of a penalized optimization problem
and derive an oracle inequality for its precision. By deriving upper and minimax lower bounds for
the error, we confirm that the estimator is minimax optimal or nearly minimax optimal up to a logarithmic
factor of the number of observations. One of the advantages of our estimation procedure is that we
do not assume that the number of clusters is known in advance. We conclude that clustering does not
have an adverse effect on the estimation precision as long as class sizes and the number of observations
are large enough. However, significant improvement in accuracy occurs only if the problem is not
severely ill-posed. 