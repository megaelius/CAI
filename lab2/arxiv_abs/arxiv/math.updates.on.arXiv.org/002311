A spectral approach to building the exterior calculus in manifold learning problems is developed.
The spectral approach is shown to converge to the true exterior calculus in the limit of large data.
Simultaneously, the spectral approach decouples the memory requirements from the amount of data
points and ambient space dimension. To achieve this, the exterior calculus is reformulated entirely
in terms of the eigenvalues and eigenfunctions of the Laplacian operator on functions. The exterior
derivatives of these eigenfunctions (and their wedge products) are shown to form a frame (a type
of spanning set) for appropriate L^2 spaces of k-forms, as well as higher-order Sobolev spaces.
Formulas are derived to express the Laplace-de Rham operators on forms in terms of the eigenfunctions
and eigenvalues of the Laplacian on functions. By representing the Laplace-de Rham operators in
this frame, spectral convergence results are obtained via Galerkin approximation techniques.
Numerical examples demonstrate accurate recovery of eigenvalues and eigenforms of the Laplace-de
Rham operator on 1-forms. The correct Betti numbers are obtained from the kernel of this operator
approximated from data sampled on several orientable and non-orientable manifolds, and the eigenforms
are visualized via their corresponding vector fields. These vector fields form a natural orthonormal
basis for the space of square integrable vector fields, and are ordered by a Dirichlet energy functional
which measures oscillatory behavior. The spectral framework also shows promising results on a
non-smooth example (the Lorenz 63 attractor), suggesting that a spectral formulation of exterior
calculus may be feasible in spaces with no differentiable structure. 