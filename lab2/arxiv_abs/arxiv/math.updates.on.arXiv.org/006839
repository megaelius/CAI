Our work is motivated by a desire to study the theoretical underpinning for the convergence of stochastic
gradient type algorithms widely used for non-convex learning tasks such as training of neural networks.
The key insight is that a certain class of the finite-dimensional non-convex problems becomes convex
when lifted to infinite-dimensional space of measures. We leverage this observation and show that
the corresponding energy functional defined on the space of probability measures has a unique minimiser
which can be characterised by a first-order condition using the notion of linear functional derivative.
Next, we study the corresponding gradient flow structure in 2-Wasserstein metric, which we call
Mean-Field Langevin Dynamics (MFLD), and show that the flow of marginal laws induced by the gradient
flow converges to a stationary distribution, which is exactly the minimiser of the energy functional.
We observe that this convergence is exponential under conditions that are satisfied for highly
regularised learning tasks. Our proof of convergence to stationary probability measure is novel
and it relies on a generalisation of LaSalle's invariance principle combined with HWI inequality.
Importantly, we assume neither that interaction potential of MFLD is of convolution type nor that
it has any particular symmetric structure. Furthermore, we allow for the general convex objective
function, unlike, most papers in the literature that focus on quadratic loss. Finally, we show that
the error between finite-dimensional optimisation problem and its infinite-dimensional limit
is of order one over the number of parameters. 