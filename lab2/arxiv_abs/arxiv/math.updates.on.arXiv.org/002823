An important problem arising in the study of complex networks, for instance in community detection
and motif finding, is the sampling of graphs with fixed degree sequence. The equivalent problem
of generating random 0,1 matrices with fixed row and column sums is frequently used as a quantitative
tool in ecology. It has however proven very challenging to design sampling algorithms that are both
fast and unbiased. This article focusses on Markov chain approaches for sampling, where a close-to-random
graph is produced by applying a large number N of small changes to a given graph. Examples are the switch
chain and Curveball chain, which are both commonly used by practitioners as they are easy to implement
and known to sample unbiased when N is large enough. Within theoretical research, much effort has
gone into proving bounds on N. However, existing theoretical bounds are impractically large for
most applications while experiments suggest that much fewer steps are needed to obtain a good sample.
The contribution of this article is twofold. Firstly it is a step towards better understanding of
the discrepancy between experimental observations and theoretically proven bounds. In particular,
we argue that while existing Markov chain algorithms run on the set of all labelled graphs with a given
degree sequence, node labels are unimportant in practice and are usually ignored in determining
experimental bounds. We prove that ignoring node labels corresponds to projecting a Markov chain
onto equivalence classes of isomorphic graphs and that the resulting projected Markov chain converges
to its stationary distribution at least as fast as the original Markov chain. Often convergence
is much faster, as we show in examples, explaining part of the difference between theory and experiments...
