The goal of this thesis is to provide efficient and provably convergent numerical methods for solving
partial differential equations (PDEs) coming from impulse control problems motivated by finance.
Impulses, which are controlled jumps in a stochastic process, are used to model realistic features
in financial problems which cannot be captured by ordinary stochastic controls. The dynamic programming
equations associated with impulse control problems are Hamilton-Jacobi-Bellman quasi-variational
inequalities (HJBQVIs) Other than in certain special cases, the numerical schemes that come from
the discretization of HJBQVIs take the form of complicated nonlinear matrix equations also known
as Bellman problems. We prove that a policy iteration algorithm can be used to compute their solutions.
In order to do so, we employ the theory of weakly chained diagonally dominant (w.c.d.d.) matrices.
As a byproduct of our analysis, we obtain some new results regarding a particular family of Markov
decision processes which can be thought of as impulse control problems on a discrete state space
and the relationship between w.c.d.d. matrices and M-matrices. Since HJBQVIs are nonlocal PDEs,
we are unable to directly use the seminal result of Barles and Souganidis (concerning the convergence
of monotone, stable, and consistent numerical schemes to the viscosity solution) to prove the convergence
of our schemes. We address this issue by extending the work of Barles and Souganidis to nonlocal PDEs
in a manner general enough to apply to HJBQVIs. We apply our schemes to compute the solutions of various
classical problems from finance concerning optimal control of the exchange rate, optimal consumption
with fixed and proportional transaction costs, and guaranteed minimum withdrawal benefits in
variable annuities. 