Motivated by big data applications, we consider stochastic mirror descent (SMD) methods for solving
stochastic optimization problems with strongly convex objective functions. Much of the interest
in the literature of SMD methods has focused on convergence and rate analysis in terms of magnitude
of the error bounds. Yet, the finite-time performance of this class of methods is tied closely to
the choice of the stepsize sequence. As such, our goal is to develop SMD schemes that achieve an optimal
rate of convergence with a minimum constant factor with respect to the choice of the stepsize sequence.
To this end, we consider three variants of SMD methods namely (a) subgradient SMD methods addressing
nonsmooth problems, (b) gradient SMD methods addressing smooth problems, and (c) randomized block
coordinate SMD methods addressing high-dimensional problems. For each scheme, we develop self-tuned
stepsize rules that are characterized in terms of problem parameters and algorithm settings. Our
main contributions are as follows: (i) using self-tuned stepsize rules, we show that the non-averaging
iterate generated by the underlying SMD method converges to the optimal solution both in an almost
sure and a mean sense; (ii) for each scheme, we derive error bounds and show that using the corresponding
self-tuned stepsizes, such an error bound is minimized; (iii) in the case where problem parameters
are unknown, we develop a unifying self-tuned update rule that can be applied in both smooth and nonsmooth
settings. We show that for any arbitrary and small enough initial stepsize, a suitably defined error
bound is minimized; (iv) We provide constant factor comparisons with standard SMD methods. 