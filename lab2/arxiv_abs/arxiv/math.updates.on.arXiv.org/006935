By exploiting the computing power and local data of distributed clients, federated learning (FL)
features ubiquitous properties such as reduction of communication overhead and preserving data
privacy. In each communication round of FL, the clients update local models based on their own data
and upload their local updates via wireless channels. However, latency caused by hundreds to thousands
of communication rounds remains a bottleneck in FL. To minimize the training latency, this work
provides a multi-armed bandit-based framework for online client scheduling (CS) in FL without
knowing wireless channel state information and statistical characteristics of clients. Firstly,
we propose a CS algorithm based on the upper confidence bound policy (CS-UCB) for ideal scenarios
where local datasets of clients are independent and identically distributed (i.i.d.) and balanced.
An upper bound of the expected performance regret of the proposed CS-UCB algorithm is provided,
which indicates that the regret grows logarithmically over communication rounds. Then, to address
non-ideal scenarios with non-i.i.d. and unbalanced properties of local datasets and varying availability
of clients, we further propose a CS algorithm based on the UCB policy and virtual queue technique
(CS-UCB-Q). An upper bound is also derived, which shows that the expected performance regret of
the proposed CS-UCB-Q algorithm can have a sub-linear growth over communication rounds under certain
conditions. Besides, the convergence performance of FL training is also analyzed. Finally, simulation
results validate the efficiency of the proposed algorithms. 