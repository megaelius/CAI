In this paper, we consider solving a class of convex optimization problem which minimizes the sum
of three convex functions $f(x)+g(x)+h(Bx)$, where $f(x)$ is differentiable with a Lipschitz
continuous gradient, $g(x)$ and $h(x)$ have a closed-form expression of their proximity operators
and $B$ is a bounded linear operator. This type of optimization problem has wide application in signal
recovery and image processing. To make full use of the differentiability function in the optimization
problem, we take advantage of two operator splitting methods: the forward-backward splitting
method and the three operator splitting method. In the iteration scheme derived from the two operator
splitting methods, we need to compute the proximity operator of $g+h \circ B$ and $h \circ B$, respectively.
Although these proximity operators do not have a closed-form solution in general, they can be solved
very efficiently. We mainly employ two different approaches to solve these proximity operators:
one is dual and the other is primal-dual. Following this way, we fortunately find that three existing
iterative algorithms including Condat and Vu algorithm, primal-dual fixed point (PDFP) algorithm
and primal-dual three operator (PD3O) algorithm are a special case of our proposed iterative algorithms.
Moreover, we discover a new kind of iterative algorithm to solve the considered optimization problem,
which is not covered by the existing ones. Under mild conditions, we prove the convergence of the
proposed iterative algorithms. Numerical experiments applied on fused Lasso problem, constrained
total variation regularization in computed tomography (CT) image reconstruction and low-rank
total variation image super-resolution problem demonstrate the effectiveness and efficiency
of the proposed iterative algorithms. 