A well-know drawback of l1-penalized estimators is the systematic shrinkage of the large coefficients
towards zero. A simple remedy is to treat Lasso as a model-selection procedure and to perform a second
refitting step on the selected support. In this work we formalize the notion of refitting and provide
oracle bounds for arbitrary refitting procedures of the Lasso solution. One of the most widely used
refitting techniques which is based on least-squares may bring a problem of interpretability,
since the signs of the refitted estimator might be flipped with respect to the original estimator.
This problem arises from the fact that the least-square refitting considers only the support of
the Lasso solution, avoiding any information about signs or amplitudes. To this end we define a sign-consistent
refitting as an arbitrary refitting procedure, preserving the signs of the first step Lasso solution
and provide Oracle inequalities for such estimators. Finally, we consider special refitting strategies:
Bregman Lasso and Boosted Lasso. Bregman Lasso has a fruitful property to converge to the sign-consistent
least-squares refitting (least-squares with sign constraints), which provides with greater
interpretability. We additionally study the Bregman Lasso refitting in the case of orthogonal
design, providing with simple intuition behind the proposed method. Boosted Lasso, in contrast,
considers information about magnitudes of the first Lasso step and allows to develop better oracle
rates for prediction. Finally, we conduct an extensive numerical study to show advantages of one
approach over others in different synthetic and semi-real scenarios. 