In the context of pointwise density estimation, we introduce the notion of best possible individual
minimax speed of convergence over H\"older classes $\mathscr{P}_d(\beta,L)$, leading to a new
uniform risk criterion, weighted according to the inverse of this individual speed of convergence.
While it bears similarities to the oracle approach, our concept keeps the classical notion of minimax
optimality and is not restricted to a prespecified class of estimators. The individual speed of
convergence is getting faster as the density approaches zero, being substantially faster than
the classical minimax optimal rate. It splits into two regimes depending on the value of the density.
An estimator $\hat{p}_n$ tailored to the new risk criterion is constructed such that $$ \underset{p
\in \mathscr{P}_d(\beta,L)}{\sup}\, \underset{t \in \mathbb{R}^d}{\sup} \ \mathbb{E}_p^{\otimes
n}\bigg( \frac{\vert \hat{p}_n(t) - p(t) \vert}{{\Psi}_n (p(t),\beta,L)}\bigg)^r $$ is bounded,
uniformly over a range of parameters $(\beta,L)$. It provably obtains pointwise rates of convergence
${\Psi}_n(p(t),\beta,L)$ which can be substantially faster than $n^{-1/2}$. We demonstrate
that the new estimator uniformly improves the global minimax rate of convergence, adapts to the
second regime, and finally that adaptation into the fastest regime is not possible in principal
if the density's regularity is unknown. Consequences on plug-in rules for support recovery based
on the new estimator are worked out in detail. In contrast to those with classical density estimators,
the plug-in rules based on the new construction are minimax-optimal, up to some logarithmic factor.
As a by-product, we demonstrate that the rates on support estimation obtained in Cuevas and Fraiman
(1997, Ann. Statist.) are always suboptimal in case of H\"older continuous densities. 