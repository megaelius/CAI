We introduce a new information-theoretic formulation of quantum measurement uncertainty relations,
based on the notion of relative entropy between measurement probabilities. In the case of a finite-dimensional
system and for any approximate joint measurement of two target discrete observables, we define
the entropic divergence as the maximal total loss of information occurring in the approximation
at hand. For fixed target observables, we study the joint measurements minimizing the entropic
divergence, and we prove the general properties of its minimum value. Such a minimum is our uncertainty
lower bound: the total information lost by replacing the target observables with their optimal
approximations, evaluated at the worst possible state. The bound turns out to be also an entropic
incompatibility degree, that is, a good information-theoretic measure of incompatibility: indeed,
it vanishes if and only if the target observables are compatible, it is state-independent, and it
enjoys all the invariance properties which are desirable for such a measure. In this context, we
point out the difference between general approximate joint measurements and sequential approximate
joint measurements; to do this, we introduce a separate index for the tradeoff between the error
of the first measurement and the disturbance of the second one. By exploiting the symmetry properties
of the target observables, exact values, lower bounds and optimal approximations are evaluated
in two different concrete examples: (1) a couple of spin-1/2 components (not necessarily orthogonal);
(2) two Fourier conjugate mutually unbiased bases in prime power dimension. Finally, the entropic
incompatibility degree straightforwardly generalizes to the case of many observables, still
maintaining all its relevant properties; we explicitly compute it for three orthogonal spin-1/2
components. 