An important use of the singular value decomposition (SVD) is low-rank approximation via truncation,
giving a low-rank matrix $\widehat{A}$ that approximates $A$ in the sense that $A - \widehat{A}$
has small norm. However, in many applications like graph regularity, CUR decomposition, dense
approximation algorithms, spectral sparsifiers, etc., one needs additional structure on $\widehat{A}$:
not only is it low rank, but it must be a linear combination of rank one matrices $vw^T$ taken from a
restricted domain of vector pairs $P = \{vw^T\}$. We propose a new method for achieving such an approximation,
which we call the \emph{projection value decomposition (PVD)}. Our main technical result is that
low-rank approximation with SVD has a direct generalization via the PVD to arbitrary domains of
vector pairs $P$, giving this stronger form for $\widehat{A}$ in exchange for only controlling
the operator norm of $A - \widehat{A}$ over $P$. Our main application is to \emph{sparse graph regularity},
where we leverage the PVD to give a single, unified proof of the \Szemeredi{} regularity lemma, the
weak regularity lemma of Frieze and Kannan, and many various extensions and new regularity lemmas
for classes of sparse graphs including $L_p$ upper (quasi)regular graphs, graphs with low threshold
rank, and graphs with low core density. Beyond this we show extensions of the PVD to tensors and we
show additional applications to CUR decomposition (with non-standard approximation guarantees).
We also prove that the PVD is algorithmic in all cases of interest, and we show that it implies PTASes
for MAX-CUT, MAX-BISECTION, MIN-BISECTION, and MAX-CSP for new expanded classes of input graphs
(we remark that none of these problems admits a PTAS in the general case). 