This paper is motivated by the desire to develop distributed algorithms for nonconvex optimization
problems with complicated constraints associated with a network. The network can be a physical
one, such as an electric power network, where the constraints are nonlinear power flow equations,
or an abstract one that represents constraint couplings between decision variables of different
agents. Thus, this type of problems are ubiquitous in applications. Despite the recent development
of distributed algorithms for nonconvex programs, highly complicated constraints still pose
a significant challenge in theory and practice. We first identify some intrinsic difficulties
with the existing algorithms based on the alternating direction method of multipliers (ADMM) for
dealing with such problems. We then propose a reformulation for constrained nonconvex programs
that enables us to design a two-level algorithm, which embeds a specially structured three-block
ADMM at the inner level in an augmented Lagrangian method (ALM) framework. Furthermore, we prove
the global convergence of this new scheme for both smooth and nonsmooth constrained nonconvex programs.
The proof builds on and extends the classic and recent works on ALM and ADMM. Finally, we demonstrate
with computation that the new scheme provides convergent and parallelizable algorithms for several
classes of constrained nonconvex programs, for all of which existing algorithms may fail. To the
best of our knowledge, this is the first distributed algorithm that extends the ADMM architecture
to general nonlinear nonconvex constrained optimization. The proposed algorithmic framework
also provides a new principled way for parallel computation of constrained nonconvex optimization.
