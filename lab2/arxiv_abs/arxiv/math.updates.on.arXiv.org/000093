This paper is devoted to establish quantitative and qualitative estimates related to the notion
of chaos as firstly formulated by M. Kac \cite{Kac1956} in his study of mean-field limit for systems
of $N$ undistinguishable particles as $N\to\infty$. First, we quantitatively liken three usual
measures of {\it Kac's chaos}, some involving the all $N$ variables, other involving a finite fixed
number of variables. The cornerstone of the proof is a new representation of the Monge-Kantorovich-Wasserstein
(MKW) distance for symmetric $N$-particle probability measures in terms of the distance between
the law of the associated empirical measures on the one hand, and a new estimate on some MKW distance
on probability measures spaces endowed with a suitable Hilbert norm taking advantage of the associated
good algebraic structure. Next, we define the notion of {\it entropy chaos} and {\it Fisher information
chaos} in a similar way as defined by Carlen et al \cite{CCLLV}. We show that {\it Fisher information
chaos} is stronger than {\it entropy chaos}, which in turn is stronger than {\it Kac's chaos}. More
importantly, with the help of the HWI inequality of Otto-Villani, we establish a quantitative estimate
between these quantities, which in particular asserts that {\it Kac's chaos} plus {\it Fisher information
bound} implies {\it entropy chaos}. We then extend the above quantitative and qualitative results
about chaos in the framework of probability measures with support on the {\it Kac's spheres}, revisiting
\cite{CCLLV} and giving a possible answer to \cite[Open problem 11]{CCLLV}. Additionally to the
above mentioned tool, we use and prove an optimal rate local CLT in $L^\infty$ norm for distributions
with finite 6-th moment and finite $L^p$ norm, for some $p>1$. Last, we investigate how our techniques
can be used without assuming chaos, in the context of probability measures mixtures introduced
by De Finetti, Hewitt and Savage. In particular, we define the (level 3) Fisher information for mixtures
and prove that it is l.s.c. and affine, as that was done in \cite{RR} for the level 3 Boltzmann's entropy.
