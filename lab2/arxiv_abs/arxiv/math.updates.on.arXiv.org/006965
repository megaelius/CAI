Efficient sampling and remote estimation is critical for a plethora of wireless-empowered applications
in the Internet of Things and cyber-physical systems. Motivated by such applications, this work
proposes decentralized policies for the real-time monitoring and estimation of autoregressive
processes over random access channels. Two classes of policies are investigated: (i) oblivious
schemes in which sampling and transmission policies are independent of the processes that are monitored,
and (ii) non-oblivious schemes in which transmitters causally observe their corresponding processes
for decision making. In the class of oblivious policies, we show that minimizing the expected time-average
estimation error is equivalent to minimizing the expected age of information. Consequently, we
prove lower and upper bounds on the minimum achievable estimation error in this class. Next, we consider
non-oblivious policies and design a threshold policy, called error-based thinning, in which each
source node becomes active if its instantaneous error has crossed a fixed threshold (which we optimize).
Active nodes then transmit stochastically following a slotted ALOHA policy. A closed-form, approximately
optimal, solution is found for the threshold as well as the resulting estimation error. It is shown
that non-oblivious policies offer a multiplicative gain close to $3$ compared to oblivious policies.
Moreover, it is shown that oblivious policies that use the age of information for decision making
improve the state-of-the-art at least by the multiplicative factor $2$. The performance of all
discussed policies is compared using simulations. Numerical comparison shows that the performance
of the proposed decentralized policy is very close to that of centralized greedy scheduling. 