We study the SIR epidemiological model, with a variable contagion rate, applied to the evolution
of COVID19 in Cuba. It is highlighted that an increase in the predictive character depends on understanding
the dynamics for the temporal evolution of the rate of contagion $\beta^*$. A semi-empirical model
for this dynamics is formulated, where reaching $\beta^*\approx0$ due to isolation is achieved
after the mean duration of the disease $\tau=1/\gamma$, in which the number of infected in the confined
families has decreased. It is considered that $\beta^*(t)$ should have an abrupt decrease on the
day of initiation of confinement and decrease until canceling at the end of the interval $\tau$.
The analysis describes appropriately the infection curve for Germany. The model is applied to predict
an infection curve for Cuba, which estimates a maximum number of infected as less than 2000 in the
middle of May, depending on the rigor of the isolation. This is suggested by the ratio between the
daily detected cases and the total. We consider the ratio between the observed and real infected
cases (k) less than unity. The low value of k decreases the maximum obtained when $\beta^*-\gamma>0$.
The observed evolution is independent of k in the linear region. The value of $\beta^*$ is also studied
by time intervals, adjusting to the data of Cuba, Germany and South Korea. We compare the extrapolation
of the evolution of Cuba with the contagion rate until 16.04.20 with that obtained by a strict quarantine
at the end of April. This model with variable $\beta^*$ correctly describes the observed infected
evolution curves. We emphasize that the desired maximum of the SIR infected curve is not the maximum
standard with constant $\beta^*$, but one achieved due to quarantine when $\tilde R_0=\beta^*/\gamma<1$.
For the countries controlling the epidemic the maxima are in the region in which SIR equations are
linear. 