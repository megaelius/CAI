In this article we consider the iterative schemes to compute the canonical (CP) approximation of
quantized data generated by a function discretized on a large uniform grid in an interval on the real
line. This paper continues the research on the QTT method [16] developed for the tensor train (TT)
approximation of the quantized images of function related data. In the QTT approach the target vector
of length $2^{L}$ is reshaped to a $L^{th}$ order tensor with two entries in each mode (Quantized
representation) and then approximated by the QTT tenor including $2r^2 L$ parameters, where $r$
is the maximal TT rank. In what follows, we consider the Alternating Least-Squares (ALS) iterative
scheme to compute the rank-$r$ CP approximation of the quantized vectors, which requires only $2
r L\ll 2^L$ parameters for storage. In the earlier papers [17] such a representation was called Q$_{Can}$
format, while in this paper we abbreviate it as the QCP representation. We test the ALS algorithm
to calculate the QCP approximation on various functions, and in all cases we observed the exponential
error decay in the QCP rank. The main idea for recovering a discretized function in the rank-$r$ QCP
format using the reduced number the functional samples, calculated only at $O(2rL)$ grid points,
is presented. The special version of ALS scheme for solving the arising minimization problem is
described. This approach can be viewed as the sparse QCP-interpolation method that allows to recover
all $2r L$ representation parameters of the rank-$r$ QCP tensor. Numerical examples show the efficiency
of the QCP-ALS type iteration and indicate the exponential convergence rate in $r$. 