We present a new stochastic service model with capacity sharing and interruptions, appropriate
for the evaluation of the quality of real-time streaming (RTS), like e.g. mobile TV, in wireless
cellular networks. The general model takes into account multi-class Markovian process of call
arrivals, (to capture different radio channel conditions, requested streaming bit-rates and
durations) and allows for a general resource allocation policy saying which users are temporarily
denied the requested fixed streaming bit-rates (put in outage) due to resource constraints. We
give expressions for several important performance characteristics of the model, including mean
time spent in outage and mean number of outage incidents for a typical user of a given class. These
expressions involve only stationary probabilities of the (free) traffic demand process, which
is a vector of independent Poisson random variables describing the number of users of different
classes. In order to analyze RTS in 3GPP Long Term Evolution (LTE) cellular networks, we specify
our general model assuming orthogonal user channels with the peak bit-rates close to the theoretical
Shannon's bound in the additive white Gaussian noise (AWGN) channel, which leads to the resource
constraints in a multi-rate linear form. In this setting we consider a natural class of least-effort-served-first
resource allocation policies, for which the characteristics of the model can be further evaluated
using Fourier analysis of Poisson variables. Within this class we identify and evaluate an optimal
and a fair policy, the latter being suggested by LTE implementations. We also propose some intermediate
policies, which allow to solve the optimality/fairness tradeoff caused by unequal user radio-channel
conditions. Our results can be used for the evaluation of the quality of RTS in LTE networks and dimensioning
of these networks. 