An update-efficient code is a mapping from messages to codewords such that for a small perturbation
in the message the corresponding codeword changes only slightly. Analogously, a code is called
locally recoverable or repairable if any symbol of a codeword can be recovered by reading only a small
(constant) number of other symbols. The notions of local recoverability and update-efficiency
are important in the area of distributed storage systems, where the most frequent error event is
a single storage node failure and most updates on data are small. A common objective is to repair a
failed node by downloading data from as few other storage nodes as possible. For updates, one wants
to change as few nodes as possible. In this paper, we first study update-efficient error-correcting
codes and their basic properties. While update-efficiency and error-correction are two conflicting
properties, we provide conditions for the existence of such codes. One of our main results is to show
that the update-efficiency has to scale logarithmically with the block-length of the code if we
are to to achieve any nontrivial rate with vanishing probability of error over the binary symmetric
or binary erasure channels. There exist capacity-achieving codes with this scaling. We also explore
the notion of update-efficiency in the presence of adversarial errors. The capacity result for
the case of locally repairable codes is also considered here. We provide tight upper and lower bounds
on the local-recoverability of a code that achieves capacity on the binary erasure channel. In particular,
it is shown that if the code-rate is $\epsilon$ less than the capacity, then for the optimal codes,
the maximum number of codeword symbols required to recover one lost symbol must scale as $\log1/\epsilon$.
The results extend to the case of nonbinary alphabets. 