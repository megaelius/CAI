Assume that $X_{\Sigma}\in\mathbb{R}^{n}$ is a random vector following a multivariate normal
distribution with zero mean and positive definite covariance matrix $\Sigma$. Let $g:\mathbb{R}^{n}\to\mathbb{C}$
be measurable and of moderate growth, e.g., $|g(x)| \lesssim (1+|x|)^{N}$. We show that the map
$\Sigma\mapsto\mathbb{E}\left[g(X_{\Sigma})\right]$ is smooth, and we derive convenient
expressions for its partial derivatives, in terms of certain expectations $\mathbb{E}\left[(\partial^{\alpha}g)(X_{\Sigma})\right]$
of partial (distributional) derivatives of $g$. As we discuss, this result can be used to derive
bounds for the expectation $\mathbb{E}\left[g(X_{\Sigma})\right]$ of a nonlinear function
$g(X_{\Sigma})$ of a Gaussian random vector $X_{\Sigma}$ with possibly correlated entries. For
the case when $g(x) =g_{1}(x_{1})\cdots g_{n}(x_{n})$ has tensor-product structure, the above
result is known in the engineering literature as Price's theorem, originally published in 1958.
For dimension $n=2$, it was generalized in 1964 by McMahon to the general case $g:\mathbb{R}^{2}\to\mathbb{C}$.
Our contribution is to unify these results, and to give a mathematically fully rigorous proof. Precisely,
we consider a normally distributed random vector $X_{\Sigma}\in\mathbb{R}^{n}$ of arbitrary
dimension $n\in\mathbb{N}$, and we allow the nonlinearity $g$ to be a general tempered distribution.
To this end, we replace the expectation $\mathbb{E}\left[g(X_{\Sigma})\right]$ by the dual pairing
$\left\langle g,\,\phi_{\Sigma}\right\rangle_{\mathcal{S}',\mathcal{S}}$, where $\phi_{\Sigma}$
denotes the probability density function of $X_{\Sigma}$. 