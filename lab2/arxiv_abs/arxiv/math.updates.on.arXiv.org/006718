This article is about the quantitative homogenization theory of linear elliptic equations in divergence
form with random coefficients. We derive gradient estimates on the homogenization error, i.e.
on the difference between the actual solution and the two-scale expansion of the homogenized solution,
both in terms of strong norms (oscillation) and weak norms (fluctuation). These estimates are optimal
in terms of scaling in the ratio between the microscopic and the macroscopic scale. The purpose of
this article is to highlight the usage of the recently introduced annealed Calderon-Zygmund (CZ)
estimates in obtaining the above, previously known, error estimates. Moreover, the article provides
a novel proof of these annealed CZ estimate that completely avoids quenched regularity theory,
but rather relies on functional analysis. It is based on the observation that even on the level of
operator norms, the Helmholtz projection is close to the one for the homogenized coefficient (for
which annealed CZ estimates are easily obtained). In this article, we strive for simple proofs,
and thus restrict ourselves to ensembles of coefficient fields that are local transformations
of Gaussian random fields with integrable correlations and H\"older continuous realizations.
As in earlier work, we use the natural objects from the general theory of homogenization, like the
(potential and flux) correctors and the homogenization commutator. Both oscillation and fluctuation
estimates rely on a sensitivity calculus, i.e. on estimating how sensitively the quantity of interest
does depend on an infinitesimal change in the coefficient field, which is fed into the Spectral Gap
inequality. In this article, the annealed CZ estimate is the only form in which elliptic regularity
theory enters. 