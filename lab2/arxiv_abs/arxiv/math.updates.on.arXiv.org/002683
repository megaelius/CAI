Memcomputing is a novel paradigm of computation that utilizes dynamical elements with memory to
both store and process information on the same physical location. Its building blocks can be fabricated
in hardware with standard electronic circuits, thus offering a path to its practical realization.
In addition, since memcomputing is based on non-quantum elements, the equations of motion describing
these machines can be simulated efficiently on standard computers. In fact, it was recently realized
that memcomputing, and in particular its digital (hence scalable) version, when simulated on a
classical machine provides a significant speed-up over state-of-the-art algorithms on a variety
of non-convex problems. Here, we stress-test the capabilities of this approach on finding approximate
solutions to hard combinatorial optimization problems. These fall into a class which is known to
require exponentially growing resources in the worst cases, even to generate approximations.
We recently showed that in a region where state of the art algorithms demonstrate this exponential
growth, simulations of digital memcomputing machines performed using the Falcon$^\copyright$
simulator of MemComputing, Inc. only require time and memory resources that scale linearly. These
results are extended in a stress-test up to $64\times10^6$ variables (corresponding to about 1
billion literals), namely the largest case that we could fit on a single node with 128 GB of DRAM. Since
memcomputing can be applied to a wide variety of optimization problems, this stress test shows the
considerable advantage of non-combinatorial, physics-inspired approaches over standard combinatorial
ones. 