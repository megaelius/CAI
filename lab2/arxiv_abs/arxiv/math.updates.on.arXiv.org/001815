In this paper we consider zero-sum repeated games when the maximizer is restricted to strategies
requiring no more than a limited amount of randomness. Particularly we analyze the maxmin payoff
of the maximizer in two models: the first model (the Gossner and Vieille model) forces the maximizer
to randomize her action in each stage just by conditioning her decision to outcomes of a given sequence
of random source, while in the second model (the Gossner and Tomala model) the maximizer is a team
of players who are free to randomize privately their corresponding actions but do not access to any
explicit source of shared randomness needed for cooperation. The works of Gossner and Vieille,
and Gossner and Tomala adopted the method of types to establish their results while we utilize the
idea of random hashing which is the core of randomness extractors in the information theory literature.
Besides we adopt the well-studied tool of simulation of a source from another source. By utilizing
this tools, we are able to not only simplify the prior results, but also extend them. We characterize
the maxmin payoff of the maximizer in the repeated games under study. Particularly, the maxmin payoff
of the first model is fully described by the function $J(h)$ which is the maximum payoff that the maximizer
can secure in a one shot game by choosing mixed strategies of entropy at most $h$. In the second part
of the paper, we study the computational aspects of $J(h)$. We provide three explicit lower bounds
on the entropy-payoff tradeoff curve. To do this, we provide and utilize new results for the set of
distributions that guarantee a certain payoff for Alice. In particular, we study how this set of
distributions shrinks as we increase the security level. While the use of total variation distance
is common in game theory, our derivation indicates the suitability of utilizing the Renyi-divergence
of order two. 