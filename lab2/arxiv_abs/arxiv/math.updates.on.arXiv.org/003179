Motivated by the Koml\'os conjecture in combinatorial discrepancy, we study the discrepancy of
random matrices with $m$ rows and $n$ independent columns drawn from a bounded lattice random variable.
It is known that for $n$ tending to infinity and $m$ fixed, with high probability the $\ell_\infty$-discrepancy
is at most twice the $\ell_\infty$-covering radius of the integer span of the support of the random
variable. However, the easy argument for the above fact gives no concrete bounds on the failure probability
in terms of $n$. We prove that the failure probability is inverse polynomial in $m, n$ and some well-motivated
parameters of the random variable. We also obtain the analogous bounds for the discrepancy in arbitrary
norms. We apply these results to two random models of interest. For random $t$-sparse matrices,
i.e. uniformly random matrices with $t$ ones and $m-t$ zeroes in each column, we show that the $\ell_\infty$-discrepancy
is at most $2$ with probability $1 - O(\sqrt{ \log n/n})$ for $n = \Omega(m^3 \log^2 m)$. This improves
on a bound proved by Ezra and Lovett (Ezra and Lovett, Approx+Random, 2016) showing that the same
is true for $n$ at least $m^t$. For matrices with random unit vector columns, we show that the $\ell_\infty$-discrepancy
is $O(\exp(\sqrt{ n/m^3}))$ with probability $1 - O(\sqrt{ \log n/n})$ for $n = \Omega(m^3 \log^2
m).$ Our approach, in the spirit of Kuperberg, Lovett and Peled (G. Kuperberg, S. Lovett and R. Peled,
STOC 2012), uses Fourier analysis to prove that for $m \times n$ matrices $M$ with i.i.d. columns,
and $m$ sufficiently large, the distribution of $My$ for random $y \in \{-1,1\}^n$ obeys a local
limit theorem. 