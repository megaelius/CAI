We consider two problems of estimation in high-dimensional Gaussian models. The first problem
is that of estimating a linear functional of the means of $n$ independent $p$-dimensional Gaussian
vectors, under the assumption that most of these means are equal to zero. We show that, up to a logarithmic
factor, the minimax rate of estimation in squared Euclidean norm is between $(s^2\wedge n) +sp$
and $(s^2\wedge np)+sp$. The estimator that attains the upper bound being computationally demanding,
we investigate suitable versions of group thresholding estimators. An interesting new phenomenon
revealed by this investigation is that the group thresholding leads to a substantial improvement
in the rate as compared to the element-wise thresholding. Thus, the rate of the group thresholding
is $s^2\sqrt{p}+sp$, while the element-wise thresholding has an error of order $s^2p+sp$. To the
best of our knowledge, this is the first known setting in which leveraging the group structure leads
to a polynomial improvement in the rate. The second problem studied in this work is the estimation
of the common $p$-dimensional mean of the inliers among $n$ independent Gaussian vectors. We show
that there is a strong analogy between this problem and the first one. Exploiting it, we propose new
strategies of robust estimation that are computationally tractable and have better rates of convergence
than the other computationally tractable robust (with respect to the presence of the outliers in
the data) estimators studied in the literature. However, this tractability comes with a loss of
the minimax-rate-optimality in some regimes. 