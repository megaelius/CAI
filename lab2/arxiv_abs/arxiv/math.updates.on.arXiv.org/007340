\emph{Group Testing} (GT) addresses the problem of identifying a small subset of defective items
from a large population, by grouping items into as few test pools as possible. In \emph{Adaptive
GT} (AGT), outcomes of previous tests can influence the makeup of future tests. Using an information
theoretic point of view, Aldridge $2012$ showed that in the regime of a few defectives, adaptivity
does not help much, as the number of tests required is essentially the same as for non-adaptive GT.
\emph{Secure GT} considers a scenario where there is an eavesdropper who may observe a fraction
$\delta$ of the tests results, yet should not be able to infer the status of the items. In the non-adaptive
scenario, the number of tests required is $1/(1-\delta)$ times the number of tests without the secrecy
constraint. In this paper, we consider \emph{Secure Adaptive GT}. Specifically, when during the
makeup of the pools one has access to a private feedback link from the lab, of rate $R_f$. We prove that
the number of tests required for both correct reconstruction at the legitimate lab, with high probability,
and negligible mutual information at the eavesdropper is $1/min\{1,1-\delta+R_f\}$ times the
number of tests required with no secrecy constraint. Thus, unlike non-secure GT, where an adaptive
algorithm has only a mild impact, under a security constraint it can significantly boost performance.
A key insight is that not only the adaptive link should disregard the actual test results and simply
send keys, these keys should be enhanced through a "secret sharing" scheme before usage. We drive
sufficiency and necessity bounds that completely characterizes the Secure Adaptive GT capacity.
