Surrogate-modelling techniques including Polynomial Chaos Expansion (PCE) is commonly used
for statistical estimation (aka. Uncertainty Quantification) of quantities of interests obtained
from expensive computational models. PCE is a data-driven regression-based technique that relies
on spectral polynomials as basis-functions. In this technique, the outputs of few numerical simulations
are used to estimate the PCE coefficients within a regression framework combined with regularization
techniques where the regularization parameters are estimated using standard cross-validation
as applied in supervised machine learning methods. In the present work, we introduce an efficient
method for estimating the PCE coefficients combining Elastic Net regularization with a data-driven
feature ranking approach. Our goal is to increase the probability of identifying the most significant
PCE components by assigning each of the PCE coefficients a numerical value reflecting the magnitude
of the coefficient and its stability with respect to perturbations in the input data. In our evaluations,
the proposed approach has shown high convergence rate for high-dimensional problems, where standard
feature ranking might be challenging due to the curse of dimensionality. The presented method is
implemented within a standard machine learning library (Scikit-learn) allowing for easy experimentation
with various solvers and regularization techniques (e.g. Tikhonov, LASSO, LARS, Elastic Net)
and enabling automatic cross-validation techniques using a widely used and well tested implementation.
We present a set of numerical tests on standard analytical functions, a two-phase subsurface flow
model and a simulation dataset for CO2 sequestration in a saline aquifer. For all test cases, the
proposed approach resulted in a significant increase in PCE convergence rates. 