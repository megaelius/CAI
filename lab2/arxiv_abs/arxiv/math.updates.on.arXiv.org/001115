In this paper, we address the challenging problem of optimal experimental design (OED) of constrained
inverse problems. We consider two OED formulations that allow reducing the experimental costs
by minimizing the number of measurements. The first formulation assumes a fine discretization
of the design parameter space and uses sparsity promoting regularization to obtain an efficient
design. The second formulation parameterizes the design and seeks optimal placement for these
measurements by solving a small-dimensional optimization problem. We consider both problems
in a Bayes risk as well as an empirical Bayes risk minimization framework. For the unconstrained
inverse state problem, we exploit the closed form solution for the inner problem to efficiently
compute derivatives for the outer OED problem. The empirical formulation does not require an explicit
solution of the inverse problem and therefore allows to integrate constraints efficiently. A key
contribution is an efficient optimization method for solving the resulting, typically high-dimensional,
bilevel optimization problem using derivative-based methods. To overcome the lack of non-differentiability
in active set methods for inequality constraints problems, we use a relaxed interior point method.
To address the growing computational complexity of empirical Bayes OED, we parallelize the computation
over the training models. Numerical examples and illustrations from tomographic reconstruction,
for various data sets and under different constraints, demonstrate the impact of constraints on
the optimal design and highlight the importance of OED for constrained problems. 