We demonstrate that a large class of first-order quantum phase transitions can be described as a
condensation in the space of states. Given a system having Hamiltonian $H=K+gV$, where $K$ and $V$
are hopping and potential operators acting on the space of states $\mathbb{F}$, we may always write
$\mathbb{F}=\mathbb{F}_\mathrm{cond} \oplus \mathbb{F}_\mathrm{norm}$ where $\mathbb{F}_\mathrm{cond}$
is the subspace which spans the eigenstates of $V$ with minimal eigenvalue and $\mathbb{F}_\mathrm{norm}=\mathbb{F}_\mathrm{cond}^\perp$.
If, in the thermodynamic limit, $M_\mathrm{cond}/M \to 0$, where $M$ and $M_\mathrm{cond}$ are,
respectively, the dimensions of $\mathbb{F}$ and $\mathbb{F}_\mathrm{cond}$, the above decomposition
of $\mathbb{F}$ becomes effective, in the sense that the ground state energy per particle of the
system, $\epsilon$, coincides with the smaller between $\epsilon_\mathrm{cond}$ and $\epsilon_\mathrm{norm}$,
the ground state energies per particle of the system restricted to the subspaces $\mathbb{F}_\mathrm{cond}$
and $\mathbb{F}_\mathrm{norm}$, respectively. It may then happen that, as a function of the parameter
$g$, the energies $\epsilon_\mathrm{cond}$ and $\epsilon_\mathrm{norm}$ cross at $g=g_\mathrm{c}$.
In this case, a first-order quantum phase transition takes place between a condensed phase (system
restricted to the small subspace $\mathbb{F}_\mathrm{cond}$) and a normal phase (system spread
over the large subspace $\mathbb{F}_\mathrm{norm}$). Since, in the thermodynamic limit, $M_\mathrm{cond}/M
\to 0$, the confinement into $\mathbb{F}_\mathrm{cond}$ is actually a condensation in which the
system falls into a ground state orthogonal to that of the normal phase, something reminiscent of
Andersons' orthogonality catastrophe. The outlined mechanism is tested on a variety of benchmark
lattice models. 