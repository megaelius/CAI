In this work we study convergence properties of sparse polynomial approximations for a class of
affine parametric saddle point problems. Such problems can be found in many computational science
and engineering fields, including the Stokes equations for viscous incompressible flow, mixed
formulation of diffusion equations for heat conduction or groundwater flow, time-harmonic Maxwell
equations for electromagnetics, etc. Due to the lack of knowledge or intrinsic randomness, the
coefficients of such problems are uncertain and can often be represented or approximated by high-
or countably infinite-dimensional random parameters equipped with suitable probability distributions,
and the coefficients affinely depend on a series of either globally or locally supported basis functions,
e.g., Karhunen--Lo\`eve expansion, piecewise polynomials, or adaptive wavelet approximations.
Consequently, we are faced with solving affine parametric saddle point problems. Here we study
sparse polynomial approximations of the parametric solutions, in particular sparse Taylor approximations,
and their convergence properties for these parametric problems. With suitable sparsity assumptions
on the parametrization, we obtain the algebraic convergence rates $O(N^{-r})$ for the sparse polynomial
approximations of the parametric solutions, in cases of both globally and locally supported basis
functions. We prove that $r$ depends only on a sparsity parameter in the parametrization of the random
input, and in particular does not depend on the number of active parameter dimensions or the number
of polynomial terms $N$. These results imply that sparse polynomial approximations can effectively
break the curse of dimensionality, thereby establishing a theoretical foundation for the development
and application of such practical algorithms as adaptive, least-squares, and compressive sensing
constructions. 