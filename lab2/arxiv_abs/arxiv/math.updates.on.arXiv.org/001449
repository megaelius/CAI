We present the first family of binary codes that attains optimal scaling and quasi-linear complexity,
at least for the binary erasure channel (BEC). In other words, for any fixed $\delta > 0$, we provide
codes that ensure reliable communication at rates within $\varepsilon > 0$ of the Shannon capacity
with block length $n=O(1/\varepsilon^{2+\delta})$, construction complexity $\Theta(n)$,
and encoding/decoding complexity $\Theta(n\log n)$. Furthermore, this scaling between the gap
to capacity and the block length is optimal in an information-theoretic sense. Our proof is based
on the construction and analysis of binary polar codes obtained from large kernels. It was recently
shown that, for all binary-input symmetric memoryless channels, conventional polar codes (based
on a $2\times 2$ kernel) allow reliable communication at rates within $\varepsilon > 0$ of the Shannon
capacity with block length, construction, encoding and decoding complexity all bounded by a polynomial
in $1/\varepsilon$. In particular, this means that the block length $n$ scales as $O(1/\varepsilon^{\mu})$,
where $\mu$ is referred to as the scaling exponent. It is furthermore known that the optimal scaling
exponent is $\mu=2$, and it is achieved by random linear codes. However, for general channels, the
decoding complexity of random linear codes is exponential in the block length. As far as conventional
polar codes, their scaling exponent depends on the channel, and for the BEC it is given by $\mu=3.63$.
Our main contribution is a rigorous proof of the following result: there exist $\ell\times\ell$
binary kernels, such that polar codes constructed from these kernels achieve scaling exponent
$\mu(\ell)$ that tends to the optimal value of $2$ as $\ell$ grows. The resulting binary codes also
achieve construction complexity $\Theta(n)$ and encoding/decoding complexity $\Theta(n\log
n)$. 