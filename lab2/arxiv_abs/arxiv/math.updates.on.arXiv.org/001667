Most long memory forecasting studies assume that the memory is generated by the fractional difference
operator. We argue that the most cited theoretical arguments for the presence of long memory do not
imply the fractional difference operator, and assess the performance of the autoregressive fractionally
integrated moving average $(ARFIMA)$ model when forecasting series with long memory generated
by nonfractional processes. We find that high-order autoregressive $(AR)$ models produce similar
or superior forecast performance than $ARFIMA$ models at short horizons. Nonetheless, as the forecast
horizon increases, the $ARFIMA$ models tend to dominate in forecast performance. Hence, $ARFIMA$
models are well suited for forecasts of long memory processes regardless of the long memory generating
mechanism, particularly for medium and long forecast horizons. Additionally, we analyse the forecasting
performance of the heterogeneous autoregressive ($HAR$) model which imposes restrictions on
high-order $AR$ models. We find that the structure imposed by the $HAR$ model produces better long
horizon forecasts than $AR$ models of the same order, at the price of inferior short horizon forecasts
in some cases. Our results have implications for, among others, Climate Econometrics and Financial
Econometrics models dealing with long memory series at different forecast horizons. We show in
an example that while a short memory autoregressive moving average $(ARMA)$ model gives the best
performance when forecasting the Realized Variance of the S\&P 500 up to a month ahead, the $ARFIMA$
model gives the best performance for longer forecast horizons. 