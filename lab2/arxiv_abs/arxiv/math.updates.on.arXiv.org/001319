We consider the sequential decision problem faced by the manager of an electric vehicle (EV) charging
station, who aims to satisfy the charging demand of the customer while minimizing cost. Since the
total time needed to charge the EV up to capacity is often less than the amount of time that the customer
is away, there are opportunities to exploit electricity spot price variations within some reservation
window. We formulate the problem as a finite horizon Markov decision process (MDP) and consider
a risk-averse objective function by optimizing under a dynamic risk measure constructed using
a convex combination of expected value and conditional value at risk (CVaR). It has been recognized
that the objective function of a risk-averse MDP lacks a practical interpretation. Therefore,
in both academic and industry practice, the dynamic risk measure objective is often not of primary
interest; instead, the risk-averse MDP is used as a computational tool for solving problems with
predefined "practical" risk and reward objectives (termed the base model). In this paper, we study
the extent to which the two sides of this framework are compatible with each other for the EV setting
-- roughly speaking, does a "more risk-averse" MDP provide lower risk in the practical sense as well?
In order to answer such a question, the effect of the degree of dynamic risk-aversion on the optimal
MDP policy is analyzed. Based on these results, we also propose a principled approximation approach
to finding an instance of the risk-averse MDP whose optimal policy behaves well under the practical
objectives of the base model. Our numerical experiments suggest that EV charging stations can be
operated at a significantly higher level of profitability if dynamic charging is adopted and a small
amount of risk is tolerated. 