The principle of maximum entropy (Maxent) suggests to select the distribution with maximal entropy.
While this has served the community as a useful tool it has recently become clear that distributions
with high entropy may indeed be produced by short generative programs. Here we refine the principle
by considering recursive (computable) generative programs as a refinement to classical Maxent.
We take advantage of a causal algorithmic calculus to derive a thermodynamic-like result based
on how difficult it is to reprogram a computer code to produce an output with a different algorithmic
probability. Using the distinction between computable and algorithmic randomness we quantify
the cost in information loss associated with reprogramming. To illustrate this we construct reference
graphs reversing the same algorithmic calculus and introduce a Maximal Algorithmic Randomness
Preferential Attachment (MARPA) Algorithm, a generalisation over previous approaches. Using
MARPA and reprogrammability we refine Maxent by quantifying the algorithmic typicality of an object
based on a combined distance from algorithmic randomness. Classical entropy-based Maxent collapse
all random-looking cases despite the generating mechanism thereby confounding all distinct degrees
of randomness and pseudo-randomness. We discuss practical implications of evaluation of network
randomness. Our analysis provides insight in that the reprogrammability asymmetry appears to
originate from a non-monotonic relationship to algorithmic probability. Our analysis motivates
further analysis of the origin and consequences of the aforementioned asymmetries, reprogrammability,
and computation. 