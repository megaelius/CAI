The Gaussian stochastic process (GaSP) is a useful technique for predicting nonlinear outcomes.
The estimated mean function in a GaSP, however, can be far from the reality in terms of the $L_2$ distance.
This problem was widely observed in calibrating imperfect mathematical models using experimental
data, when the discrepancy function is modeled as a GaSP. In this work, we study the theoretical properties
of the scaled Gaussian stochastic process (S-GaSP), a new stochastic process to address the identifiability
problem of the mean function in the GaSP model. The GaSP is a special case of the S-GaSP with the scaling
parameter being zero. We establish the explicit connection between the GaSP and S-GaSP through
the orthogonal series representation. We show the predictive mean estimator in the S-GaSP calibration
model converges to the reality at the same rate as the GaSP with the suitable choice of the regularization
parameter and scaling parameter. We also show the calibrated mathematical model in the S-GaSP calibration
converges to the one that minimizes the $L_2$ loss between the reality and mathematical model with
the same regularization and scaling parameters, whereas the GaSP model does not have this property.
From the regularization perspective, the loss function from the S-GaSP calibration penalizes
the native norm and $L_2$ norm of the discrepancy function simultaneously, whereas the one from
the GaSP calibration only penalizes the native norm of the discrepancy function. The predictive
error from the S-GaSP matches well with the theoretical bound, and numerical evidence is presented
concerning the performance of the studied approaches. Both the GaSP and S-GaSP calibration models
are implemented in the "RobustCalibration" R Package on CRAN. 