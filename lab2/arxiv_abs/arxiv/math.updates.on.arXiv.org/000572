In this paper, we consider an infinite dimensional generalization of finite dimensional exponential
family where the elements of the infinite dimensional family, $\mathcal{P}$ are parametrized
by functions in a reproducing kernel Hilbert space, $H$. We show that $\mathcal{P}$ is quite rich
in the sense that a broad class of densities on $\Omega\subset\mathbb{R}^d$ can be approximated
arbitrarily well in Kullback-Leibler (KL) divergence by elements in $\mathcal{P}$. The main goal
of the paper is to estimate an unknown density, $p_0$ through an element in $\mathcal{P}$. Since
standard techniques like maximum likelihood estimation (MLE) or pseudo MLE (based on the method
of sieves), which are based on minimizing the KL divergence between $p_0$ and $\mathcal{P}$, do
not yield practically useful estimators because of their inability to handle the log-partition
function efficiently, we propose an estimator, $\hat{p}_n$ based on minimizing the \emph{Fisher
divergence}, $J(p_0\Vert p)$ between $p_0$ and $p\in \mathcal{P}$, which involves solving a simple
finite dimensional linear system. When $p_0\in\mathcal{P}$, we show that the proposed estimator
is consistent, and provide a convergence rate of $n^{-\min\left\{\frac{2}{3},\frac{2\beta+1}{2\beta+2}\right\}}$
in Fisher divergence under the smoothness assumption that $\log p_0\in\mathcal{R}(C^\beta)$
for some $\beta\ge 0$ where $C$ is a covariance operator on $H$ and $\mathcal{R}(C^\beta)$ denotes
the image of $C^\beta$. We also investigate the misspecified case of $p_0\notin\mathcal{P}$ and
show that $J(p_0\Vert\hat{p}_n)\rightarrow \inf_{p\in\mathcal{P}}J(p_0\Vert p)$ as $n\rightarrow\infty$
and provide the above mentioned rate for this convergence assuming that the infimum is attained
in $\mathcal{P}$ and the logarithm of the attained infimum is in $\mathcal{R}(C^\beta)$ for some
$\beta\ge 0$. 