The integration of machine learning methods and Model Predictive Control (MPC) has received increasing
attention in recent years. In general, learning-based predictive control (LPC) is promising to
build data-driven models and solve the online optimization problem with lower computational costs.
However, the robustness of LPC is difficult to be guaranteed since there will be uncertainties due
to function approximation used in machine learning algorithms. In this paper, a novel robust learning-based
predictive control (r-LPC) scheme is proposed for constrained nonlinear systems with unknown
dynamics. In r-LPC, the Koopman operator is used to form a global linear representation of the unknown
dynamics, and an incremental actor-critic algorithm is presented for receding horizon optimization.
To realize the satisfaction of system constraints, soft logarithmic barrier functions are designed
within the learning predictive framework. The recursive feasibility and stability of the closed-loop
system are discussed under the convergence arguments of the approximation algorithms adopted.
Also, the robustness property of r-LPC is analyzed theoretically by taking into consideration
the existence of perturbations on the controller due to possible approximation errors. Simulation
results with the proposed learning control approach for the data-driven regulation of a Van der
Pol oscillator system have been reported, including the comparisons with a classic MPC and an infinite-horizon
Dual Heuristic Programming (DHP) algorithm. The results show that the r-LPC significantly outperforms
the DHP algorithm in terms of control performance and can be comparative to the MPC in terms of regulating
control as well as energy consumption. Moreover, its average computational cost is much smaller
than that with the MPC in the adopted environment. 