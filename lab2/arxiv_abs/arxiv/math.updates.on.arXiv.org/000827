First-order methods play a central role in large-scale convex optimization. Even though many variations
exist, each suited to a particular problem form, almost all such methods fundamentally rely on two
types of algorithmic steps and two corresponding types of analysis: gradient-descent steps, which
yield primal progress, and mirror-descent steps, which yield dual progress. In this paper, we observe
that the performances of these two types of step are complementary, so that faster algorithms can
be designed by coupling the two steps and combining their analyses. In particular, we show how to
obtain a conceptually simple interpretation of Nesterov's accelerated gradient method, a cornerstone
algorithm in convex optimization. Nesterov's method is the optimal first-order method for the
class of smooth convex optimization problems. However, to the best of our knowledge, the proof of
the fast convergence of Nesterov's method has not found a clear interpretation and is still regarded
by many as crucially relying on an "algebraic trick". We apply our novel insights to express Nesterov's
algorithm as a natural coupling of gradient descent and mirror descent and to write its proof of convergence
as a simple combination of the convergence analyses of the two underlying steps. We believe that
the complementary view of gradient descent and mirror descent proposed in this paper will prove
very useful in the design of first-order methods as it allows us to design fast algorithms in a conceptually
easier way. For instance, our view greatly facilitates the adaptation of non-trivial variants
of Nesterov's method to specific scenarios, such as packing and covering problems [AO14, AO15].
