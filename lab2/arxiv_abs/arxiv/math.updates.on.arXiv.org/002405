We examine the task of privacy amplification from information-theoretic and coding-theoretic
points of view. In the former, we give a one-shot characterization of the optimal rate of privacy
amplification against classical adversaries in terms of the optimal type-II error in asymmetric
hypothesis testing. This formulation can be easily computed to give finite-blocklength bounds
and turns out to be equivalent to smooth min-entropy bounds by Renner and Wolf [Asiacrypt 2005] and
Watanabe and Hayashi [ISIT 2013], as well as a bound in terms of the $E_\gamma$ divergence by Yang,
Schaefer, and Poor [arXiv:1706.03866 [cs.IT]]. In the latter, we show that protocols for privacy
amplification based on linear codes can be easily repurposed for channel simulation. Combined
with known relations between channel simulation and lossy source coding, this implies that privacy
amplification can be understood as a basic primitive for both channel simulation and lossy compression.
Applied to symmetric channels or lossy compression settings, our construction leads to proto-
cols of optimal rate in the asymptotic i.i.d. limit. Finally, appealing to the notion of channel
duality recently detailed by us in [IEEE Trans. Info. Theory 64, 577 (2018)], we show that linear
error-correcting codes for symmetric channels with quantum output can be transformed into linear
lossy source coding schemes for classical variables arising from the dual channel. This explains
a "curious duality" in these problems for the (self-dual) erasure channel observed by Martinian
and Yedidia [Allerton 2003; arXiv:cs/0408008] and partly anticipates recent results on optimal
lossy compression by polar and low-density generator matrix codes. 