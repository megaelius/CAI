This paper considers the problem of distributed bandit online convex optimization with time-varying
coupled inequality constraints. This problem can be defined as a repeated game between a group of
learners and an adversary. The learners attempt to minimize a sequence of global loss functions
and at the same time satisfy a sequence of coupled constraint functions. The global loss and the coupled
constraint functions are the sum of local convex loss and constraint functions, respectively,
which are adaptively generated by the adversary. The local loss and constraint functions are revealed
in a bandit manner, i.e., only the values of loss and constraint functions at sampled points are revealed
to the learners, and the revealed function values are held privately by each learner. We consider
two scenarios, one- and two-point bandit feedback, and propose two corresponding distributed
bandit online algorithms used by the learners. We show that sublinear expected regret and constraint
violation are achieved by these two algorithms, if the accumulated variation of the comparator
sequence also grows sublinearly. In particular, we show that $\mathcal{O}(T^{\theta_1})$ expected
static regret and $\mathcal{O}(T^{7/4-\theta_1})$ constraint violation are achieved in the
one-point bandit feedback setting, and $\mathcal{O}(T^{\max\{\kappa,1-\kappa\}})$ expected
static regret and $\mathcal{O}(T^{1-\kappa/2})$ constraint violation in the two-point bandit
feedback setting, where $\theta_1\in(3/4,5/6]$ and $\kappa\in(0,1)$ are user-defined trade-off
parameters. Finally, these theoretical results are illustrated by numerical simulations of a
simple power grid example. 