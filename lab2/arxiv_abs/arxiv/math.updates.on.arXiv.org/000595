We propose and analyze a novel Multi Index Monte Carlo (MIMC) method for weak approximation of stochastic
models that are described in terms of differential equations either driven by random measures or
with random coefficients. The MIMC method is both a stochastic version of the combination technique
introduced by Zenger, Griebel and collaborators and an extension of the Multilevel Monte Carlo
(MLMC) method first described by Heinrich and Giles. Inspired by Giles's seminal work, instead
of using first order differences as in MLMC, we use in MIMC high order differences to reduce the variance
of the hierarchical differences dramatically. This in turn yields new and improved complexity
results, which are natural generalizations of Giles' MLMC analysis, and which increase the domain
of problem parameters for which we achieve the optimal convergence, $\mathcal{O}(\text{TOL}^{-2}).$
Moreover, we motivate the systematic construction of optimal sets of indices for approximation
based on properly defined profits that in turn depend on the average cost per sample and the corresponding
weak and strong errors. Under standard assumptions on weak and strong error and work per sample,
the optimal index set turns out to be of Total Degree (TD) type. In some cases, using TD index sets,
MIMC achieves a better rate for the computational complexity than the corresponding rate when using
Full Tensor sets. We also show the asymptotic normality of the statistical error in the resulting
MIMC estimator and justify in this way our error estimate, which allows both the required accuracy
and the confidence in our computational results to be prescribed. 