We consider an $\ell_0$-minimization problem where $f(x) + \|x\|_0$ is minimized over a polyhedral
set and the $\ell_0$-norm penalty implicitly emphasizes sparsity of the solution. Such a setting
captures a range of problems in image processing and statistical learning. However, given the the
nonconvex and discontinuous nature of this norm, convex penalties are often employed as substitutes,
and far less is known about directly solving the $\ell_0$-minimization problem. In this paper,
inspired by Feng et.al. [20], we consider the resolution of an equivalent formulation of the $\ell_0$-minimization
problem as a mathematical program with complementarity constraints (MPCC) and make the following
contributions. (i) First, we show that feasible points of this formulation satisfy Guignard constraint
qualification. In fact, under suitable convexity assumptions on $f(x)$, KKT conditions are sufficient.
(ii) Next, we consider the resolution of the MPCC formulation through two Lagrangian schemes. The
first is an ADMM scheme in which we prove that despite the overall nonconvexity, each ADMM subproblem
can be solved efficiently recognizing a hidden convexity property. Furthermore, every limit point
of the sequence produced by this scheme is a first-order KKT point and a local minimizer, under additional
conditions. (iii) The second algorithm is an augmented Lagrangian scheme in which the Lagrangian
subproblem is resolved by a proximal alternating algorithm. Under suitable boundedness requirements,
the sequence admits a limit point that satisfies the criticality requirement. Preliminary numerics
show that solutions of the ADMM scheme are near global in low dimensions and competitive against
other methods in high dimensions. Moreover, the augmented Lagrangian scheme often provides solutions
of comparable or better quality than the ADMM scheme at some computational cost. 