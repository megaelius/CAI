We study the interplay of two important issues on Bayesian model selection (BMS): censoring and
model misspecification. We consider additive accelerated failure time (AAFT), Cox proportional
hazards and probit models, and a more general concave log-likelihood structure. A fundamental
question is what solution can one hope BMS to provide, when (inevitably) models are misspecified.
We show that asymptotically BMS keeps any covariate with predictive power for either the outcome
or censoring times, and discards other covariates. Misspecification refers to assuming the wrong
model or functional effect on the response, including using a finite basis for a truly non-parametric
effect, or omitting truly relevant covariates. We argue for using simple models that are computationally
practical yet attain good power to detect potentially complex effects, despite misspecification.
Misspecification and censoring both have an asymptotically negligible effect on (suitably-defined)
false positives, but their impact on power is exponential. We portray these issues via simple descriptions
of early/late censoring and the drop in predictive accuracy due to misspecification. From a methods
point of view, we consider local priors and a novel structure that combines local and non-local priors
to enforce sparsity. We develop algorithms to capitalize on the AAFT tractability, approximations
to AAFT and probit likelihoods giving significant computational gains, a simple augmented Gibbs
sampler to hierarchically explore linear and non-linear effects, and an implementation in the
R package mombf. We illustrate the proposed methods and others based on likelihood penalties via
extensive simulations under misspecification and censoring. We present two applications concerning
the effect of gene expression on colon and breast cancer. 