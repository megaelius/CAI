We derive exponential finite-sample nonasymptotic deviation inequalities for the sample average
approximation (SAA) estimator's near-optimal solution set and optimal value. In that respect,
we give three contributions. First, our bounds do not require \emph{sub-Gaussian} assumptions
as in previous literature of stochastic optimization (SO). Instead, we just assume random H\"older
continuity and a \emph{heavy-tailed} distribution with finite 2nd moments, a framework more suited
for risk-averse portfolio optimization. Second, we derive new deviation inequalities for SO problems
with \emph{expected-valued stochastic constraints} which guarantee \emph{joint} near feasibility
and optimality in terms of the original problem. Unlike previous works, we do not assume a metric
regular (MR) \emph{solution set}, strong growth conditions on the objective nor an indirect problem
reformulation (such as penalization or first order conditions, both of which are often necessary
but not sufficient conditions). Instead, we just assume a MR \emph{feasible set}, making our analysis
general enough for many classes of problems. A finite-sample near feasibility and optimality deviation
is established for MR sets which are nonconvex or which are convex and \emph{non}-strictly feasible.
For strictly feasible convex sets, we obtain \emph{finite-sample} \emph{exact} feasibility
and near optimality guarantees. The feasible set's MR constant is an additional condition number.
For convex sets, we present \emph{localized} feasibility guarantees in terms of smaller metric
entropies. Third, we obtain a general uniform concentration inequality for heavy-tailed H\"older
continuous functions using empirical process theory. This is the main tool in our analysis but it
is also a result of independent interest. 