This paper presents a theory of optimization fabrics, second-order differential equations that
encode nominal behaviors on a space and can be used to define the behavior of a smooth optimizer. Optimization
fabrics can encode commonalities among optimization problems that reflect the structure of the
space itself, enabling smooth optimization processes to intelligently navigate each problem
even when optimizing simple naive potential functions. Importantly, optimization over a fabric
is inherently asymptotically stable. The majority of this paper is dedicated to the development
of a tool set for the design and use of a broad class of fabrics called geometric fabrics. Geometric
fabrics encode behavior as general nonlinear geometries which are covariant second-order differential
equations with a special homogeneity property that ensures their behavior is independent of the
system's speed through the medium. A class of Finsler Lagrangian energies can be used to both define
how these nonlinear geometries combine with one another and how they react when potential functions
force them from their nominal paths. Furthermore, these geometric fabrics are closed under the
standard operations of pullback and combination on a transform tree. For behavior representation,
this class of geometric fabrics constitutes a broad class of spectral semi-sprays (specs), also
known as Riemannian Motion Policies (RMPs) in the context of robotic motion generation, that captures
both the intuitive separation between acceleration policy and priority metric critical for modular
design and are inherently stable. Therefore, geometric fabrics are safe and easier to use by less
experienced behavioral designers. Application of this theory to policy representation and generalization
in learning are discussed as well. 