Recent applications of large network models to machine learning, and to neural network suggest
a need for a systematic study of the general correspondence, (i) discrete vs (ii) continuous. Even
if the starting point is (i), limit considerations lead to (ii), or, more precisely, to a measure
theoretic framework which we make precise. Our motivation derives from graph analysis, e.g., studies
of (infinite) electrical networks of resistors, but our focus will be (ii), i.e., the measure theoretic
setting. In electrical networks of resistors, one considers pairs (of typically countably infinite),
sets $V$ (vertices), $E$ (edges) a suitable subset of $V \times V$, and prescribed positive symmetric
functions $c$ on $E$ . A conductance function $c$ is defined on $E$ (edges), or on $V \times V$, but
with $E$ as its support. From an initial triple $(V, E, c)$ , one gets graph-Laplacians, generalized
Dirichlet spaces (also called energy Hilbert spaces), dipoles, relative reproducing kernel-theory,
dissipation spaces, reversible Markov chains, and more. Our main results include: spectral theory
and Green's functions for measure theoretic graph-Laplace operators; the theory of reproducing
kernel Hilbert spaces related to Laplace operators; a rigorous analysis of the Laplacian on Borel
equivalence relations; a new decomposition theory; irreducibility criteria; dynamical systems
governed by endomorphisms and measurable fields; orbit equivalence criteria; and path-space
measures and induced dissipation Hilbert spaces. We consider several applications of our results
to other fields such as machine learning problems, reproducing kernel Hilbert spaces, Gaussian
and determinantal processes, and joinings. 