Assume that $X_{\Sigma} \in \mathbb{R}^{n}$ is a centered random vector following a multivariate
normal distribution with positive definite covariance matrix $\Sigma$. Let $g : \mathbb{R}^{n}
\to \mathbb{C}$ be measurable and of moderate growth, say $|g(x)| \lesssim (1 + |x|)^{N}$. We show
that the map $\Sigma \mapsto \mathbb{E}[g(X_{\Sigma})]$ is smooth, and we derive convenient expressions
for its partial derivatives, in terms of certain expectations $\mathbb{E}[(\partial^{\alpha}g)(X_{\Sigma})]$
of partial (distributional) derivatives of $g$. As we discuss, this result can be used to derive
bounds for the expectation $\mathbb{E}[g(X_{\Sigma})]$ of a nonlinear function $g(X_{\Sigma})$
of a Gaussian random vector $X_{\Sigma}$ with possibly correlated entries. For the case when $g\left(x\right)
= g_{1}(x_{1}) \cdots g_{n}(x_{n})$ has tensor-product structure, the above result is known in
the engineering literature as Price's theorem, originally published in 1958. For dimension $n
= 2$, it was generalized in 1964 by McMahon to the general case $g : \mathbb{R}^{2} \to \mathbb{C}$.
Our contribution is to unify these results, and to give a mathematically fully rigorous proof. Precisely,
we consider a normally distributed random vector $X_{\Sigma} \in \mathbb{R}^{n}$ of arbitrary
dimension $n \in \mathbb{N}$, and we allow the nonlinearity $g$ to be a general tempered distribution.
To this end, we replace the expectation $\mathbb{E}\left[g(X_{\Sigma})\right]$ by the dual pairing
$\left\langle g,\,\phi_{\Sigma}\right\rangle_{\mathcal{S}',\mathcal{S}}$, where $\phi_{\Sigma}$
denotes the probability density function of $X_{\Sigma}$. 