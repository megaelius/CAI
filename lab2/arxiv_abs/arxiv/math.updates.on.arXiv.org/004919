Dependence measures based on reproducing kernel Hilbert spaces, also known as Hilbert-Schmidt
Independence Criterion and denoted HSIC, are widely used to statistically decide whether or not
two random vectors are dependent. Recently, non-parametric HSIC-based statistical tests of independence
have been performed. However, these tests lead to the question of the choice of the kernels associated
to the HSIC. In particular, there is as yet no method to objectively select specific kernels with
theoretical guarantees in terms of first and second kind errors. One of the main contributions of
this work is to develop a new HSIC-based aggregated procedure which avoids such a kernel choice,
and to provide theoretical guarantees for this procedure. To achieve this, we first introduce non-asymptotic
single tests based on Gaussian kernels with a given bandwidth, which are of prescribed level $\alpha
\in (0,1)$. From a theoretical point of view, we upper-bound their uniform separation rate of testing
over Sobolev and Nikol'skii balls. Then, we aggregate several single tests, and obtain similar
upper-bounds for the uniform separation rate of the aggregated procedure over the same regularity
spaces. Another main contribution is that we provide a lower-bound for the non-asymptotic minimax
separation rate of testing over Sobolev balls, and deduce that the aggregated procedure is adaptive
in the minimax sense over such regularity spaces. Finally, from a practical point of view, we perform
numerical studies in order to assess the efficiency of our aggregated procedure and compare it to
existing independence tests in the literature. 