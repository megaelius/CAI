In general coding theory, we often assume that error is observed in transferring or storing encoded
symbols, while the process of encoding itself is error-free. Motivated by recent applications
of coding theory, we introduce the problem of distributed encoding which comprises of a set of $K
\in \mathbb{N}$ isolated source nodes and $N \in \mathbb{N}$ encoding nodes. Each source node has
one symbol from a finite field, which is sent to each of the encoding nodes. Each encoding node stores
an encoded symbol from the same field, as a function of the received symbols. However, some of the
source nodes are controlled by the adversary and may send different symbols to different encoding
nodes. Depending on the number of adversarial nodes, denoted by $\beta \in \mathbb{N}$, and the
cardinality of the set of symbols that each one generates, denoted by $v \in \mathbb{N}$, this would
make the process of decoding from the encoded symbols impossible. Assume that a decoder connects
to an arbitrary subset of $t \in \mathbb{N}$ encoding nodes and wants to decode the symbols of the
honest nodes correctly, without necessarily identifying the sets of honest and adversarial nodes.
In this paper, we characterize $t^* \in \mathbb{N}$, as the minimum of such $t$, as a function of $K$,
$N$, $\beta$, and $v$. We show that for $\beta\geq 1, v\ge 2$, $t^*=K+\beta (v-1)+1$, if $N \geq K+\beta
(v-1)+1 $, and $t^*=N$, if $N \le K+\beta (v-1)$. In order to achieve $t^*$, we introduce a nonlinear
code. In continue, we focus on linear coding and show that $t^*_{\textrm{linear}}=K+2\beta(v-1)$,
if $N\ge K+2\beta(v-1)$, and $t^*_{\textrm{linear}}=N$, if $N\le K+2\beta(v-1)$. 