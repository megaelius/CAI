Enforcing sparse structure within learning has led to significant advances in the field of pure
data-driven discovery of dynamical systems. However, such methods require access not only to time-series
of the state of the dynamical system, but also the time derivative. This poses problems when dealing
with data polluted by noise, or when learning stochastic systems with non-differentiable solutions.
To overcome such limitations we propose a sparse learning methodology to discover the vector fields
defining a (possibly stochastic or partial) differential equation, using time-averaged statistics
derived from time-series data. Such a formulation of sparse learning naturally leads to a nonlinear
inverse problem to which we apply the methodology of ensemble Kalman inversion (EKI). EKI is chosen
because it may be formulated in terms of the iterative solution of quadratic optimization problems;
sparsity is then easily imposed. We then apply the EKI-based sparse learning methodology to various
examples governed by stochastic differential equations (a noisy Lorenz 63 system), ordinary differential
equations (Lorenz 96 system and coalescence equations), and a partial differential equation (the
Kuramoto-Sivashinsky equation). The results demonstrate that data-driven discovery of differential
equations can be achieved using sparse EKI with time-averaged statistics. The proposed sparse
learning methodology extends the scope of pure data-driven discovery of differential equations
to previously challenging applications and data-acquisition scenarios. Furthermore, although
we apply the method in the context of learning dynamical systems, the EKI-based sparse methodology
may be more widely applied within nonlinear inverse problems generally. 