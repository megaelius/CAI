We consider median regression and, more generally, a possibly infinite collection of quantile
regressions in high-dimensional sparse models. In these models the overall number of regressors
$p$ is very large, possibly larger than the sample size $n$, but only $s$ of these regressors have
non-zero impact on the conditional quantile of the response variable, where $s$ grows slower than
$n$. We consider quantile regression penalized by the $\ell_1$-norm of coefficients ($\ell_1$-QR).
First, we show that $\ell_1$-QR is consistent at the rate $\sqrt{s/n} \sqrt{\log p}$. The overall
number of regressors $p$ affects the rate only through the $\log p$ factor, thus allowing nearly
exponential growth in the number of zero-impact regressors. The rate result holds under relatively
weak conditions, requiring that $s/n$ converges to zero at a super-logarithmic speed and that regularization
parameter satisfies certain theoretical constraints. Second, we propose a pivotal, data-driven
choice of the regularization parameter and show that it satisfies these theoretical constraints.
Third, we show that $\ell_1$-QR correctly selects the true minimal model as a valid submodel, when
the non-zero coefficients of the true model are well separated from zero. We also show that the number
of non-zero coefficients in $\ell_1$-QR is of same stochastic order as $s$. Fourth, we analyze the
rate of convergence of a two-step estimator that applies ordinary quantile regression to the selected
model. Fifth, we evaluate the performance of $\ell_1$-QR in a Monte-Carlo experiment, and illustrate
its use on an international economic growth application. 