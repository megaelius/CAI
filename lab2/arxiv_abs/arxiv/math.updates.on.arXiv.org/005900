Feedback asymptotic stabilization of nonlinear control systems is an important topic of control
theory and applications. Broadly speaking, if the system $\dot{x} = f(x,u)$ is locally asymptotically
stabilizable, then there exists a feedback control $u(x)$ ensuring the convergence to an equilibrium
for any trajectory starting from a point sufficiently close to the equilibrium state. In this paper,
we develop a reasonably natural and general composition operator approach to stabilizability
of nonlinear systems. To begin with, we provide an extension of the classical Hautus lemma to the
generalized context of composition operators and show that Brockett's theorem is still necessary
for local asymptotic stabilizability in this generalized framework by using continuous operator
compositions. Further, we employ a powerful version of the implicit function theorem--as given
by Jittorntrum and Kumagai--to cover the situation where the system is stabilizable but only by
means of non-${\rm C}^{1}$ feedbacks. Under some injectivity criterion, this gives us a variety
of sufficient conditions for stabilizability via composition operators and characterizations
of what stabilizing controls must be like. Employing the obtained characterizations, we establish
relationships between stabilizability in the conventional sense and in the generalized composition
operator sense. Among other things, it gives us a stronger version of Coron's condition provided
that a certain conjecture is true. We conclude by arguing that this perspective is the `correct'
one to approach the problem of stabilizability for continuous-time dynamical systems. 