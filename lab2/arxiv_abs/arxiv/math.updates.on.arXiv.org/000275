The Gaussian graphical model has attracted great attention in recent years. This paper considers
a fundamental question: When is it possible to estimate low-dimensional parameters at parametric
square-root rate in a large Gaussian graphical model? A novel regression approach is proposed to
obtain asymptotically efficient estimation of each entry of a precision matrix under a sparseness
condition relative to the sample size. When the precision matrix is not sufficiently sparse, a lower
bound is established to show that it is no longer possible to achieve the parametric rate in the estimation
of each entry. This lower bound result, which provides an answer to the delicate sample size question,
is established with a novel construction of a subset of sparse precision matrices in an application
of Le Cam's Lemma. Moreover, the proposed estimator is proven to have optimal convergence rate when
the parametric rate cannot be achieved, under a minimal sample requirement. The proposed estimator
is applied to test the presence of an edge in the Gaussian graphical model or to recover the support
of the entire model, to obtain adaptive rate-optimal estimation of the entire precision matrix
as measured by the matrix $l_{q}$ operator norm, and to make inference in latent variables in the
graphical model. All these are achieved under a sparsity condition on the precision matrix and a
side condition on the range of its spectrum. This significantly relaxes the commonly imposed uniform
signal strength condition on the precision matrix, irrepresentable condition on the Hessian tensor
operator of the covariance matrix or the $\ell_{1}$ constraint on the precision matrix. Numerical
results confirm our theoretical findings. The ROC curve of the proposed algorithm, Asymptotic
Normal Thresholding (ANT), for support recovery significantly outperforms that of the popular
GLasso algorithm. 