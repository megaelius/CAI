Markov Random Field (MRF) models are powerful tools for contextual modelling in the study of complex
systems. However, little is known about how the spatial dependence between their elements is encoded
in terms of information-theoretic measures. In this paper, we enlight the connection between Fisher
information, Shannon entropy and spatial properties of the random field in case of Gaussian random
variables, by defining analytical expressions to compute local and global versions of these measures
using Besag's pseudo-likelihood function. The proposed expressions provide analytical tools
for the analysis of contextual patterns in data, allowing among other things, the detection of the
most informative ones. Besides, we show that from a statistical inference perspective these measures
are directly related to the uncertainty in the estimation of the global system behavior by means
of the asymptotic variance of the maximum pseudo-likelihood estimator of the spatial dependence
parameter. Moreover, the results indicate that the accuracy on the estimation of the global behavior
on GMRF's (inverse temperature) depends essentially on two quite intuitive conditions: concentration
of patterns with high local log-likelihood value (minimization of type-I Fisher information),
which means patterns "aligned" to the expected global behavior, and also concentration of patterns
showing high local log-likelihood curvature (maximization of type-II Fisher information), which
means stability. Inspired by these findings we defined L-information, a measure calculated by
the ratio of the first two derivatives of the log-pseudo-likelihood function regarding the spatial
dependence parameter on a MRF. Computational experiments show the effectiveness of the proposed
equations in the analysis of spatially dependent random variables. 