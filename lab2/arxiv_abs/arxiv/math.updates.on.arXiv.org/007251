In a Hilbert space $H$, in order to develop fast optimization methods, we analyze the asymptotic
behavior, as time $t$ tends to infinity, of inertial continuous dynamics where the damping acts
as a closed-loop control. The function $f: H \to R$ to be minimized (not necessarily convex) enters
the dynamic through it gradient, which is assumed to be Lipschitz continuous on the bounded subsets
of $H$. This gives autonomous dynamical systems with nonlinear damping and nonlinear driving force.
We first consider the case where the damping term $\partial \phi (\dot{x}(t))$ acts as a closed-loop
control of the velocity. The damping potential $\phi : H \to [0,+\infty)$ is a convex continuous
function which achieves its minimum at the origin. We show the existence and uniqueness of a global
solution to the associated Cauchy problem. Then, we analyze the asymptotic convergence properties
of the generated trajectories generated. We use techniques from optimization, control theory,
and PDE's: Lyapunov analysis based on the decreasing property of an energy-like function, quasi-gradient
and Kurdyka-Lojasiewicz theory, monotone operator theory for wave-like equations. Convergence
rates are obtained based on the geometric properties of the data $f$ and $\phi$. When $f$ is strongly
convex, we give general conditions which provide exponential convergence rates. Then, we extend
the results to the case where an additional Hessian-driven damping enters the dynamic, which reduces
the oscillations. Finally, we consider an inertial system involving jointly the velocity $\dot{x}(t)$
and the gradient $\nabla f(x(t))$. In addition to its original results, this work surveys the numerous
works devoted in recent years to the interaction between continuous damped inertial dynamics and
numerical algorithms for optimization, with the emphasis on autonomous systems, closed-loop
adaptive procedures, and convergence rates. 