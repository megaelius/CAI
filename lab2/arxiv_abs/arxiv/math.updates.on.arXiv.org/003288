Choosing an encoding over binary strings for input/output to/by a Turing Machine is usually straightforward
and/or inessential for discrete data (like graphs), but crucially affects the computability of
problems involving continuous data (like real numbers), and even more so their computational complexity.
We introduce 'quantitative admissibility' as condition for complexity-theoretically sensible
encodings of arbitrary compact metric spaces, a refinement of qualitative 'admissibility' due
to Kreitz and Weihrauch (1985): An admissible representation of a T$_0$ space $X$ is a (i) continuous
partial surjective mapping from the Cantor space of infinite binary sequences which is (ii) maximal
w.r.t. continuous reduction. By the Kreitz-Weihrauch (aka "Main") Theorem of computability over
continuous data, for fixed spaces $X,Y$ equipped with admissible representations, a function
$f:X\to Y$ is continuous iff it admits continuous a code-translating mapping on Cantor space, a
so-called REALIZER. We define a LINEARLY/POLYNOMIALLY admissible representation of a compact
metric space $(X,d)$ to have (i) asymptotically optimal modulus of continuity, namely close to
the entropy of $X$, and (ii) be maximal w.r.t. reduction having optimal modulus of continuity in
a similar sense. Careful constructions show the category of such representations to be Cartesian
closed, and non-empty: every compact $(X,d)$ admits a linearly-admissible representation. Moreover
such representations give rise to a tight quantitative correspondence between the modulus of continuity
of a function $f:X\to Y$ on the one hand and on the other hand that of its realizer: the MAIN THEOREM
of computational complexity. It suggests (how) to take into account the entropies of the spaces
under consideration when measuring algorithmic cost over continuous data. 