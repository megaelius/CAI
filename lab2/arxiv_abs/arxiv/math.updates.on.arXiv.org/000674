Our investigation concerns the estimation of predictive densities and a study of efficiency as
measured by the frequentist risk of such predictive densities with integrated $L_2$ and $L_1$ losses.
Our findings relate to a $p-$variate spherically symmetric observable $X \sim p_X(\|x-\mu\|^2)$
and the objective of estimating the density of $Y \sim q_Y(\|y-\mu\|^2)$ based on $X$. For $L_2$
loss, we describe Bayes estimation, minimum risk equivariant estimation (MRE), and minimax estimation.
We focus on the risk performance of the benchmark minimum risk equivariant estimator, plug-in estimators,
and plug-in type estimators with expanded scale. For the multivariate normal case, we make use of
a duality result with a point estimation problem bringing into play reflected normal loss. In three
of more dimensions (i.e., $p \geq 3$), we show that the MRE estimator is inadmissible under $L_2$
loss and provide dominating estimators. This brings into play Stein-type results for estimating
a multivariate normal mean with a loss which is a concave and increasing function of $\|\hat{\mu}-\mu\|^2$.
We also study the phenomenon of improvement on the plug-in density estimator of the form $q_Y(\|y-aX\|^2)\,,
0<a \leq 1\,,$ by a subclass of scale expansions $\frac{1}{c^p} \, q_Y(\|(y -aX)/c \|^2)$ with
$c>1$, showing in some cases, inevitably for large enough $p$, that all choices $c>1$ are
dominating estimators. Extensions are obtained for scale mixture of normals including a general
inadmissibility result of the MRE estimator for $p \geq 3$. Finally, we describe and expand on analogous
plug-in dominance results for spherically symmetric distributions with $p \geq 4$ under $L_1$
loss. 