In this work we provide a computationally tractable procedure for designing affine control policies,
applied to constrained, discrete-time, partially observable, linear systems subject to set bounded
disturbances, stochastic noise and potentially Markovian switching over a finite horizon. We
investigate the situation when performance specifications are expressed via averaged quadratic
inequalities on the random state-control trajectory. Our methodology also applies to steering
the density of the state-control trajectory under set bounded uncertainty. Our developments are
based on expanding the notion of affine policies that are functions of the so-called "purified outputs",
to the class of Markov jump linear systems. This re-parametrization of the set of policies, induces
a bi-affine structure in the state and control variables that can further be exploited via robust
optimization techniques, with the approximate inhomogeneous $S$-lemma being the cornerstone.
Tractability is understood in the sense that for each type of performance specification considered,
an explicit convex program for selecting the parameters specifying the control policy is provided.
Our contributions to the existing literature on the subject of robust constrained control lies
in the fact that we are addressing a wider class of systems than the ones already studied, by including
Markovian switching, and the consideration of quadratic inequalities rather than just linear
ones. Our work expands on the previous investigations on finite horizon covariance control by addressing
the robustness issue and the possibility that the full state may not be available, therefore enabling
the steering of the state-control trajectory density in the presence of disturbances under partial
observation. 