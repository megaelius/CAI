We propose a program for establishing a conjectural extension to the class of (origin-symmetric)
log-concave probability measures $\mu$, of the classical dual Sudakov Minoration on the expectation
of the supremum of a Gaussian process: \begin{equation} \label{eq:abstract} M(Z_p(\mu), C \int
||x||_K d\mu \cdot K) \leq \exp(C p) \;\;\, \forall p \geq 1 . \end{equation} Here $K$ is an origin-symmetric
convex body, $Z_p(\mu)$ is the $L_p$-centroid body associated to $\mu$, $M(A,B)$ is the packing-number
of $B$ in $A$, and $C > 0$ is a universal constant. The Program consists of first establishing a Weak
Generalized Dual Sudakov Minoration, involving the dimension $n$ of the ambient space, which is
then self-improved to a dimension-free estimate after applying a dimension-reduction step. The
latter step may be thought of as a conjectural "small-ball one-sided" variant of the Johnson--Lindenstrauss
dimension-reduction lemma. We establish the Weak Generalized Dual Sudakov Minoration for a variety
of log-concave probability measures and convex bodies (for instance, this step is fully resolved
assuming a positive answer to the Slicing Problem). The Separation Dimension-Reduction step is
fully established for ellipsoids and, up to logarithmic factors in the dimension, for cubes, resulting
in a corresponding Generalized (regular) Dual Sudakov Minoration estimate for these bodies and
arbitrary log-concave measures, which are shown to be (essentially) best-possible. Along the
way, we establish a regular version of (\ref{eq:abstract}) for all $p \geq n$ and provide a new direct
proof of Sudakov Minoration via The Program. 