Music Genre Classification is the problem of associating genre-related labels to digitized music
tracks. It has applications in the organization of commercial and personal music collections.
Often, music tracks are described as a set of timbre-inspired sound textures. In shallow-learning
systems, the total number of sound textures per track is usually too high, and texture downsampling
is necessary to make training tractable. Although previous work has solved this by linear downsampling,
no extensive work has been done to evaluate how texture selection benefits genre classification
in the context of the bag of frames track descriptions. In this paper, we evaluate the impact of frame
selection on automatic music genre classification in a bag of frames scenario. We also present a
novel texture selector based on K-Means aimed to identify diverse sound textures within each track.
We evaluated texture selection in diverse datasets, four different feature sets, as well as its
relationship to a univariate feature selection strategy. The results show that frame selection
leads to significant improvement over the single vector baseline on datasets consisting of full-length
tracks, regardless of the feature set. Results also indicate that the K-Means texture selector
achieves significant improvements over the baseline, using fewer textures per track than the commonly
used linear downsampling. The results also suggest that texture selection is complementary to
the feature selection strategy evaluated. Our qualitative analysis indicates that texture variety
within classes benefits model generalization. Our analysis shows that selecting specific audio
excerpts can improve classification performance, and it can be done automatically. 