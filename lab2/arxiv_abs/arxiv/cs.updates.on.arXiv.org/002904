During their first years of life, infants learn the language(s) of their environment at an amazing
speed despite large cross cultural variations in amount and complexity of the available language
input. Understanding this simple fact still escapes current cognitive and linguistic theories.
Recently, spectacular progress in the engineering science, notably, machine learning and wearable
technology, offer the promise of revolutionizing the study of cognitive development. Machine
learning offers powerful learning algorithms that can achieve human-like performance on many
linguistic tasks. Wearable sensors can capture vast amounts of data, which enable the reconstruction
of the sensory experience of infants in their natural environment. The project of 'reverse engineering'
language development, i.e., of building an effective system that mimics infant's achievements
appears therefore to be within reach. Here, we analyze the conditions under which such a project
can contribute to our scientific understanding of early language development. We argue that instead
of defining a sub-problem or simplifying the data, computational models should address the full
complexity of the learning situation, and take as input the raw sensory signals available to infants.
This implies that (1) accessible but privacy-preserving repositories of home data be setup and
widely shared, and (2) models be evaluated at different linguistic levels through a benchmark of
psycholinguist tests that can be passed by machines and humans alike, (3) linguistically and psychologically
plausible learning architectures be scaled up to real data using probabilistic/optimization
principles from machine learning. We discuss the feasibility of this approach and present preliminary
results. 