As wireless services and applications become more sophisticated and require faster and higher-capacity
networks, there is a need for an efficient management of the execution of increasingly complex tasks
based on the requirements of each application. In this regard, fog computing enables the integration
of virtualized servers into networks and brings cloud services closer to end devices. In contrast
to the cloud server, the computing capacity of fog nodes is limited and thus a single fog node might
not be capable of computing-intensive tasks. In this context, task offloading can be particularly
useful at the fog nodes by selecting the suitable nodes and proper resource management while guaranteeing
the Quality-of-Service (QoS) requirements of the users. This paper studies the design of a joint
task offloading and resource allocation control for heterogeneous service tasks in multi-fog
nodes systems. This problem is formulated as a partially observable stochastic game, in which each
fog node cooperates to maximize the aggregated local rewards while the nodes only have access to
local observations. To deal with partial observability, we apply a deep recurrent Q-network (DRQN)
approach to approximate the optimal value functions. The solution is then compared to a deep Q-network
(DQN) and deep convolutional Q-network (DCQN) approach to evaluate the performance of different
neural networks. Moreover, to guarantee the convergence and accuracy of the neural network, an
adjusted exploration-exploitation method is adopted. Provided numerical results show that the
proposed algorithm can achieve a higher average success rate and lower average overflow than baseline
methods. 