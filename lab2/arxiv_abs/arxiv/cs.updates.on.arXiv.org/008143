Electroencephalography (EEG) is another mode for performing Person Identification (PI). Due
to the nature of the EEG signals, EEG-based PI is typically done while the person is performing some
kind of mental task, such as motor control. However, few works have considered EEG-based PI while
the person is in different mental states (affective EEG). The aim of this paper is to improve the performance
of affective EEG-based PI using a deep learning approach. \textcolor{red}{We proposed a cascade
of deep learning using a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural
Networks (RNNs)}. CNNs are used to handle the spatial information from the EEG while RNNs extract
the temporal information. \textcolor{red}{We evaluated two types of RNNs, namely, Long Short-Term
Memory (CNN-LSTM) and Gated Recurrent Unit (CNN-GRU). } The proposed method is evaluated on the
state-of-the-art affective dataset DEAP. The results indicate that CNN-GRU and CNN-LSTM can perform
PI from different affective states and reach up to 99.90--100\% mean Correct Recognition Rate (CRR),
significantly outperforming a support vector machine (SVM) baseline system that uses power spectral
density (PSD) features. Notably, the 100\% mean \emph{CRR} comes from only 40 subjects in DEAP dataset.
To reduce the number of EEG electrodes from thirty-two to five for more practical applications,
the frontal region gives the best results reaching up to 99.17\% CRR (from CNN-GRU). Amongst the
two deep learning models, we find CNN-GRU to slightly outperform CNN-LSTM, while having faster
training time. \textcolor{red}{Furthermore, CNN-GRU overcomes the influence of affective states
in EEG-Based PI reported in the previous works. 