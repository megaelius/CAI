Interactive Educational Systems (IESs) have developed rapidly in recent years to address the issue
of quality and affordability of education. Analogous to other domains in AI, there are specific
tasks of AIEd for which labels are scarce. For instance, labels like exam score and grade are considered
important in educational and social context. However, obtaining the labels is costly as they require
student actions taken outside the system. Likewise, while student events like course dropout and
review correctness are automatically recorded by IESs, they are few in number as the events occur
sporadically in practice. A common way of circumventing the label-scarcity problem is the pre-train/fine-tine
method. Accordingly, existing works pre-train a model to learn representations of contents in
learning items. However, such methods fail to utilize the student interaction data available and
model student learning behavior. To this end, we propose assessment modeling, fundamental pre-training
tasks for IESs. An assessment is a feature of student-system interactions which can act as pedagogical
evaluation, such as student response correctness or timeliness. Assessment modeling is the prediction
of assessments conditioned on the surrounding context of interactions. Although it is natural
to pre-train interactive features available in large amount, narrowing down the prediction targets
to assessments holds relevance to the label-scarce educational problems while reducing irrelevant
noises. To the best of our knowledge, this is the first work investigating appropriate pre-training
method of predicting educational features from student-system interactions. While the effectiveness
of different combinations of assessments is open for exploration, we suggest assessment modeling
as a guiding principle for selecting proper pre-training tasks for the label-scarce educational
problems. 