Physical event detection has long been the domain of static event processors operating on numeric
sensor data. This works well for large scale strong-signal events such as hurricanes, and important
classes of events such as earthquakes. However, for a variety of domains there is insufficient sensor
coverage, e.g., landslides, wildfires, and flooding. Social networks have provided massive volume
of data from billions of users, but data from these generic social sensors contain much more noise
than physical sensors. One of the most difficult challenges presented by social sensors is \textit{concept
drift}, where the terms associated with a phenomenon evolve and change over time, rendering static
machine learning (ML) classifiers less effective. To address this problem, we develop the ASSED
(Adaptive Social Sensor Event Detection) framework with an ML-based event processing engine and
show how it can perform simple and complex physical event detection on strong- \textit{and} weak-signal
with low-latency, high scalability, and accurate coverage. Specifically, ASSED is a framework
to support continuous filter generation and updates with machine learning using streaming data
from high-confidence sources (physical and annotated sensors) and social networks. We build ASSED
to support procedures for integrating high-confidence sources into social sensor event detection
to generate high-quality filters and to perform dynamic filter selection by tracking its own performance.
We demonstrate ASSED capabilities through a landslide detection application that detects almost
350\% more landslides compared to static approaches. More importantly, ASSED automates the handling
of concept drift: four years after initial data collection and classifier training, ASSED achieves
event detection accuracy of 0.988 (without expert manual intervention), compared to 0.762 for
static approaches. 