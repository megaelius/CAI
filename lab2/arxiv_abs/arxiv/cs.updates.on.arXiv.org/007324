In this paper, we propose a novel quadratic optimized model based on the deep convolutional neural
network (QODCNN) for full-reference and no-reference screen content image (SCI) quality assessment.
Unlike traditional CNN methods taking all image patches as training data and using average quality
pooling, our model is optimized to obtain a more effective model including three steps. In the first
step, an end-to-end deep CNN is trained to preliminarily predict the image visual quality, and batch
normalized (BN) layers and l2 regularization are employed to improve the speed and performance
of network fitting. For second step, the pretrained model is fine-tuned to achieve better performance
under analysis of the raw training data. An adaptive weighting method is proposed in the third step
to fuse local quality inspired by the perceptual property of the human visual system (HVS) that the
HVS is sensitive to image patches containing texture and edge information. The novelty of our algorithm
can be concluded as follows: 1) with the consideration of correlation between local quality and
subjective differential mean opinion score (DMOS), the Euclidean distance is utilized to measure
effectiveness of image patches, and the pretrained model is fine-tuned with more effective training
data; 2) an adaptive pooling approach is employed to fuse patch quality of textual and pictorial
regions, whose feature only extracted from distorted images owns strong noise robust and effects
on both FR and NR IQA; 3) Considering the characteristics of SCIs, a deep and valid network architecture
is designed for both NR and FR visual quality evaluation of SCIs. Experimental results verify that
our model outperforms both current no-reference and full-reference image quality assessment
methods on the benchmark screen content image quality assessment database (SIQAD). 