Critical infrastructure systems such as electric power networks, water networks, and transportation
systems play a major role in the welfare of any community. In the aftermath of disasters, their recovery
is of paramount importance; orderly and efficient recovery involves the assignment of limited
resources (a combination of human repair workers and machines) to repair damaged infrastructure
components. The decision maker must also deal with uncertainty in the outcome of the resource-allocation
actions during recovery. The manual assignment of resources seldom is optimal despite the expertise
of the decision maker because of the large number of choices and uncertainties in consequences of
sequential decisions. This combinatorial assignment problem under uncertainty is known to be
\mbox{NP-hard}. We propose a novel decision technique that addresses the massive number of decision
choices for large-scale real-world problems; in addition, our method also features an experiential
learning component that adaptively determines the utilization of the computational resources
based on the performance of a small number of choices. Our framework is closed-loop, and naturally
incorporates all the attractive features of such a decision-making system. In contrast to myopic
approaches, which do not account for the future effects of the current choices, our methodology
has an anticipatory learning component that effectively incorporates \emph{lookahead} into
the solutions. To this end, we leverage the theory of regression analysis, Markov decision processes
(MDPs), multi-armed bandits, and stochastic models of community damage from natural disasters
to develop a method for near-optimal recovery of communities. Our method contributes to the general
problem of MDPs with massive action spaces with application to recovery of communities affected
by hazards. 