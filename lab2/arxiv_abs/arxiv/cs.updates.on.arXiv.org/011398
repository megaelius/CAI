Deep generative models have recently achieved impressive results for many real-world applications,
successfully generating high-resolution and diverse samples from complex datasets. Due to this
improvement, fake digital contents have proliferated growing concern and spreading distrust
in image content, leading to an urgent need for automated ways to detect these AI-generated fake
images. Despite the fact that many face editing algorithms seem to produce realistic human faces,
upon closer examination, they do exhibit artifacts in certain domains which are often hidden to
the naked eye. In this work, we present a simple way to detect such fake face images - so-called DeepFakes.
Our method is based on a classical frequency domain analysis followed by basic classifier. Compared
to previous systems, which need to be fed with large amounts of labeled data, our approach showed
very good results using only a few annotated training samples and even achieved good accuracies
in fully unsupervised scenarios. For the evaluation on high resolution face images, we combined
several public datasets of real and fake faces into a new benchmark: Faces-HQ. Given such high-resolution
images, our approach reaches a perfect classification accuracy of 100% when it is trained on as little
as 20 annotated samples. In a second experiment, in the evaluation of the medium-resolution images
of the CelebA dataset, our method achieves 100% accuracy supervised and 96% in an unsupervised setting.
Finally, evaluating a low-resolution video sequences of the FaceForensics++ dataset, our method
achieves 91% accuracy detecting manipulated videos. Source Code: https://github.com/cc-hpc-itwm/DeepFakeDetection
