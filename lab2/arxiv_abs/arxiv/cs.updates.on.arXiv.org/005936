Functions of one or more variables are usually approximated with a basis: a complete, linearly-independent
system of functions that spans a suitable function space. The topic of this paper is the numerical
approximation of functions using the more general notion of frames: that is, complete systems that
are generally redundant but provide infinite representations with bounded coefficients. While
frames are well-known in image and signal processing, coding theory and other areas of applied mathematics,
their use in numerical analysis is far less widespread. Yet, as we show via a series of examples, frames
are more flexible than bases, and can be constructed easily in a range of problems where finding orthonormal
bases with desirable properties (rapid convergence, high resolution power, etc.) is difficult
or impossible. A key concern when using frames is that computing a best approximation requires solving
an ill-conditioned linear system. Nonetheless, we construct a frame approximation via regularization
with bounded condition number (with respect to perturbations in the data), and which approximates
any function up to an error of order $\sqrt{\epsilon}$, or even of order $\epsilon$ with suitable
modifications. Here $\epsilon$ is a threshold value that can be chosen by the user. Crucially, rate
of decay of the error down to this level is determined by the existence of approximate representations
of $f$ in the frame possessing small-norm coefficients. We demonstrate the existence of such representations
in all of our examples. Overall, our analysis suggests that frames are a natural generalization
of bases in which to develop numerical approximation. In particular, even in the presence of severely
ill-conditioned linear systems, the frame condition imposes sufficient mathematical structure
in order to give rise to accurate, well-conditioned approximations. 