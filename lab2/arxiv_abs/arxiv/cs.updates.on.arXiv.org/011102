Properly modeling the latent image distributions always plays a key role in a variety of low-level
vision problems. Most existing approaches, such as Maximum A Posterior (MAP), aimed at establishing
optimization models with prior regularization to address this task. However, designing sophisticated
priors may lead to challenging optimization model and time-consuming iteration process. Recent
studies tried to embed learnable network architectures into the MAP scheme. Unfortunately, for
the MAP model with deeply trained priors, the exact behaviors and the inference process are actually
hard to investigate, due to their inexact and uncontrolled nature. In this work, by investigating
task-driven latent feasibility for the MAP-based model, we provide a new perspective to enforce
domain knowledge and data distributions to MAP-based image modeling. Specifically, we first introduce
an energy-based feasibility constraint to the given MAP model. By introducing the proximal gradient
updating scheme to the objective and performing an adaptive averaging process, we obtain a completely
new MAP inference process, named Proximal Average Optimization (PAO), for image modeling. Owning
to the flexibility of PAO, we can also incorporate deeply trained architectures into the feasibility
module. Finally, we provide a simple monotone descent-based control mechanism to guide the propagation
of PAO. We prove in theory that the sequence generated by both our PAO and its learning-based extension
can successfully converge to the critical point of the original MAP optimization task. We demonstrate
how to apply our framework to address different vision applications. Extensive experiments verify
the theoretical results and show the advantages of our method against existing state-of-the-art
approaches. 