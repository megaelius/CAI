As a generalization of the use of graphs to describe pairwise interactions, simplicial complexes
can be used to model higher-order interactions between three or more objects in complex systems.
There has been a recent surge in activity for the development of data analysis methods applicable
to simplicial complexes, including techniques based on computational topology, higher-order
random processes, generalized Cheeger inequalities, isoperimetric inequalities, and spectral
methods. In particular, spectral learning methods (e.g. label propagation and clustering) that
directly operate on simplicial complexes represent a new direction emerging from the confluence
of computational topology and machine learning. Similar to the challenges faced by massive graphs,
computational methods that process simplicial complexes are severely limited by computational
costs associated with massive datasets. To apply spectral methods in learning to massive datasets
modeled as simplicial complexes, we work towards the sparsification of simplicial complexes based
on preserving the spectrum of the associated Laplacian operators. We show that the theory of Spielman
and Srivastava for the sparsification of graphs extends to simplicial complexes via the up Laplacian.
In particular, we introduce a generalized effective resistance for simplexes; provide an algorithm
for sparsifying simplicial complexes at a fixed dimension; and give a specific version of the generalized
Cheeger inequality for weighted simplicial complexes. Finally, we demonstrate via experiments
the preservation of the up Laplacian during sparsification, as well as the utility of sparsification
with respect to spectral clustering. 