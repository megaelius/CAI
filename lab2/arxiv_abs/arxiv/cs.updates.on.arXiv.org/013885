We present a pipeline for geomorphological analysis that uses structure from motion (SfM) and deep
learning on close-range aerial imagery to estimate spatial distributions of rock traits (diameter,
size, and orientation) along a tectonic fault scarp. Unpiloted aircraft systems (UAS) have enabled
acquisition of high-resolution imagery at close range, revolutionizing domains such as infrastructure
inspection, precision agriculture, and disaster response. Our pipeline leverages UAS-based
imagery to help scientists gain a better understanding of tectonic surface processes. We start
by using SfM on aerial imagery to produce georeferenced orthomosaics and digital elevation models
(DEM), then a human expert annotates rocks on a set of image tiles sampled from the orthomosaics.
These annotations are used to train a deep neural network to detect and segment individual rocks
in the whole site. This pipeline automatically extracts semantic information (rock boundaries)
on large volumes of unlabeled, high-resolution aerial imagery, which allows subsequent structural
analysis and shape descriptors to result in estimates of rock diameter, size and orientation. We
present results of two experiments conducted along a fault scarp in the Volcanic Tablelands near
Bishop, California. We conducted the first experiment with a hexrotor and a multispectral camera
to produce a DEM and five spectral orthomosaics in red, green, blue, red edge (RE), and near infrared
(NIR). We then trained deep neural networks with different input channel combinations to study
the most effective learning method for inference. In the second experiment, we deployed a DJI Phantom
4 Pro equipped with an RGB camera, and focused on the spatial difference of rock-trait histograms
in a larger area. Although presented in the context of geology, our pipeline can be extended to a variety
of geomorphological analysis tasks in other domains. 