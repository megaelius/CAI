Recent studies, targeting Facebook, showed the tendency of users to interact with information
adhering to their preferred narrative and to ignore dissenting information. Primarily driven
by confirmation bias, users tend to join homogeneous and polarized clusters (echo chambers) where
they cooperate to frame and reinforce a like-minded system of beliefs, thus facilitating misinformation
cascades. To gain a deeper understanding of these phenomena, in this work we analyze the lexicons
used by the communities of users emerging on Facebook around two very conflicting narratives: science
and conspiracy. We show how the words exhibiting a significant differentiation in frequency from
one community to another, provide important insights about the kind of information processed by
the two groups of users and about the overall sentiment expressed in their comments. Furthermore,
by focusing on comment threads, a context of interaction mediated by the posts, we observe a strong
positive correlation between the lexical convergence of co-commenters and their number of interactions,
both in the case of co-commenters polarized towards the same content as well as in the case of co-commenters
with opposing polarization. Nevertheless, the analysis of how lexical convergence evolves through
time suggests that such a trend is a proxy of the emergence of collective identities in the case of
co-commenters polarized toward the same content, whereas during cross interactions it is more
likely due to the need for a common vocabulary to achieve communication than to real opinion convergence.
Nonetheless, the fact that even users with opposing views try to coordinate their lexical choices
when joining a discussion, suggests that a dialogue between competing parties is possible and indeed
it should be stimulated in an attempt to smooth polarization and to reduce both the risk and the consequences
of misinformation. 