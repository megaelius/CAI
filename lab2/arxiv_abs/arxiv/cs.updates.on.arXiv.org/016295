In this paper, we propose to use commercial off-the-shelf (COTS) monostatic RFID devices (i.e.
which use a single antenna at a time for both transmitting and receiving RFID signals to and from the
tags) to monitor browsing activity of customers in front of display items in places such as retail
stores. To this end, we propose TagSee, a multi-person imaging system based on monostatic RFID imaging.
TagSee is based on the insight that when customers are browsing the items on a shelf, they stand between
the tags deployed along the boundaries of the shelf and the reader, which changes the multi-paths
that the RFID signals travel along, and both the RSS and phase values of the RFID signals that the reader
receives change. Based on these variations observed by the reader, TagSee constructs a coarse grained
image of the customers. Afterwards, TagSee identifies the items that are being browsed by the customers
by analyzing the constructed images. The key novelty of this paper is on achieving browsing behavior
monitoring of multiple customers in front of display items by constructing coarse grained images
via robust, analytical model-driven deep learning based, RFID imaging. To achieve this, we first
mathematically formulate the problem of imaging humans using monostatic RFID devices and derive
an approximate analytical imaging model that correlates the variations caused by human obstructions
in the RFID signals. Based on this model, we then develop a deep learning framework to robustly image
customers with high accuracy. We implement TagSee scheme using a Impinj Speedway R420 reader and
SMARTRAC DogBone RFID tags. TagSee can achieve a TPR of more than ~90% and a FPR of less than ~10% in
multi-person scenarios using training data from just 3-4 users. 