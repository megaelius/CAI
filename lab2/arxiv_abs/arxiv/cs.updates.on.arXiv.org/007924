Hyperspectral images of land-cover captured by airborne or satellite-mounted sensors provide
a rich source of information about the chemical composition of the materials present in a given place.
This makes hyperspectral imaging an important tool for earth sciences, land-cover studies, and
military and strategic applications. However, the scarcity of labeled training examples and spatial
variability of spectral signature are two of the biggest challenges faced by hyperspectral image
classification. In order to address these issues, we aim to develop a framework for material-agnostic
information retrieval in hyperspectral images based on Positive-Unlabelled (PU) classification.
Given a hyperspectral scene, the user labels some positive samples of a material he/she is looking
for and our goal is to retrieve all the remaining instances of the query material in the scene. Additionally,
we require the system to work equally well for any material in any scene without the user having to
disclose the identity of the query material. This material-agnostic nature of the framework provides
it with superior generalization abilities. We explore two alternative approaches to solve the
hyperspectral image classification problem within this framework. The first approach is an adaptation
of non-negative risk estimation based PU learning for hyperspectral data. The second approach
is based on one-versus-all positive-negative classification where the negative class is approximately
sampled using a novel spectral-spatial retrieval model. We propose two annotator models - uniform
and blob - that represent the labelling patterns of a human annotator. We compare the performances
of the proposed algorithms for each annotator model on three benchmark hyperspectral image datasets
- Indian Pines, Pavia University and Salinas. 