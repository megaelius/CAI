Data inconsistency and bias are inevitable among different facial expression recognition (FER)
datasets due to subjective annotating process and different collecting conditions. Recent works
resort to adversarial mechanisms that learn domain-invariant features to mitigate domain shift.
However, most of these works focus on holistic feature adaptation, and they ignore local features
that are more transferable across different datasets. Moreover, local features carry more detailed
and discriminative content for expression recognition, and thus integrating local features may
enable fine-grained adaptation. In this work, we propose a novel Adversarial Graph Representation
Adaptation (AGRA) framework that unifies graph representation propagation with adversarial
learning for cross-domain holistic-local feature co-adaptation. To achieve this, we first build
a graph to correlate holistic and local regions within each domain and another graph to correlate
these regions across different domains. Then, we learn the per-class statistical distribution
of each domain and extract holistic-local features from the input image to initialize the corresponding
graph nodes. Finally, we introduce two stacked graph convolution networks to propagate holistic-local
feature within each domain to explore their interaction and across different domains for holistic-local
feature co-adaptation. In this way, the AGRA framework can adaptively learn fine-grained domain-invariant
features and thus facilitate cross-domain expression recognition. We conduct extensive and fair
experiments on several popular benchmarks and show that the proposed AGRA framework achieves superior
performance over previous state-of-the-art methods. 