Deep Convolutional Neural Networks (CNNs) are a special type of Neural Networks, which have shown
exemplary performance on several competitions related to Computer Vision and Image Processing.
Interesting application areas of CNN include Image Classification and Segmentation, Object Detection,
Video Processing, Natural Language Processing, Speech Recognition, etc. The powerful learning
ability of deep CNN is largely due to the use of multiple feature extraction stages that can automatically
learn representations from the data. Availability of a large amount of data and improvements in
the hardware technology have accelerated the research in CNNs, and recently very interesting deep
CNN architectures have been reported. In fact, several interesting ideas to bring advancements
in CNNs have been explored such as the use of different activation and loss functions, parameter
optimization, regularization, and architectural innovations. However, the major improvement
in representational capacity of the deep CNN is achieved through architectural innovations. Especially,
the idea of exploiting spatial and channel information, depth and width of architecture, and multi-path
information processing has gained substantial attention. Similarly, the idea of using a block
of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic
taxonomy present in the recently reported deep CNN architectures and consequently, classifies
the recent innovations in CNN architectures into seven different categories. These seven categories
are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel
boosting, and attention. Additionally, the elementary understanding of CNN components, current
challenges and applications of CNN are also provided. 