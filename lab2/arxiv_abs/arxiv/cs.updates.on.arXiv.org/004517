Face recognition (FR) systems for video surveillance (VS) applications attempt to accurately
detect the presence of target individuals over a distributed network of cameras. In video-based
FR systems, facial models of target individuals are designed a priori during enrollment using a
limited number of reference still images or video data. These facial models are not typically representative
of faces being observed during operations due to large variations in illumination, pose, scale,
occlusion, blur, and to camera inter-operability. Specifically, in still-to-video FR application,
a single high-quality reference still image captured with still camera under controlled conditions
is employed to generate a facial model to be matched later against lower-quality faces captured
with video cameras under uncontrolled conditions. Current video-based FR systems can perform
well on controlled scenarios, while their performance is not satisfactory in uncontrolled scenarios
mainly because of the differences between the source (enrollment) and the target (operational)
domains. Most of the efforts in this area have been toward the design of robust video-based FR systems
in unconstrained surveillance environments. This chapter presents an overview of recent advances
in still-to-video FR scenario through deep convolutional neural networks (CNNs). In particular,
deep learning architectures proposed in the literature based on triplet-loss function (e.g.,
cross-correlation matching CNN, trunk-branch ensemble CNN and HaarNet) and supervised autoencoders
(e.g., canonical face representation CNN) are reviewed and compared in terms of accuracy and computational
complexity. 