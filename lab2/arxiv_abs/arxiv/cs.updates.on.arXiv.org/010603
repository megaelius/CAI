State of the art algorithms for many pattern recognition problems rely on deep network models. Training
these models requires a large labeled dataset and considerable computational resources. Also,
it is difficult to understand the working of these learned models, limiting their use in some critical
applications. Towards addressing these limitations, our architecture draws inspiration from
research in cognitive systems, and integrates the principles of commonsense logical reasoning,
inductive learning, and deep learning. In the context of answering explanatory questions about
scenes and the underlying classification problems, the architecture uses deep networks for extracting
features from images and for generating answers to queries. Between these deep networks, it embeds
components for non-monotonic logical reasoning with incomplete commonsense domain knowledge,
and for decision tree induction. It also incrementally learns and reasons with previously unknown
constraints governing the domain's states. We evaluated the architecture in the context of datasets
of simulated and real-world images, and a simulated robot computing, executing, and providing
explanatory descriptions of plans. Experimental results indicate that in comparison with an ``end
to end'' architecture of deep networks, our architecture provides better accuracy on classification
problems when the training dataset is small, comparable accuracy with larger datasets, and more
accurate answers to explanatory questions. Furthermore, incremental acquisition of previously
unknown constraints improves the ability to answer explanatory questions, and extending non-monotonic
logical reasoning to support planning and diagnostics improves the reliability and efficiency
of computing and executing plans on a simulated robot. 