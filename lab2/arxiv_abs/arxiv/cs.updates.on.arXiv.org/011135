Throughout the course of my Ph.D., I have been designing the user experience (UX) of various machine
learning (ML) systems. In this workshop, I share two projects as case studies in which people engage
with ML in much more complicated and nuanced ways than the technical HCML work might assume. The first
case study describes how cardiology teams in three hospitals used a clinical decision-support
system that helps them decide whether and when to implant an artificial heart to a heart failure patient.
I demonstrate that physicians cannot draw on their decision-making experience by seeing only patient
data on paper. They are also confused by some fundamental premises upon which ML operates. For example,
physicians asked: Are ML predictions made based on clinicians' best efforts? Is it ethical to make
decisions based on previous patients' collective outcomes? In the second case study, my collaborators
and I designed an intelligent text editor, with the goal of improving authors' writing experience
with NLP (Natural Language Processing) technologies. We prototyped a number of generative functionalities
where the system provides phrase-or-sentence-level writing suggestions upon user request. When
writing with the prototype, however, authors shared that they need to "see where the sentence is
going two paragraphs later" in order to decide whether the suggestion aligns with their writing;
Some even considered adopting machine suggestions as plagiarism, therefore "is simply wrong".
By sharing these unexpected and intriguing responses from these real-world ML users, I hope to start
a discussion about such previously-unknown complexities and nuances of -- as the workshop proposal
states -- "putting ML at the service of people in a way that is accessible, useful, and trustworthy
to all". 