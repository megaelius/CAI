This paper presents our method for enabling a UAV quadrotor, equipped with a monocular camera, to
autonomously avoid collisions with obstacles in unstructured and unknown indoor environments.
When compared to obstacle avoidance in ground vehicular robots, UAV navigation brings in additional
challenges because the UAV motion is no more constrained to a well-defined indoor ground or street
environment. Horizontal structures in indoor and outdoor environments like decorative items,
furnishings, ceiling fans, sign-boards, tree branches etc., also become relevant obstacles unlike
those for ground vehicular robots. Thus, methods of obstacle avoidance developed for ground robots
are clearly inadequate for UAV navigation. Current control methods using monocular images for
UAV obstacle avoidance are heavily dependent on environment information. These controllers do
not fully retain and utilize the extensively available information about the ambient environment
for decision making. We propose a deep reinforcement learning based method for UAV obstacle avoidance
(OA) and autonomous exploration which is capable of doing exactly the same. The crucial idea in our
method is the concept of partial observability and how UAVs can retain relevant information about
the environment structure to make better future navigation decisions. Our OA technique uses recurrent
neural networks with temporal attention and provides better results compared to prior works in
terms of distance covered during navigation without collisions. In addition, our technique has
a high inference rate (a key factor in robotic applications) and is energy-efficient as it minimizes
oscillatory motion of UAV and reduces power wastage. 