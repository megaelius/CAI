In January 2019, YouTube announced it would exclude potentially harmful content from video recommendations
but allow such videos to remain on the platform. While this step intends to reduce YouTube's role
in propagating such content, continued availability of these videos in other online spaces makes
it unclear whether this compromise actually reduces their spread. To assess this impact, we apply
interrupted time series models to measure whether different types of YouTube sharing in Twitter
and Reddit changed significantly in the eight months around YouTube's announcement. We evaluate
video sharing across three curated sets of potentially harmful, anti-social content: a set of conspiracy
videos that have been shown to experience reduced recommendations in YouTube, a larger set of videos
posted by conspiracy-oriented channels, and a set of videos posted by alternative influence network
(AIN) channels. As a control, we also evaluate effects on video sharing in a dataset of videos from
mainstream news channels. Results show conspiracy-labeled and AIN videos that have evidence of
YouTube's de-recommendation experience a significant decreasing trend in sharing on both Twitter
and Reddit. For videos from conspiracy-oriented channels, however, we see no significant effect
in Twitter but find a significant increase in the level of conspiracy-channel sharing in Reddit.
For mainstream news sharing, we actually see an increase in trend on both platforms, suggesting
YouTube's suppressing particular content types has a targeted effect. This work finds evidence
that reducing exposure to anti-social videos within YouTube, without deletion, has potential
pro-social, cross-platform effects. At the same time, increases in the level of conspiracy-channel
sharing raise concerns about content producers' responses to these changes, and platform transparency
is needed to evaluate these effects further. 