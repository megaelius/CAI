In this work, we explore the possibility of decoding Imagined Speech brain waves using machine learning
techniques. We propose a covariance matrix of Electroencephalogram channels as input features,
projection to tangent space of covariance matrices for obtaining vectors from covariance matrices,
principal component analysis for dimension reduction of vectors, an artificial feed-forward
neural network as a classification model and bootstrap aggregation for creating an ensemble of
neural network models. After the classification, two different Finite State Machines are designed
that create an interface for controlling a computer system using an Imagined Speech-based BCI system.
The proposed approach is able to decode the Imagined Speech signal with a maximum mean classification
accuracy of 85% on binary classification task of one long word and a short word. We also show that our
proposed approach is able to differentiate between imagined speech brain signals and rest state
brain signals with maximum mean classification accuracy of 94%. We compared our proposed method
with other approaches for decoding imagined speech and show that our approach performs equivalent
to the state of the art approach on decoding long vs. short words and outperforms it significantly
on the other two tasks of decoding three short words and three vowels with an average margin of 11%
and 9%, respectively. We also obtain an information transfer rate of 21-bits-per-minute when using
an IS based system to operate a computer. These results show that the proposed approach is able to
decode a wide variety of imagined speech signals without any human-designed features. 