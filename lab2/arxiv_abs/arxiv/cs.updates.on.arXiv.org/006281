Building meaningful interoperation with external software units requires performing the conceptual
interoperability analysis that starts with identifying the conceptual interoperability constraints
of each software unit, then it compares the systems' constraints to detect their conceptual mismatch.
We call the conceptual interoperability constraints (the COINs) that can be of different types
including structure, dynamic, and quality. Missing such constraints may lead to unexpected mismatches,
expensive resolution, and running-late projects. However, it is a challenging task for software
architects and analysts to manually analyze the unstructured text in API documents to identify
the COINs. Not only it is a tedious and time-consuming task, but also it needs knowledge about the
constraint types. In this article, we present and evaluate our idea of utilizing machine learning
techniques in automating the COIN identification, which is the first step of conceptual interoperability
analysis, from human text in API documents. Our empirical research started with a multiple-case
study to build the ground truth dataset, on which we contributed our machine learning COIN-Classification
Model. We show the model's robustness through experiments using different machine learning text-classification
algorithms. The experiments' results revealed that our model can achieve up to 87% accuracy in automatically
identifying the COINs in text. Thus, we implemented a tool that embeds our model to demonstrate its
practical value in industrial context. Then, we evaluated the practitioners' acceptance for the
tool and found that they significantly agreed on its usefulness and ease of use. 