Human flexible cognition and behavior indicate that the human brain can effectively use its internal
feature representations acquired through limited experiences for new experiences in different
domains. This function is analogous to transfer learning (TL) in the field of machine learning.
TL uses a well-trained feature space in a specific task domain to improve performance in new tasks
with insufficient training data. TL with rich feature representations, such as features of convolutional
neural networks (CNNs), shows high generalization ability across different task domains. However,
such TL is still insufficient in making machine learning attain generalization ability comparable
to that of the human brain. To address this, we introduce a method for TL mediated by human brains to
improve the performance of TL especially on pattern recognition in which human high-level cognition
is considered. Our method transforms feature representations of audiovisual inputs in CNNs into
those in activation patterns of individual brains via their association learned ahead using measured
brain responses. Then, to estimate labels reflecting human cognition and behavior induced by the
audiovisual inputs, the transformed representations are used for TL. We demonstrate that our brain-mediated
TL (BTL) shows higher performance in the label estimation than the standard TL. In addition, we illustrate
that the estimations mediated by different brains vary from brain to brain, and the variability
reflects the individual variability in perception. Thus, our BTL provides a framework to improve
the generalization ability of machine-learning feature representations and enable machine learning
to estimate human-like cognition and behavior, including individual variability. 