Trained machine learning models are increasingly used to perform high-impact tasks in areas such
as law enforcement, medicine, education, and employment. In order to clarify the intended use cases
of machine learning models and minimize their usage in contexts for which they are not well suited,
we recommend that released models be accompanied by documentation detailing their performance
characteristics. In this paper, we propose a framework that we call model cards, to encourage such
transparent model reporting. Model cards are short documents accompanying trained machine learning
models that provide benchmarked evaluation in a variety of conditions, such as across different
cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick
skin type) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that
are relevant to the intended application domains. Model cards also disclose the context in which
models are intended to be used, details of the performance evaluation procedures, and other relevant
information. While we focus primarily on human-centered machine learning models in the application
fields of computer vision and natural language processing, this framework can be used to document
any trained machine learning model. To solidify the concept, we provide cards for two supervised
models: One trained to detect smiling faces in images, and one trained to detect toxic comments in
text. We propose model cards as a step towards the responsible democratization of machine learning
and related AI technology, increasing transparency into how well AI technology works. We hope this
work encourages those releasing trained machine learning models to accompany model releases with
similar detailed evaluation numbers and other relevant documentation. 