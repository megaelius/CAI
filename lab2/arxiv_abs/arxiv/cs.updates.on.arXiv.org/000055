Parallel computing using accelerators has gained widespread research attention in the past few
years. In particular, using GPUs for general purpose computing has brought forth several success
stories with respect to time taken, cost, power, and other metrics. However, accelerator based
computing has signifi- cantly relegated the role of CPUs in computation. As CPUs evolve and also
offer matching computational resources, it is important to also include CPUs in the computation.
We call this the hybrid computing model. Indeed, most computer systems of the present age offer a
degree of heterogeneity and therefore such a model is quite natural. We reevaluate the claim of a
recent paper by Lee et al.(ISCA 2010). We argue that the right question arising out of Lee et al. (ISCA
2010) should be how to use a CPU+GPU platform efficiently, instead of whether one should use a CPU
or a GPU exclusively. To this end, we experiment with a set of 13 diverse workloads ranging from databases,
image processing, sparse matrix kernels, and graphs. We experiment with two different hybrid platforms:
one consisting of a 6-core Intel i7-980X CPU and an NVidia Tesla T10 GPU, and another consisting of
an Intel E7400 dual core CPU with an NVidia GT520 GPU. On both these platforms, we show that hybrid
solutions offer good advantage over CPU or GPU alone solutions. On both these platforms, we also
show that our solutions are 90% resource efficient on average. Our work therefore suggests that
hybrid computing can offer tremendous advantages at not only research-scale platforms but also
the more realistic scale systems with significant performance gains and resource efficiency to
the large scale user community. 