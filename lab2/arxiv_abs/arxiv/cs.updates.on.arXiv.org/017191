Experts in Artificial Intelligence (AI) development predict that advances in the development
of intelligent systems and agents will reshape vital areas in our society. Nevertheless, if such
an advance is not made prudently and critically, reflexively, it can result in negative outcomes
for humanity. For this reason, several researchers in the area have developed a robust, beneficial,
and safe concept of AI for the preservation of humanity and the environment. Currently, several
of the open problems in the field of AI research arise from the difficulty of avoiding unwanted behaviors
of intelligent agents and systems, and at the same time specifying what we really want such systems
to do, especially when we look for the possibility of intelligent agents acting in several domains
over the long term. It is of utmost importance that artificial intelligent agents have their values
aligned with human values, given the fact that we cannot expect an AI to develop human moral values
simply because of its intelligence, as discussed in the Orthogonality Thesis. Perhaps this difficulty
comes from the way we are addressing the problem of expressing objectives, values, and ends, using
representational cognitive methods. A solution to this problem would be the dynamic approach proposed
by Dreyfus, whose phenomenological philosophy shows that the human experience of being-in-the-world
in several aspects is not well represented by the symbolic or connectionist cognitive method, especially
in regards to the question of learning values. A possible approach to this problem would be to use
theoretical models such as SED (situated embodied dynamics) to address the values learning problem
in AI. 