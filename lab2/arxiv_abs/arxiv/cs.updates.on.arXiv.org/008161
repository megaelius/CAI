Emotions play a crucial role in human interaction, health care and security investigations and
monitoring. Automatic emotion recognition (AER) using electroencephalogram (EEG) signals is
an effective method for decoding the real emotions, which are independent of body gestures, but
it is a challenging problem. Several automatic emotion recognition systems have been proposed,
which are based on traditional hand-engineered approaches and their performances are very poor.
Motivated by the outstanding performance of deep learning (DL) in many recognition tasks, we introduce
an AER system (Deep-AER) based on EEG brain signals using DL. A DL model involves a large number of
learnable parameters, and its training needs a large dataset of EEG signals, which is difficult
to acquire for AER problem. To overcome this problem, we proposed a lightweight pyramidal one-dimensional
convolutional neural network (LP-1D-CNN) model, which involves a small number of learnable parameters.
Using LP-1D-CNN, we build a two level ensemble model. In the first level of the ensemble, each channel
is scanned incrementally by LP-1D-CNN to generate predictions, which are fused using majority
vote. The second level of the ensemble combines the predictions of all channels of an EEG signal using
majority vote for detecting the emotion state. We validated the effectiveness and robustness of
Deep-AER using DEAP, a benchmark dataset for emotion recognition research. The results indicate
that FRONT plays dominant role in AER and over this region, Deep-AER achieved the accuracies of 98.43%
and 97.65% for two AER problems, i.e., high valence vs low valence (HV vs LV) and high arousal vs low
arousal (HA vs LA), respectively. The comparison reveals that Deep-AER outperforms the state-of-the-art
systems with large margin. The Deep-AER system will be helpful in monitoring for health care and
security investigations. 