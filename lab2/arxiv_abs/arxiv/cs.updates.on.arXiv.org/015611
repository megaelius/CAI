Many people struggling with mental health issues are unable to access adequate care due to high costs
and a shortage of mental health professionals, leading to a global mental health crisis. Online
mental health communities can help mitigate this crisis by offering a scalable, easily accessible
alternative to in-person sessions with therapists or support groups. However, people seeking
emotional or psychological support online may be especially vulnerable to the kinds of antisocial
behavior that sometimes occur in online discussions. Moderation can improve online discourse
quality, but we lack an understanding of its effects on online mental health conversations. In this
work, we leveraged a natural experiment, occurring across 200,000 messages from 7,000 conversations
hosted on a mental health mobile application, to evaluate the effects of moderation on online mental
health discussions. We found that participation in group mental health discussions led to improvements
in psychological perspective, and that these improvements were larger in moderated conversations.
The presence of a moderator increased user engagement, encouraged users to discuss negative emotions
more candidly, and dramatically reduced bad behavior among chat participants. Moderation also
encouraged stronger linguistic coordination, which is indicative of trust building. In addition,
moderators who remained active in conversations were especially successful in keeping conversations
on topic. Our findings suggest that moderation can serve as a valuable tool to improve the efficacy
and safety of online mental health conversations. Based on these findings, we discuss implications
and trade-offs involved in designing effective online spaces for mental health support. 