Object detection and semantic segmentation are two main themes in object retrieval from high-resolution
remote sensing images, which have recently achieved remarkable performance by surfing the wave
of deep learning and, more notably, convolutional neural networks (CNNs). In this paper, we are
interested in a novel, more challenging problem of vehicle instance segmentation, which entails
identifying, at a pixel-level, where the vehicles appear as well as associating each pixel with
a physical instance of a vehicle. In contrast, vehicle detection and semantic segmentation each
only concern one of the two. We propose to tackle this problem with a semantic boundary-aware multi-task
learning network. More specifically, we utilize the philosophy of residual learning (ResNet)
to construct a fully convolutional network that is capable of harnessing multi-level contextual
feature representations learned from different residual blocks. We theoretically analyze and
discuss why residual networks can produce better probability maps for pixel-wise segmentation
tasks. Then, based on this network architecture, we propose a unified multi-task learning network
that can simultaneously learn two complementary tasks, namely, segmenting vehicle regions and
detecting semantic boundaries. The latter subproblem is helpful for differentiating closely
spaced vehicles, which are usually not correctly separated into instances. Currently, datasets
with pixel-wise annotation for vehicle extraction are ISPRS dataset and IEEE GRSS DFC2015 dataset
over Zeebrugge, which specializes in semantic segmentation. Therefore, we built a new, more challenging
dataset for vehicle instance segmentation, called the Busy Parking Lot UAV Video dataset, and we
make our dataset available at this http URL so that it can be used to benchmark future vehicle instance
segmentation algorithms. 