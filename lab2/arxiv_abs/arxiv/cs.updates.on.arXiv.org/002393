Machine learning and computer vision have driven many of the greatest advances in the modeling of
Deep Convolutional Neural Networks (DCNNs). Nowadays, most of the research has been focused on
improving recognition accuracy with better DCNN models and learning approaches. The recurrent
convolutional approach is not applied very much, other than in a few DCNN architectures. On the other
hand, Inception-v4 and Residual networks have promptly become popular among computer the vision
community. In this paper, we introduce a new DCNN model called the Inception Recurrent Residual
Convolutional Neural Network (IRRCNN), which utilizes the power of the Recurrent Convolutional
Neural Network (RCNN), the Inception network, and the Residual network. This approach improves
the recognition accuracy of the Inception-residual network with same number of network parameters.
In addition, this proposed architecture generalizes the Inception network, the RCNN, and the Residual
network with significantly improved training accuracy. We have empirically evaluated the performance
of the IRRCNN model on different benchmarks including CIFAR-10, CIFAR-100, TinyImageNet-200,
and CU3D-100. The experimental results show higher recognition accuracy against most of the popular
DCNN models including the RCNN. We have also investigated the performance of the IRRCNN approach
against the Equivalent Inception Network (EIN) and the Equivalent Inception Residual Network
(EIRN) counterpart on the CIFAR-100 dataset. We report around 4.53%, 4.49% and 3.56% improvement
in classification accuracy compared with the RCNN, EIN, and EIRN on the CIFAR-100 dataset respectively.
Furthermore, the experiment has been conducted on the TinyImageNet-200 and CU3D-100 datasets
where the IRRCNN provides better testing accuracy compared to the Inception Recurrent CNN (IRCNN),
the EIN, and the EIRN. 