Time series classification (TSC) is a challenging task that attracted many researchers in the last
few years. One main challenge in TSC is the diversity of domains where time series data come from.
Thus, there is no "one model that fits all" in TSC. Some algorithms are very accurate in classifying
a specific type of time series when the whole series is considered, while some only target the existence/non-existence
of specific patterns/shapelets. Yet other techniques focus on the frequency of occurrences of
discriminating patterns/features. This paper presents a new classification technique that addresses
the inherent diversity problem in TSC using a nature-inspired method. The technique is stimulated
by how flies look at the world through "compound eyes" that are made up of thousands of lenses, called
ommatidia. Each ommatidium is an eye with its own lens, and thousands of them together create a broad
field of vision. The developed technique similarly uses different lenses and representations
to look at the time series, and then combines them for broader visibility. These lenses have been
created through hyper-parameterisation of symbolic representations (Piecewise Aggregate and
Fourier approximations). The algorithm builds a random forest for each lens, then performs soft
dynamic voting for classifying new instances using the most confident eyes, i.e, forests. We evaluate
the new technique, coined Co-eye, using the recently released extended version of UCR archive,
containing more than 100 datasets across a wide range of domains. The results show the benefits of
bringing together different perspectives reflecting on the accuracy and robustness of Co-eye
in comparison to other state-of-the-art techniques. 