Learning by Demonstration provides a sample efficient way to equip robots with complex sensorimotor
skills in supervised manner. Several movement primitive representations can be used for flexible
motor representation and learning. A recent state-of-the art approach is Conditional Neural Movement
Primitives (CNMP) that can learn non-linear relations between environment parameters and complex
multi-modal trajectories from a few expert demonstrations by forming powerful latent space representations.
In this study, to improve the applicability of CNMP to changing tasks and/or environments, we couple
it with a reinforcement learning agent that exploits the formed representations by the original
CNMP network, and learns to generate synthetic demonstrations for further learning. This enables
the CNMP network to generalize to new environments by adapting its internal representations. In
the current implementation, the reinforcement learning agent is triggered when a failure in task
execution is detected, and the CNMP is trained with the newly discovered demonstration (trajectory),
which shares essential characteristics with the original demonstrations due to the representation
sharing. As a result, the overall system increases its capacity and handle situations in scenarios
where the initial CNMP network can not produce a useful trajectory. To show the validity of our proposed
model, we compare our approach with original CNMP work and other movement primitives approaches.
Furthermore, we presents the experimental results from the implementation of the proposed model
on real robotics setups, which indicate the applicability of our approach as an effective adaptive
learning by demonstration system. 