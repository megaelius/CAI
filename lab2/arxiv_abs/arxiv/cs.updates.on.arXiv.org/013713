User reviews reflect significant value of product in the world of e-market. Many firms or product
providers hire spammers for misleading new customers by posting spam reviews. There are three types
of fake reviews, untruthful reviews, brand reviews and non-reviews. All three types mislead the
new customers. A multinomial organization "Yelp" is separating fake reviews from non-fake reviews
since last decade. However, there are many e-commerce sites which do not filter fake and non-fake
reviews separately. Automatic fake review detection is focused by researcher for last ten years.
Many approaches and feature set are proposed for improving classification model of fake review
detection. There are two types of dataset commonly used in this research area: psuedo fake and real
life reviews. Literature reports low performance of classification model real life dataset if
compared with pseudo fake reviews. After investigation behavioral and contextual features are
proved important for fake review detection Our research has exploited important behavioral feature
of reviewer named as "reviewer deviation". Our study comprises of investigating reviewer deviation
with other contextual and behavioral features. We empirically proved importance of selected feature
set for classification model to identify fake reviews. We ranked features in selected feature set
where reviewer deviation achieved ninth rank. To assess the viability of selected feature set we
scaled dataset and concluded that scaling dataset can improve recall as well as accuracy. Our selected
feature set contains a contextual feature which capture text similarity between reviews of a reviewer.
We experimented on NNC, LTC and BM25 term weighting schemes for calculating text similarity of reviews.
We report that BM25 outperformed other term weighting scheme. 