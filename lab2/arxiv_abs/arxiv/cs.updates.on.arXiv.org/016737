Greenhouse segmentation has pivotal importance for climate-smart agricultural land-use planning.
Deep learning-based approaches provide state-of-the-art performance in natural image segmentation.
However, semantic segmentation on high-resolution optical satellite imagery is a challenging
task because of the complex environment. In this paper, a sound methodology is proposed for pixel-wise
classification on images acquired by the Azersky (SPOT-7) optical satellite. In particular, customized
variations of U-Net-like architectures are employed to identify greenhouses. Two models are proposed
which uniquely incorporate dilated convolutions and skip connections, and the results are compared
to that of the baseline U-Net model. The dataset used consists of pan-sharpened orthorectified
Azersky images (red, green, blue,and near infrared channels) with 1.5-meter resolution and annotation
masks, collected from 15 regions in Azerbaijan where the greenhouses are densely congested. The
images cover the cumulative area of 1008 $km^2$ and annotation masks contain 47559 polygons in total.
The $F_1, Kappa, AUC$, and $IOU$ scores are used for performance evaluation. It is observed that
the use of the deconvolutional layers alone throughout the expansive path does not yield satisfactory
results; therefore, they are either replaced or coupled with bilinear interpolation. All models
benefit from the hard example mining (HEM) strategy. It is also reported that the best accuracy of
$93.29\%$ ($F_1\,score$) is recorded when the weighted binary cross-entropy loss is coupled with
the dice loss. Experimental results showed that both of the proposed models outperformed the baseline
U-Net architecture such that the best model proposed scored $4.48\%$ higher in comparison to the
baseline architecture. 