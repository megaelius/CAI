In biomedical research many different types of patient data can be collected, including various
types of omics data and medical imaging modalities. Applying multi-view learning to these different
sources of information can increase the accuracy of medical classification models compared with
single-view procedures. However, the collection of biomedical data can be expensive and taxing
on patients, so that superfluous data collection should be avoided. It is therefore necessary to
develop multi-view learning methods which can accurately identify the views most important for
prediction. In recent years, several biomedical studies have used an approach known as multi-view
stacking (MVS), where a model is trained on each view separately and the resulting predictions are
combined through stacking. In these studies, MVS has been shown to increase classification accuracy.
However, the MVS framework can also be used for selecting a subset of important views. To study the
view selection potential of MVS, we develop a special case called stacked penalized logistic regression
(StaPLR). Compared with existing view-selection methods, StaPLR can make use of faster optimization
algorithms and is easily parallelized. We show that nonnegativity constraints on the parameters
of the function which combines the views are important for preventing unimportant views from entering
the model. We investigate the performance of StaPLR through simulations, and consider two real
data examples. We compare the performance of StaPLR with an existing view selection method called
the group lasso and observe that, in terms of view selection, StaPLR has a consistently lower false
positive rate. 