Continual acquisition of novel experience without interfering previously learned knowledge,
i.e. continual learning, is critical for artificial neural networks, but limited by catastrophic
forgetting. A neural network adjusts its parameters when learning a new task, but then fails to conduct
the old tasks well. By contrast, the brain has a powerful ability to continually learn new experience
without catastrophic interference. The underlying neural mechanisms possibly attribute to the
interplay of hippocampus-dependent memory system and neocortex-dependent memory system, mediated
by prefrontal cortex. Specifically, the two memory systems develop specialized mechanisms to
consolidate information as more specific forms and more generalized forms, respectively, and
complement the two forms of information in the interplay. Inspired by such brain strategy, we propose
a novel approach named triple memory networks (TMNs) for continual learning. TMNs model the interplay
of hippocampus, prefrontal cortex and sensory cortex (a neocortex region) as a triple-network
architecture of generative adversarial networks (GAN). The input information is encoded as specific
representation of the data distributions in a generator, or generalized knowledge of solving tasks
in a discriminator and a classifier, with implementing appropriate brain-inspired algorithms
to alleviate catastrophic forgetting in each module. Particularly, the generator replays generated
data of the learned tasks to the discriminator and the classifier, both of which are implemented
with a weight consolidation regularizer to complement the lost information in generation process.
TMNs achieve new state-of-the-art performance on a variety of class-incremental learning benchmarks
on MNIST, SVHN, CIFAR-10 and ImageNet-50, comparing with strong baseline methods. 