Deep learning based computer vision fails to work when labeled images are scarce. Recently, Meta
learning algorithm has been confirmed as a promising way to improve the ability of learning from
few images for computer vision. However, previous Meta learning approaches expose problems: 1)
they ignored the importance of attention mechanism for the Meta learner; 2) they didn't give the
Meta learner the ability of well using the past knowledge which can help to express images into high
representations, resulting in that the Meta learner has to solve few shot learning task directly
from the original high dimensional RGB images. In this paper, we argue that the attention mechanism
and the past knowledge are crucial for the Meta learner, and the Meta learner should be trained on
high representations of the RGB images instead of directly on the original ones. Based on these arguments,
we propose two methods: Attention augmented Meta Learning (AML) and Representation based and Attention
augmented Meta Learning(RAML). The method AML aims to improve the Meta learner's attention ability
by explicitly embedding an attention model into its network. The method RAML aims to give the Meta
learner the ability of leveraging the past learned knowledge to reduce the dimension of the original
input data by expressing it into high representations, and help the Meta learner to perform well.
Extensive experiments demonstrate the effectiveness of the proposed models, with state-of-the-art
few shot learning performances on several few shot learning benchmarks. The source code of our proposed
methods will be released soon to facilitate further studies on those aforementioned problem. 