Strictly proper scoring rules (SPSR) are widely used when designing incentive mechanisms to elicit
private information from strategic agents using realized ground truth signals, and they can help
quantify the value of elicited information. In this paper, we extend such scoring rules to settings
where a mechanism designer does not have access to ground truth. We consider two such settings: (i)
a setting when the mechanism designer has access to a noisy proxy version of the ground truth, with
{\em known} biases; and (ii) the standard peer prediction setting where agents' reports, and possibly
some limited prior knowledge of ground truth, are the only source of information that the mechanism
designer has. We introduce {\em surrogate scoring rules} (SSR) for the first setting, which use
the noisy ground truth to evaluate quality of elicited information. We show that SSR preserves the
strict properness of SPSR. Using SSR, we then develop a multi-task scoring mechanism -- called \emph{uniform
dominant truth serum} (DTS) -- to achieve strict properness when there are sufficiently many tasks
and agents, and when the mechanism designer only has access to agents' reports and one bit information
about the marginal of the entire set of tasks' ground truth. In comparison to standard equilibrium
concepts in peer prediction, we show that DTS can achieve truthfulness in \emph{uniform dominant
strategy} in a multi-task setting when agents adopt the same strategy for all the tasks that they
are assigned (hence the term uniform). A salient feature of SSR and DTS is that they quantify the quality
of information despite lack of ground truth, just as proper scoring rules do for the {\em with} verification
setting. Our method is verified both theoretically and empirically using data collected from real
human participants. 