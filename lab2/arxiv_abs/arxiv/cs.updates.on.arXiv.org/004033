Convolutional neural network models (CNNs) have made major advances in computer vision tasks in
the last five years. Given the challenge in collecting real world datasets, most studies report
performance metrics based on available research datasets. In scenarios where CNNs are to be deployed
on images or videos from mobile devices, models are presented with new challenges due to lighting,
angle, and camera specifications, which are not accounted for in research datasets. It is essential
for assessment to also be conducted on real world datasets if such models are to be reliably integrated
with products and services in society. Plant disease datasets can be used to test CNNs in real time
and gain insight into real world performance. We train a CNN object detection model to identify foliar
symptoms of diseases (or lack thereof) in cassava (Manihot esculenta Crantz). We then deploy the
model on a mobile app and test its performance on mobile images and video of 720 diseased leaflets
in an agricultural field in Tanzania. Within each disease category we test two levels of severity
of symptoms - mild and pronounced, to assess the model performance for early detection of symptoms.
In both severities we see a decrease in the F-1 score for real world images and video. The F-1 score
dropped by 32% for pronounced symptoms in real world images (the closest data to the training data)
due to a drop in model recall. If the potential of smartphone CNNs are to be realized our data suggest
it is crucial to consider tuning precision and recall performance in order to achieve the desired
performance in real world settings. In addition, the varied performance related to different input
data (image or video) is an important consideration for the design of CNNs in real world applications.
