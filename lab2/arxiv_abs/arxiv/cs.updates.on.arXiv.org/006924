The powerful paradigm of Fog computing is currently receiving major interest, as it provides the
possibility to integrate virtualized servers into networks and brings cloud service closer to
end devices. To support this distributed intelligent platform, Software-Defined Network (SDN)
has emerged as a viable network technology in the Fog computing environment. However, uncertainties
related to task demands and the different computing capacities of Fog nodes, inquire an effective
load balancing algorithm. In this paper, the load balancing problem has been addressed under the
constraint of achieving the minimum latency in Fog networks. To handle this problem, a reinforcement
learning based decision-making process has been proposed to find the optimal offloading decision
with unknown reward and transition functions. The proposed process allows Fog nodes to offload
an optimal number of tasks among incoming tasks by selecting an available neighboring Fog node under
their respective resource capabilities with the aim to minimize the processing time and the overall
overloading probability. Compared with the traditional approaches, the proposed scheme not only
simplifies the algorithmic framework without imposing any specific assumption on the network
model but also guarantees convergence in polynomial time. The results show that, during average
delays, the proposed reinforcement learning-based offloading method achieves significant performance
improvements over the variation of service rate and traffic arrival rate. The proposed algorithm
achieves 1.17%, 1.02%, and 3.21% lower overload probability relative to random, least-queue and
nearest offloading selection schemes, respectively. 