For many applications in the field of computer assisted surgery, such as providing the position
of a tumor, specifying the most probable tool required next by the surgeon or determining the remaining
duration of surgery, methods for surgical workflow analysis are a prerequisite. Often machine
learning based approaches serve as basis for surgical workflow analysis. In general machine learning
algorithms, such as convolutional neural networks (CNN), require large amounts of labeled data.
While data is often available in abundance, many tasks in surgical workflow analysis need data annotated
by domain experts, making it difficult to obtain a sufficient amount of annotations. The aim of using
active learning to train a machine learning model is to reduce the annotation effort. Active learning
methods determine which unlabeled data points would provide the most information according to
some metric, such as prediction uncertainty. Experts will then be asked to only annotate these data
points. The model is then retrained with the new data and used to select further data for annotation.
Recently, active learning has been applied to CNN by means of Deep Bayesian Networks (DBN). These
networks make it possible to assign uncertainties to predictions. In this paper, we present a DBN-based
active learning approach adapted for image-based surgical workflow analysis task. Furthermore,
by using a recurrent architecture, we extend this network to video-based surgical workflow analysis.
We evaluate these approaches on the Cholec80 dataset by performing instrument presence detection
and surgical phase segmentation. Here we are able to show that using a DBN-based active learning
approach for selecting what data points to annotate next outperforms a baseline based on randomly
selecting data points. 