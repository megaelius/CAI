Fourier ptychography (FP) is a newly developed computational imaging approach that achieves both
high resolution and wide field of view by stitching a series of low-resolution images captured under
angle-varied illumination. So far, many supervised data-driven models have been applied to solve
inverse imaging problems. These models need massive amounts of data to train, and are limited by
the dataset characteristics. In FP problems, generic datasets are always scarce, and the optical
aberration varies greatly under different acquisition conditions. To address these dilemmas,
we model the forward physical imaging process as an interpretable physics-guided neural network
(PgNN), where the reconstructed image in the complex domain is considered as the learnable parameters
of the neural network. Since the optimal parameters of the PgNN can be derived by minimizing the difference
between the model-generated images and real captured angle-varied images corresponding to the
same scene, the proposed PgNN can get rid of the problem of massive training data as in traditional
supervised methods. Applying the alternate updating mechanism and the total variation regularization,
PgNN can flexibly reconstruct images with improved performance. In addition, the Zernike mode
is incorporated to compensate for optical aberrations to enhance the robustness of FP reconstructions.
As a demonstration, we show our method can reconstruct images with smooth performance and detailed
information in both simulated and experimental datasets. In particular, when validated in an extension
of a high-defocus, high-exposure tissue section dataset, PgNN outperforms traditional FP methods
with fewer artifacts and distinguishable structures. 