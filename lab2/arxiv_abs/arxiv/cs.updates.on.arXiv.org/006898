A graph is a powerful concept for representation of relations between pairs of entities. Data with
underlying graph structure can be found across many disciplines and there is a natural desire for
understanding such data better. Deep learning (DL) has achieved significant breakthroughs in
a variety of machine learning tasks in recent years, especially where data is structured on a grid,
such as in text, speech, or image understanding. However, surprisingly little has been done to explore
the applicability of DL on arbitrary graph-structured data directly. The goal of this thesis is
to investigate architectures for DL on graphs and study how to transfer, adapt or generalize concepts
that work well on sequential and image data to this domain. We concentrate on two important primitives:
embedding graphs or their nodes into a continuous vector space representation (encoding) and,
conversely, generating graphs from such vectors back (decoding). To that end, we make the following
contributions. First, we introduce Edge-Conditioned Convolutions (ECC), a convolution-like
operation on graphs performed in the spatial domain where filters are dynamically generated based
on edge attributes. The method is used to encode graphs with arbitrary and varying structure. Second,
we propose SuperPoint Graph, an intermediate point cloud representation with rich edge attributes
encoding the contextual relationship between object parts. Based on this representation, ECC
is employed to segment large-scale point clouds without major sacrifice in fine details. Third,
we present GraphVAE, a graph generator allowing us to decode graphs with variable but upper-bounded
number of nodes making use of approximate graph matching for aligning the predictions of an autoencoder
with its inputs. The method is applied to the task of molecule generation. 