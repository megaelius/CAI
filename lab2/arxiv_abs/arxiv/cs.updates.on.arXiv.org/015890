Feature selection is a widely used dimension reduction technique to select feature subsets because
of its interpretability. Many methods have been proposed and achieved good results, in which the
relationships between adjacent data points are mainly concerned. But the possible associations
between data pairs that are may not adjacent are always neglected. Different from previous methods,
we propose a novel and very simple approach for unsupervised feature selection, named MMFS (Multi-step
Markov transition probability for Feature Selection). The idea is using multi-step Markov transition
probability to describe the relation between any data pair. Two ways from the positive and negative
viewpoints are employed respectively to keep the data structure after feature selection. From
the positive viewpoint, the maximum transition probability that can be reached in a certain number
of steps is used to describe the relation between two points. Then, the features which can keep the
compact data structure are selected. From the viewpoint of negative, the minimum transition probability
that can be reached in a certain number of steps is used to describe the relation between two points.
On the contrary, the features that least maintain the loose data structure are selected. And the
two ways can also be combined. Thus three algorithms are proposed. Our main contributions are a novel
feature section approach which uses multi-step transition probability to characterize the data
structure, and three algorithms proposed from the positive and negative aspects for keeping data
structure. The performance of our approach is compared with the state-of-the-art methods on eight
real-world data sets, and the experimental results show that the proposed MMFS is effective in unsupervised
feature selection. 