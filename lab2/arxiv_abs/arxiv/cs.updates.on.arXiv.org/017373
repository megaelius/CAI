In this paper, we propose an easily trained yet powerful representation learning approach with
performance highly competitive to deep neural networks in a digital pathology image segmentation
task. The method, called sparse coding driven deep decision tree ensembles that we abbreviate as
ScD2TE, provides a new perspective on representation learning. We explore the possibility of stacking
several layers based on non-differentiable pairwise modules and generate a densely concatenated
architecture holding the characteristics of feature map reuse and end-to-end dense learning.
Under this architecture, fast convolutional sparse coding is used to extract multi-level features
from the output of each layer. In this way, rich image appearance models together with more contextual
information are integrated by learning a series of decision tree ensembles. The appearance and
the high-level context features of all the previous layers are seamlessly combined by concatenating
them to feed-forward as input, which in turn makes the outputs of subsequent layers more accurate
and the whole model efficient to train. Compared with deep neural networks, our proposed ScD2TE
does not require back-propagation computation and depends on less hyper-parameters. ScD2TE is
able to achieve a fast end-to-end pixel-wise training in a layer-wise manner. We demonstrated the
superiority of our segmentation technique by evaluating it on the multi-disease state and multi-organ
dataset where consistently higher performances were obtained for comparison against several
state-of-the-art deep learning methods such as convolutional neural networks (CNN), fully convolutional
networks (FCN), etc. 