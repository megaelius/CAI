In order to solve the robustness and generality problems of the image fusion task,inspired by the
human brain cognitive mechanism, we propose a robust and general image fusion method with autonomous
evolution ability, and is therefore denoted with AE-Net. Through the collaborative optimization
of multiple image fusion methods to simulate the cognitive process of human brain, unsupervised
learning image fusion task can be transformed into semi-supervised image fusion task or supervised
image fusion task, thus promoting the evolutionary ability of network model weight. Firstly, the
relationship between human brain cognitive mechanism and image fusion task is analyzed and a physical
model is established to simulate human brain cognitive mechanism. Secondly, we analyze existing
image fusion methods and image fusion loss functions, select the image fusion method with complementary
features to construct the algorithm module, establish the multi-loss joint evaluation function
to obtain the optimal solution of algorithm module. The optimal solution of each image is used to
guide the weight training of network model. Our image fusion method can effectively unify the cross-modal
image fusion task and the same modal image fusion task, and effectively overcome the difference
of data distribution between different datasets. Finally, extensive numerical results verify
the effectiveness and superiority of our method on a variety of image fusion datasets, including
multi-focus dataset, infrared and visi-ble dataset, medical image dataset and multi-exposure
dataset. Comprehensive experiments demonstrate the superiority of our image fusion method in
robustness and generality. In addition, experimental results also demonstate the effectiveness
of human brain cognitive mechanism to improve the robustness and generality of image fusion. 