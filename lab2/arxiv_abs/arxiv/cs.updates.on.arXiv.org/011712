It is essential for the advancement of science that scientists and researchers share, reuse and
reproduce workflows and protocols used by others. The FAIR principles are a set of guidelines that
aim to maximize the value and usefulness of research data, and emphasize a number of important points
regarding the means by which digital objects are found and reused by others. The question of how to
apply these principles not just to the static input and output data but also to the dynamic workflows
and protocols that consume and produce them is still under debate and poses a number of challenges.
In this paper we describe our inclusive and overarching approach to apply the FAIR principles to
workflows and protocols and demonstrate its benefits. We apply and evaluate our approach on a case
study that consists of making the PREDICT workflow, a highly cited drug repurposing workflow, open
and FAIR. This includes FAIRification of the involved datasets, as well as applying semantic technologies
to represent and store data about the detailed versions of the general protocol, of the concrete
workflow instructions, and of their execution traces. A semantic model was proposed to better address
these specific requirements and were evaluated by answering competency questions. This semantic
model consists of classes and relations from a number of existing ontologies, including Workflow4ever,
PROV, EDAM, and BPMN. This allowed us then to formulate and answer new kinds of competency questions.
Our evaluation shows the high degree to which our FAIRified OpenPREDICT workflow now adheres to
the FAIR principles and the practicality and usefulness of being able to answer our new competency
questions. 