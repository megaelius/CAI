Semantic segmentation has been one of the leading research interests in computer vision recently.
It serves as a perception foundation for many fields, such as robotics and autonomous driving. The
fast development of semantic segmentation attributes enormously to the large scale datasets,
especially for the deep learning related methods. There already exist several semantic segmentation
datasets for comparison among semantic segmentation methods in complex urban scenes, such as the
Cityscapes and CamVid datasets, where the side views of the objects are captured with a camera mounted
on the driving car. There also exist semantic labeling datasets for the airborne images and the satellite
images, where the top views of the objects are captured. However, only a few datasets capture urban
scenes from an oblique Unmanned Aerial Vehicle (UAV) perspective, where both of the top view and
the side view of the objects can be observed, providing more information for object recognition.
In this paper, we introduce our UAVid dataset, a new high-resolution UAV semantic segmentation
dataset as a complement, which brings new challenges, including large scale variation, moving
object recognition and temporal consistency preservation. Our UAV dataset consists of 30 video
sequences capturing 4K high-resolution images in slanted views. In total, 300 images have been
densely labeled with 8 classes for the semantic labeling task. We have provided several deep learning
baseline methods with pre-training, among which the proposed Multi-Scale-Dilation net performs
the best via multi-scale feature extraction. Our UAVid website and the labeling tool have been published
https://uavid.nl/. 