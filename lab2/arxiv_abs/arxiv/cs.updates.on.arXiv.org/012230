In this paper, we present a novel approach for training a Variational Autoencoder (VAE) on a highly
imbalanced data set. The proposed training of a high-resolution VAE model begins with the training
of a low-resolution core model, which can be successfully trained on imbalanced data set. In subsequent
training steps, new convolutional, upsampling, deconvolutional, and downsampling layers are
iteratively attached to the model. In each iteration, the additional layers are trained based on
the intermediate pretrained model - a result of previous training iterations. Thus, the resolution
of the model is progressively increased up to the required resolution level. In this paper, the progressive
VAE training is exploited for learning a latent representation with imbalanced, highly sparse
data sets and, consequently, generating routes in a constrained 2D space. Routing problems (e.g.,
vehicle routing problem, travelling salesman problem, and arc routing) are of special significance
in many modern applications (e.g., route planning, network maintenance, developing high-performance
nanoelectronic systems, and others) and typically associated with sparse imbalanced data. In
this paper, the critical problem of routing billions of components in nanoelectronic devices is
considered. The proposed approach exhibits a significant training speedup as compared with state-of-the-art
existing VAE training methods, while generating expected image outputs from unseen input data.
Furthermore, the final progressive VAE models exhibit much more precise output representation,
than the Generative Adversarial Network (GAN) models trained with comparable training time. The
proposed method is expected to be applicable to a wide range of applications, including but not limited
image impainting, sentence interpolation, and semi-supervised learning. 