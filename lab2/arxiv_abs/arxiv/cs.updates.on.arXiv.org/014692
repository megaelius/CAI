Word2vec is one of the most used algorithms to generate word embeddings because of a good mix of efficiency,
quality of the generated representations and cognitive grounding. However, word meaning is not
static and depends on the context in which words are used. Differences in word meaning that depends
on time, location, topic, and other factors, can be studied by analyzing embeddings generated from
different corpora in collections that are representative of these factors. For example, language
evolution can be studied using a collection of news articles published in different time periods.
In this paper, we present a general framework to support cross-corpora language studies with word
embeddings, where embeddings generated from different corpora can be compared to find correspondences
and differences in meaning across the corpora. CADE is the core component of our framework and solves
the key problem of aligning the embeddings generated from different corpora. In particular, we
focus on providing solid evidence about the effectiveness, generality, and robustness of CADE.
To this end, we conduct quantitative and qualitative experiments in different domains, from temporal
word embeddings to language localization and topical analysis. The results of our experiments
suggest that CADE achieves state-of-the-art or superior performance on tasks where several competing
approaches are available, yet providing a general method that can be used in a variety of domains.
Finally, our experiments shed light on the conditions under which the alignment is reliable, which
substantially depends on the degree of cross-corpora vocabulary overlap. 