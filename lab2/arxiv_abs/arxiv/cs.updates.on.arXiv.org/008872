Automatic grading is not a new approach but the need to adapt the latest technology to automatic grading
has become very important. As the technology has rapidly became more powerful on scoring exams and
essays, especially from the 1990s onwards, partially or wholly automated grading systems using
computational methods have evolved and have become a major area of research. In particular, the
demand of scoring of natural language responses has created a need for tools that can be applied to
automatically grade these responses. In this paper, we focus on the concept of automatic grading
of short answer questions such as are typical in the UK GCSE system, and providing useful feedback
on their answers to students. We present experimental results on a dataset provided from the introductory
computer science class in the University of North Texas. We first apply standard data mining techniques
to the corpus of student answers for the purpose of measuring similarity between the student answers
and the model answer. This is based on the number of common words. We then evaluate the relation between
these similarities and marks awarded by scorers. We then consider an approach that groups student
answers into clusters. Each cluster would be awarded the same mark, and the same feedback given to
each answer in a cluster. In this manner, we demonstrate that clusters indicate the groups of students
who are awarded the same or the similar scores. Words in each cluster are compared to show that clusters
are constructed based on how many and which words of the model answer have been used. The main novelty
in this paper is that we design a model to predict marks based on the similarities between the student
answers and the model answer. 