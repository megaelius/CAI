Existing FNNs are mostly developed under a shallow network configuration having lower generalization
power than those of deep structures. This paper proposes a novel self-organizing deep FNN, namely
DEVFNN. Fuzzy rules can be automatically extracted from data streams or removed if they play limited
role during their lifespan. The structure of the network can be deepened on demand by stacking additional
layers using a drift detection method which not only detects the covariate drift, variations of
input space, but also accurately identifies the real drift, dynamic changes of both feature space
and target space. DEVFNN is developed under the stacked generalization principle via the feature
augmentation concept where a recently developed algorithm, namely gClass, drives the hidden layer.
It is equipped by an automatic feature selection method which controls activation and deactivation
of input attributes to induce varying subsets of input features. A deep network simplification
procedure is put forward using the concept of hidden layer merging to prevent uncontrollable growth
of dimensionality of input space due to the nature of feature augmentation approach in building
a deep network structure. DEVFNN works in the sample-wise fashion and is compatible for data stream
applications. The efficacy of DEVFNN has been thoroughly evaluated using seven datasets with non-stationary
properties under the prequential test-then-train protocol. It has been compared with four popular
continual learning algorithms and its shallow counterpart where DEVFNN demonstrates improvement
of classification accuracy. Moreover, it is also shown that the concept drift detection method
is an effective tool to control the depth of network structure while the hidden layer merging scenario
is capable of simplifying the network complexity of a deep network with negligible compromise of
generalization performance. 