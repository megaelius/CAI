Healthcare question answering assistance aims to provide customer healthcare information, which
widely appears in both Web and mobile Internet. The questions usually require the assistance to
have proficient healthcare background knowledge as well as the reasoning ability on the knowledge.
Recently a challenge involving complex healthcare reasoning, HeadQA dataset, has been proposed,
which contains multiple-choice questions authorized for the public healthcare specialization
exam. Unlike most other QA tasks that focus on linguistic understanding, HeadQA requires deeper
reasoning involving not only knowledge extraction, but also complex reasoning with healthcare
knowledge. These questions are the most challenging for current QA systems, and the current performance
of the state-of-the-art method is slightly better than a random guess. In order to solve this challenging
task, we present a Multi-step reasoning with Knowledge extraction framework (MurKe). The proposed
framework first extracts the healthcare knowledge as supporting documents from the large corpus.
In order to find the reasoning chain and choose the correct answer, MurKe iterates between selecting
the supporting documents, reformulating the query representation using the supporting documents
and getting entailment score for each choice using the entailment model. The reformulation module
leverages selected documents for missing evidence, which maintains interpretability. Moreover,
we are striving to make full use of off-the-shelf pre-trained models. With less trainable weight,
the pre-trained model can easily adapt to healthcare tasks with limited training samples. From
the experimental results and ablation study, our system is able to outperform several strong baselines
on the HeadQA dataset. 