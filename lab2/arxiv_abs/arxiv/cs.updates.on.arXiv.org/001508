Algorithmic image-based diagnosis and prognosis of neurodegenerative diseases on longitudinal
data has drawn great interest from computer vision researchers. The current state-of-the-art
models for many image classification tasks are based on the Convolutional Neural Networks (CNN).
However, a key challenge in applying CNN to biological problems is that the available labeled training
samples are very limited. Another issue for CNN to be applied in computer aided diagnosis applications
is that to achieve better diagnosis and prognosis accuracy, one usually has to deal with the longitudinal
dataset, i.e., the dataset of images scanned at different time points. Here we argue that an enhanced
CNN model with transfer learning for the joint analysis of tasks from multiple time points or regions
of interests may have a potential to improve the accuracy of computer aided diagnosis. To reach this
goal, we innovate a CNN based deep learning multi-task dictionary learning framework to address
the above challenges. Firstly, we pre-train CNN on the ImageNet dataset and transfer the knowledge
from the pre-trained model to the medical imaging progression representation, generating the
features for different tasks. Then, we propose a novel unsupervised learning method, termed Multi-task
Stochastic Coordinate Coding (MSCC), for learning different tasks by using shared and individual
dictionaries and generating the sparse features required to predict the future cognitive clinical
scores. We apply our new model in a publicly available neuroimaging cohort to predict clinical measures
with two different feature sets and compare them with seven other state-of-the-art methods. The
experimental results show our proposed method achieved superior results. 