With state-of-the-art sensing and photogrammetric techniques, Microsoft Bing Maps team has created
over 125 highly detailed 3D cities from 11 different countries that cover hundreds of thousands
of square kilometer areas. The 3D city models were created using the photogrammetric technique
with high-resolution images that were captured from aircraft-mounted cameras. Such a large 3D
city database has caught the attention of the US Army for creating virtual simulation environments
to support military operations. However, the 3D city models do not have semantic information such
as buildings, vegetation, and ground and cannot allow sophisticated user-level and system-level
interaction. At I/ITSEC 2019, the authors presented a fully automated data segmentation and object
information extraction framework for creating simulation terrain using UAV-based photogrammetric
data. This paper discusses the next steps in extending our designed data segmentation framework
for segmenting 3D city data. In this study, the authors first investigated the strengths and limitations
of the existing framework when applied to the Bing data. The main differences between UAV-based
and aircraft-based photogrammetric data are highlighted. The data quality issues in the aircraft-based
photogrammetric data, which can negatively affect the segmentation performance, are identified.
Based on the findings, a workflow was designed specifically for segmenting Bing data while considering
its characteristics. In addition, since the ultimate goal is to combine the use of both small unmanned
aerial vehicle (UAV) collected data and the Bing data in a virtual simulation environment, data
from these two sources needed to be aligned and registered together. To this end, the authors also
proposed a data registration workflow that utilized the traditional iterative closest point (ICP)
with the extracted semantic information. 