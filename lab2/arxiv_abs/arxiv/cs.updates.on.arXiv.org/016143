Telepresence robots are used in various forms in various use-cases that helps to avoid physical
human presence at the scene of action. In this work, we focus on a telepresence robot that can be used
to attend a meeting remotely with a group of people. Unlike a one-to-one meeting, participants in
a group meeting can be located at a different part of the room, especially in an informal setup. As
a result, all of them may not be at the viewing angle of the robot, a.k.a. the remote participant. In
such a case, to provide a better meeting experience, the robot should localize the speaker and bring
the speaker at the center of the viewing angle. Though sound source localization can easily be done
using a microphone-array, bringing the speaker or set of speakers at the viewing angle is not a trivial
task. First of all, the robot should react only to a human voice, but not to the random noises. Secondly,
if there are multiple speakers, to whom the robot should face or should it rotate continuously with
every new speaker? Lastly, most robotic platforms are resource-constrained and to achieve a real-time
response, i.e., avoiding network delay, all the algorithms should be implemented within the robot
itself. This article presents a study and implementation of an attention shifting scheme in a telepresence
meeting scenario which best suits the needs and expectations of the collocated and remote attendees.
We define a policy to decide when a robot should rotate and how much based on real-time speaker localization.
Using user satisfaction study, we show the efficacy and usability of our system in the meeting scenario.
Moreover, our system can be easily adapted to other scenarios where multiple people are located.
