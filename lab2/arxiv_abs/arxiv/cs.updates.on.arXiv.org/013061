Motivated by the inconceivable capability of the human brain in simultaneously processing multi-modal
signals and its real-time feedback to the outer world events, there has been a surge of interest in
establishing a communication bridge between the human brain and a computer, which are referred
to as Brain-computer Interfaces (BCI). To this aim, monitoring the electrical activity of brain
through Electroencephalogram (EEG) has emerged as the prime choice for BCI systems. To discover
the underlying and specific features of brain signals for different mental tasks, a considerable
number of research works are developed based on statistical and data-driven techniques. However,
a major bottleneck in the development of practical and commercial BCI systems is their limited performance
when the number of mental tasks for classification is increased. In this work, we propose a new EEG
processing and feature extraction paradigm based on Siamese neural networks, which can be conveniently
merged and scaled up for multi-class problems. The idea of Siamese networks is to train a double-input
neural network based on a contrastive loss-function, which provides the capability of verifying
if two input EEG trials are from the same class or not. In this work, a Siamese architecture, which
is developed based on Convolutional Neural Networks (CNN) and provides a binary output on the similarity
of two inputs, is combined with OVR and OVO techniques to scale up for multi-class problems. The efficacy
of this architecture is evaluated on a 4-class Motor Imagery (MI) dataset from BCI Competition IV-2a
and the results suggest a promising performance compared to its counterparts. 