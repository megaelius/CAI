Deep neural networks have been successfully applied to many real-world applications. However,
these successes rely heavily on large amounts of labeled data, which is expensive to obtain. Recently,
Auto-Encoding Transformation (AET) and MixMatch have been proposed and achieved state-of-the-art
results for unsupervised and semi-supervised learning, respectively. In this study, we train
an Ensemble of Auto-Encoding Transformations (EnAET) to learn from both labeled and unlabeled
data based on the embedded representations by decoding both spatial and non-spatial transformations.
This distinguishes EnAET from conventional semi-supervised methods that focus on improving prediction
consistency and confidence by different models on both unlabeled and labeled examples. In contrast,
we propose to explore the role of self-supervised representations in semi-supervised learning
under a rich family of transformations. Experiment results on CIFAR-10, CIFAR-100, SVHN and STL10
demonstrate that the proposed EnAET outperforms the state-of-the-art semi-supervised methods
by significant margins. In particular, we apply the proposed method to extremely challenging scenarios
with only 10 images per class, and show that EnAET can achieve an error rate of 9.35% on CIFAR-10 and
16.92% on SVHN. In addition, EnAET achieves the best result when compared with fully supervised
learning using all labeled data with the same network architecture. The performance on CIFAR-10,
CIFAR-100 and SVHN with a smaller network is even more competitive than the state-of-the-art of
supervised learning methods based on a larger network. We also set a new performance record with
an error rate of 1.99% on CIFAR-10 and 4.52% on STL10. The code and experiment records are released
at https://github.com/maple-research-lab/EnAET. 