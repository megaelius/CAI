We study federated learning (FL) at the wireless edge, where power-limited devices with local datasets
collaboratively train a joint model with the help of a remote parameter server (PS). We assume that
the devices are connected to the PS through a bandwidth-limited shared wireless channel. At each
iteration of FL, a subset of the devices are scheduled to transmit their local model updates to the
PS over orthogonal channel resources, while each participating device must compress its model
update to accommodate to its link capacity. We design novel scheduling and resource allocation
policies that decide on the subset of the devices to transmit at each round, and how the resources
should be allocated among the participating devices, not only based on their channel conditions,
but also on the significance of their local model updates. We then establish convergence of a wireless
FL algorithm with device scheduling, where devices have limited capacity to convey their messages.
The results of numerical experiments show that the proposed scheduling policy, based on both the
channel conditions and the significance of the local model updates, provides a better long-term
performance than scheduling policies based only on either of the two metrics individually. Furthermore,
we observe that when the data is independent and identically distributed (i.i.d.) across devices,
selecting a single device at each round provides the best performance, while when the data distribution
is non-i.i.d., scheduling multiple devices at each round improves the performance. This observation
is verified by the convergence result, which shows that the number of scheduled devices should increase
for a less diverse and more biased data distribution. 