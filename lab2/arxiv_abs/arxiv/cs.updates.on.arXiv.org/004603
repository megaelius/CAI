Automatic multi-class object detection in remote sensing images in unconstrained scenarios is
of high interest for several applications including traffic monitoring and disaster management.
%a crucial and needed tool. The huge variation in object scale, orientation, category, and complex
backgrounds, as well as the different camera sensors pose great challenges for current algorithms.
In this work, we propose a new method consisting of a novel joint image cascade and feature pyramid
network with multi-size convolution kernels to extract multi-scale strong and weak semantic features.
These features are fed into rotation-based region proposal and region of interest networks to produce
object detections. Finally, rotational non-maximum suppression is applied to remove redundant
detections. During training, we minimize joint horizontal and oriented bounding box loss functions,
as well as a novel loss that enforces oriented boxes to be rectangular. Our method achieves 68.16\%
mAP on horizontal and 72.45\% mAP on oriented bounding box detection tasks on the challenging new
DOTA dataset, outperforming all published methods by a large margin ($+6$\% and $+12$\% absolute
improvement, respectively). % whereas the best results in the leader-board are 54.13\% and 60.46\%.
Furthermore, it generalizes to two other datasets, NWPU VHR-10 and UCAS-AOD, and achieves competitive
results with the baselines even when trained on DOTA. Our method can be deployed in multi-class object
detection applications, regardless of the image and object scales and orientations, making it
a great choice for unconstrained aerial and satellite imagery. 