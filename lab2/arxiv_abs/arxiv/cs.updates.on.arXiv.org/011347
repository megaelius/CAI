Histograms and synthetic data are of key importance in data analysis. However, researchers have
shown that even aggregated data such as histograms, containing no obvious sensitive attributes,
can result in privacy leakage. To enable data analysis, a strong notion of privacy is required to
avoid risking unintended privacy violations. Such a strong notion of privacy is differential privacy,
a statistical notion of privacy that makes privacy leakage quantifiable. The caveat regarding
differential privacy is that while it has strong guarantees for privacy, privacy comes at a cost
of accuracy. Despite this trade off being a central and important issue in the adoption of differential
privacy, there exists a gap in the literature for understanding the trade off and addressing it appropriately.
Through a systematic literature review (SLR), we investigate the state-of-the-art within accuracy
improving differentially private algorithms for histogram and synthetic data publishing. Our
contribution is two-fold: 1) we provide an understanding of the problem by crystallizing the categories
of accuracy improving techniques, the core problems they solve, as well as to investigate how composable
the techniques are, and 2) we pave the way for future work. In order to provide an understanding, we
position and visualize the ideas in relation to each other and external work, and deconstruct each
algorithm to examine the building blocks separately with the aim of pinpointing which dimension
of noise reduction each technique is targeting. Hence, this systematization of knowledge (SoK)
provides an understanding of in which dimensions and how accuracy improvement can be pursued without
sacrificing privacy. 