Convolutional neural networks (CNN) show the excellent performance compared to conventional
machine learning algorithms in various computer vision applications. In recent years, FPGA-based
CNN accelerators have been proposed to optimize the performance and power efficiency. Most accelerators
are designed for object detection and recognition that perform on low-resolution (LR) images.
However, image super-resolution (SR) cannot be implemented in real-time with these accelerators
because of the long execution cycles required to generate high-resolution (HR) images such as 4K
ultra-high-definition (UHD). In this paper, we propose a novel CNN accelerator with the efficient
parallelization methods in SR application. First, we propose a new methodology to optimize deconvolutional
neural networks (DCNN) used for up-scaling the feature maps based on trained filters. Second, we
propose a method to optimize CNN dataflow using an on-chip memory so that CNN-based SR algorithm
can be driven at low power in display applications. Third, we propose a two-stage quantization algorithm
to select the optimized hardware size for the limited number of DSPs. Finally, we present the energy-efficient
CNN architecture for SR and validate our architecture on a mobile panel with quad-high-definition
(QHD) resolution. Experimental results show that the proposed DCNN accelerator achieves up to
108 times higher throughput than the conventional DCNN accelerator with the same hardware resources.
In addition, our CNN based SR system achieves energy efficiency of 92.65 GOPS/W, 173.53 GOPS/W,
and 286.76 GOPS/W when scale factors for SR are 2, 3, and 4, respectively. Furthermore, we demonstrate
that our system can support more scale factors to create image of different sizes and restore HR images
to higher peak signal-to-noise-ratio (PSNR) when compared to conventional SR systems. 