In a leader-follower multi-agent system (MAS), the leader agents act as control inputs and influence
the states of the remaining follower agents. The rate at which the follower agents converge to their
desired states, as well as the errors in the follower agent states prior to convergence, are determined
by the choice of leader agents. In this paper, we study leader selection in order to minimize convergence
errors experienced by the follower agents, which we define as a norm of the distance between the follower
agents' intermediate states and the convex hull of the leader agent states. By introducing a novel
connection to random walks on the network graph, we show that the convergence error has an inherent
supermodular structure as a function of the leader set. Supermodularity enables development of
efficient discrete optimization algorithms that directly approximate the optimal leader set,
provide provable performance guarantees, and do not rely on continuous relaxations. We formulate
two leader selection problems within the supermodular optimization framework, namely, the problem
of selecting a fixed number of leader agents in order to minimize the convergence error, as well as
the problem of selecting the minimum-size set of leader agents to achieve a given bound on the convergence
error. We introduce algorithms for approximating the optimal solution to both problems in static
networks, dynamic networks with known topology distributions, and dynamic networks with unknown
and unpredictable topology distributions. Our approach is shown to provide significantly lower
convergence errors than existing random and degree-based leader selection methods in a numerical
study. 