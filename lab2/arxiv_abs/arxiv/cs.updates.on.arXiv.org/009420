Generative Adversarial Networks (GANs) are the emerging machine learning technology that can
learn to automatically create labeled datasets in massive application domains such as speech,
image, video and texts. A GAN typically includes a generative model that is taught to generate any
distribution of data, and a discriminator trained to distinguish the synthetic data from real-world
data. Both convolutional and deconvolutional layers are the major source of performance overhead
for GANs and directly impacts the efficiency of GAN-based systems. There are many prior works investigating
specialized hardware architectures that can accelerate convolution and deconvolution simultaneously,
but they entail intensive hardware modifications to the existing CNN accelerators or processors
that focus on convolution acceleration. In contrast, this work proposes a novel deconvolution
layer implementation with a software approach and enables fast and efficient generative network
inference on the legacy Convolutional Neural Networks (CNNs) accelerators. Our proposed method
reorganizes the computation of deconvolutional layer and allows the CNN accelerators to treat
it as the standard convolutional layer after we split the original deconvolutional filters into
multiple small filters. The proposed data flow is implemented on representative CNN accelerators
including dot-production array and regular 2D PE array architectures. Compared to the prior baseline
acceleration scheme, the implemented acceleration scheme achieves 2.4X - 4.3X performance speedup
and reduces the energy consumption by 27.7% - 54.5% on a set of realistic benchmarks. 