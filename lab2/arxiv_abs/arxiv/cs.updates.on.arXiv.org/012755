Machine translation has gained much attention in recent years. It is a sub-field of computational
linguistic which focus on translating text from one language to other language. Among different
translation techniques, neural network currently leading the domain with its capabilities of
providing a single large neural network with attention mechanism, sequence-to-sequence and long-short
term modelling. Despite significant progress in domain of machine translation, translation of
out-of-vocabulary words(OOV) which include technical terms, named-entities, foreign words
are still a challenge for current state-of-art translation systems, and this situation becomes
even worse while translating between low resource languages or languages having different structures.
Due to morphological richness of a language, a word may have different meninges in different context.
In such scenarios, translation of word is not only enough in order provide the correct/quality translation.
Transliteration is a way to consider the context of word/sentence during translation. For low resource
language like Urdu, it is very difficult to have/find parallel corpus for transliteration which
is large enough to train the system. In this work, we presented transliteration technique based
on Expectation Maximization (EM) which is un-supervised and language independent. Systems learns
the pattern and out-of-vocabulary (OOV) words from parallel corpus and there is no need to train
it on transliteration corpus explicitly. This approach is tested on three models of statistical
machine translation (SMT) which include phrasebased, hierarchical phrase-based and factor based
models and two models of neural machine translation which include LSTM and transformer model. 