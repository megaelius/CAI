In this paper, we study the non-stationary online second price auction problem. We assume that the
seller is selling the same type of items in $T$ rounds by the second price auction, and she can set the
reserve price in each round. In each round, the bidders draw their private values from a joint distribution
unknown to the seller. Then, the seller announced the reserve price in this round. Next, bidders
with private values higher than the announced reserve price in that round will report their values
to the seller as their bids. The bidder with the highest bid larger than the reserved price would win
the item and she will pay to the seller the price equal to the second-highest bid or the reserve price,
whichever is larger. The seller wants to maximize her total revenue during the time horizon $T$ while
learning the distribution of private values over time. The problem is more challenging than the
standard online learning scenario since the private value distribution is non-stationary, meaning
that the distribution of bidders' private values may change over time, and we need to use the \emph{non-stationary
regret} to measure the performance of our algorithm. To our knowledge, this paper is the first to
study the repeated auction in the non-stationary setting theoretically. Our algorithm achieves
the non-stationary regret upper bound $\tilde{\mathcal{O}}(\min\{\sqrt{\mathcal S T}, \bar{\mathcal{V}}^{\frac{1}{3}}T^{\frac{2}{3}}\})$,
where $\mathcal S$ is the number of switches in the distribution, and $\bar{\mathcal{V}}$ is the
sum of total variation, and $\mathcal S$ and $\bar{\mathcal{V}}$ are not needed to be known by the
algorithm. We also prove regret lower bounds $\Omega(\sqrt{\mathcal S T})$ in the switching case
and $\Omega(\bar{\mathcal{V}}^{\frac{1}{3}}T^{\frac{2}{3}})$ in the dynamic case, showing
that our algorithm has nearly optimal \emph{non-stationary regret}. 