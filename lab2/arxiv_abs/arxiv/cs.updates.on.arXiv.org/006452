In this paper, we propose a convolutional recurrent neural network for joint sound event localization
and detection (SELD) of multiple overlapping sound events in three-dimensional (3D) space. The
proposed network takes a sequence of consecutive spectrogram time-frames as input and maps it to
two outputs in parallel. As the first output, the sound event detection (SED) is performed as a multi-label
classification task on each time-frame producing temporal activity for all the sound event classes.
As the second output, localization is performed by estimating the 3D Cartesian coordinates of the
direction-of-arrival (DOA) for each sound event class using multi-output regression. The proposed
method is able to associate multiple DOAs with respective sound event labels and further track this
association with respect to time. The proposed method uses separately the phase and magnitude component
of the spectrogram calculated on each audio channel as the feature, thereby avoiding any method-
and array-specific feature extraction. The method is evaluated on five Ambisonic and two circular
array format datasets with different overlapping sound events in anechoic, reverberant and real-life
scenarios. The proposed method is compared with two SED, three DOA estimation, and one SELD baselines.
The results show that the proposed method is generic and applicable to any array structures, robust
to unseen DOA values, reverberation, and low SNR scenarios. The proposed method achieved a consistently
higher recall of the estimated number of DOAs across datasets in comparison to the best baseline.
Additionally, this recall was observed to be significantly better than the best baseline method
for a higher number of overlapping sound events. 