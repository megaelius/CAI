Graph deep learning has recently emerged as a powerful ML concept allowing to generalize successful
deep neural architectures to non-Euclidean structured data. Such methods have shown promising
results on a broad spectrum of applications ranging from social science, biomedicine, and particle
physics to computer vision, graphics, and chemistry. One of the limitations of the majority of the
current graph neural network architectures is that they are often restricted to the transductive
setting and rely on the assumption that the underlying graph is known and fixed. In many settings,
such as those arising in medical and healthcare applications, this assumption is not necessarily
true since the graph may be noisy, partially- or even completely unknown, and one is thus interested
in inferring it from the data. This is especially important in inductive settings when dealing with
nodes not present in the graph at training time. Furthermore, sometimes such a graph itself may convey
insights that are even more important than the downstream task. In this paper, we introduce Differentiable
Graph Module (DGM), a learnable function predicting the edge probability in the graph relevant
for the task, that can be combined with convolutional graph neural network layers and trained in
an end-to-end fashion. We provide an extensive evaluation of applications from the domains of healthcare
(disease prediction), brain imaging (gender and age prediction), computer graphics (3D point
cloud segmentation), and computer vision (zero-shot learning). We show that our model provides
a significant improvement over baselines both in transductive and inductive settings and achieves
state-of-the-art results. 