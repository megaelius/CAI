Very important breakthroughs in data-centric machine learning algorithms led to impressive performance
in transactional point applications such as detecting anger in speech, alerts from a Face Recognition
system, or EKG interpretation. Non-transactional applications, e.g. medical diagnosis beyond
the EKG results, require AI algorithms that integrate deeper and broader knowledge in their problem-solving
capabilities, e.g. integrating knowledge about anatomy and physiology of the heart with EKG results
and additional patient findings. Similarly, for military aerial interpretation, where knowledge
about enemy doctrines on force composition and spread helps immensely in situation assessment
beyond image recognition of individual objects. The Double Deep Learning approach advocates integrating
data-centric machine self-learning techniques with machine-teaching techniques to leverage
the power of both and overcome their corresponding limitations. To take AI to the next level, it is
essential that we rebalance the roles of data and knowledge. Data is important but knowledge- deep
and commonsense- are equally important. An initiative is proposed to build Wikipedia for Smart
Machines, meaning target readers are not human, but rather smart machines. Named ReKopedia, the
goal is to develop methodologies, tools, and automatic algorithms to convert humanity knowledge
that we all learn in schools, universities and during our professional life into Reusable Knowledge
structures that smart machines can use in their inference algorithms. Ideally, ReKopedia would
be an open source shared knowledge repository similar to the well-known shared open source software
code repositories. Examples in the article are based on- or inspired by- real-life non-transactional
AI systems I deployed over decades of AI career that benefit hundreds of millions of people around
the globe. 