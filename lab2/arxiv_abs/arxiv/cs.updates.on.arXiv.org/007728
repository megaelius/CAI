With the enhancements in the field of software-defined networking and virtualization technologies,
novel networking paradigms such as network function virtualization (NFV) and the Internet of things
(IoT) are rapidly gaining ground. Development of IoT as well as 5G networks and explosion in online
services has resulted in an exponential growth of devices connected to the network. As a result,
application service providers (ASPs) and Internet service providers (ISPs) are being confronted
with the unprecedented challenge of accommodating increasing service and traffic demands from
the geographically distributed users. To tackle this problem, many ASPs and ISPs, such as Netflix,
Facebook, AT&T and others are increasingly adopting micro-services (MS) application architecture.
Despite the success of MS in the industry, there is no specific standard or research work for service
providers as guidelines, especially from the perspective of basic micro-service operations.
In this work, we aim to bridge this gap between industry and academia and discuss different micro-service
deployment, discovery and communication options for service providers as a means to forming complete
service chains. In addition, we address the problem of scheduling micro-services across multiple
clouds, including micro-clouds. We consider different user-level SLAs, such as latency and cost,
while scheduling such services. We aim to reduce overall turnaround time as well as costs for the
deployment of complete end-to-end service. In this work, we present a novel affinity-based fair
weighted scheduling heuristic to solve this problem. We also compare the results of proposed solution
with standard greedy scheduling algorithms presented in the literature and observe significant
improvements. 