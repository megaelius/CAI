The goal of this work is the accurate prediction of millimeter-wave received power leveraging both
radio frequency (RF) signals and heterogeneous visual data from multiple distributed cameras,
in a communication and energy-efficient manner while preserving data privacy. To this end, firstly
focusing on data privacy, we propose heteromodal split learning with feature aggregation (HetSLAgg)
that splits neural network (NN) models into camera-side and base station (BS)-side segments. The
BS-side NN segment fuses RF signals and uploaded image features without collecting raw images.
However, the usage of multiple visual data leads to an increase in NN input dimensions, which gives
rise to additional communication and energy costs. To overcome additional communication and energy
costs due to image interpolation to blend different frame rates, we propose a novel BS-side manifold
mixup technique that offloads the interpolation operations from cameras to a BS. Subsequently,
we confront energy costs for operating a larger size of the BS- side NN segment due to concatenating
image features across cameras and propose an energy-efficient aggregation method. This is done
via a linear combination of image features instead of concatenating them, where the NN size is independent
of the number of cameras. Comprehensive test-bed experiments with measured channels demonstrate
that HetSLAgg reduces the prediction error by 44% compared to a baseline leveraging only RF received
power. Moreover, the experiments show that the designed HetSLAgg achieves over 20% gains in terms
of communication and energy cost reduction compared to several baseline designs within at most
1% of accuracy loss. 