Video rain/snow removal from surveillance videos is an important task in the computer vision community
since rain/snow existed in videos can severely degenerate the performance of many surveillance
system. Various methods have been investigated extensively, but most only consider consistent
rain/snow under stable background scenes. Rain/snow captured from practical surveillance camera,
however, is always highly dynamic in time with the background scene transformed occasionally.
To this issue, this paper proposes a novel rain/snow removal approach, which fully considers dynamic
statistics of both rain/snow and background scenes taken from a video sequence. Specifically,
the rain/snow is encoded as an online multi-scale convolutional sparse coding (OMS-CSC) model,
which not only finely delivers the sparse scattering and multi-scale shapes of real rain/snow,
but also well encodes their temporally dynamic configurations by real-time ameliorated parameters
in the model. Furthermore, a transformation operator imposed on the background scenes is further
embedded into the proposed model, which finely conveys the dynamic background transformations,
such as rotations, scalings and distortions, inevitably existed in a real video sequence. The approach
so constructed can naturally better adapt to the dynamic rain/snow as well as background changes,
and also suitable to deal with the streaming video attributed its online learning mode. The proposed
model is formulated in a concise maximum a posterior (MAP) framework and is readily solved by the
ADMM algorithm. Compared with the state-of-the-art online and offline video rain/snow removal
methods, the proposed method achieves better performance on synthetic and real videos datasets
both visually and quantitatively. Specifically, our method can be implemented in relatively high
efficiency, showing its potential to real-time video rain/snow removal. 