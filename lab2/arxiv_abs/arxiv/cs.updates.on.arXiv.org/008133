In a self-driving car, objection detection, object classification, lane detection and object
tracking are considered to be the crucial modules. In recent times, using the real time video one
wants to narrate the scene captured by the camera fitted in our vehicle. To effectively implement
this task, deep learning techniques and automatic video annotation tools are widely used. In the
present paper, we compare the various techniques that are available for each module and choose the
best algorithm among them by using appropriate metrics. For object detection, YOLO and Retinanet-50
are considered and the best one is chosen based on mean Average Precision (mAP). For object classification,
we consider VGG-19 and Resnet-50 and select the best algorithm based on low error rate and good accuracy.
For lane detection, Udacity's 'Finding Lane Line' and deep learning based LaneNet algorithms are
compared and the best one that can accurately identify the given lane is chosen for implementation.
As far as object tracking is concerned, we compare Udacity's 'Object Detection and Tracking' algorithm
and deep learning based Deep Sort algorithm. Based on the accuracy of tracking the same object in
many frames and predicting the movement of objects, the best algorithm is chosen. Our automatic
video annotation tool is found to be 83% accurate when compared with a human annotator. We considered
a video with 530 frames each of resolution 1035 x 1800 pixels. At an average each frame had about 15
objects. Our annotation tool consumed 43 minutes in a CPU based system and 2.58 minutes in a mid-level
GPU based system to process all four modules. But the same video took nearly 3060 minutes for one human
annotator to narrate the scene in the given video. Thus we claim that our proposed automatic video
annotation tool is reasonably fast (about 1200 times in a GPU system) and accurate. 