Low-rank matrix completion is a popular paradigm in machine learning, but little is known about
the completion properties of non-random observation patterns. A fundamental open question in
this direction is the following: given an observation pattern of a sufficiently generic (e.g. incoherent)
$m \times n$ real matrix $X$ of rank $r$ with exactly $r(m+n-r)$ entries being observed, this number
being the dimension of the space of real rank-$r$ $m \times n$ matrices, are there finitely many rank-$r$
completions? This is a challenging problem whose answer is known only for ranks $1$, $2$ and $\min\{m,n\}-1$.
In this paper we study this problem by bringing tools from algebraic geometry. In particular, we
exploit the fact that both the space of real rank-$r$ $m \times n$ matrices as well as the set of $r$-dimensional
subspaces of $\mathbb{R}^m$, known as the Grassmannian, are algebraic varieties. Our approach
is based on a novel formulation of matrix completion in terms of Pl{\"u}cker coordinates, the latter
a traditionally powerful tool in computer vision and graphics and a classical notion in algebraic
geometry. This formulation allows us to characterize a large class of minimal (i.e. of size $r(m+n-r)$)
observation patterns for which a generic matrix admits finitely many rank-r completions. We conjecture
that the converse is also true: any minimal pattern which is generically finitely completable must
be of that type. As a consequence, we generalize results that have previously appeared and are being
used in the literature, but lack a sufficient theoretical justification. We believe the Pl{\"u}cker-coordinate
based link that we establish between low-rank matrices and the Grassmannian in the context of matrix
completion to be of wider significance for matrix and subspace learning problems with incomplete
data. 