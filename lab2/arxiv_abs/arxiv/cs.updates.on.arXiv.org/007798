In this work we reduce undersampling artefacts in two-dimensional ($2D$) golden-angle radial
cine cardiac MRI by applying a modified version of the U-net. We train the network on $2D$ spatio-temporal
slices which are previously extracted from the image sequences. We compare our approach to two $2D$
and a $3D$ Deep Learning-based post processing methods and to three iterative reconstruction methods
for dynamic cardiac MRI. Our method outperforms the $2D$ spatially trained U-net and the $2D$ spatio-temporal
U-net. Compared to the $3D$ spatio-temporal U-net, our method delivers comparable results, but
with shorter training times and less training data. Compared to the Compressed Sensing-based methods
$kt$-FOCUSS and a total variation regularised reconstruction approach, our method improves image
quality with respect to all reported metrics. Further, it achieves competitive results when compared
to an iterative reconstruction method based on adaptive regularization with Dictionary Learning
and total variation, while only requiring a small fraction of the computational time. A persistent
homology analysis demonstrates that the data manifold of the spatio-temporal domain has a lower
complexity than the spatial domain and therefore, the learning of a projection-like mapping is
facilitated. Even when trained on only one single subject without data-augmentation, our approach
yields results which are similar to the ones obtained on a large training dataset. This makes the
method particularly suitable for training a network on limited training data. Finally, in contrast
to the spatial $2D$ U-net, our proposed method is shown to be naturally robust with respect to image
rotation in image space and almost achieves rotation-equivariance where neither data-augmentation
nor a particular network design are required. 