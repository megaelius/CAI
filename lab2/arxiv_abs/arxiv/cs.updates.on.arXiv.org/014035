Many websites import large JavaScript (JS) libraries to customize and enhance user experiences.
Our data shows that many JS libraries are only partially utilized during a page load, and therefore,
contain superfluous code that is never executed. Many top-ranked websites contain up to hundreds
of kilobytes of compressed superfluous code and a JS resource on a median page contains 31% superfluous
code. Superfluous JS code inflates the page weight, and thereby, the time to download, parse, and
compile a JS resource. It is therefore important to monitor the usage and optimize the payload of
JS resources to improve Web performance. However, given that the webpage design and functionality
could depend on a user's preferences or device, among many other factors, actively loading webpages
in controlled environments cannot cover all possible conditions in which webpage content and functionality
changes. In this paper, we show that passive measurement techniques, such as real user monitoring
systems (RUM), that monitor the performance of real user page loads under different conditions
can be leveraged to identify superfluous code. Using a custom man-in-the-middle proxy (similar
to a content delivery network's proxy server), we designed a systematic approach for website developers
that relies on pages loaded by real users to passively identify superfluous code on JS resources.
We then elide any superfluous code from JS resources before subsequent page load requests. Our data
shows that eliding superfluous JS code improves the median page load time by 5% and by at least 10%
for pages in the long tail. Through results presented in this paper, we motivate for the need for rigorous
monitoring of the usage of JS resources under different real world conditions, with the goal to improve
Web performance. 