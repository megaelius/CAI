Adaptive sampling is a useful algorithmic tool for data summarization problems in the classical
centralized setting, where the entire dataset is available to the single processor performing
the computation. Adaptive sampling repeatedly selects rows of an underlying matrix $\mathbf{A}\in\mathbb{R}^{n\times
d}$, where $n\gg d$, with probabilities proportional to their distances to the subspace of the previously
selected rows. Intuitively, adaptive sampling seems to be limited to trivial multi-pass algorithms
in the streaming model of computation due to its inherently sequential nature of assigning sampling
probabilities to each row only after the previous iteration is completed. Surprisingly, we show
this is not the case by giving the first one-pass algorithms for adaptive sampling on turnstile streams
and using space $\text{poly}(d,k,\log n)$, where $k$ is the number of adaptive sampling rounds
to be performed. Our adaptive sampling procedure has a number of applications to various data summarization
problems that either improve state-of-the-art or have only been previously studied in the more
relaxed row-arrival model. We give the first relative-error algorithms for column subset selection,
subspace approximation, projective clustering, and volume maximization on turnstile streams
that use space sublinear in $n$. We complement our volume maximization algorithmic results with
lower bounds that are tight up to lower order terms, even for multi-pass algorithms. By a similar
construction, we also obtain lower bounds for volume maximization in the row-arrival model, which
we match with competitive upper bounds. See paper for full abstract. 