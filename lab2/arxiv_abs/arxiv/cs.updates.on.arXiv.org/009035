Objective quality assessment of stereoscopic omnidirectional images is a challenging problem
since it is influenced by multiple aspects such as projection deformation, field of view (FoV) range,
binocular vision, visual comfort, etc. Existing studies show that classic 2D or 3D image quality
assessment (IQA) metrics are not able to perform well for stereoscopic omnidirectional images.
However, very few research works have focused on evaluating the perceptual visual quality of omnidirectional
images, especially for stereoscopic omnidirectional images. In this paper, based on the predictive
coding theory of the human vision system (HVS), we propose a stereoscopic omnidirectional image
quality evaluator (SOIQE) to cope with the characteristics of 3D 360-degree images. Two modules
are involved in SOIQE: predictive coding theory based binocular rivalry module and multi-view
fusion module. In the binocular rivalry module, we introduce predictive coding theory to simulate
the competition between high-level patterns and calculate the similarity and rivalry dominance
to obtain the quality scores of viewport images. Moreover, we develop the multi-view fusion module
to aggregate the quality scores of viewport images with the help of both content weight and location
weight. The proposed SOIQE is a parametric model without necessary of regression learning, which
ensures its interpretability and generalization performance. Experimental results on our published
stereoscopic omnidirectional image quality assessment database (SOLID) demonstrate that our
proposed SOIQE method outperforms state-of-the-art metrics. Furthermore, we also verify the
effectiveness of each proposed module on both public stereoscopic image datasets and panoramic
image datasets. 