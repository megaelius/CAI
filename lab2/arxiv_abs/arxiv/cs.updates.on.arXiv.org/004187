Deep Learning (DL) models have caused a paradigm shift in our ability to comprehend raw data in various
important fields, ranging from intelligence warfare and healthcare to autonomous transportation
and automated manufacturing. A practical concern, in the rush to adopt DL models as a service, is
protecting the models against Intellectual Property (IP) infringement. The DL models are commonly
built by allocating significant computational resources that process vast amounts of proprietary
training data. The resulting models are therefore considered to be the IP of the model builder and
need to be protected to preserve the owner's competitive advantage. This paper proposes DeepSigns,
a novel end-to-end IP protection framework that enables insertion of coherent digital watermarks
in contemporary DL models. DeepSigns, for the first time, introduces a generic watermarking methodology
that can be used for protecting DL owner's IP rights in both white-box and black-box settings, where
the adversary may or may not have the knowledge of the model internals. The suggested methodology
is based on embedding the owner's signature (watermark) in the probability density function (pdf)
of the data abstraction obtained in different layers of a DL model. DeepSigns can demonstrably withstand
various removal and transformation attacks, including model compression, model fine-tuning,
and watermark overwriting. Proof-of-concept evaluations on MNIST, and CIFAR10 datasets, as well
as a wide variety of neural network architectures including Wide Residual Networks, Convolution
Neural Networks, and Multi-Layer Perceptrons corroborate DeepSigns' effectiveness and applicability.
