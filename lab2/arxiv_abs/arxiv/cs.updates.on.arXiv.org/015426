We introduce a novel deep learning framework for data-driven motion retargeting between skeletons,
which may have different structure, yet corresponding to homeomorphic graphs. Importantly, our
approach learns how to retarget without requiring any explicit pairing between the motions in the
training set. We leverage the fact that different homeomorphic skeletons may be reduced to a common
primal skeleton by a sequence of edge merging operations, which we refer to as skeletal pooling.
Thus, our main technical contribution is the introduction of novel differentiable convolution,
pooling, and unpooling operators. These operators are skeleton-aware, meaning that they explicitly
account for the skeleton's hierarchical structure and joint adjacency, and together they serve
to transform the original motion into a collection of deep temporal features associated with the
joints of the primal skeleton. In other words, our operators form the building blocks of a new deep
motion processing framework that embeds the motion into a common latent space, shared by a collection
of homeomorphic skeletons. Thus, retargeting can be achieved simply by encoding to, and decoding
from this latent space. Our experiments show the effectiveness of our framework for motion retargeting,
as well as motion processing in general, compared to existing approaches. Our approach is also quantitatively
evaluated on a synthetic dataset that contains pairs of motions applied to different skeletons.
To the best of our knowledge, our method is the first to perform retargeting between skeletons with
differently sampled kinematic chains, without any paired examples. 