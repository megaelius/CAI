Unsupervised online video object segmentation (VOS) aims to automatically segment the moving
objects over an unconstrained video without the requirements of any prior information about the
objects or camera motion. It is therefore a very challenging problem for high-level video analysis.
So far, limited number of such methods have been reported in literature and most of them still have
distance to a satisfactory performance. Targeting this challenging problem,in this paper, we
propose a novel unsupervised online VOS framework by understanding the motion property as the meaning
of \emph{moving} in concurrence with \emph{a generic object} for the segmented regions. By incorporating
\emph{salient motion detection} and \emph{object proposal}, a pixel-wise fusion strategy is
developed to effectively remove detection noises such as background movements and stationary
objects. Furthermore, by leveraging the obtained segmentation from immediately preceding frames,
a forward propagation algorithm is proposed to deal with the unreliable motion detection and object
proposals. Experimental results on DAVIS-2016 and SegTrack-v2 benchmark dataset show that the
proposed method outperforms the other state-of-the-art unsupervised online segmentation by
achieving 5.6\% absolute improvement at least, and additionally even achieves a better performance
than the best unsupervised offline method on DAVIS-2016 dataset. Another significant advantage
also need to be addressed that in all the experiments, there is only one existing trained model for
object proposal (Mask RCNN on COCO dataset) being used without any fine-tuning, which is the demonstration
of robustness. The most contribution of this work might sheds light on the potential and to motivate
more VOS framework studies based on characteristic motion properties. 