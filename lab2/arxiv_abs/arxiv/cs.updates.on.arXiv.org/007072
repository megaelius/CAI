Visual localization has become a key enabling component of many place recognition and SLAM systems.
Contemporary research has primarily focused on improving accuracy and precision-recall type
metrics, with relatively little attention paid to a system's absolute storage scaling characteristics,
its flexibility to adapt to available computational resources, and its longevity with respect
to easily incorporating newly learned or hand-crafted image descriptors. Most significantly,
improvement in one of these aspects typically comes at the cost of others: for example, a snapshot-based
system that achieves sub-linear storage cost typically provides no metric pose estimation, or,
a highly accurate pose estimation technique is often ossified in adapting to recent advances in
appearance-invariant features. In this paper, we present a novel 6-DOF localization system that
for the first time simultaneously achieves all the three characteristics: significantly sub-linear
storage growth, agnosticism to image descriptors, and customizability to available storage and
computational resources. The key features of our method are developed based on a novel adaptation
of multiple-label learning, together with effective dimensional reduction and learning techniques
that enable simple and efficient optimization. We evaluate our system on several large benchmarking
datasets and provide detailed comparisons to state-of-the-art systems. The proposed method demonstrates
competitive accuracy with existing pose estimation methods while achieving better sub-linear
storage scaling, significantly reduced absolute storage requirements, and faster training and
deployment speeds. 