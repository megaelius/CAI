Single image defogging is a classical and challenging problem in computer vision. Existing methods
towards this problem mainly include handcrafted priors based methods that rely on the use of the
atmospheric degradation model and learning based approaches that require paired fog-fogfree
training example images. In practice, however, prior-based methods are prone to failure due to
their own limitations and paired training data are extremely difficult to acquire. Inspired by
the principle of CycleGAN network, we have developed an end-to-end learning system that uses unpaired
fog and fogfree training images, adversarial discriminators and cycle consistency losses to automatically
construct a fog removal system. Similar to CycleGAN, our system has two transformation paths; one
maps fog images to a fogfree image domain and the other maps fogfree images to a fog image domain. Instead
of one stage mapping, our system uses a two stage mapping strategy in each transformation path to
enhance the effectiveness of fog removal. Furthermore, we make explicit use of prior knowledge
in the networks by embedding the atmospheric degradation principle and a sky prior for mapping fogfree
images to the fog images domain. In addition, we also contribute the first real world nature fog-fogfree
image dataset for defogging research. Our multiple real fog images dataset (MRFID) contains images
of 200 natural outdoor scenes. For each scene, there are one clear image and corresponding four foggy
images of different fog densities manually selected from a sequence of images taken by a fixed camera
over the course of one year. Qualitative and quantitative comparison against several state-of-the-art
methods on both synthetic and real world images demonstrate that our approach is effective and performs
favorably for recovering a clear image from a foggy image. 