Depth estimation is an active area of research in the field of computer vision, and has garnered significant
interest due to its rising demand in a large number of applications ranging from robotics and unmanned
aerial vehicles to autonomous vehicles. A particularly challenging problem in this area is monocular
depth estimation, where the goal is to infer depth from a single image. An effective strategy that
has shown considerable promise in recent years for tackling this problem is the utilization of deep
convolutional neural networks. Despite these successes, the memory and computational requirements
of such networks have made widespread deployment in embedded scenarios very challenging. In this
study, we introduce DepthNet Nano, a highly compact self normalizing network for monocular depth
estimation designed using a human machine collaborative design strategy, where principled network
design prototyping based on encoder-decoder design principles are coupled with machine-driven
design exploration. The result is a compact deep neural network with highly customized macroarchitecture
and microarchitecture designs, as well as self-normalizing characteristics, that are highly
tailored for the task of embedded depth estimation. The proposed DepthNet Nano possesses a highly
efficient network architecture (e.g., 24X smaller and 42X fewer MAC operations than Alhashim et
al. on KITTI), while still achieving comparable performance with state-of-the-art networks on
the NYU-Depth V2 and KITTI datasets. Furthermore, experiments on inference speed and energy efficiency
on a Jetson AGX Xavier embedded module further illustrate the efficacy of DepthNet Nano at different
resolutions and power budgets (e.g., ~14 FPS and >0.46 images/sec/watt at 384 X 1280 at a 30W power
budget on KITTI). 