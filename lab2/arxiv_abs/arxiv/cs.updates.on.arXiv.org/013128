Person re-identification (re-id), the process of matching pedestrian images across different
camera views, is an important task in visual surveillance. Substantial development of re-id has
recently been observed, and the majority of existing models are largely dependent on color appearance
and assume that pedestrians do not change their clothes across camera views. This limitation, however,
can be an issue for re-id when tracking a person at different places and at different time if that person
(e.g., a criminal suspect) changes his/her clothes, causing most existing methods to fail, since
they are heavily relying on color appearance and thus they are inclined to match a person to another
person wearing similar clothes. In this work, we call the person re-id under clothing change the
"cross-clothes person re-id". In particular, we consider the case when a person only changes his
clothes moderately as a first attempt at solving this problem based on visible light images; that
is we assume that a person wears clothes of a similar thickness, and thus the shape of a person would
not change significantly when the weather does not change substantially within a short period of
time. We perform cross-clothes person re-id based on a contour sketch of person image to take advantage
of the shape of the human body instead of color information for extracting features that are robust
to moderate clothing change. Due to the lack of a large-scale dataset for cross-clothes person re-id,
we contribute a new dataset that consists of 33698 images from 221 identities. Our experiments illustrate
the challenges of cross-clothes person re-id and demonstrate the effectiveness of our proposed
method. 