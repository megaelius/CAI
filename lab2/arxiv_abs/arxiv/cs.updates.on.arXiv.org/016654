We consider basic conceptual questions concerning the relationship between statistical estimation
and causal inference. Firstly, we show how to translate causal inference problems into an abstract
statistical formalism without requiring any structure beyond an arbitrarily-indexed family
of probability models. The formalism is simple but can incorporate a variety of causal modelling
frameworks, including 'structural causal models', but also models expressed in terms of, e.g.,
differential equations. We focus primarily on the structural/graphical causal modelling literature,
however. Secondly, we consider the extent to which causal and statistical concerns can be cleanly
separated, examining the fundamental question: 'What can be estimated from data?'. We call this
the problem of estimability. We approach this by analysing a standard formal definition of 'can
be estimated' commonly adopted in the causal inference literature -- identifiability -- in our
abstract statistical formalism. We use elementary category theory to show that identifiability
implies the existence of a Fisher-consistent estimator, but also show that this estimator may be
discontinuous, and thus unstable, in general. This difficulty arises because the causal inference
problem is, in general, an ill-posed inverse problem. Inverse problems have three conditions which
must be satisfied to be considered well-posed: existence, uniqueness, and stability of solutions.
Here identifiability corresponds to the question of uniqueness; in contrast, we take estimability
to mean satisfaction of all three conditions, i.e. well-posedness. Lack of stability implies that
naive translation of a causally identifiable quantity into an achievable statistical estimation
target may prove impossible. Our article is primarily expository and aimed at unifying ideas from
multiple fields, though we provide new constructions and proofs. 