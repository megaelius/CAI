Owing to the ubiquitous availability of radio-frequency (RF) signals, RF energy harvesting is
emerging as an appealing solution for powering IoT devices. In this paper, we model and analyze an
IoT network which harvests RF energy and receives information from the same wireless network. In
order to enable this operation, each time slot is partitioned into charging and information reception
phases. For this setup, we characterize two performance metrics: (i) energy coverage and (ii) joint
signal-to-interference-plus-noise (SINR) and energy coverage. The analysis is performed using
a realistic spatial model that captures the spatial coupling between the locations of the IoT devices
and the nodes of the wireless network (referred henceforth as the IoT gateways), which is often ignored
in the literature. In particular, we model the locations of the IoT devices using a Poisson cluster
process (PCP) and assume that some of the clusters have IoT gateways (GWs) deployed at their centers
while the other GWs are deployed independently of the IoT devices. The level of coupling can be controlled
by tuning the fraction of total GWs that are deployed at the cluster centers. Due to the inherent intractability
of computing the distribution of shot noise process for this setup, we propose two accurate approximations,
using which the aforementioned metrics are characterized. Multiple system design insights are
drawn from our results. For instance, we demonstrate the existence of optimal slot partitioning
that maximizes the system throughput. In addition, we explore the effect of the level of coupling
between the locations of the IoT devices and the GWs on this optimal slot partitioning. Particularly,
our results reveal that the optimal value of time duration for the charging phase increases as the
level of coupling decreases. 