One-shot face recognition measures the ability to identify persons with only seeing them at one
glance, and is a hallmark of human visual intelligence. It is challenging for conventional machine
learning approaches to mimic this way, since limited data are hard to effectively represent the
data variance. The goal of one-shot face recognition is to learn a large-scale face recognizer,
which is capable to fight off the data imbalance challenge. In this paper, we propose a novel generative
adversarial one-shot face recognizer, attempting to synthesize meaningful data for one-shot
classes by adapting the data variances from other normal classes. Specifically, we target at building
a more effective general face classifier for both normal persons and one-shot persons. Technically,
we design a new loss function by formulating knowledge transfer generator and a general classifier
into a unified framework. Such a two-player minimax optimization can guide the generation of more
effective data, which effectively promote the underrepresented classes in the learned model and
lead to a remarkable improvement in face recognition performance. We evaluate our proposed model
on the MS-Celeb-1M one-shot learning benchmark task, where we could recognize 94.98% of the test
images at the precision of 99% for the one-shot classes, keeping an overall Top1 accuracy at $99.80\%$
for the normal classes. To the best of our knowledge, this is the best performance among all the published
methods using this benchmark task with the same setup, including all the participants in the recent
MS-Celeb-1M challenge at ICCV 2017\footnote{this http URL}. 