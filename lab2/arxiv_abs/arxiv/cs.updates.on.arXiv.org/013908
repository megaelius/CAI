Cyber Physical Systems (CPS) have increasingly started using Learning Enabled Components (LECs)
for performing perception-based control tasks. The simple design approach, and their capability
to continuously learn has led to their widespread use in different autonomous applications. Despite
their simplicity and impressive capabilities, these models are difficult to assure, which makes
their use challenging. The problem of assuring CPS with untrusted controllers has been achieved
using the Simplex Architecture. This architecture integrates the system to be assured with a safe
controller and provides a decision logic to switch between the decisions of these controllers.
However, the key challenges in using the Simplex Architecture are: (1) designing an effective decision
logic, and (2) sudden transitions between controller decisions lead to inconsistent system performance.
To address these research challenges, we make three key contributions: (1) \textit{dynamic-weighted
simplex strategy} -- we introduce ``weighted simplex strategy" as the weighted ensemble extension
of the classical Simplex Architecture. We then provide a reinforcement learning based mechanism
to find dynamic ensemble weights, (2) \textit{middleware framework} -- we design a framework that
allows the use of the dynamic-weighted simplex strategy, and provides a resource manager to monitor
the computational resources, and (3) \textit{hardware testbed} -- we design a remote-controlled
car testbed called DeepNNCar to test and demonstrate the aforementioned key concepts. Using the
hardware, we show that the dynamic-weighted simplex strategy has 60\% fewer out-of-track occurrences
(soft constraint violations), while demonstrating higher optimized speed (performance) of 0.4
m/s during indoor driving than the original LEC driven system. 