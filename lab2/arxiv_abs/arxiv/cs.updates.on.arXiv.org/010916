Artificial intelligence (AI) holds great promise to empower us with knowledge and augment our effectiveness.
We can -- and must -- ensure that we keep humans safe and in control, particularly with regard to government
and public sector applications that affect broad populations. How can AI development teams harness
the power of AI systems and design them to be valuable to humans? Diverse teams are needed to build
trustworthy artificial intelligent systems, and those teams need to coalesce around a shared set
of ethics. There are many discussions in the AI field about ethics and trust, but there are few frameworks
available for people to use as guidance when creating these systems. The Human-Machine Teaming
(HMT) Framework for Designing Ethical AI Experiences described in this paper, when used with a set
of technical ethics, will guide AI development teams to create AI systems that are accountable,
de-risked, respectful, secure, honest, and usable. To support the team's efforts, activities
to understand people's needs and concerns will be introduced along with the themes to support the
team's efforts. For example, usability testing can help determine if the audience understands
how the AI system works and complies with the HMT Framework. The HMT Framework is based on reviews
of existing ethical codes and best practices in human-computer interaction and software development.
Human-machine teams are strongest when human users can trust AI systems to behave as expected, safely,
securely, and understandably. Using the HMT Framework to design trustworthy AI systems will provide
support to teams in identifying potential issues ahead of time and making great experiences for
humans. 