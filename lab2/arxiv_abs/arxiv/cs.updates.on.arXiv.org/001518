The introduction of artificial intelligence (AI) on visual images for emotional analysis obliterates
the natural subjectivity and contextual dependence of our facial displays. Emotion AI places itself
as an algorithmic lens on our digital artifacts and real-time interactions, creating the illusion
of a new, objective class of data: our emotional and mental states. Building upon a rich network of
existing public photographs--as well as fresh feeds from surveillance footage or smart phone cameras--these
emotion algorithms require no additional infrastructure or improvements on image quality. In
order to examine the potential policy and legal remedies for emotion AI as an emerging technology,
we first establish a framework of actors, collection motivations, time scales, and space considerations
that differentiates emotion AI from other algorithmic lenses. Each of these elements influences
available policy remedies, and should shape continuing discussions on the antecedent conditions
that make emotional AI acceptable or not in particular contexts. Based on our framework of unique
elements, we examine potential available policy remedies to prevent or remediate harm. Specifically,
our paper looks toward the regulatory role of the Federal Trade Commission in the US, gaps in the EU's
General Data Protection Regulation (GDPR) allowing for emotion data collection, and precedent
set by polygraph technologies in evidentiary and use restrictions set by law. We also examine the
way social norms and adaptations could grow to also modulate broader use. Given the challenges in
controlling the flow of these data, we call for further research and attention as emotion AI technology
remains poised for adoption. 