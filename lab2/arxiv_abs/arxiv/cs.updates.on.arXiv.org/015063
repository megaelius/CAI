Tackling real-world socio-economic challenges requires designing and testing economic policies.
However, this is hard in practice, due to a lack of appropriate (micro-level) economic data and limited
opportunity to experiment. In this work, we train social planners that discover tax policies in
dynamic economies that can effectively trade-off economic equality and productivity. We propose
a two-level deep reinforcement learning approach to learn dynamic tax policies, based on economic
simulations in which both agents and a government learn and adapt. Our data-driven approach does
not make use of economic modeling assumptions, and learns from observational data alone. We make
four main contributions. First, we present an economic simulation environment that features competitive
pressures and market dynamics. We validate the simulation by showing that baseline tax systems
perform in a way that is consistent with economic theory, including in regard to learned agent behaviors
and specializations. Second, we show that AI-driven tax policies improve the trade-off between
equality and productivity by 16% over baseline policies, including the prominent Saez tax framework.
Third, we showcase several emergent features: AI-driven tax policies are qualitatively different
from baselines, setting a higher top tax rate and higher net subsidies for low incomes. Moreover,
AI-driven tax policies perform strongly in the face of emergent tax-gaming strategies learned
by AI agents. Lastly, AI-driven tax policies are also effective when used in experiments with human
participants. In experiments conducted on MTurk, an AI tax policy provides an equality-productivity
trade-off that is similar to that provided by the Saez framework along with higher inverse-income
weighted social welfare. 