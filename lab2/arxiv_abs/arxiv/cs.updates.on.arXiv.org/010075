Numerous learning methods for fuzzy cognitive maps (FCMs), such as the Hebbian-based and the population-based
learning methods, have been developed for modeling and simulating dynamic systems. However, these
methods are faced with several obvious limitations. Most of these models are extremely time consuming
when learning the large-scale FCMs with hundreds of nodes. Furthermore, the FCMs learned by those
algorithms lack robustness when the experimental data contain noise. In addition, reasonable
distribution of the weights is rarely considered in these algorithms, which could result in the
reduction of the performance of the resulting FCM. In this article, a straightforward, rapid, and
robust learning method is proposed to learn FCMs from noisy data, especially, to learn large-scale
FCMs. The crux of the proposed algorithm is to equivalently transform the learning problem of FCMs
to a classic-constrained convex optimization problem in which the least-squares term ensures
the robustness of the well-learned FCM and the maximum entropy term regularizes the distribution
of the weights of the well-learned FCM. A series of experiments covering two frequently used activation
functions (the sigmoid and hyperbolic tangent functions) are performed on both synthetic datasets
with noise and real-world datasets. The experimental results show that the proposed method is rapid
and robust against data containing noise and that the well-learned weights have better distribution.
In addition, the FCMs learned by the proposed method also exhibit superior performance in comparison
with the existing methods. Index Terms-Fuzzy cognitive maps (FCMs), maximum entropy, noisy data,
rapid and robust learning. 