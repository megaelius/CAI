We introduce a dynamic artificial neural network-based (ANN) adaptive inference process, which
learns temporal predictive models of dynamical systems. We term the process REPRISE, a REtrospective
and PRospective Inference SchEme. REPRISE infers the unobservable contextual state that best
explains its recently encountered sensorimotor experiences as well as accompanying, context-dependent
temporal predictive models retrospectively. Meanwhile, it executes prospective inference,
optimizing upcoming motor activities in a goal-directed manner. In a first implementation, a recurrent
neural network (RNN) is trained to learn a temporal forward model, which predicts the sensorimotor
contingencies of different simulated dynamic vehicles. The RNN is augmented with contextual neurons,
which enable the compact encoding of distinct, but related sensorimotor dynamics. We show that
REPRISE is able to concurrently learn to separate and approximate the encountered sensorimotor
dynamics. Moreover, we show that REPRISE can exploit the learned model to induce goal-directed,
model-predictive control, that is, approximate active inference: Given a goal state, the system
imagines a motor command sequence optimizing it with the prospective objective to minimize the
distance to a given goal. Meanwhile, the system evaluates the encountered sensorimotor contingencies
retrospectively, adapting its neural hidden states for maintaining model coherence. The RNN activities
thus continuously imagine the upcoming future and reflect on the recent past, optimizing both,
hidden state and motor activities. In conclusion, the combination of temporal predictive structures
with modulatory, generative encodings offers a way to develop compact event codes, which selectively
activate particular types of sensorimotor event-specific dynamics. 