With Machine Learning (ML) services now used in a number of mission-critical human-facing domains,
ensuring the integrity and trustworthiness of ML models becomes all-important. In this work, we
consider the paradigm where cloud service providers collect big data from resource-constrained
devices for building ML-based prediction models that are then sent back to be run locally on the intermittently-connected
resource-constrained devices. Our proposed solution comprises an intelligent polynomial-time
heuristic that maximizes the level of trust of ML models by selecting and switching between a subset
of the ML models from a superset of models in order to maximize the trustworthiness while respecting
the given reconfiguration budget/rate and reducing the cloud communication overhead. We evaluate
the performance of our proposed heuristic using two case studies. First, we consider Industrial
IoT (IIoT) services, and as a proxy for this setting, we use the turbofan engine degradation simulation
dataset to predict the remaining useful life of an engine. Our results in this setting show that the
trust level of the selected models is 0.49% to 3.17% less compared to the results obtained using Integer
Linear Programming (ILP). Second, we consider Smart Cities services, and as a proxy of this setting,
we use an experimental transportation dataset to predict the number of cars. Our results show that
the selected model's trust level is 0.7% to 2.53% less compared to the results obtained using ILP.
We also show that our proposed heuristic achieves an optimal competitive ratio in a polynomial-time
approximation scheme for the problem. 