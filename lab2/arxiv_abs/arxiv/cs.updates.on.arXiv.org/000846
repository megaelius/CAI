The task of a visual landmark recognition system is to identify photographed buildings or objects
in query photos and to provide the user with relevant information on them. With their increasing
coverage of the world's landmark buildings and objects, Internet photo collections are now being
used as a source for building such systems in a fully automatic fashion. This process typically consists
of three steps: clustering large amounts of images by the objects they depict; determining object
names from user-provided tags; and building a robust, compact, and efficient recognition index.
To this date, however, there is little empirical information on how well current approaches for
those steps perform in a large-scale open-set mining and recognition task. Furthermore, there
is little empirical information on how recognition performance varies for different types of landmark
objects and where there is still potential for improvement. With this paper, we intend to fill these
gaps. Using a dataset of 500k images from Paris, we analyze each component of the landmark recognition
pipeline in order to answer the following questions: How many and what kinds of objects can be discovered
automatically? How can we best use the resulting image clusters to recognize the object in a query?
How can the object be efficiently represented in memory for recognition? How reliably can semantic
information be extracted? And finally: What are the limiting factors in the resulting pipeline
from query to semantics? We evaluate how different choices of methods and parameters for the individual
pipeline steps affect overall system performance and examine their effects for different query
categories such as buildings, paintings or sculptures. 