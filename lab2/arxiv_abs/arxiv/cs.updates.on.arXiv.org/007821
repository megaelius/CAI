Deep Convolutional Neural Networks (CNNs) are a special type of Neural Networks, which have shown
state-of-the-art results on various competitive benchmarks. The powerful learning ability of
deep CNN is largely achieved with the use of multiple feature extraction stages that can automatically
learn hierarchical representations from the data. Availability of a large amount of data and improvements
in the hardware processing units have accelerated the research in CNNs, and recently very interesting
deep CNN architectures are reported. The recent race in developing deep CNN architectures has shown
that the innovative architectural ideas, as well as parameter optimization, can improve the CNN
performance on various vision-related tasks. In this regard, different ideas in the CNN design
have been explored such as the use of different activation and loss functions, parameter optimization,
regularization, and restructuring of the processing units. However, the major improvement in
representational capacity of the deep CNN is achieved by the restructuring of the processing units.
Especially, the idea of using a block as a structural unit instead of a layer is receiving substantial
attention. This survey thus focuses on the intrinsic taxonomy present in the recently reported
deep CNN architectures and consequently, classifies the recent innovations in CNN architectures
into seven different categories. These seven categories are based on spatial exploitation, depth,
multi-path, width, feature map exploitation, channel boosting, and attention. Additionally,
it covers the elementary understanding of the CNN components and sheds light on the current challenges
and applications of CNNs. 