Modern wearable rehabilitation devices and health support systems operate by sensing and analysing
human body activities. The information produced by such systems requires efficient methods for
classification and analysis. Deep learning algorithms have shown remarkable potential regarding
such analyses, however, the use of such algorithms on low-power wearable devices is challenged
by resource constraints. Most of the available on-chip deep learning processors contain complex
and dense hardware architectures in order to achieve the highest possible throughput. Such a trend
in hardware design may not be efficient in applications where on-node computation is required and
the focus is more on the area and power efficiency as in the case of portable and embedded biomedical
devices. The aim of this paper is to overcome some of the limitations in a current typical deep learning
framework and present a flexible and efficient platform for biomedical time series classification.
Here, throughput is traded off with hardware complexity and cost exploiting resource sharing techniques.
This compromise is only feasible in systems where the underlying time series is characterised by
slow dynamics as in the case of physiological systems. A Long-Short-Term-Memory (LSTM) based architecture
with ternary weight precision is employed and synthesized on a Xilinx FPGA. Hardware synthesis
and physical implementation confirm that the proposed hardware can accurately classify hand gestures
using surface-electromyographical time series data with low area and power consumption. Most
notably, our classifier reaches 1.46$\times$ higher GOPs/Slice than similar state of the art FPGA-based
accelerators. 