Robot sequential decision-making in the real world is a challenge because it requires the robots
to simultaneously reason about the current world state and dynamics, while planning actions to
accomplish complex tasks. On the one hand, declarative languages and reasoning algorithms well
support representing and reasoning with commonsense knowledge. But these algorithms are not good
at planning actions toward maximizing cumulative reward over a long, unspecified horizon. On the
other hand, probabilistic planning frameworks, such as Markov decision processes (MDPs) and partially
observable MDPs (POMDPs), well support planning to achieve long-term goals under uncertainty.
But they are ill-equipped to represent or reason about knowledge that is not directly related to
actions. In this article, we present a novel algorithm, called iCORPP, to simultaneously estimate
the current world state, reason about world dynamics, and construct task-oriented controllers.
In this process, robot decision-making problems are decomposed into two interdependent (smaller)
subproblems that focus on reasoning to "understand the world" and planning to "achieve the goal"
respectively. Contextual knowledge is represented in the reasoning component, which makes the
planning component epistemic and enables active information gathering. The developed algorithm
has been implemented and evaluated both in simulation and on real robots using everyday service
tasks, such as indoor navigation, dialog management, and object delivery. Results show significant
improvements in scalability, efficiency, and adaptiveness, compared to competitive baselines
including handcrafted action policies. 