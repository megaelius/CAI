In recent years, the use of deep learning algorithms has become increasingly more prominent for
their unparalleled ability to automatically learn discriminant features from large amounts of
data. However, within the field of electromyography-based gesture recognition, deep learning
algorithms are seldom employed as it requires an unreasonable amount of time for a single person,
in a single session, to generate tens of thousands of examples. This work's hypothesis is that general,
informative features can be learned from the large amount of data generated by aggregating the signals
of multiple users, thus reducing the recording burden imposed on a single person while enhancing
gesture recognition. As such, this paper proposes applying transfer learning on the aggregated
data of multiple users, while leveraging the capacity of deep learning algorithms to learn discriminant
features from large dataset, without the need for in-depth feature engineering. To this end, two
datasets are recorded with the Myo Armband (Thalmic Labs), a low-cost, low-sampling rate (200Hz),
8-channel, consumer-grade, dry electrode sEMG armband. These two datasets are comprised of 19
and 17 able-bodied participants respectively. A third dataset, also recorded with the Myo Armband,
was taken from the NinaPro database and is comprised of 10 able-bodied participants. This transfer
learning scheme is shown to outperform the current state-of-the-art in gesture recognition. It
achieves an average accuracy of 98.31% for 7 hand/wrist gestures over 17 able-bodied participants
and 65.57% for 18 hand/wrist gestures over 10 able-bodied participants. Finally, a use-case study
employing eight able-bodied participants suggests that real-time feedback reduces the degradation
in accuracy normally experienced over time. 