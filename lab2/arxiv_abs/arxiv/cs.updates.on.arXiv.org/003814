In this paper, we consider an adversarial scenario where one agent seeks to achieve an objective
and its adversary seeks to learn the agent's intentions and prevent the agent from achieving its
objective. The agent has an incentive to try to deceive the adversary about its intentions, while
at the same time working to achieve its objective. The primary contribution of this paper is to introduce
a mathematically rigorous framework for the notion of deception within the context of optimal control.
The central notion introduced in the paper is that of a belief-induced reward: a reward dependent
not only on the agent's state and action, but also adversary's beliefs. Design of an optimal deceptive
strategy then becomes a question of optimal control design on the product of the agent's state space
and the adversary's belief space. The proposed framework allows for deception to be defined in an
arbitrary control system endowed with a reward function, as well as with additional specifications
limiting the agent's control policy. In addition to defining deception, we discuss design of optimally
deceptive strategies under uncertainties in agent's knowledge about the adversary's learning
process. In the latter part of the paper, we focus on a setting where the agent's behavior is governed
by a Markov decision process, and show that the design of optimally deceptive strategies under lack
of knowledge about the adversary naturally reduces to previously discussed problems in control
design on partially observable or uncertain Markov decision processes. Finally, we present two
examples of deceptive strategies: a "cops and robbers" scenario and an example where an agent may
use camouflage while moving. We show that optimally deceptive strategies in such examples follow
the intuitive idea of how to deceive an adversary in the above settings. 