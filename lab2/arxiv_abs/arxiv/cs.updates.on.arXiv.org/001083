As parallelism becomes critically important in the semiconductor technology, high-performance
computing, and cloud applications, parallel network systems will increasingly follow suit. Today,
parallelism is an essential architectural feature of 40/100/400 Gigabit Ethernet standards,
whereby high speed Ethernet systems are equipped with multiple parallel network interfaces. This
creates new network topology abstractions and new technology requirements: instead of a single
high capacity network link, multiple Ethernet end-points and interfaces need to be considered
together with multiple links in form of discrete parallel paths. This new paradigm is enabling implementations
of various new features to improve overall system performance. In this paper, we analyze the performance
of parallel network systems with network coding. In particular, by using random LNC (RLNC), - a code
without the need for decoding, we can make use of the fact that we have codes that are both distributed
(removing the need for coordination or optimization of resources) and composable (without the
need to exchange code information), leading to a fully stateless operation. We propose a novel theoretical
modeling framework, including derivation of the upper and lower bounds as well as an expected value
of the differential delay of parallel paths, and the resulting queue size at the receiver. The results
show a great promise of network system parallelism in combination with RLNC: with a proper set of
design parameters, the differential delay and the buffer size at the Ethernet receiver can be reduced
significantly, while the cross-layer design and routing can be greatly simplified. 