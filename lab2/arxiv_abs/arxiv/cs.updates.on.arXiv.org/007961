What is the current state-of-the-art for image restoration and enhancement applied to degraded
images acquired under less than ideal circumstances? Can the application of such algorithms as
a pre-processing step to improve image interpretability for manual analysis or automatic visual
recognition to classify scene content? While there have been important advances in the area of computational
photography to restore or enhance the visual quality of an image, the capabilities of such techniques
have not always translated in a useful way to visual recognition tasks. Consequently, there is a
pressing need for the development of algorithms that are designed for the joint problem of improving
visual appearance and recognition, which will be an enabling factor for the deployment of visual
recognition tools in many real-world scenarios. To address this, we introduce the UG^2 dataset
as a large-scale benchmark composed of video imagery captured under challenging conditions, and
two enhancement tasks designed to test algorithmic impact on visual quality and automatic object
recognition. Furthermore, we propose a set of metrics to evaluate the joint improvement of such
tasks as well as individual algorithmic advances, including a novel psychophysics-based evaluation
regime for human assessment and a realistic set of quantitative measures for object recognition
performance. We introduce six new algorithms for image restoration or enhancement, which were
created as part of the IARPA sponsored UG^2 Challenge workshop held at CVPR 2018. Under the proposed
evaluation regime, we present an in-depth analysis of these algorithms and a host of deep learning-based
and classic baseline approaches. From the observed results, it is evident that we are in the early
days of building a bridge between computational photography and visual recognition, leaving many
opportunities for innovation in this area. 