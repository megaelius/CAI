Competency Questions (CQs) are natural language questions outlining and constraining the scope
of knowledge represented by an ontology. Despite that CQs are a part of several ontology engineering
methodologies, we have observed that the actual publication of CQs for the available ontologies
is very limited and even scarcer is the publication of their respective formalisations in terms
of, e.g., SPARQL queries. This paper aims to contribute to addressing the engineering shortcomings
of using CQs in ontology development, to facilitate wider use of CQs. In order to understand the relation
between CQs and the queries over the ontology to test the CQs on an ontology, we gather, analyse, and
publicly release a set of 234 CQs and their translations to SPARQL-OWL for several ontologies in
different domains developed by different groups. We analysed the CQs in two principal ways. The
first stage focused on a linguistic analysis of the natural language text itself, i.e., a lexico-syntactic
analysis without any presuppositions of ontology elements, and a subsequent step of semantic analysis
in order to find patterns. This increased diversity of CQ sources resulted in a 5-fold increase of
hitherto published patterns, to 106 distinct CQ patterns, which have a limited subset of few patterns
shared across the CQ sets from the different ontologies. Next, we analysed the relation between
the found CQ patterns and the 46 SPARQL-OWL query signatures, which revealed that one CQ pattern
may be realised by more than one SPARQL-OWL query signature, and vice versa. We hope that our work
will contribute to establishing common practices, templates, automation, and user tools that
will support CQ formulation, formalisation, execution, and general management. 