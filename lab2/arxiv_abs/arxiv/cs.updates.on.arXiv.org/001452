This work addresses the problem of semantic foggy scene understanding (SFSU). Although extensive
research has been performed on image dehazing and on semantic scene understanding with weather-clear
images, little attention has been paid to SFSU. Due to the difficulty of collecting and annotating
foggy images, we choose to generate synthetic fog on real images that depict weather-clear outdoor
scenes, and then leverage these synthetic data for SFSU by employing state-of-the-art convolutional
neural networks (CNN). In particular, a complete pipeline to generate synthetic fog on real, weather-clear
images using incomplete depth information is developed. We apply our fog synthesis on the Cityscapes
dataset and generate Foggy Cityscapes with 20550 images. SFSU is tackled in two fashions: 1) with
typical supervised learning, and 2) with a novel semi-supervised learning, which combines 1) with
an unsupervised supervision transfer from weather-clear images to their synthetic foggy counterparts.
In addition, this work carefully studies the usefulness of image dehazing for SFSU. For evaluation,
we present Foggy Driving, a dataset with 101 real-world images depicting foggy driving scenes,
which come with ground truth annotations for semantic segmentation and object detection. Extensive
experiments show that 1) supervised learning with our synthetic data significantly improves the
performance of state-of-the-art CNN for SFSU on Foggy Driving; 2) our semi-supervised learning
strategy further improves performance; and 3) image dehazing marginally benefits SFSU with our
learning strategy. The datasets, models and code will be made publicly available to encourage further
research in this direction. 