Different convolutional neural network (CNN) models have been tested for their application in
histological image analyses. However, these models are prone to overfitting due to their large
parameter capacity, requiring more data or valuable computational resources for model training.
Given these limitations, we introduced a novel architecture (termed PlexusNet). We utilized 310
Hematoxylin and Eosin stained (H&E) annotated histological images of prostate cancer cases from
TCGA-PRAD and Stanford University and 398 H&E whole slides images from the Camelyon 2016 challenge.
PlexusNet-architecture -derived models were compared to models derived from several existing
"state of the art" architectures. We measured discrimination accuracy, calibration, and clinical
utility. An ablation study was conducted to study the effect of each component of PlexusNet on model
performance. A well-fitted PlexusNet-based model delivered comparable classification performance
(AUC: 0.963) in distinguishing prostate cancer from healthy tissues, although it was at least 23
times smaller, had a better model calibration and clinical utility than the comparison models.
A separate smaller PlexusNet model accurately detected slides with breast cancer metastases (AUC:
0.978); it helped reduce the slide number to examine by 43.8% without consequences, although its
parameter capacity was 200 times smaller than ResNet18. We found that the partitioning of the development
set influences the model calibration for all models. However, with PlexusNet architecture, we
could achieve comparable well-calibrated models trained on different partitions. In conclusion,
PlexusNet represents a novel model architecture for histological image analysis that achieves
classification performance comparable to other models while providing orders-of-magnitude
parameter reduction. 