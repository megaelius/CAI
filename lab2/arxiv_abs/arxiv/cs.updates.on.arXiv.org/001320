In this paper we present current trends in real-time music tracking (a.k.a. score following). Casually
speaking, these algorithms "listen" to a live performance of music, compare the audio signal to
an abstract representation of the score, and "read" along in the sheet music. In this way at any given
time the exact position of the musician(s) in the sheet music is computed. Here, we focus on the aspects
of flexibility and usability of these algorithms. This comprises work on automatic identification
and flexible tracking of the piece being played as well as current approaches based on Deep Learning.
The latter enables direct learning of correspondences between complex audio data and images of
the sheet music, avoiding the complicated and time-consuming definition of a mid-level representation.
----- Diese Arbeit befasst sich mit aktuellen Entwicklungen in der automatischen Musikverfolgung
durch den Computer. Es handelt sich dabei um Algorithmen, die einer musikalischen Auff\"uhrung
"zuh\"oren", das aufgenommene Audiosignal mit einer (abstrakten) Repr\"asentation des Notentextes
vergleichen und sozusagen in diesem mitlesen. Der Algorithmus kennt also zu jedem Zeitpunkt die
Position der Musiker im Notentext. Neben der Vermittlung eines generellen \"Uberblicks, liegt
der Schwerpunkt dieser Arbeit auf der Beleuchtung des Aspekts der Flexibilit\"at und der einfacheren
Nutzbarkeit dieser Algorithmen. Es wird dargelegt, welche Schritte get\"atigt wurden (und aktuell
get\"atigt werden) um den Prozess der automatischen Musikverfolgung einfacher zug\"anglich
zu machen. Dies umfasst Arbeiten zur automatischen Identifikation von gespielten St\"ucken und
deren flexible Verfolgung ebenso wie aktuelle Ans\"atze mithilfe von Deep Learning, die es erlauben
Bild und Ton direkt zu verbinden, ohne Umwege \"uber abstrakte und nur unter gro{\ss}em Zeitaufwand
zu erstellende Zwischenrepr\"asentationen. 