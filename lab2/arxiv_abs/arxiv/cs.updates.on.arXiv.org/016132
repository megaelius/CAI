FinBots are chatbots built on automated decision technology, aimed to facilitate accessible banking
and to support customers in making financial decisions. Chatbots are increasing in prevalence,
sometimes even equipped to mimic human social rules, expectations and norms, decreasing the necessity
for human-to-human interaction. As banks and financial advisory platforms move towards creating
bots that enhance the current state of consumer trust and adoption rates, we investigated the effects
of chatbot vignettes with and without socio-emotional features on intention to use the chatbot
for financial support purposes. We conducted a between-subject online experiment with N = 410 participants.
Participants in the control group were provided with a vignette describing a secure and reliable
chatbot called XRO23, whereas participants in the experimental group were presented with a vignette
describing a secure and reliable chatbot that is more human-like and named Emma. We found that Vignette
Emma did not increase participants' trust levels nor lowered their privacy concerns even though
it increased perception of social presence. However, we found that intention to use the presented
chatbot for financial support was positively influenced by perceived humanness and trust in the
bot. Participants were also more willing to share financially-sensitive information such as account
number, sort code and payments information to XRO23 compared to Emma - revealing a preference for
a technical and mechanical FinBot in information sharing. Overall, this research contributes
to our understanding of the intention to use chatbots with different features as financial technology,
in particular that socio-emotional support may not be favoured when designed independently of
financial function. 