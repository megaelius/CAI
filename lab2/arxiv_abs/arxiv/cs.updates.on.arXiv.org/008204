Egocentric vision is an emerging field of computer vision that is characterized by the acquisition
of images and video from the first person perspective. In this paper we address the challenge of egocentric
human action recognition by utilizing the presence and position of detected regions of interest
in the scene explicitly, without further use of visual features. Initially, we recognize that human
hands are essential in the execution of actions and focus on obtaining their movements as the principal
cues that define actions. We employ object detection and region tracking techniques to locate hands
and capture their movements. Prior knowledge about egocentric views facilitates hand identification
between left and right. With regard to detection and tracking, we contribute a pipeline that successfully
operates on unseen egocentric videos to find the camera wearer's hands and associate them through
time. Moreover, we emphasize on the value of scene information for action recognition. We acknowledge
that the presence of objects is significant for the execution of actions by humans and in general
for the description of a scene. To acquire this information, we utilize object detection for specific
classes that are relevant to the actions we want to recognize. Our experiments are targeted on videos
of kitchen activities from the Epic-Kitchens dataset. We model action recognition as a sequence
learning problem of the detected spatial positions in the frames. Our results show that explicit
hand and object detections with no other visual information can be relied upon to classify hand-related
human actions. Testing against methods fully dependent on visual features, signals that for actions
where hand motions are conceptually important, a region-of-interest-based description of a video
contains equally expressive information with comparable classification performance. 