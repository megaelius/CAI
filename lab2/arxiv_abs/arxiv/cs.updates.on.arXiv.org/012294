Any deletion and addition of image features are absolutely forbidden in many computer vision applications,
such as those in medicine, space, remote sensing and sciences. Therefore, professional users often
require image compression methods to be mathematically lossless. But lossless image coding has
a rather low compression ratio (around 2:1 for natural images). The only known technique to achieve
significant compression while meeting the stringent fidelity requirements is the methodology
of $\ell_\infty$-constrained coding that was developed and standardized in nineties. We make
a major progress in $\ell_\infty$-constrained image coding after two decades, by deep neural networks
crafted for $\ell_\infty$-constrained decoding. The new $\ell_\infty$-constrained decompression
network enjoys the advantages of Convolutional Neural Networks (CNN) in image restoration and
at the same time it also enforces a tight error bound on a per pixel basis. In our design, no small, distinctive
structures of the original image can be dropped or distorted, even if they are statistical outliers
that are otherwise sacrificed by mainstream CNN restoration methods; our decompression method
preserves sharp edges and hence achieves superior perceptual quality thanks to the $\ell_\infty$
minmax criterion. More importantly, this research ushers in a new hybrid image compression strategy,
called light encoding and deep decoding (LEDD), which couples the $\ell_\infty$-constrained
predictive encoding and a DCNN-based decoding. The LEDD strategy beats or matches the best of existing
lossy image compression methods such as BPG, WebP, not only in $\ell_\infty$ but also in $\ell_2$
error metric and perceptual quality, for bit rates near the threshold of perceptually transparent
reconstruction. Moreover, The LEDD has a very low encoding complexity and hence is suited for real-time
applications on end devices. 