Natural language understanding (NLU) of text is a fundamental challenge in AI, and it has received
significant attention throughout the history of NLP research. This primary goal has been studied
under different tasks, such as Question Answering (QA) and Textual Entailment (TE). In this thesis,
we investigate the NLU problem through the QA task and focus on the aspects that make it a challenge
for the current state-of-the-art technology. This thesis is organized into three main parts: In
the first part, we explore multiple formalisms to improve existing machine comprehension systems.
We propose a formulation for abductive reasoning in natural language and show its effectiveness,
especially in domains with limited training data. Additionally, to help reasoning systems cope
with irrelevant or redundant information, we create a supervised approach to learn and detect the
essential terms in questions. In the second part, we propose two new challenge datasets. In particular,
we create two datasets of natural language questions where (i) the first one requires reasoning
over multiple sentences; (ii) the second one requires temporal common sense reasoning. We hope
that the two proposed datasets will motivate the field to address more complex problems. In the final
part, we present the first formal framework for multi-step reasoning algorithms, in the presence
of a few important properties of language use, such as incompleteness, ambiguity, etc. We apply
this framework to prove fundamental limitations for reasoning algorithms. These theoretical
results provide extra intuition into the existing empirical evidence in the field. 