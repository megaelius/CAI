Recent work has shown that adversarial Windows malware samples - also referred to as adversarial
EXEmples in this paper - can bypass machine learning-based detection relying on static code analysis
by perturbing relatively few input bytes. To preserve malicious functionality, previous attacks
either add bytes to existing non-functional areas of the file, potentially limiting their effectiveness,
or require running computationally-demanding validation steps to discard malware variants that
do not correctly execute in sandbox environments. In this work, we overcome these limitations by
developing a unifying framework that not only encompasses and generalizes previous attacks against
machine-learning models, but also includes two novel attacks based on practical, functionality-preserving
manipulations to the Windows Portable Executable (PE) file format, based on injecting the adversarial
payload by respectively extending the DOS header and shifting the content of the first section.
Our experimental results show that these attacks outperform existing ones in both white-box and
black-box attack scenarios by achieving a better trade-off in terms of evasion rate and size of the
injected payload, as well as enabling evasion of models that were shown to be robust to previous attacks.
To facilitate reproducibility and future work, we open source our framework and all the corresponding
attack implementations. We conclude by discussing the limitations of current machine learning-based
malware detectors, along with potential mitigation strategies based on embedding domain knowledge
coming from subject-matter experts naturally into the learning process. 