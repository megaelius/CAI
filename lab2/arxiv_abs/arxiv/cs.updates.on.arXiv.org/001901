Synthesizing face sketches from real photos and its inverse are well studied problems and they have
many applications in digital forensics and entertainment. However, photo/sketch synthesis remains
a challenging problem due to the fact that photo and sketch have different characteristics. In this
work, we consider this task as an image-to-image translation problem and explore the recently popular
generative models (GANs) to generate high-quality realistic photos from sketches and sketches
from photos. Recent methods such as Pix2Pix, CycleGAN and DualGAN have shown promising results
on image-to-image translation problems and photo-to-sketch synthesis in particular, however,
they are known to have limited abilities in generating high-resolution realistic images. To this
end, we propose a novel synthesis framework called Photo-Sketch Synthesis using Multi-Adversarial
Networks, (PS\textsuperscript{2}-MAN) that iteratively generates low resolution to high resolution
images in an adversarial way. The hidden layers of the generator are supervised to first generate
lower resolution images followed by implicit refinement in the network to generate higher resolution
images. Furthermore, since photo-sketch synthesis is a coupled/paired translation problem where
photo-sketch and sketch-photo are equally important, we leverage the pair information in the CycleGAN
framework. Evaluation of the proposed method is performed on two datasets: CUHK and CUFSF. Both
Image Quality Assessment (IQA) and Photo-Sketch Matching experiments are conducted to demonstrate
the superior performance of our framework in comparison to existing state-of-the-art solutions.
Additionally, ablation studies are conducted to verify the effectiveness iterative synthesis
and various loss functions. 