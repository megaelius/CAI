Providing force feedback as relevant information in current Robot-Assisted Minimally Invasive
Surgery systems constitutes a technological challenge due to the constraints imposed by the surgical
environment. In this context, Sensorless Force Estimation techniques represent a potential solution,
enabling to sense the interaction forces between the surgical instruments and soft-tissues. Specifically,
if visual feedback is available for observing soft-tissues' deformation, this feedback can be
used to estimate the forces applied to these tissues. To this end, a force estimation model, based
on Convolutional Neural Networks and Long-Short Term Memory networks, is proposed in this work.
This model is designed to process both, the spatiotemporal information present in video sequences
and the temporal structure of tool data (the surgical tool-tip trajectory and its grasping status).
A series of analyses are carried out to reveal the advantages of the proposal and the challenges that
remain for real applications. This research work focuses on two surgical task scenarios, referred
to as pushing and pulling tissue. For these two scenarios, different input data modalities and their
effect on the force estimation quality are investigated. These input data modalities are tool data,
video sequences and a combination of both. The results suggest that the force estimation quality
is better when both, the tool data and video sequences, are processed by the neural network model.
Moreover, this study reveals the need for a loss function, designed to promote the modeling of smooth
and sharp details found in force signals. Finally, the results show that the modeling of forces due
to pulling tasks is more challenging than for the simplest pushing actions. 