This paper summarizes the idea of Low-Cost Interlinked Subarrays (LISA), which was published in
HPCA 2016, and examines the work's significance and future potential. Contemporary systems perform
bulk data movement movement inefficiently, by transferring data from DRAM to the processor, and
then back to DRAM, across a narrow off-chip channel. The use of this narrow channel results in high
latency and energy consumption. Prior work proposes to avoid these high costs by exploiting the
existing wide internal DRAM bandwidth for bulk data movement, but the limited connectivity of wires
within DRAM allows fast data movement within only a single DRAM subarray. Each subarray is only a
few megabytes in size, greatly restricting the range over which fast bulk data movement can happen
within DRAM. Our HPCA 2016 paper proposes a new DRAM substrate, Low-Cost Inter-Linked Subarrays
(LISA), whose goal is to enable fast and efficient data movement across a large range of memory at
low cost. LISA adds low-cost connections between adjacent subarrays. By using these connections
to interconnect the existing internal wires (bitlines) of adjacent subarrays, LISA enables wide-bandwidth
data transfer across multiple subarrays with little (only 0.8%) DRAM area overhead. As a DRAM substrate,
LISA is versatile, enabling a variety of new applications. We describe and evaluate three such applications
in detail: (1) fast inter-subarray bulk data copy, (2) in-DRAM caching using a DRAM architecture
whose rows have heterogeneous access latencies, and (3) accelerated bitline precharging by linking
multiple precharge units together. Our extensive evaluations show that each of LISA's three applications
significantly improves performance and memory energy efficiency on a variety of workloads and
system configurations. 