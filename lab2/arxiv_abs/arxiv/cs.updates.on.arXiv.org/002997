Humans and animals have the ability to continually acquire and fine-tune knowledge throughout
their lifespan. This ability is mediated by a rich set of neurocognitive functions that together
contribute to the early development and experience-driven specialization of our sensorimotor
skills. Consequently, the ability to learn from continuous streams of information is crucial for
computational learning systems and autonomous agents (inter)acting in the real world. However,
continual lifelong learning remains a long-standing challenge for machine learning and neural
network models since the incremental acquisition of new skills from non-stationary data distributions
generally leads to catastrophic forgetting or interference. This limitation represents a major
drawback also for state-of-the-art deep neural network models that typically learn representations
from stationary batches of training data, thus without accounting for situations in which the number
of tasks is not known a priori and the information becomes incrementally available over time. In
this review, we critically summarize the main challenges linked to continual lifelong learning
for artificial learning systems and compare existing neural network approaches that alleviate,
to different extents, catastrophic interference. Although significant advances have been made
in domain-specific continual lifelong learning with neural networks, extensive research efforts
are required for the development of general-purpose artificial intelligence and autonomous agents.
We discuss well-established research and recent methodological trends motivated by experimentally
observed lifelong learning factors in biological systems. Such factors include principles of
neurosynaptic stability-plasticity, critical developmental stages, intrinsically motivated
exploration, transfer learning, and crossmodal integration. 