We present new randomized algorithms that improve the complexity of the classic $(\Delta+1)$-coloring
problem, and its generalization $(\Delta+1)$-list-coloring, in three well-studied models of
distributed, parallel, and centralized computation: Distributed Congested Clique: We present
an $O(1)$-round randomized algorithm for $(\Delta+1)$-list coloring in the congested clique
model of distributed computing. This settles the asymptotic complexity of this problem. It moreover
improves upon the $O(\log^\ast \Delta)$-round randomized algorithms of Parter and Su [DISC'18]
and $O((\log\log \Delta)\cdot \log^\ast \Delta)$-round randomized algorithm of Parter [ICALP'18].
Massively Parallel Computation: We present a $(\Delta+1)$-list coloring algorithm with round
complexity $O(\sqrt{\log\log n})$ in the Massively Parallel Computation (MPC) model with strongly
sublinear memory per machine. This algorithm uses a memory of $O(n^{\alpha})$ per machine, for
any desirable constant $\alpha>0$, and a total memory of $\widetilde{O}(m)$, where $m$ is the size
of the graph. Notably, this is the first coloring algorithm with sublogarithmic round complexity,
in the sublinear memory regime of MPC. For the quasilinear memory regime of MPC, an $O(1)$-round
algorithm was given very recently by Assadi et al. [SODA'19]. Centralized Local Computation: We
show that $(\Delta+1)$-list coloring can be solved with $\Delta^{O(1)} \cdot O(\log n)$ query
complexity, in the centralized local computation model. The previous state-of-the-art for $(\Delta+1)$-list
coloring in the centralized local computation model are based on simulation of known LOCAL algorithms.
