With pervasive applications of medical imaging in health-care, biomedical image segmentation
plays a central role in quantitative analysis, clinical diagno- sis, and medical intervention.
Since manual anno- tation su ers limited reproducibility, arduous e orts, and excessive time, automatic
segmentation is desired to process increasingly larger scale histopathological data. Recently,
deep neural networks (DNNs), par- ticularly fully convolutional networks (FCNs), have been widely
applied to biomedical image segmenta- tion, attaining much improved performance. At the same time,
quantization of DNNs has become an ac- tive research topic, which aims to represent weights with
less memory (precision) to considerably reduce memory and computation requirements of DNNs while
maintaining acceptable accuracy. In this paper, we apply quantization techniques to FCNs for accurate
biomedical image segmentation. Unlike existing litera- ture on quantization which primarily
targets memory and computation complexity reduction, we apply quan- tization as a method to reduce
over tting in FCNs for better accuracy. Speci cally, we focus on a state-of- the-art segmentation
framework, suggestive annotation [22], which judiciously extracts representative annota- tion
samples from the original training dataset, obtain- ing an e ective small-sized balanced training
dataset. We develop two new quantization processes for this framework: (1) suggestive annotation
with quantiza- tion for highly representative training samples, and (2) network training with
quantization for high accuracy. Extensive experiments on the MICCAI Gland dataset show that both
quantization processes can improve the segmentation performance, and our proposed method exceeds
the current state-of-the-art performance by up to 1%. In addition, our method has a reduction of
up to 6.4x on memory usage. 