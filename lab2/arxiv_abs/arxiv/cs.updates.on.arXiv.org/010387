Applications of Fully Convolutional Networks (FCN) in iris segmentation have shown promising
advances. For mobile and embedded systems, a significant challenge is that the proposed FCN architectures
are extremely computationally demanding. In this article, we propose a resource-efficient, end-to-end
iris recognition flow, which consists of FCN-based segmentation, contour fitting, followed by
Daugman normalization and encoding. To attain accurate and efficient FCN models, we propose a three-step
SW/HW co-design methodology consisting of FCN architectural exploration, precision quantization,
and hardware acceleration. In our exploration, we propose multiple FCN models, and in comparison
to previous works, our best-performing model requires 50X less FLOPs per inference while achieving
a new state-of-the-art segmentation accuracy. Next, we select the most efficient set of models
and further reduce their computational complexity through weights and activations quantization
using 8-bit dynamic fixed-point (DFP) format. Each model is then incorporated into an end-to-end
flow for true recognition performance evaluation. A few of our end-to-end pipelines outperform
the previous state-of-the-art on two datasets evaluated. Finally, we propose a novel DFP accelerator
and fully demonstrate the SW/HW co-design realization of our flow on an embedded FPGA platform.
In comparison with the embedded CPU, our hardware acceleration achieves up to 8.3X speedup for the
overall pipeline while using less than 15% of the available FPGA resources. We also provide comparisons
between the FPGA system and an embedded GPU showing different benefits and drawbacks for the two
platforms. 