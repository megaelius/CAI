Software testing plays a crucial role to ensure the conformance of software systems with their requirements.
Exhaustive testing procedures are enforced by functional safety standards which mandate that
each requirement be covered by system test cases. Test engineers need to identify all the representative
test execution scenarios from requirements, determine the runtime conditions that trigger these
scenarios, and finally provide the test input data that satisfy these conditions. Given that requirements
specifications are typically large and often provided in natural language (e.g., use case specifications),
the generation of system test cases tends to be expensive and error-prone. In this paper, we present
Use Case Modelling for System Tests Generation (UMTG), an approach that supports the generation
of executable system test cases from requirements specifications in natural language, with the
goal of reducing the manual effort required to generate test cases and ensuring requirements' coverage.
More specifically, UMTG automates the generation of system test cases based on use case specifications
and a domain model for the system under test, which are commonly produced in many development environments.
Unlike existing approaches, it does not impose strong restrictions on the template of use case specifications.
It relies on recent advances in natural language processing to automatically identify test scenarios
and to generate formal constraints that capture conditions triggering the execution of the scenarios,
thus enabling the generation of test data. In two industrial case studies, UMTG automatically and
correctly translated 95% of the use case specification steps into formal constraints required
for test data generation; furthermore, it generated test cases that exercise critical scenarios
not previously considered by engineers. 