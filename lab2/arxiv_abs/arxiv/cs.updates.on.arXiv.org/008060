Data driven soft sensor design has recently gained immense popularity, due to advances in sensory
devices, and a growing interest in data mining. While partial least squares (PLS) is traditionally
used in the process literature for designing soft sensors, the statistical literature has focused
on sparse learners, such as Lasso and relevance vector machine (RVM), to solve the high dimensional
data problem. In the current study, predictive performances of three regression techniques, PLS,
Lasso and RVM were assessed and compared under various offline and online soft sensing scenarios
applied on datasets from five real industrial plants, and a simulated process. In offline learning,
predictions of RVM and Lasso were found to be superior to those of PLS when a large number of time-lagged
predictors were used. Online prediction results gave a slightly more complicated picture. It was
found that the minimum prediction error achieved by PLS under moving window (MW), or just-in-time
learning scheme was decreased up to ~5-10% using Lasso, or RVM. However, when a small MW size was used,
or the optimum number of PLS components was as low as ~1, prediction performance of PLS surpassed
RVM, which was found to yield occasional unstable predictions. PLS and Lasso models constructed
via online parameter tuning generally did not yield better predictions compared to those constructed
via offline tuning. We present evidence to suggest that retaining a large portion of the available
process measurement data in the predictor matrix, instead of preselecting variables, would be
more advantageous for sparse learners in increasing prediction accuracy. As a result, Lasso is
recommended as a better substitute for PLS in soft sensors; while performance of RVM should be validated
before online application. 