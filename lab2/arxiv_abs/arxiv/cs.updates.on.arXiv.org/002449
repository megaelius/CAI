Single image haze removal is a very challenging and ill-posed problem. The existing haze removal
methods in literature, including the recently introduced deep learning methods, model the problem
of haze removal as that of estimating intermediate parameters, viz., scene transmission map and
atmospheric light. These are used to compute the haze-free image from the hazy input image. Such
an approach only focuses on accurate estimation of intermediate parameters, while the aesthetic
quality of the haze-free image is unaccounted for in the optimization framework. Thus, errors in
the estimation of intermediate parameters often lead to generation of inferior quality haze-free
images. In this paper, we present CANDY (Conditional Adversarial Networks based Dehazing of hazY
images), a fully end-to-end model which directly generates a clean haze-free image from a hazy input
image. CANDY also incorporates the visual quality of haze-free image into the optimization function;
thus, generating a superior quality haze-free image. To the best of our knowledge, this is the first
work in literature to propose a fully end-to-end model for single image haze removal. Also, this
is the first work to explore the newly introduced concept of generative adversarial networks for
the problem of single image haze removal. The proposed model CANDY was trained on a synthetically
created haze image dataset, while evaluation was performed on challenging synthetic as well as
real haze image datasets. The extensive evaluation and comparison results of CANDY reveal that
it significantly outperforms existing state-of-the-art haze removal methods in literature,
both quantitatively as well as qualitatively. 