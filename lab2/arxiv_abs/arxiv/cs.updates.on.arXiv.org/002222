In interpretation of remote sensing images, it is possible that some images which are supplied by
different sensors become understandable. For better visual perception of these images, it is essential
to operate series of pre-processing and elementary corrections and then operate a series of main
processing steps for more precise analysis on the images. There are several approaches for processing
which are depended on the type of remote sensing images. The discussed approach in this article,
i.e. image fusion, is the use of natural colors of an optical image for adding color to a grayscale
satellite image which gives us the ability for better observation of the HR image of OLI sensor of
Landsat-8. This process with emphasis on details of fusion technique has previously been performed;
however, we are going to apply the concept of the interpolation process. In fact, we see many important
software tools such as ENVI and ERDAS as the most famous remote sensing image processing tools have
only classical interpolation techniques (such as bi-linear (BL) and bi-cubic/cubic convolution
(CC)). Therefore, ENVI- and ERDAS-based researches in image fusion area and even other fusion researches
often dont use new and better interpolators and are mainly concentrated on the fusion algorithms
details for achieving a better quality, so we only focus on the interpolation impact on fusion quality
in Landsat-8 multispectral images. The important feature of this approach is to use a statistical,
adaptive, and edge-guided interpolation method for improving the color quality in the images in
practice. Numerical simulations show selecting the suitable interpolation techniques in MRF-based
images creates better quality than the classical interpolators. 