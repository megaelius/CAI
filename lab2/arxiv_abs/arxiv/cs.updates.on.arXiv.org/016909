We propose a class of neural network models that universally approximate any point process intensity
function. Our model can be easily applied to a wide variety of applications where the distribution
of event times is of interest, such as, earthquake aftershocks, social media events, and financial
transactions. Point processes have long been used to model these events, but more recently, neural
network point process models have been developed to provide further flexibility. However, the
theoretical foundations of these neural point processes are not well understood. We propose a neural
network point process model which uses the summation of basis functions and the function composition
of a transfer function to define point process intensity functions. In contrast to prior work, we
prove that our model has universal approximation properties in the limit of infinite basis functions.
We demonstrate how to use positive monotonic Lipschitz continuous transfer functions to shift
universal approximation from the class of real valued continuous functions to the class of point
process intensity functions. To this end, the Stone-Weierstrass Theorem is used to provide sufficient
conditions for the sum of basis functions to achieve point process universal approximation. We
further extend the notion of universal approximation mentioned in prior work for neural point processes
to account for the approximation of sequences, instead of just single events. Using these insights,
we design and implement a novel neural point process model that achieves strong empirical results
on synthetic and real world datasets; outperforming state-of-the-art neural point process on
all but one real world dataset. 