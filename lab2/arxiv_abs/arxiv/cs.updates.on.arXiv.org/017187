We present a data-driven approach using word embeddings to discover and categorise language biases
on the discussion platform Reddit. As spaces for isolated user communities, platforms such as Reddit
are increasingly connected to issues of racism, sexism and other forms of discrimination. Hence,
there is a need to monitor the language of these groups. One of the most promising AI approaches to
trace linguistic biases in large textual datasets involves word embeddings, which transform text
into high-dimensional dense vectors and capture semantic relations between words. Yet, previous
studies require predefined sets of potential biases to study, e.g., whether gender is more or less
associated with particular types of jobs. This makes these approaches unfit to deal with smaller
and community-centric datasets such as those on Reddit, which contain smaller vocabularies and
slang, as well as biases that may be particular to that community. This paper proposes a data-driven
approach to automatically discover language biases encoded in the vocabulary of online discourse
communities on Reddit. In our approach, protected attributes are connected to evaluative words
found in the data, which are then categorised through a semantic analysis system. We verify the effectiveness
of our method by comparing the biases we discover in the Google News dataset with those found in previous
literature. We then successfully discover gender bias, religion bias, and ethnic bias in different
Reddit communities. We conclude by discussing potential application scenarios and limitations
of this data-driven bias discovery method. 