Up-to-date catalogs of the urban tree population are important for municipalities to monitor and
improve quality of life in cities. Despite much research on automation of tree mapping, mainly relying
on dedicated airborne LiDAR or hyperspectral campaigns, trees are still mostly mapped manually
in practice. We present a fully automated tree detection and species recognition pipeline to process
thousands of trees within a few hours using publicly available aerial and street view images of Google
MapsTM. These data provide rich information (viewpoints, scales) from global tree shapes to bark
textures. Our work-flow is built around a supervised classification that automatically learns
the most discriminative features from thousands of trees and corresponding, public tree inventory
data. In addition, we introduce a change tracker to keep urban tree inventories up-to-date. Changes
of individual trees are recognized at city-scale by comparing street-level images of the same tree
location at two different times. Drawing on recent advances in computer vision and machine learning,
we apply convolutional neural networks (CNN) for all classification tasks. We propose the following
pipeline: download all available panoramas and overhead images of an area of interest, detect trees
per image and combine multi-view detections in a probabilistic framework, adding prior knowledge;
recognize fine-grained species of detected trees. In a later, separate module, track trees over
time and identify the type of change. We believe this is the first work to exploit publicly available
image data for fine-grained tree mapping at city-scale, respectively over many thousands of trees.
Experiments in the city of Pasadena, California, USA show that we can detect > 70% of the street trees,
assign correct species to > 80% for 40 different species, and correctly detect and classify changes
in > 90% of the cases. 