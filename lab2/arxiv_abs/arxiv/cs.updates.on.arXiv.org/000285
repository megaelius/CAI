Scientific problems that depend on processing large amounts of data require overcoming challenges
in multiple areas: managing large-scale data distribution, controlling co-placement and scheduling
of data with compute resources, and storing, transferring, and managing large volumes of data.
Although there exist multiple approaches to addressing each of these challenges, an integrative
approach is missing; furthermore, extending existing functionality or enabling interoperable
capabilities remains difficult at best. We propose the concept of Pilot-Data to address the fundamental
challenges of co-placement and scheduling of data and compute in heterogeneous and distributed
environments with interoperability and extensibility as first-order concerns. Pilot-Data is
an extension of the Pilot-Job abstraction for supporting the management of data in conjunction
with compute tasks. Pilot-Data separates logical data units from physical storage, thereby providing
the basis for efficient compute/data placement and scheduling. In this paper, we discuss the design
and implementation of the Pilot-Data prototype, demonstrate its use by data-intensive applications
on multiple production distributed cyberinfrastructure and illustrate the advantages arising
from flexible execution modes enabled by Pilot-Data. Our experiments utilize an implementation
of Pilot-Data in conjunction with a scalable Pilot-Job (BigJob) to establish the application performance
that can be enabled by the use of Pilot-Data. We demonstrate how the concept of Pilot-Data also provides
the basis upon which to build tools and support capabilities like affinity which in turn can be used
for advanced data-compute co-placement and scheduling. 