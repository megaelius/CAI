A key step in medical diagnosis is giving the patient a universally recognized label (e.g. Appendicitis)
which essentially assigns the patient to a class(es) of patients with similar body failures. However,
two patients having the same disease label(s) with high probability may still have differences
in their feature manifestation patterns implying differences in the required treatments. Additionally,
in many cases, the labels of the primary diagnoses leave some findings unexplained. Medical diagnosis
is only partially about probability calculations for label X or Y. Diagnosis is not complete until
the patient overall situation is clinically understood to the level that enables the best therapeutic
decisions. Most machine learning models are data centric models, and evidence so far suggest they
can reach expert level performance in the disease labeling phase. Nonetheless, like any other mathematical
technique, they have their limitations and applicability scope. Primarily, data centric algorithms
are knowledge blind and lack anatomy and physiology knowledge that physicians leverage to achieve
complete diagnosis. This article advocates to complement them with intelligence to overcome their
inherent limitations as knowledge blind algorithms. Machines can learn many things from data,
but data is not the only source that machines can learn from. Historic patient data only tells us what
the possible manifestations of a certain body failure are. Anatomy and physiology knowledge tell
us how the body works and fails. Both are needed for complete diagnosis. The proposed Double Deep
Learning approach, along with the initiative for Medical Wikipedia for Smart Machines, leads to
AI diagnostic support solutions for complete diagnosis beyond the limited data only labeling solutions
we see today. AI for medicine will forever be limited until their intelligence also integrates anatomy
and physiology. 