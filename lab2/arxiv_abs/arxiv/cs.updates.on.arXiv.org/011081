The Internet of Things (IoT) has become the forefront of bridging different technologies together.
It brings rise to online computational services that make mundane tasks convenient. However, the
volume of devices connecting to the network started to increase. In turn, services that thrived
on centralized storage are being strained and overloaded. As applications and software advances,
processing and computational power become a concern to technology companies. With data risks and
large numbers of connected devices, cloud computing has become outdated. Devices are forced to
commit unnecessary expenses to stay relevant in the market due to the increase in software complexity.
This need for change resulted in the introduction of edge computing. Edge computing distributes
the computational strain between the server and the devices. This contribution allows the cloud
to accommodate more users and devices are no longer in need to make significant changes to their design
every so often. Many real-time applications have evolved to require high amounts of processing
power to execute. For example, sound classification comes with massive computational needs due
to its affiliation with neural networks and deep learning. This paper aims to create a feasible and
deployable real-time sound classification system. There were three configurations tested in
this paper. The results of our experiments show that cloud computing and edge computing alone cannot
cater to a technological market that is exponentially growing in size and complexity. However,
the same results show promise in finding optimal configurations in terms of a combination of end
device power consumption, application runtime and server latency to systems instead of focusing
on a single model. Overall, it is better to take into consideration the strengths and weaknesses
of each computing architecture. 