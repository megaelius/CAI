Recent years have witnessed the emergence and development of graph neural networks (GNNs), which
have been shown as a powerful approach for graph representation learning in many tasks, such as node
classification and graph classification. The research on the robustness of these models has also
started to attract attentions in the machine learning field. However, most of the existing work
in this area focus on the GNNs for node-level tasks, while little work has been done to study the robustness
of the GNNs for the graph classification task. In this paper, we aim to explore the vulnerability
of the Hierarchical Graph Pooling (HGP) Neural Networks, which are advanced GNNs that perform very
well in the graph classification in terms of prediction accuracy. We propose an adversarial attack
framework for this task. Specifically, we design a surrogate model that consists of convolutional
and pooling operators to generate adversarial samples to fool the hierarchical GNN-based graph
classification models. We set the preserved nodes by the pooling operator as our attack targets,
and then we perturb the attack targets slightly to fool the pooling operator in hierarchical GNNs
so that they will select the wrong nodes to preserve. We show the adversarial samples generated from
multiple datasets by our surrogate model have enough transferability to attack current state-of-art
graph classification models. Furthermore, we conduct the robust train on the target models and
demonstrate that the retrained graph classification models are able to better defend against the
attack from the adversarial samples. To the best of our knowledge, this is the first work on the adversarial
attack against hierarchical GNN-based graph classification models. 