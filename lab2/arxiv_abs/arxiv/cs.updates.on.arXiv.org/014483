Motivated by modern applications of light detection and ranging (LIDAR), we study the model of an
optical receiver based on an avalanche photo-diode (APD), followed by electronic circuitry for
detection of reflected optical signals and estimation of their delay.This model is known to be quite
complicated as it consists of at least three different types of noise: thermal noise, shot noise,
and multiplicative noise (excess noise) that stems from the random gain associated with the photo-multiplication
of the APD. Consequently, the derivation of the optimal likelihood ratio test (LRT) associated
with signal detection is a non-trivial task, which has no apparent exact closed--form solution.
We consider instead a class of relatively simple detectors, that are based on correlating the noisy
received signal with a given deterministic waveform, and our purpose is to characterize the optimal
waveform in the sense of the best trade--off between the false-alarm (FA) error exponent and the
missed-detection (MD) error exponent. In the same spirit, we also study the problem of estimating
the delay on the basis of maximizing the correlation between the received signal and a time-shifted
waveform, as a function of this time shift. We characterize the optimal correlator waveform that
minimizes the mean square error (MSE) in the regime of high signal-to-noise ratio (SNR). The optimal
correlator waveforms for detection and for estimation turn out to be different, but their limiting
behavior is the same: when the thermal Gaussian noise is dominant, the optimal correlator waveform
becomes proportional to the clean signal, but when the thermal noise is negligible compared to the
other noises, then it becomes logarithmic function of the clean signal, as expected. 