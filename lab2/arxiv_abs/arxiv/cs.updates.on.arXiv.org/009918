Explainable recommendation attempts to develop models that generate not only high-quality recommendations
but also intuitive explanations. The explanations may either be post-hoc or directly come from
an explainable model (also called interpretable or transparent model in some context). Explainable
recommendation tries to address the problem of why: by providing explanations to users or system
designers, it helps humans to understand why certain items are recommended by the algorithm, where
the human can either be users or system designers. Explainable recommendation helps to improve
the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation
systems. In this survey, we review works on explainable recommendation in or before the year of 2019.
We first highlight the position of explainable recommendation in recommender system research
by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then
conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide
a chronological research timeline of explainable recommendation, including user study approaches
in the early years and more recent model-based approaches. 2) We provide a two-dimensional taxonomy
to classify existing explainable recommendation research: one dimension is the information source
(or display style) of the explanations, and the other dimension is the algorithmic mechanism to
generate explainable recommendations. 3) We summarize how explainable recommendation applies
to different recommendation tasks, such as product recommendation, social recommendation, and
POI recommendation. We also devote a section to discuss the explanation perspectives in broader
IR and AI/ML research. We end the survey by discussing potential future directions to promote the
explainable recommendation research area and beyond. 