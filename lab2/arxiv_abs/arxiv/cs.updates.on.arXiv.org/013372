Strictly proper scoring rules (SPSR) are incentive compatible for eliciting information about
random variables from strategic agents when the principal can reward agents after the realization
of the random variables. They also quantify the quality of elicited information, with more accurate
predictions receiving higher score in expectation. In this paper, we extend such scoring rules
to settings where a principal elicits private probabilistic beliefs but only has access to agents'
reports. We name our solution \emph{Surrogate Scoring Rules} (SSR). SSR build on a bias correction
step and an error rate estimation procedure for a reference answer defined using agents' reports.
We show that, with one bit of information about the prior distribution of the random variables, SSR
in a multi-task setting recover SPSR in expectation, as if having access to the ground truth. Therefore,
a salient feature of SSR is that they quantify the quality of information despite the lack of ground
truth, just as SPSR do for the {\em with} ground truth setting. As a by-product, SSR induce \emph{dominant
truthfulness} in reporting. Our work complements the proper scoring rule literature via extending
existing SPSR to operate when there is no clean ground truth verification. Because of the non-existence
of verification, our setting falls into the classical information elicitation without verification
(IEWV) domain, which has focused on eliciting discrete signals. Therefore our work also contributes
to the peer prediction literature via providing a scoring rule that elicits continuous probabilistic
beliefs, an approach that rewards accuracy instead of correlation, and a mechanism that achieves
truthfulness in \emph{dominant strategy} in a multi-task setting. Our method is verified both
theoretically and empirically using data collected from real human forecasters. 