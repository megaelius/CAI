Purpose Surgical simulations play an increasingly important role in surgeon education and developing
algorithms that enable robots to perform surgical subtasks. To model anatomy, Finite Element Method
(FEM) simulations have been held as the gold standard for calculating accurate soft-tissue deformation.
Unfortunately, their accuracy is highly dependent on the simulation parameters, which can be difficult
to obtain. Methods In this work, we investigate how live data acquired during any robotic endoscopic
surgical procedure may be used to correct for inaccurate FEM simulation results. Since FEMs are
calculated from initial parameters and cannot directly incorporate observations, we propose
to add a correction factor that accounts for the discrepancy between simulation and observations.
We train a network to predict this correction factor. Results To evaluate our method, we use an open-source
da Vinci Surgical System to probe a soft-tissue phantom and replay the interaction in simulation.
We train the network to correct for the difference between the predicted mesh position and the measured
point cloud. This results in 15-30% improvement in the mean distance, demonstrating the effectiveness
of our approach across a large range of simulation parameters. Conclusion We show a first step towards
a framework that synergistically combines the benefits of model-based simulation and real-time
observations. It corrects discrepancies between simulation and the scene that results from inaccurate
modeling parameters. This can provide a more accurate simulation environment for surgeons and
better data with which to train algorithms. 