Few-shot learning (FSL) aims at recognizing novel classes given only few training samples, which
still remains a great challenge for deep learning. However, humans can easily recognize novel classes
with only few samples. A key component of such ability is the compositional recognition that human
can perform, which has been well studied in cognitive science but is not well explored in FSL. Inspired
by such capability of humans, to imitate humans' ability of learning visual primitives and composing
primitives to recognize novel classes, we propose an approach to FSL to learn a feature representation
composed of important primitives, which is jointly trained with two parts, i.e. primitive discovery
and primitive enhancing. In primitive discovery, we focus on learning primitives related to object
parts by self-supervision from the order of image splits, avoiding extra laborious annotations
and alleviating the effect of semantic gaps. In primitive enhancing, inspired by current studies
on the interpretability of deep networks, we provide our composition view for the FSL baseline model.
To modify this model for effective composition, inspired by both mathematical deduction and biological
studies (the Hebbian Learning rule and the Winner-Take-All mechanism), we propose a soft composition
mechanism by enlarging the activation of important primitives while reducing that of others, so
as to enhance the influence of important primitives and better utilize these primitives to compose
novel classes. Extensive experiments on public benchmarks are conducted on both the few-shot image
classification and video recognition tasks. Our method achieves the state-of-the-art performance
on all these datasets and shows better interpretability. 