We reveal that the Analytic Signal phase, and its gradient have a hitherto unstudied discontinuity
in $2-D $ and higher dimensions. The shortcoming can result in severe artifacts whereas the problem
does not exist in $1-D $ signals. Direct use of Gabor phase, or its gradient, in computer vision and
biometric recognition e.g., as done in influential studies \cite{fleet90,wiskott1997face},
may produce undesired results that will go unnoticed unless special images similar to ours reveal
them. Instead of the Analytic Signal phase, we suggest the use of Linear Symmetry phase, relying
on more than one set of Gabor filters, but with a negligible computational add-on, as a remedy. Gradient
magnitudes of this phase are continuous in contrast to that of the analytic signal whereas continuity
of the gradient direction of the phase is guaranteed if Linear Symmetry Tensor replaces gradient
vector. The suggested phase has also a built-in automatic scale estimator, useful for robust detection
of patterns by multi-scale processing. We show crucial concepts on synthesized fingerprint images,
where ground truth regarding instantaneous frequency, (scale \& direction), and phase are known
with favorable results. A comparison to a baseline alternative is also reported. To that end, a novel
multi-scale minutia model where location, direction, and scale of minutia parameters are steerable,
without the creation of uncontrollable minutia is also presented. This is a useful tool, to reduce
development times of minutia detection methods with explainable behavior. A revealed consequence
is that minutia directions are not determined by the linear phase alone, but also by each other and
the influence must be corrected to obtain steerability and accurate ground truths. Essential conclusions
are readily transferable to $N-D $, and unrelated applications, e.g. optical flow or disparity
estimation in stereo. 