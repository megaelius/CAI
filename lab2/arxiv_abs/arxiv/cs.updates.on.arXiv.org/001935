Incentive mechanism plays a critical role in privacy-aware crowdsensing. Most previous studies
on co-design of incentive mechanism and privacy preservation assume a trustworthy fusion center
(FC). Very recent work has taken steps to relax the assumption on trustworthy FC and allows participatory
users (PUs) to add well calibrated noise to their raw sensing data before reporting them, whereas
the focus is on the equilibrium behavior of data subjects with binary data. Making a paradigm shift,
this paper aim to quantify the privacy compensation for continuous data sensing while allowing
FC to directly control PUs. There are two conflicting objectives in such scenario: FC desires better
quality data in order to achieve higher aggregation accuracy whereas PUs prefer adding larger noise
for higher privacy-preserving levels (PPLs). To achieve a good balance therein, we design an efficient
incentive mechanism to REconcile FC's Aggregation accuracy and individual PU's data Privacy (REAP).
Specifically, we adopt the celebrated notion of differential privacy to measure PUs' PPLs and quantify
their impacts on FC's aggregation accuracy. Then, appealing to Contract Theory, we design an incentive
mechanism to maximize FC's aggregation accuracy under a given budget. The proposed incentive mechanism
offers different contracts to PUs with different privacy preferences, by which FC can directly
control PUs. It can further overcome the information asymmetry, i.e., the FC typically does not
know each PU's precise privacy preference. We derive closed-form solutions for the optimal contracts
in both complete information and incomplete information scenarios. Further, the results are generalized
to the continuous case where PUs' privacy preferences take values in a continuous domain. Extensive
simulations are provided to validate the feasibility and advantages of our proposed incentive
mechanism. 