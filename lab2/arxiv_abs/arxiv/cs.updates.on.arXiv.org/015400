While recent advances in deep learning have significantly advanced the state of the art for vessel
detection in color fundus (CF) images, the success for detecting vessels in fluorescein angiography
(FA) has been stymied due to the lack of labeled ground truth datasets. We propose a novel pipeline
to detect retinal vessels in FA images using deep neural networks that reduces the effort required
for generating labeled ground truth data by combining two key components: cross-modality transfer
and human-in-the-loop learning. The cross-modality transfer exploits concurrently captured
CF and fundus FA images. Binary vessels maps are first detected from CF images with a pre-trained
neural network and then are geometrically registered with and transferred to FA images via robust
parametric chamfer alignment to a preliminary FA vessel detection obtained with an unsupervised
technique. Using the transferred vessels as initial ground truth labels for deep learning, the
human-in-the-loop approach progressively improves the quality of the ground truth labeling by
iterating between deep-learning and labeling. The approach significantly reduces manual labeling
effort while increasing engagement. We highlight several important considerations for the proposed
methodology and validate the performance on three datasets. Experimental results demonstrate
that the proposed pipeline significantly reduces the annotation effort and the resulting deep
learning methods outperform prior existing FA vessel detection methods by a significant margin.
A new public dataset, RECOVERY-FA19, is introduced that includes high-resolution ultra-widefield
images and accurately labeled ground truth binary vessel maps. 