Road extraction in remote sensing images is of great importance for a wide range of applications.
Because of the complex background, and high density, most of the existing methods fail to accurately
extract a road network that appears correct and complete. Moreover, they suffer from either insufficient
training data or high costs of manual annotation. To address these problems, we introduce a new model
to apply structured domain adaption for synthetic image generation and road segmentation. We incorporate
a feature pyramid network into generative adversarial networks to minimize the difference between
the source and target domains. A generator is learned to produce quality synthetic images, and the
discriminator attempts to distinguish them. We also propose a feature pyramid network that improves
the performance of the proposed model by extracting effective features from all the layers of the
network for describing different scales objects. Indeed, a novel scale-wise architecture is introduced
to learn from the multi-level feature maps and improve the semantics of the features. For optimization,
the model is trained by a joint reconstruction loss function, which minimizes the difference between
the fake images and the real ones. A wide range of experiments on three datasets prove the superior
performance of the proposed approach in terms of accuracy and efficiency. In particular, our model
achieves state-of-the-art 78.86 IOU on the Massachusetts dataset with 14.89M parameters and 86.78B
FLOPs, with 4x fewer FLOPs but higher accuracy (+3.47% IOU) than the top performer among state-of-the-art
approaches used in the evaluation. 