Our aural experience plays an integral role in the perception and memory of the events in our lives.
Some of the sounds we encounter throughout the day stay lodged in our minds more easily than others;
these, in turn, may serve as powerful triggers of our memories. In this paper, we measure the memorability
of everyday sounds across 20,000 crowd-sourced aural memory games, and assess the degree to which
a sound's memorability is constant across subjects. We then use this data to analyze the relationship
between memorability and acoustic features like harmonicity, spectral skew, and models of cognitive
salience; we also assess the relationship between memorability and high-level features with a
dependence on the sound source itself, such as its familiarity, valence, arousal, source type,
causal certainty, and verbalizability. We find that (1) our crowd-sourced measures of memorability
and confusability are reliable and robust across participants; (2) that the authors' measure of
collective causal uncertainty detailed in our previous work, coupled with measures of visualizability
and valence, are the strongest individual predictors of memorability; (3) that acoustic and salience
features play a heightened role in determining "confusability" (the false positive selection
rate associated with a sound) relative to memorability, and that (4), within the framework of our
assessment, memorability is an intrinsic property of the sounds from the dataset, shown to be independent
of surrounding context. We suggest that modeling these cognitive processes opens the door for human-inspired
compression of sound environments, automatic curation of large-scale environmental recording
datasets, and real-time modification of aural events to alter their likelihood of memorability.
