Developing neural network image classification models often requires significant architecture
engineering. In this paper, we attempt to automate this engineering process by learning the model
architectures directly on the dataset of interest. As this approach is expensive when the dataset
is large, we propose to search for an architectural building block on a small dataset and then transfer
the block to a larger dataset. Our key contribution is the design of a new search space which enables
transferability. In our experiments, we search for the best convolutional layer (or "cell") on
the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies
of this cell, each with their own parameters. Although the cell is not searched for directly on ImageNet,
an architecture constructed from the best cell achieves, among the published works, state-of-the-art
accuracy of 82.7% top-1 and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than
the best human-invented architectures while having 9 billion fewer FLOPS -- a reduction of 28% in
computational demand from the previous state-of-the-art model. When evaluated at different levels
of computational cost, accuracies of our models exceed those of the state-of-the-art human-designed
models. For instance, a smaller network constructed from the best cell also achieves 74% top-1 accuracy,
which is 3.1% better than equivalently-sized, state-of-the-art models for mobile platforms.
On CIFAR-10, an architecture constructed from the best cell achieves 2.4% error rate, which is also
state-of-the-art. Finally, the image features learned from image classification can also be transferred
to other computer vision problems. On the task of object detection, the learned features used with
the Faster-RCNN framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO dataset.
