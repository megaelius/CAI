Quantum superposition says that any physical system simultaneously exists in all of its possible
states, the number of which is exponential in the number of entities composing the system. The strength
of presence of each possible state in the superposition, i.e., its probability of being observed,
is represented by its probability amplitude coefficient. The assumption that these coefficients
must be represented physically disjointly from each other, i.e., localistically, is nearly universal
in the quantum theory/computing literature. Alternatively, these coefficients can be represented
using sparse distributed representations (SDR), wherein each coefficient is represented by small
subset of an overall population of units, and the subsets can overlap. Specifically, I consider
an SDR model in which the overall population consists of Q WTA clusters, each with K binary units.
Each coefficient is represented by a set of Q units, one per cluster. Thus, K^Q coefficients can be
represented with KQ units. Thus, the particular world state, X, whose coefficient's representation,
R(X), is the set of Q units active at time t has the max probability and the probability of every other
state, Y_i, at time t, is measured by R(Y_i)'s intersection with R(X). Thus, R(X) simultaneously
represents both the particular state, X, and the probability distribution over all states. Thus,
set intersection may be used to classically implement quantum superposition. If algorithms exist
for which the time it takes to store (learn) new representations and to find the closest-matching
stored representation (probabilistic inference) remains constant as additional representations
are stored, this meets the criterion of quantum computing. Such an algorithm has already been described:
it achieves this "quantum speed-up" without esoteric hardware, and in fact, on a single-processor,
classical (Von Neumann) computer. 