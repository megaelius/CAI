We consider the problem of enumerating relevant features hidden in other irrelevant information
for multi-labeled data, which is formalized as learning juntas. A $k$-junta function is a function
which depends on only $k$ coordinates of the input. For relatively small $k$ w.r.t. the input size
$n$, learning $k$-junta functions is one of fundamental problems both theoretically and practically
in machine learning. For the last two decades, much effort has been made to design efficient learning
algorithms for Boolean junta functions, and some novel techniques have been developed. However,
in real world, multi-labeled data seem to be obtained in much more often than binary-labeled one.
Thus, it is a natural question whether these techniques can be applied to more general cases about
the alphabet size. In this paper, we expand the Fourier detection techniques for the binary alphabet
to any finite field $\mathbb{F}_q$, and give, roughly speaking, an $O(n^{0.8k})$-time learning
algorithm for $k$-juntas over $\mathbb{F}_q$. Note that our algorithm is the first non-trivial
(i.e., non-brute force) algorithm for such a class even in the case where $q=3$ and we give an affirmative
answer to the question posed by Mossel et al. Our algorithm consists of two reductions: (1) from learning
juntas to LDME which is a variant of the learning with errors (LWE) problems introduced by Regev,
and (2) from LDME to the light bulb problem (LBP) introduced by L.Valiant. Since the reduced problem
(i.e., LBP) is a kind of binary problem regardless of the alphabet size of the original problem (i.e.,
learning juntas), we can directly apply the techniques for the binary case in the previous work.
