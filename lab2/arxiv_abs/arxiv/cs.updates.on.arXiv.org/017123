Heterogeneous Domain Adaptation (HDA) addresses the transfer learning problems where data from
the source and target domains are of different modalities (e.g., texts and images) or feature dimensions
(e.g., features extracted with different methods). It is useful for multi-modal data analysis.
Traditional domain adaptation algorithms assume that the representations of source and target
samples reside in the same feature space, hence are likely to fail in solving the heterogeneous domain
adaptation problem. Contemporary state-of-the-art HDA approaches are usually composed of complex
optimization objectives for favourable performance and are therefore computationally expensive
and less generalizable. To address these issues, we propose a novel Cross-Domain Structure Preserving
Projection (CDSPP) algorithm for HDA. As an extension of the classic LPP to heterogeneous domains,
CDSPP aims to learn domain-specific projections to map sample features from source and target domains
into a common subspace such that the class consistency is preserved and data distributions are sufficiently
aligned. CDSPP is simple and has deterministic solutions by solving a generalized eigenvalue problem.
It is naturally suitable for supervised HDA but has also been extended for semi-supervised HDA where
the unlabeled target domain samples are available. Extensive experiments have been conducted
on commonly used benchmark datasets (i.e. Office-Caltech, Multilingual Reuters Collection,
NUS-WIDE-ImageNet) for HDA as well as the Office-Home dataset firstly introduced for HDA by ourselves
due to its significantly larger number of classes than the existing ones (65 vs 10, 6 and 8). The experimental
results of both supervised and semi-supervised HDA demonstrate the superior performance of our
proposed method against contemporary state-of-the-art methods. 