Mobile Edge Computing (MEC), which incorporates the Cloud, edge nodes and end devices, has shown
great potential in bringing data processing closer to the data sources. Meanwhile, Federated learning
(FL) has emerged as a promising privacy-preserving approach to facilitating AI applications.
However, it remains a big challenge to optimize the efficiency and effectiveness of FL when it is
integrated with the MEC architecture. Moreover, the unreliable nature (e.g., stragglers and intermittent
drop-out) of end devices significantly slows down the FL process and affects the global model's
quality in such circumstances. In this paper, a multi-layer federated learning protocol called
HybridFL is designed for the MEC architecture. HybridFL adopts two levels (the edge level and the
cloud level) of model aggregation enacting different aggregation strategies. Moreover, in order
to mitigate stragglers and end device drop-out, we introduce regional slack factors into the stage
of client selection performed at the edge nodes using a probabilistic approach without identifying
or probing the state of end devices (whose reliability is agnostic). We demonstrate the effectiveness
of our method in modulating the proportion of clients selected and present the convergence analysis
for our protocol. We have conducted extensive experiments with machine learning tasks in different
scales of MEC system. The results show that HybridFL improves the FL training process significantly
in terms of shortening the federated round length, speeding up the global model's convergence (by
up to 12X) and reducing end device energy consumption (by up to 58%) 