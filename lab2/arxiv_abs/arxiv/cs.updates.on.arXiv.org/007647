In millimeter wave (mmWave) vehicular communications, multi-hop relay disconnection by line-of-sight
(LOS) blockage is a critical problem, especially in the early diffusion phase of mmWave-available
vehicles, where not all the vehicles have mmWave communication devices. This paper proposes a distributed
position control method for autonomous vehicles to make long relays connecting to road side units
(RSUs) by avoiding blockages to communicate with each other via LOS paths. Even though vehicles
with the proposed method do not use the whole information of the environments and cooperate with
each other, they can decide their action (e.g., lane change and overtaking) to form long relays using
only information of its surroundings (e.g., surrounding vehicle positions). The decision-making
problem is formulated as a Markov decision process so that autonomous vehicles can learn a practical
movement strategy of making long relays by a reinforcement learning (RL) algorithm. This paper
designs a learning algorithm based on a sophisticated deep reinforcement learning algorithm,
asynchronous advantage actor-critic (A3C), which enables vehicles to learn a complex movement
strategy quickly by its deepneural-network architecture and multi-agent-learning mechanism.
Once the strategy is well trained, vehicles can distributedly move to positions where the long relay
to the RSU is established. Simulations results confirm that the proposed method can increase the
relay length and coverage even if the traffic conditions and penetration ratio of mmWave communication
devices in learning and operation phases are different. 