In hyperspectral remote sensing data mining, it is important to take into account of both spectral
and spatial information, such as the spectral signature, texture feature and morphological property,
to improve the performances, e.g., the image classification accuracy. In a feature representation
point of view, a nature approach to handle this situation is to concatenate the spectral and spatial
features into a single but high dimensional vector and then apply a certain dimension reduction
technique directly on that concatenated vector before feed it into the subsequent classifier.
However, multiple features from various domains definitely have different physical meanings
and statistical properties, and thus such concatenation hasn't efficiently explore the complementary
properties among different features, which should benefit for boost the feature discriminability.
Furthermore, it is also difficult to interpret the transformed results of the concatenated vector.
Consequently, finding a physically meaningful consensus low dimensional feature representation
of original multiple features is still a challenging task. In order to address the these issues,
we propose a novel feature learning framework, i.e., the simultaneous spectral-spatial feature
selection and extraction algorithm, for hyperspectral images spectral-spatial feature representation
and classification. Specifically, the proposed method learns a latent low dimensional subspace
by projecting the spectral-spatial feature into a common feature space, where the complementary
information has been effectively exploited, and simultaneously, only the most significant original
features have been transformed. Encouraging experimental results on three public available hyperspectral
remote sensing datasets confirm that our proposed method is effective and efficient. 