In Machine Learning scenarios, privacy is a crucial concern when models have to be trained with private
data coming from users of a service, such as a recommender system, a location-based mobile service,
a mobile phone text messaging service providing next word prediction, or a face image classification
system. The main issue is that, often, data are collected, transferred, and processed by third parties.
These transactions violate new regulations, such as GDPR. Furthermore, users usually are not willing
to share private data such as their visited locations, the text messages they wrote, or the photo
they took with a third party. On the other hand, users appreciate services that work based on their
behaviors and preferences. In order to address these issues, Federated Learning (FL) has been recently
proposed as a means to build ML models based on private datasets distributed over a large number of
clients, while preventing data leakage. A federation of users is asked to train a same global model
on their private data, while a central coordinating server receives locally computed updates by
clients and aggregate them to obtain a better global model, without the need to use clients' actual
data. In this work, we extend the FL approach by pushing forward the state-of-the-art approaches
in the aggregation step of FL, which we deem crucial for building a high-quality global model. Specifically,
we propose an approach that takes into account a suite of client-specific criteria that constitute
the basis for assigning a score to each client based on a priority of criteria defined by the service
provider. Extensive experiments on two publicly available datasets indicate the merits of the
proposed approach compared to standard FL baseline. 