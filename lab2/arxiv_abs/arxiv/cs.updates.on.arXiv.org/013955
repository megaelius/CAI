It is a big problem that a model of deep learning for a picking robot needs many labeled images. Operating
costs of retraining a model becomes very expensive because the object shape of a product or a part
often is changed in a factory. It is important to reduce the amount of labeled images required to train
a model for a picking robot. In this study, we propose a multi-task learning framework for few-shot
classification using feature vectors from an intermediate layer of a model that detects grasping
positions. In the field of manufacturing, multitask for shape classification and grasping-position
detection is often required for picking robots. Prior multi-task learning studies include methods
to learn one task with feature vectors from a deep neural network (DNN) learned for another task.
However, the DNN that was used to detect grasping positions has two problems with respect to extracting
feature vectors from a layer for shape classification: (1) Because each layer of the grasping position
detection DNN is activated by all objects in the input image, it is necessary to refine the features
for each grasping position. (2) It is necessary to select a layer to extract the features suitable
for shape classification. To tackle these issues, we propose a method to refine the features for
each grasping position and to select features from the optimal layer of the DNN. We then evaluated
the shape classification accuracy using these features from the grasping positions. Our results
confirm that our proposed framework can classify object shapes even when the input image includes
multiple objects and the number of images available for training is small. 