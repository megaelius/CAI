The primary motivation of Image-to-Image Transformation is to convert an image of one domain to
another domain. Most of the research has been focused on the task of image transformation for a set
of pre-defined domains. Very few works are reported that actually developed a common framework
for image-to-image transformation for different domains. With the introduction of Generative
Adversarial Networks (GANs) as a general framework for the image generation problem, there is a
tremendous growth in the area of image-to-image transformation. Most of the research focuses over
the suitable objective function for image-to-image transformation. In this paper, we propose
a new Cyclic-Synthesized Generative Adversarial Networks (CSGAN) for image-to-image transformation.
The proposed CSGAN uses a new objective function (loss) called Cyclic-Synthesized Loss (CS) between
the synthesized image of one domain and cycled image of another domain. The performance of the proposed
CSGAN is evaluated on two benchmark image-to-image transformation datasets, including CUHK Face
dataset and CMP Facades dataset. The results are computed using the widely used evaluation metrics
such as MSE, SSIM, PSNR, and LPIPS. The experimental results of the proposed CSGAN approach are compared
with the latest state-of-the-art approaches such as GAN, Pix2Pix, DualGAN, CycleGAN and PS2GAN.
The proposed CSGAN technique outperforms all the methods over CUHK dataset and exhibits the promising
and comparable performance over Facades dataset in terms of both qualitative and quantitative
measures. The code is available at https://github.com/KishanKancharagunta/CSGAN. 