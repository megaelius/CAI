This inherent relations among multiple face analysis tasks, such as landmark detection, head pose
estimation, gender recognition and face attribute estimation are crucial to boost the performance
of each task, but have not been thoroughly explored since typically these multiple face analysis
tasks are handled as separate tasks. In this paper, we propose a novel deep multi-task adversarial
learning method to localize facial landmark, estimate head pose and recognize gender jointly or
estimate multiple face attributes simultaneously through exploring their dependencies from
both image representation-level and label-level. Specifically, the proposed method consists
of a deep recognition network R and a discriminator D. The deep recognition network is used to learn
the shared middle-level image representation and conducts multiple face analysis tasks simultaneously.
Through multi-task learning mechanism, the recognition network explores the dependencies among
multiple face analysis tasks, such as facial landmark localization, head pose estimation, gender
recognition and face attribute estimation from image representation-level. The discriminator
is introduced to enforce the distribution of the multiple face analysis tasks to converge to that
inherent in the ground-truth labels. During training, the recognizer tries to confuse the discriminator,
while the discriminator competes with the recognizer through distinguishing the predicted label
combination from the ground-truth one. Though adversarial learning, we explore the dependencies
among multiple face analysis tasks from label-level. Experimental results on four benchmark databases,
i.e., the AFLW database, the Multi-PIE database, the CelebA database and the LFWA database, demonstrate
the effectiveness of the proposed method for multiple face analyses. 