This paper studies the design of feedback controllers that steer the output of a switched linear
time-invariant system to the solution of a possibly time-varying optimization problem. The design
of the feedback controllers is based on an online gradient descent method, and an online hybrid controller
that can be seen as a regularized Nesterov's accelerated gradient method. Both of the proposed approaches
accommodate output measurements of the plant, and are implemented in closed-loop with the switched
dynamical system. By design, the controllers continuously steer the system output to an optimal
trajectory implicitly defined by the time-varying optimization problem without requiring knowledge
of exogenous inputs and disturbances. For cost functions that are smooth and satisfy the Polyak-Lojasiewicz
inequality, we demonstrate that the online gradient descent controller ensures uniform global
exponential stability when the time-scales of the plant and the controller are sufficiently separated
and the switching signal of the plant is slow on the average. Under a strong convexity assumption,
we also show that the online hybrid Nesterov's method guarantees tracking of optimal trajectories,
and outperforms online controllers based on gradient descent. Interestingly, the proposed hybrid
accelerated controller resolves the potential lack of robustness suffered by standard continuous-time
accelerated gradient methods when coupled with a dynamical system. When the function is not strongly
convex, we establish global practical asymptotic stability results for the accelerated method,
and we unveil the existence of a trade-off between acceleration and exact convergence in online
optimization problems with controllers using dynamic momentum. Our theoretical results are illustrated
via different numerical examples. 