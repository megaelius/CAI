In this paper, a real-time Internet of Things (IoT) monitoring system is considered in which multiple
IoT devices must transmit timely updates on the status information of a common underlying physical
process to a common destination. In particular, a real-world IoT scenario is considered in which
multiple (partially) observed status information by different IoT devices are required at the
destination, so that the real-time status of the physical process can be properly re-constructed.
By taking into account such correlated status information at the IoT devices, the problem of IoT
device scheduling is studied in order to jointly minimize the average age of information (AoI) at
the destination and the average energy cost at the IoT devices. Particularly, two types of IoT devices
are considered: Type-I devices whose status updates randomly arrive and type-II devices whose
status updates can be generated-at-will with an associated sampling cost. This stochastic problem
is formulated as an infinite horizon average cost Markov decision process (MDP). The optimal scheduling
policy is shown to be threshold-based with respect to the AoI at the destination, and the threshold
is non-increasing with the channel condition of each device. For a special case in which all devices
are type-II, the original MDP can be reduced to an MDP with much smaller state and action spaces. The
optimal policy is further shown to have a similar threshold-based structure and the threshold is
non-decreasing with an energy cost function of the devices. Simulation results illustrate the
structure of the optimal policy and show the effectiveness of the optimal policy compared with a
myopic baseline policy. 