The design of robotic systems is largely dictated by our purely human intuition about how we perceive
the world. This intuition has been proven incorrect with regard to a number of critical issues, such
as visual change blindness. In order to develop truly autonomous robots, we must step away from this
intuition and let robotic agents develop their own way of perceiving. The robot should start from
scratch and gradually develop perceptual notions, under no prior assumptions, exclusively by
looking into its sensorimotor experience and identifying repetitive patterns and invariants.
One of the most fundamental perceptual notions, space, cannot be an exception to this requirement.
In this paper we look into the prerequisites for the emergence of simplified spatial notions on the
basis of a robot's sensorimotor flow. We show that the notion of space as environment-independent
cannot be deduced solely from exteroceptive information, which is highly variable and is mainly
determined by the contents of the environment. The environment-independent definition of space
can be approached by looking into the functions that link the motor commands to changes in exteroceptive
inputs. In a sufficiently rich environment, the kernels of these functions correspond uniquely
to the spatial configuration of the agent's exteroceptors. We simulate a redundant robotic arm
with a retina installed at its end-point and show how this agent can learn the configuration space
of its retina. The resulting manifold has the topology of the Cartesian product of a plane and a circle,
and corresponds to the planar position and orientation of the retina. 