Lower dimensional signal representation schemes frequently assume that the signal of interest
lies in a single vector space. In the context of the recently developed theory of compressive sensing
(CS), it is often assumed that the signal of interest is sparse in an orthonormal basis. However,
in many practical applications, this requirement may be too restrictive. A generalization of the
standard sparsity assumption is that the signal lies in a union of subspaces. Recovery of such signals
from a small number of samples has been studied recently in several works. Here, we consider the problem
of subspace detection in which our goal is to identify the subspace (from the union) in which the signal
lies from a small number of samples, in the presence of noise. More specifically, we derive performance
bounds and conditions under which reliable subspace detection is guaranteed using maximum likelihood
(ML) detection. We begin by treating general unions and then specify the results to the special case
in which the subspaces have structure leading to block sparsity. In our analysis, we treat both general
sampling operators and random sampling matrices. With general unions, we show that under certain
conditions, the number of measurements required for reliable subspace detection in the presence
of noise via ML is less than that implied using the restricted isometry property which guarantees
signal recovery. In the special case of block sparse signals, we quantify the gain achievable over
standard sparsity in subspace detection. Our results also strengthen existing results on sparsity
pattern recovery in the presence of noise under the standard sparsity model. 