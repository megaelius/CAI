Accurate segmentation of the prostate from magnetic resonance (MR) images provides useful information
for prostate cancer diagnosis and treatment. However, automated prostate segmentation from 3D
MR images still faces several challenges. For instance, a lack of clear edge between the prostate
and other anatomical structures makes it challenging to accurately extract the boundaries. The
complex background texture and large variation in size, shape and intensity distribution of the
prostate itself make segmentation even further complicated. With deep learning, especially convolutional
neural networks (CNNs), emerging as commonly used methods for medical image segmentation, the
difficulty in obtaining large number of annotated medical images for training CNNs has become much
more pronounced that ever before. Since large-scale dataset is one of the critical components for
the success of deep learning, lack of sufficient training data makes it difficult to fully train
complex CNNs. To tackle the above challenges, in this paper, we propose a boundary-weighted domain
adaptive neural network (BOWDA-Net). To make the network more sensitive to the boundaries during
segmentation, a boundary-weighted segmentation loss (BWL) is proposed. Furthermore, an advanced
boundary-weighted transfer leaning approach is introduced to address the problem of small medical
imaging datasets. We evaluate our proposed model on the publicly available MICCAI 2012 Prostate
MR Image Segmentation (PROMISE12) challenge dataset. Our experimental results demonstrate that
the proposed model is more sensitive to boundary information and outperformed other state-of-the-art
methods. 