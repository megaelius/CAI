We consider the distributed computing framework of Map-Reduce, which consists of three phases,
the Map phase, the Shuffle phase and the Reduce phase. For this framework, we propose the use of binary
matrices (with $0,1$ entries) called \textit{computing matrices} to describe the map phase and
the shuffle phase. Similar binary matrices were recently proposed for the coded caching framework.
The structure of ones and zeroes in the binary computing matrix captures the map phase of the Map-reduce
framework. We present a new simple coded data shuffling scheme for this binary matrix model, based
on a \textit{identity submatrix cover} of the computing matrix. This new coded shuffling scheme
has in general a larger communication load than existing schemes, but has the advantage of less complexity
overhead than the well-known earlier schemes in literature in terms of the file-splitting and associated
indexing and coordination required. We also show that there exists a binary matrix based distributed
computing scheme with our new data-shuffling scheme which has strictly less than twice than the
communication load of the known optimal scheme in literature. The structure of this new scheme enables
it to be applied to the framework of Map-reduce with stragglers also, in a straightforward manner,
borrowing its advantages and disadvantages from the no-straggler situation. Finally, using binary
matrices derived from combinatorial designs, we show specific classes of computing schemes with
very low \textit{file complexity} (number of subfiles in the file), but with higher communication
load compared to the optimal scheme for equivalent parameters. 