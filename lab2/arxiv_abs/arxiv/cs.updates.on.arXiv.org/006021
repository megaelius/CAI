\textbf{Introduction:} Machine learning has become a basic tool in scientific research and for
the development of technologies with significant impact on society. In fact, such methods allow
to discover regularities in data and make predictions without explicit knowledge of the rules governing
the system under analysis. However, a price must be paid for exploiting such a modelling flexibility:
machine learning methods are usually black-box, meaning that it is difficult to fully understand
what the machine is doing and how. This poses constraints on the applicability of such methods, neglecting
the possibility to gather novel scientific insights from experimental data. \textbf{Methods:}
Our research aims to open the black-box of recurrent neural networks, an important family of neural
networks suitable to process sequential data. Here, we propose a novel methodology that allows
to provide a mechanistic interpretation of their behaviour when used to solve computational tasks.
The methodology is based on mathematical constructs called excitable network attractors, which
are models represented as networks in phase space composed by stable attractors and excitable connections
between them. \textbf{Results and Discussion:} As the behaviour of recurrent neural networks
depends on training and inputs driving the autonomous system, we introduce an algorithm to extract
network attractors directly from a trajectory generated by the neural network while solving tasks.
Simulations conducted on a controlled benchmark highlight the relevance of the proposed methodology
for interpreting the behaviour of recurrent neural networks on tasks that involve learning a finite
number of stable states. 