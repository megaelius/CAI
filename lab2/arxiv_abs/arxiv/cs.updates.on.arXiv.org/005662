For social robots to be brought more into widespread use in the fields of companionship, care taking
and domestic help, they must be capable of demonstrating social intelligence. In order to be acceptable,
they must exhibit socio-communicative skills. Classic approaches to program HRI from observed
human-human interactions fails to capture the subtlety of multimodal interactions as well as the
key structural differences between robots and humans. The former arises due to a difficulty in quantifying
and coding multimodal behaviours, while the latter due to a difference of the degrees of liberty
between a robot and a human. However, the notion of reverse engineering from multimodal HRI traces
to learn the underlying behavioral blueprint of the robot given multimodal traces seems an option
worth exploring. With this spirit, the entire HRI can be seen as a sequence of exchanges of speech
acts between the robot and human, each act treated as an action, bearing in mind that the entire sequence
is goal-driven. Thus, this entire interaction can be treated as a sequence of actions propelling
the interaction from its initial to goal state, also known as a plan in the domain of AI planning. In
the same domain, this action sequence that stems from plan execution can be represented as a trace.
AI techniques, such as machine learning, can be used to learn behavioral models (also known as symbolic
action models in AI), intended to be reusable for AI planning, from the aforementioned multimodal
traces. This article reviews recent machine learning techniques for learning planning action
models which can be applied to the field of HRI with the intent of rendering robots as socio-communicative.
