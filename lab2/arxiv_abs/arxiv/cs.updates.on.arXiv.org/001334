Recent progress in human-robot collaboration makes fast and fluid interactions possible, even
when human observations are partial and occluded. Methods like Interaction Probabilistic Movement
Primitives (ProMP) model human trajectories through motion capture systems. However, such representation
does not properly model tasks where similar motions handle different objects. Under current approaches,
a robot would not adapt its pose and dynamics for proper handling. We integrate the use of Electromyography
(EMG) into the Interaction ProMP framework and utilize muscular signals to augment the human observation
representation. The contribution of our paper is increased task discernment when trajectories
are similar but tools are different and require the robot to adjust its pose for proper handling.
Interaction ProMPs are used with an augmented vector that integrates muscle activity. Augmented
time-normalized trajectories are used in training to learn correlation parameters and robot motions
are predicted by finding the best weight combination and temporal scaling for a task. Collaborative
single task scenarios with similar motions but different objects were used and compared. For one
experiment only joint angles were recorded, for the other EMG signals were additionally integrated.
Task recognition was computed for both tasks. Observation state vectors with augmented EMG signals
were able to completely identify differences across tasks, while the baseline method failed every
time. Integrating EMG signals into collaborative tasks significantly increases the ability of
the system to recognize nuances in the tasks that are otherwise imperceptible, up to 74.6% in our
studies. Furthermore, the integration of EMG signals for collaboration also opens the door to a
wide class of human-robot physical interactions based on haptic communication that has been largely
unexploited in the field. 