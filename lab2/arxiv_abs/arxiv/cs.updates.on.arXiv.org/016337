Scattered radiation is a major concern impacting X-ray image-guided procedures in two ways. First,
back-scatter significantly contributes to patient (skin) dose during complicated interventions.
Second, forward-scattered radiation reduces contrast in projection images and introduces artifacts
in 3-D reconstructions. While conventionally employed anti-scatter grids improve image quality
by blocking X-rays, the additional attenuation due to the anti-scatter grid at the detector needs
to be compensated for by a higher patient entrance dose. This also increases the room dose affecting
the staff caring for the patient. For skin dose quantification, back-scatter is usually accounted
for by applying pre-determined scalar back-scatter factors or linear point spread functions to
a primary kerma forward projection onto a patient surface point. However, as patients come in different
shapes, the generalization of conventional methods is limited. Here, we propose a novel approach
combining conventional techniques with learning-based methods to simultaneously estimate the
forward-scatter reaching the detector as well as the back-scatter affecting the patient skin dose.
Knowing the forward-scatter, we can correct X-ray projections, while a good estimate of the back-scatter
component facilitates an improved skin dose assessment. To simultaneously estimate forward-scatter
as well as back-scatter, we propose a multi-task approach for joint back- and forward-scatter estimation
by combining X-ray physics with neural networks. We show that, in theory, highly accurate scatter
estimation in both cases is possible. In addition, we identify research directions for our multi-task
framework and learning-based scatter estimation in general. 