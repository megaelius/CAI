Traditional single-view object detection methods often perform worse under unconstrained video
environments. To address this problem, many modern multi-view detection approaches model complex
3D appearance representations to predict the optimal viewing angle for detection. Most of these
approaches require an intensive training process on large database, collected in advance. In this
paper, the proposed framework takes a remarkably different direction to resolve multi-view detection
problem in a bottom-up fashion. First, a scene-specific objector is obtained from a fully autonomous
learning process triggered by marking several bounding boxes around the object in the first video
frame via a mouse. Here the human labeled training data or a generic detector are not needed. Second,
this learning process is conveniently replicated many times in different surveillance scenes
and results in a particular detector under various camera viewpoints. Thus, the proposed framework
can be employed in multi-view object detection applications from unsupervised learning process.
Obviously, the initial scene-specific detector, initialed by several bounding boxes, exhibits
poor detection performance and is difficult to improve with traditional online learning algorithm.
Consequently, we propose Generative-Discriminative model to partition detection response space
and assign each partition an individual descriptor that progressively achieves high classification
accuracy. A novel online gradual learning algorithm is proposed to train the Generative-Discriminative
model automatically and focus online learning on the hard samples: the most informative samples
lying around the decision boundary. The output is a hybrid classifier based scene-specific detector
which achieves decent performance under different viewing angles. 