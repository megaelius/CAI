Spine injections are commonly performed in several clinical procedures. The localization of the
target vertebral level (i.e. the position of a vertebra in a spine) is typically done by back palpation
or under X-ray guidance, yielding either higher chances of procedure failure or exposure to ionizing
radiation. Preliminary studies have been conducted in the literature, suggesting that ultrasound
imaging may be a precise and safe alternative to X-ray for spine level detection. However, ultrasound
data are noisy and complicated to interpret. In this study, a robotic-ultrasound approach for automatic
vertebral level detection is introduced. The method relies on the fusion of ultrasound and force
data, thus providing both "tactile" and visual feedback during the procedure, which results in
higher performances in presence of data corruption. A robotic arm automatically scans the volunteer's
back along the spine by using force-ultrasound data to locate vertebral levels. The occurrences
of vertebral levels are visible on the force trace as peaks, which are enhanced by properly controlling
the force applied by the robot on the patient back. Ultrasound data are processed with a Deep Learning
method to extract a 1D signal modelling the probabilities of having a vertebra at each location along
the spine. Processed force and ultrasound data are fused using a 1D Convolutional Network to compute
the location of the vertebral levels. The method is compared to pure image and pure force-based methods
for vertebral level counting, showing improved performance. In particular, the fusion method
is able to correctly classify 100% of the vertebral levels in the test set, while pure image and pure
force-based method could only classify 80% and 90% vertebrae, respectively. The potential of the
proposed method is evaluated in an exemplary simulated clinical application. 