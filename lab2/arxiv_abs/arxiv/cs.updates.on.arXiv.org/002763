Robots have great potential to facilitate future therapies for children on the autism spectrum.
However, existing robots lack the ability to automatically perceive and respond to human affect,
which is necessary for establishing and maintaining engaging interactions. Moreover, their inference
challenge is made harder by the fact that many individuals with autism have atypical and unusually
diverse styles of expressing their affective-cognitive states. To tackle the heterogeneity in
behavioral cues of children with autism, we use the latest advances in deep learning to formulate
a personalized machine learning (ML) framework for automatic perception of the childrens affective
states and engagement during robot-assisted autism therapy. The key to our approach is a novel shift
from the traditional ML paradigm - instead of using 'one-size-fits-all' ML models, our personalized
ML framework is optimized for each child by leveraging relevant contextual information (demographics
and behavioral assessment scores) and individual characteristics of each child. We designed and
evaluated this framework using a dataset of multi-modal audio, video and autonomic physiology
data of 35 children with autism (age 3-13) and from 2 cultures (Asia and Europe), participating in
a 25-minute child-robot interaction (~500k datapoints). Our experiments confirm the feasibility
of the robot perception of affect and engagement, showing clear improvements due to the model personalization.
The proposed approach has potential to improve existing therapies for autism by offering more efficient
monitoring and summarization of the therapy progress. 