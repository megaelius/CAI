Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224x224) input
image. This requirement is "artificial" and may reduce the recognition accuracy for the images
or sub-images of an arbitrary size/scale. In this work, we equip the networks with a more principled
pooling strategy, "spatial pyramid pooling", to eliminate the above requirement. The new network
structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale.
Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in
general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate
that SPP-net boosts the accuracy of a variety of published CNN architectures despite their different
designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification
results using a single full-image representation and no fine-tuning. The power of SPP-net is also
significant in object detection. Using SPP-net, we compute the feature maps from the entire image
only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations
for training the detectors. This method avoids repeatedly computing the convolutional features.
In processing test images, our method computes convolutional features 30-170x faster than the
recent and most accurate method R-CNN (and 24-64x faster overall), while achieving better or comparable
accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014,
our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript
also introduces the improvement made for this competition. 