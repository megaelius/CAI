Recent advances in deep learning have shown their ability to learn strong feature representations
for images. The task of image clustering naturally requires good feature representations to capture
the distribution of the data and subsequently differentiate data points from one another. Often
these two aspects are dealt with independently and thus traditional feature learning alone does
not suffice in partitioning the data meaningfully. Variational Autoencoders (VAEs) naturally
lend themselves to learning data distributions in a latent space. Since we wish to efficiently discriminate
between different clusters in the data, we propose a method based on VAEs where we use a Gaussian Mixture
prior to help cluster the images accurately. We jointly learn the parameters of both the prior and
the posterior distributions. Our method represents a true Gaussian Mixture VAE. This way, our method
simultaneously learns a prior that captures the latent distribution of the images and a posterior
to help discriminate well between data points. We also propose a novel reparametrization of the
latent space consisting of a mixture of discrete and continuous variables. One key takeaway is that
our method generalizes better across different datasets without using any pre-training or learnt
models, unlike existing methods, allowing it to be trained from scratch in an end-to-end manner.
We verify our efficacy and generalizability experimentally by achieving state-of-the-art results
among unsupervised methods on a variety of datasets. To the best of our knowledge, we are the first
to pursue image clustering using VAEs in a purely unsupervised manner on real image datasets. 