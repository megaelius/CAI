Automated cardiac image interpretation has the potential to transform clinical practice in multiple
ways including enabling low-cost serial assessment of cardiac function in the primary care and
rural setting. We hypothesized that advances in computer vision could enable building a fully automated,
scalable analysis pipeline for echocardiogram (echo) interpretation. Our approach entailed:
1) preprocessing; 2) convolutional neural networks (CNN) for view identification, image segmentation,
and phasing of the cardiac cycle; 3) quantification of chamber volumes and left ventricular mass;
4) particle tracking to compute longitudinal strain; and 5) targeted disease detection. CNNs accurately
identified views (e.g. 99% for apical 4-chamber) and segmented individual cardiac chambers. Cardiac
structure measurements agreed with study report values (e.g. mean absolute deviations (MAD) of
7.7 mL/kg/m2 for left ventricular diastolic volume index, 2918 studies). We computed automated
ejection fraction and longitudinal strain measurements (within 2 cohorts), which agreed with
commercial software-derived values [for ejection fraction, MAD=5.3%, N=3101 studies; for strain,
MAD=1.5% (n=175) and 1.6% (n=110)], and demonstrated applicability to serial monitoring of breast
cancer patients for trastuzumab cardiotoxicity. Overall, we found that, compared to manual measurements,
automated measurements had superior performance across seven internal consistency metrics with
an average increase in the Spearman correlation coefficient of 0.05 (p=0.02). Finally, we developed
disease detection algorithms for hypertrophic cardiomyopathy and cardiac amyloidosis, with
C-statistics of 0.90 and 0.84, respectively. Our pipeline lays the groundwork for using automated
interpretation to support point-of-care handheld cardiac ultrasound and large-scale analysis
of the millions of echos archived within healthcare systems. 