The concept of autonomy is key to the IoT vision promising increasing integration of smart services
and systems minimizing human intervention. This vision challenges our capability to build complex
open trustworthy autonomous systems. We lack a rigorous common semantic framework for autonomous
systems. It is remarkable that the debate about autonomous vehicles focuses almost exclusively
on AI and learning techniques while it ignores many other equally important autonomous system design
issues. Autonomous systems involve agents and objects coordinated in some common environment
so that their collective behavior meets a set of global goals. We propose a general computational
model combining a system architecture model and an agent model. The architecture model allows expression
of dynamic reconfigurable multi-mode coordination between components. The agent model consists
of five interacting modules implementing each one a characteristic function: Perception, Reflection,
Goal management, Planning and Self-adaptation. It determines a concept of autonomic complexity
accounting for the specific difficulty to build autonomous systems. We emphasize that the main
characteristic of autonomous systems is their ability to handle knowledge and adaptively respond
to environment changes. We advocate that autonomy should be associated with functionality and
not with specific techniques. Machine learning is essential for autonomy although it can meet only
a small portion of the needs implied by autonomous system design. We conclude that autonomy is a kind
of broad intelligence. Building trustworthy and optimal autonomous systems goes far beyond the
AI challenge. 