There has been a surge of recent interest in learning representations for graph-structured data.
Graph representation learning methods have generally fallen into three main categories, based
on the availability of labeled data. The first, network embedding (such as shallow graph embedding
or graph auto-encoders), focuses on learning unsupervised representations of relational structure.
The second, graph regularized neural networks, leverages graphs to augment neural network losses
with a regularization objective for semi-supervised learning. The third, graph neural networks,
aims to learn differentiable functions over discrete topologies with arbitrary structure. However,
despite the popularity of these areas there has been surprisingly little work on unifying the three
paradigms. Here, we aim to bridge the gap between graph neural networks, network embedding and graph
regularization models. We propose a comprehensive taxonomy of representation learning methods
for graph-structured data, aiming to unify several disparate bodies of work. Specifically, we
propose a Graph Encoder Decoder Model (GRAPHEDM), which generalizes popular algorithms for semi-supervised
learning on graphs (e.g. GraphSage, Graph Convolutional Networks, Graph Attention Networks),
and unsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc) into a single
consistent approach. To illustrate the generality of this approach, we fit over thirty existing
methods into this framework. We believe that this unifying view both provides a solid foundation
for understanding the intuition behind these methods, and enables future research in the area.
