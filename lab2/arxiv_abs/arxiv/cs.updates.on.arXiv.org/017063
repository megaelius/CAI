Visible-infrared cross-modality person re-identification (VI-ReId) is an essential task for
video surveillance in poorly illuminated or dark environments. Despite many recent studies on
person re-identification in the visible domain (ReId), there are few studies dealing specifically
with VI-ReId. Besides challenges that are common for both ReId and VI-ReId such as pose/illumination
variations, background clutter and occlusion, VI-ReId has additional challenges as color information
is not available in infrared images. As a result, the performance of VI-ReId systems is typically
lower than that of ReId systems. In this work, we propose a four-stream framework to improve VI-ReId
performance. We train a separate deep convolutional neural network in each stream using different
representations of input images. We expect that different and complementary features can be learned
from each stream. In our framework, grayscale and infrared input images are used to train the ResNet
in the first stream. In the second stream, RGB and three-channel infrared images (created by repeating
the infrared channel) are used. In the remaining two streams, we use local pattern maps as input images.
These maps are generated utilizing local Zernike moments transformation. Local pattern maps are
obtained from grayscale and infrared images in the third stream and from RGB and three-channel infrared
images in the last stream. We improve the performance of the proposed framework by employing a re-ranking
algorithm for post-processing. Our results indicate that the proposed framework outperforms
current state-of-the-art with a large margin by improving Rank-1/mAP by 29.79%/30.91% on SYSU-MM01
dataset, and by 9.73%/16.36% on RegDB dataset. 