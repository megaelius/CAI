We consider synchronizing properties of Markov decision processes (MDP), viewed as generators
of sequences of probability distributions over states. A probability distribution is p-synchronizing
if the probability mass is at least p in some state, and a sequence of probability distributions is
weakly p-synchronizing, or strongly p-synchronizing if respectively infinitely many, or all
but finitely many distributions in the sequence are p-synchronizing. For each synchronizing mode,
an MDP can be (i) sure winning if there is a strategy that produces a 1-synchronizing sequence; (ii)
almost-sure winning if there is a strategy that produces a sequence that is, for all {\epsilon} >
0, a (1-{\epsilon})-synchronizing sequence; (iii) limit-sure winning if for all {\epsilon} >
0, there is a strategy that produces a (1-{\epsilon})-synchronizing sequence. For each synchronizing
and winning mode, we consider the problem of deciding whether an MDP is winning, and we establish
matching upper and lower complexity bounds of the problems, as well as the optimal memory requirement
for winning strategies: (a) for all winning modes, we show that the problems are PSPACE-complete
for weakly synchronizing, and PTIME-complete for strongly synchronizing; (b) we show that for
weakly synchronizing, exponential memory is sufficient and may be necessary for sure winning,
and infinite memory is necessary for almost-sure winning; for strongly synchronizing, linear-size
memory is sufficient and may be necessary in all modes; (c) we show a robustness result that the almost-sure
and limit-sure winning modes coincide for both weakly and strongly synchronizing. 