Machine Learning in coalition settings requires combining insights available from data assets
and knowledge repositories distributed across multiple coalition partners. In tactical environments,
this requires sharing the assets, knowledge and models in a bandwidth-constrained environment,
while staying in conformance with the privacy, security and other applicable policies for each
coalition member. Federated Machine Learning provides an approach for such sharing. In its simplest
version, federated machine learning could exchange training data available among the different
coalition members, with each partner deciding which part of the training data from other partners
to accept based on the quality and value of the offered data. In a more sophisticated version, coalition
partners may exchange models learnt locally, which need to be transformed, accepted in entirety
or in part based on the quality and value offered by each model, and fused together into an integrated
model. In this paper, we examine the challenges present in creating federated learning solutions
in coalition settings, and present the different flavors of federated learning that we have created
as part of our research in the DAIS ITA. The challenges addressed include dealing with varying quality
of data and models, determining the value offered by the data/model of each coalition partner, addressing
the heterogeneity in data representation, labeling and AI model architecture selected by different
coalition members, and handling the varying levels of trust present among members of the coalition.
We also identify some open problems that remain to be addressed to create a viable solution for federated
learning in coalition environments. 