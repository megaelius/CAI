Image de-fencing is one of the important aspects of recreational photography in which the objective
is to remove the fence texture present in an image and generate an aesthetically pleasing version
of the same image without the fence texture. In this paper, we aim to develop an automated and effective
technique for fence removal and image reconstruction using conditional Generative Adversarial
Networks (cGANs). These networks have been successfully applied in several domains of Computer
Vision focusing on image generation and rendering. Our initial approach is based on a two-stage
architecture involving two cGANs that generate the fence mask and the inpainted image, respectively.
Training of these networks is carried out independently and, during evaluation, the input image
is passed through the two generators in succession to obtain the de-fenced image. The results obtained
from this approach are satisfactory, but the response time is long since the image has to pass through
two sets of convolution layers. To reduce the response time, we propose a second approach involving
only a single cGAN architecture that is trained using the ground-truth of fenced de-fenced image
pairs along with the edge map of the fenced image produced by the Canny Filter. Incorporation of the
edge map helps the network to precisely detect the edges present in the input image, and also imparts
it an ability to carry out high quality de-fencing in an efficient manner, even in the presence of
a fewer number of layers as compared to the two-stage network. Qualitative and quantitative experimental
results reported in the manuscript reveal that the de-fenced images generated by the single-stage
de-fencing network have similar visual quality to those produced by the two-stage network. Comparative
performance analysis also emphasizes the effectiveness of our approach over state-of-the-art
image de-fencing techniques. 