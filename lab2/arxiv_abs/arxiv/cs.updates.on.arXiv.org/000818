This article deals with stochastic processes endowed with the Markov (memoryless) property and
evolving over general (uncountable) state spaces. The models further depend on a non-deterministic
quantity in the form of a control input, which can be selected to affect the probabilistic dynamics.
We address the synthesis of optimal controllers that maximize the probability associated to a rather
general property of interest, known as the "reach-avoid" specification. The reach-avoid specification
deals with assessing the likelihood that any finite-horizon trajectory of the model enters a given
goal set, while avoiding a given set of undesired states (both arbitrary subsets of the state space).
Equivalently, the property can be expressed as entering a goal set, while dwelling within a set of
allowed states. The reach-avoid property is a well known specification that lies at the core of a
number of modal logics used in the field of formal verification, and which is relevant for safety-critical
applications ranging from robotics to air traffic management. This article newly provides an approximate
computational scheme for the reach-avoid specification based on the Fitted Value Iteration algorithm,
which hinges on random sample extractions, and derives new formal probabilistic bounds on the error
made by the approximation algorithm: as such, the output of the numerical scheme is quantitatively
assessed and thus meaningful for safety-critical applications of the property of interest. Furthermore,
this contribution provides tighter sample-based probabilistic error bounds for the computation
of the reach-avoid problem based on the Fitted Value Iteration. The overall computational scheme
is put in relationship with alternative approximation algorithms in the literature, and finally
its performance is practically assessed over a benchmark case study. 