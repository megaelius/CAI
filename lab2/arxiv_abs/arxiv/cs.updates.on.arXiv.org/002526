Lidar datasets are becoming more and more common. They are appreciated for their precise 3D nature,
and have a wide range of applications, such as surface reconstruction, object detection, visualisation,
etc. For all this applications, having additional semantic information per point has potential
of increasing the quality and the efficiency of the application. In the last decade the use of Machine
Learning and more specifically classification methods have proved to be successful to create this
semantic information. In this paradigm, the goal is to classify points into a set of given classes
(for instance tree, building, ground, other). Some of these methods use descriptors (also called
feature) of a point to learn and predict its class. Designing the descriptors is then the heart of
these methods. Descriptors can be based on points geometry and attributes, use contextual information,
etc. Furthermore, descriptors can be used by humans for easier visual understanding and sometimes
filtering. In this work we propose a new simple geometric descriptor that gives information about
the implicit local dimensionality of the point cloud at various scale. For instance a tree seen from
afar is more volumetric in nature (3D), yet locally each leaves is rather planar (2D). To do so we build
an octree centred on the point to consider, and compare the variation of the occupancy of the cells
across the levels of the octree. We compare this descriptor with the state of the art dimensionality
descriptor and show its interest. We further test the descriptor for classification within the
Point Cloud Server, and demonstrate efficiency and correctness results. 