The availability of large-scale facial databases, together with the remarkable progresses of
deep learning technologies, in particular Generative Adversarial Networks (GANs), have led to
the generation of extremely realistic fake facial content, raising obvious concerns about the
potential for misuse. Such concerns have fostered the research on manipulation detection methods
that, contrary to humans, have already achieved astonishing results in various scenarios. In this
study, we focus on the synthesis of entire facial images, which is a specific type of facial manipulation.
The main contributions of this study are four-fold: i) a novel strategy to remove GAN "fingerprints"
from synthetic fake images based on autoencoders is described, in order to spoof facial manipulation
detection systems while keeping the visual quality of the resulting images; ii) an in-depth analysis
of the recent literature in facial manipulation detection; iii) a complete experimental assessment
of this type of facial manipulation, considering the state-of-the-art fake detection systems
(based on holistic deep networks, steganalysis, and local artifacts), remarking how challenging
is this task in unconstrained scenarios; and finally iv) we announce a novel public database, named
iFakeFaceDB, yielding from the application of our proposed GAN-fingerprint Removal approach
(GANprintR) to already very realistic synthetic fake images. The results obtained in our empirical
evaluation show that additional efforts are required to develop robust facial manipulation detection
systems against unseen conditions and spoof techniques, such as the one proposed in this study.
