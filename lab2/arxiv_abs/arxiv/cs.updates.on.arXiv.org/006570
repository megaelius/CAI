We propose a new deep learning approach for medical imaging that copes with the problem of a small
training set, the main bottleneck of deep learning, and apply it for classification of healthy and
cancer cells acquired by quantitative phase imaging. The proposed method, called transferring
of pre-trained generative adversarial network (TOP-GAN), is a hybridization between transfer
learning and generative adversarial networks (GANs). Healthy cells and cancer cells of different
metastatic potential have been imaged by low-coherence off-axis holography. After the acquisition,
the optical path delay maps of the cells have been extracted and directly used as an input to the deep
networks. In order to cope with the small number of classified images, we have used GANs to train a
large number of unclassified images from another cell type (sperm cells). After this preliminary
training, and after transforming the last layer of the network with new ones, we have designed an
automatic classifier for the correct cell type (healthy/primary cancer/metastatic cancer) with
90-99% accuracy, although small training sets of down to several images have been used. These results
are better in comparison to other classic methods that aim at coping with the same problem of a small
training set. We believe that our approach makes the combination of holographic microscopy and
deep learning networks more accessible to the medical field by enabling a rapid, automatic and accurate
classification in stain-free imaging flow cytometry. Furthermore, our approach is expected to
be applicable to many other medical image classification tasks, suffering from a small training
set. 