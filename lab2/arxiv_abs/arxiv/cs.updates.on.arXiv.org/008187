A fundamental question for understanding brain function is what types of stimuli drive neurons
to fire. In visual neuroscience, this question has also been posted as characterizing the receptive
field of a neuron. The search for effective stimuli has traditionally been based on a combination
of insights from previous studies, intuition, and luck. Recently, the same question has emerged
in the study of units in convolutional neural networks (ConvNets), and together with this question
a family of solutions were developed that are generally referred to as "feature visualization by
activation maximization." We sought to bring in tools and techniques developed for studying ConvNets
to the study of biological neural networks. However, one key difference that impedes direct translation
of tools is that gradients can be obtained from ConvNets using backpropagation, but such gradients
are not available from the brain. To circumvent this problem, we developed a method for gradient-free
activation maximization by combining a generative neural network with a genetic algorithm. We
termed this method XDream (EXtending DeepDream with real-time evolution for activation maximization),
and we have shown that this method can reliably create strong stimuli for neurons in the macaque visual
cortex (Ponce et al., 2019). In this paper, we describe extensive experiments characterizing the
XDream method by using ConvNet units as in silico models of neurons. We show that XDream is applicable
across network layers, architectures, and training sets; examine design choices in the algorithm;
and provide practical guides for choosing hyperparameters in the algorithm. XDream is an efficient
algorithm for uncovering neuronal tuning preferences in black-box networks using a vast and diverse
stimulus space. 