Recent trends in the field of neural network accelerators investigate weight quantization as a
means to increase the resource- and power-efficiency of hardware devices. As full on-chip weight
storage is necessary to avoid the high energy cost of off-chip memory accesses, memory reduction
requirements for weight storage pushed toward the use of binary weights, which were demonstrated
to have a limited accuracy reduction on many applications when quantization-aware training techniques
are used. In parallel, spiking neural network (SNN) architectures are explored to further reduce
power when processing sparse event-based data streams, while on-chip spike-based online learning
appears as a key feature for applications constrained in power and resources during the training
phase. However, designing power- and area-efficient spiking neural networks still requires the
development of specific techniques in order to leverage on-chip online learning on binary weights
without compromising the synapse density. In this work, we demonstrate MorphIC, a quad-core binary-weight
digital neuromorphic processor embedding a stochastic version of the spike-driven synaptic plasticity
(S-SDSP) learning rule and a hierarchical routing fabric for large-scale chip interconnection.
The MorphIC SNN processor embeds a total of 2k leaky integrate-and-fire (LIF) neurons and more than
two million plastic synapses for an active silicon area of 2.86mm$^2$ in 65nm CMOS, achieving a high
density of 738k synapses/mm$^2$. MorphIC demonstrates an order-of-magnitude improvement in
the area-accuracy tradeoff on the MNIST classification task compared to previously-proposed
SNNs, while having no penalty in the energy-accuracy tradeoff. 