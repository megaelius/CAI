Heterogeneous Face Recognition (HFR) is a task that matches faces across two different domains
such as VIS (visible light), NIR (near-infrared), or the sketch domain. In contrast to face recognition
in visual spectrum, because of the domain discrepancy, this task requires to extract domain-invariant
feature or common space projection learning. To bridge this domain gap, we propose a graph-structured
module that focuses on facial relational information to reduce the fundamental differences in
domain characteristics. Since relational information is domain independent, our Relational
Graph Module (RGM) performs relation modeling from node vectors that represent facial components
such as lips, nose, and chin. Propagation of the generated relational graph then reduces the domain
difference by transitioning from spatially correlated CNN (convolutional neural network) features
to inter-dependent relational features. In addition, we propose a Node Attention Unit (NAU) that
performs node-wise recalibration to focus on the more informative nodes arising from the relation-based
propagation. Furthermore, we suggest a novel conditional-margin loss function (C-Softmax) for
efficient projection learning on the common latent space of the embedding vector. Our module can
be plugged into any pre-trained face recognition network to help overcome the limitations of a small
HFR database. The proposed method shows superior performance on three different HFR databases
CAISA NIR-VIS 2.0, IIIT-D Sketch, and BUAA-VisNir in various pre-trained networks. Furthermore,
we explore our C-Softmax loss boosts HFR performance and also apply our loss to the large-scale visual
face database LFW(Labeled Faces in Wild) by learning inter-class margins adaptively. 