Our scientific knowledge is increasingly built on software output. User code which defines data
analysis pipelines and computational models is essential for research in the natural and social
sciences, but little is known about how to ensure its correctness. The structure of this code and
the development process used to build it limit the utility of traditional testing methodology.
Formal methods for software verification have seen great success in ensuring code correctness
but generally require more specialized training, development time, and funding than is available
in the natural and social sciences. Here, we present a Python library which uses lightweight formal
methods to provide correctness guarantees without the need for specialized knowledge or substantial
time investment. Our package provides runtime verification of function entry and exit condition
contracts using refinement types. It allows checking hyperproperties within contracts and offers
automated test case generation to supplement online checking. We co-developed our tool with a medium-sized
($\approx$3000 LOC) software package which simulates decision-making in cognitive neuroscience.
In addition to helping us locate trivial bugs earlier on in the development cycle, our tool was able
to locate four bugs which may have been difficult to find using traditional testing methods. It was
also able to find bugs in user code which did not contain contracts or refinement type annotations.
This demonstrates how formal methods can be used to verify the correctness of scientific software
which is difficult to test with mainstream approaches. 