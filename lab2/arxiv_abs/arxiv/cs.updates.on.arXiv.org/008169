In a social learning setting, there is a set of actions, each of which has a fixed but unknown expected
payoff. Agents arrive one by one, each chooses an action with the goal of maximizing the payoff. A
disclosure policy coordinates the choices of the agents by sending messages about the history of
past actions. These messages can alter agents' incentives towards "exploration", taking potentially
sub-optimal actions for the sake of learning more about their rewards. The goal of the disclosure
policy is to incentivize exploration so as to minimize the regret of the chosen action sequence.
Prior work achieves much progress with disclosure policies that merely recommend an action to each
user. However, all this work relies heavily on trust and rationality assumptions, standard in economic
theory, yet quite problematic in the context of the motivating applications. In this paper, we design
disclosure policies which incentivize good performance under more plausible behavioral assumptions.
We would like to retain the trustworthiness of revealing the full history, while avoiding the herding
behavior that it may induce. We focus on messages, called unbiased subhistories, consisting of
the actions and rewards from a subsequence of past agents, where the subsequence is chosen ahead
of time. We posit a flexible model of agent response, which we argue is plausible for our disclosure
policies. Our main result is a disclosure policy using unbiased, transitive subhistories that
obtains regret $\tilde{O}(\sqrt{\#rounds})$. We also exhibit simpler policies with higher,
but still sublinear, regret. These policies can be interpreted as dividing a sublinear number of
agents into constant-sized focus groups, whose histories are then fed to future agents. 