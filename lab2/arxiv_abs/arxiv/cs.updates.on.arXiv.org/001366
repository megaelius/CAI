Here, we explore the low-level statistics of images generated by state-of-the-art deep generative
models. First, Wasserstein generative adversarial network (WGAN) and deep convolutional generative
adversarial network (DCGAN) are trained on the ImageNet dataset and a large set of cartoon frames
from animations. Then, for images generated by these models as well as natural scenes and cartoons,
statistics including mean power spectrum, the number of connected components in a given image area,
distribution of random filter responses, and contrast distribution are computed. Our analyses
on training images support current findings on scale invariance, non-Gaussianity, and Weibull
contrast distribution of natural scenes. We find that although similar results hold over cartoon
images, there is still a significant difference between statistics of natural scenes and images
generated by both DCGAN and WGAN models. In particular, generated images do not have scale invariant
mean power spectrum magnitude, which indicates existence of extra structures in these images caused
by deconvolution operations. We also find that replacing deconvolution layers in the deep generative
models by sub-pixel convolution helps them generate images with a mean power spectrum more similar
to the mean power spectrum of natural images. Inspecting how well the statistics of deep generated
images match the known statistical properties of natural images, such as scale invariance, non-Gaussianity,
and Weibull contrast distribution, can a) reveal the degree to which deep learning models capture
the essence of the natural scenes, b) provide a new dimension to evaluate models, and c) allow possible
improvement of image generative models (e.g., via defining new loss functions). 