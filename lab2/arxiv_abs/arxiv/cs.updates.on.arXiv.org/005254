Nowadays, modern Earth Observation systems continuously generate huge amounts of data. A notable
example is represented by the Sentinel-2 mission, which provides images at high spatial resolution
(up to 10m) with high temporal revisit period (every 5 days), which can be organized in Satellite
Image Time Series (SITS). While the use of SITS has been proved to be beneficial in the context of Land
Use/Land Cover (LULC) map generation, unfortunately, machine learning approaches commonly leveraged
in remote sensing field fail to take advantage of spatio-temporal dependencies present in such
data. Recently, new generation deep learning methods allowed to significantly advance research
in this field. These approaches have generally focused on a single type of neural network, i.e.,
Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs), which model different
but complementary information: spatial autocorrelation (CNNs) and temporal dependencies (RNNs).
In this work, we propose the first deep learning architecture for the analysis of SITS data, namely
\method{} (DUal view Point deep Learning architecture for time series classificatiOn), that combines
Convolutional and Recurrent neural networks to exploit their complementarity. Our hypothesis
is that, since CNNs and RNNs capture different aspects of the data, a combination of both models would
produce a more diverse and complete representation of the information for the underlying land cover
classification task. Experiments carried out on two study sites characterized by different land
cover characteristics (i.e., the \textit{Gard} site in France and the \textit{Reunion Island}
in the Indian Ocean), demonstrate the significance of our proposal. 