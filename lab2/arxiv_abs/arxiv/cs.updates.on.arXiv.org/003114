Plan recognition aims to discover target plans (i.e., sequences of actions) behind observed actions,
with history plan libraries or domain models in hand. Previous approaches either discover plans
by maximally "matching" observed actions to plan libraries, assuming target plans are from plan
libraries, or infer plans by executing domain models to best explain the observed actions, assuming
that complete domain models are available. In real world applications, however, target plans are
often not from plan libraries, and complete domain models are often not available, since building
complete sets of plans and complete domain models are often difficult or expensive. In this paper
we view plan libraries as corpora and learn vector representations of actions using the corpora,
we then discover target plans based on the vector representations. Specifically, we propose two
approaches, DUP and RNNPlanner, to discover target plans based on vector representations of actions.
DUP explores the EM-style framework to capture local contexts of actions and discover target plans
by optimizing the probability of target plans, while RNNPlanner aims to leverage long-short term
contexts of actions based on RNNs (recurrent neural networks) framework to help recognize target
plans. In the experiments, we empirically show that our approaches are capable of discovering underlying
plans that are not from plan libraries, without requiring domain models provided. We demonstrate
the effectiveness of our approaches by comparing its performance to traditional plan recognition
approaches in three planning domains. We also compare DUP and RNNPlanner to see their advantages
and disadvantages. 