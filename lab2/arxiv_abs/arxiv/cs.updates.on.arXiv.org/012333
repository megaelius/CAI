Segmentation of multiple organs-at-risk (OARs) is essential for radiation therapy treatment
planning and other clinical applications. We developed an Automated deep Learning-based Abdominal
Multi-Organ segmentation (ALAMO) framework based on 2D U-net and a densely connected network structure
with tailored design in data augmentation and training procedures such as deep connection, auxiliary
supervision, and multi-view. The model takes in multi-slice MR images and generates the output
of segmentation results. Three-Tesla T1 VIBE (Volumetric Interpolated Breath-hold Examination)
images of 102 subjects were collected and used in our study. Ten OARs were studied, including the
liver, spleen, pancreas, left/right kidneys, stomach, duodenum, small intestine, spinal cord,
and vertebral bodies. Two radiologists manually labeled and obtained the consensus contours as
the ground-truth. In the complete cohort of 102, 20 samples were held out for independent testing,
and the rest were used for training and validation. The performance was measured using volume overlapping
and surface distance. The ALAMO framework generated segmentation labels in good agreement with
the manual results. Specifically, among the 10 OARs, 9 achieved high Dice Similarity Coefficients
(DSCs) in the range of 0.87-0.96, except for the duodenum with a DSC of 0.80. The inference completes
within one minute for a 3D volume of 320x288x180. Overall, the ALAMO model matches the state-of-the-art
performance. The proposed ALAMO framework allows for fully automated abdominal MR segmentation
with high accuracy and low memory and computation time demands. 