Spectral-spatial based deep learning models have recently proven to be effective in hyperspectral
image (HSI) classification for various earth monitoring applications such as land cover classification
and agricultural monitoring. However, due to the nature of "black-box" model representation,
how to explain and interpret the learning process and the model decision remains an open problem.
This study proposes an interpretable deep learning model -- a biologically interpretable two-stage
deep neural network (BIT-DNN), by integrating biochemical and biophysical associated information
into the proposed framework, capable of achieving both high accuracy and interpretability on HSI
based classification tasks. The proposed model introduces a two-stage feature learning process.
In the first stage, an enhanced interpretable feature block extracts low-level spectral features
associated with the biophysical and biochemical attributes of the target entities; and in the second
stage, an interpretable capsule block extracts and encapsulates the high-level joint spectral-spatial
features into the featured tensors representing the hierarchical structure of the biophysical
and biochemical attributes of the target ground entities, which provides the model an improved
performance on classification and intrinsic interpretability. We have tested and evaluated the
model using two real HSI datasets for crop type recognition and crop disease recognition tasks and
compared it with six state-of-the-art machine learning models. The results demonstrate that the
proposed model has competitive advantages in terms of both classification accuracy and model interpretability.
