Recently, the convolutional neural network has brought impressive improvements for object detection.
However, detecting tiny objects in large-scale remote sensing images still remains challenging.
First, the extreme large input size makes the existing object detection solutions too slow for practical
use. Second, the massive and complex backgrounds cause serious false alarms. Moreover, the ultratiny
objects increase the difficulty of accurate detection. To tackle these problems, we propose a unified
and self-reinforced network called remote sensing region-based convolutional neural network
($\mathcal{R}^2$-CNN), composing of backbone Tiny-Net, intermediate global attention block,
and final classifier and detector. Tiny-Net is a lightweight residual structure, which enables
fast and powerful features extraction from inputs. Global attention block is built upon Tiny-Net
to inhibit false positives. Classifier is then used to predict the existence of targets in each patch,
and detector is followed to locate them accurately if available. The classifier and detector are
mutually reinforced with end-to-end training, which further speed up the process and avoid false
alarms. Effectiveness of $\mathcal{R}^2$-CNN is validated on hundreds of GF-1 images and GF-2
images that are 18 000 $\times$ 18 192 pixels, 2.0-m resolution, and 27 620 $\times$ 29 200 pixels,
0.8-m resolution, respectively. Specifically, we can process a GF-1 image in 29.4 s on Titian X just
with single thread. According to our knowledge, no previous solution can detect the tiny object
on such huge remote sensing images gracefully. We believe that it is a significant step toward practical
real-time remote sensing systems. 