In this work, we study the problem of online optimization of piecewise Lipschitz functions with
semi-bandit feedback. This challenging class of non-convex optimization problems often arises
in algorithm selection problems for combinatorial settings, where the goal is to find the best algorithm
from a large algorithm family for a specific application domain. In these settings, each evaluation
of the loss functions in the optimization problem can be computationally expensive, often requiring
the learner to run a combinatorial algorithm to measure its performance. Combined with the fact
that small differences between similar algorithms in the family can lead to cascading changes in
algorithm behavior, efficient online optimization in these settings is a challenging problem.
However, we show that in many applications, evaluating the loss function for one algorithm choice
can sometimes reveal the loss for a range of similar algorithms, essentially for free. We develop
online optimization algorithms capable of using this kind of extra information by working in the
semi-bandit feedback setting. Our algorithms achieve regret bounds that are essentially as good
as algorithms under full-information feedback and are significantly more computationally efficient.
We apply our semi-bandit optimization results to obtain online algorithm selection procedures
for two rich families of combinatorial algorithms. We provide the first provable guarantees for
online algorithm selection for clustering problems using a family of clustering algorithms containing
classic linkage procedures. We also show how to select algorithms from a family of greedy knapsack
algorithms with simultaneously lower computational complexity and stronger regret bounds than
the best algorithm selection procedures from prior work. 