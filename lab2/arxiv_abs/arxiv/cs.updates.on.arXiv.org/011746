Practical automated detection and diagnosis of plant disease from wide-angle images (i.e. in-field
images containing multiple leaves using a fixed-position camera) is a very important application
for large-scale farm management, in view of the need to ensure global food security. However, developing
automated systems for disease diagnosis is often difficult, because labeling a reliable wide-angle
disease dataset from actual field images is very laborious. In addition, the potential similarities
between the training and test data lead to a serious problem of model overfitting. In this paper,
we investigate changes in performance when applying disease diagnosis systems to different scenarios
involving wide-angle cucumber test data captured on real farms, and propose an effective diagnostic
strategy. We show that leading object recognition techniques such as SSD and Faster R-CNN achieve
excellent end-to-end disease diagnostic performance only for a test dataset that is collected
from the same population as the training dataset (with F1-score of 81.5% - 84.1% for diagnosed cases
of disease), but their performance markedly deteriorates for a completely different test dataset
(with F1-score of 4.4 - 6.2%). In contrast, our proposed two-stage systems using independent leaf
detection and leaf diagnosis stages attain a promising disease diagnostic performance that is
more than six times higher than end-to-end systems (with F1-score of 33.4 - 38.9%) on an unseen target
dataset. We also confirm the efficiency of our proposal based on visual assessment, concluding
that a two-stage model is a suitable and reasonable choice for practical applications. 