Explainable recommendation attempts to develop models that generate not only high-quality recommendations
but also intuitive explanations. The explanations may either be post-hoc or directly come from
an explainable model (also called interpretable or transparent model in some contexts). Explainable
recommendation tries to address the problem of why: by providing explanations to users or system
designers, it helps humans to understand why certain items are recommended by the algorithm, where
the human can either be users or system designers. Explainable recommendation helps to improve
the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation
systems. It also facilitates system designers for better system debugging. In recent years, a large
number of explainable recommendation approaches -- especially model-based methods -- have been
proposed and applied in real-world systems. In this survey, we provide a comprehensive review for
the explainable recommendation research. We first highlight the position of explainable recommendation
in recommender system research by categorizing recommendation problems into the 5W, i.e., what,
when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation
on three perspectives: 1) We provide a chronological research timeline of explainable recommendation.
2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research.
3) We summarize how explainable recommendation applies to different recommendation tasks. We
also devote a chapter to discuss the explanation perspectives in broader IR and AI/ML research.
We end the survey by discussing potential future directions to promote the explainable recommendation
research area and beyond. 