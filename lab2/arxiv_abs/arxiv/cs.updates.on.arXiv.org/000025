Crowdsourcing is now widely used to replace judgement by an expert authority with an aggregate evaluation
from a number of non-experts, in applications ranging from rating and categorizing online content
to evaluation of student assignments in massively open online courses via peer grading. A key issue
in these settings, where direct monitoring is infeasible, is incentivizing agents in the `crowd'
to put in effort to make good evaluations, as well as to truthfully report their evaluations. This
leads to a new family of information elicitation problems with unobservable ground truth, where
an agent's proficiency- the probability with which she correctly evaluates the underlying ground
truth- is endogenously determined by her strategic choice of how much effort to put into the task.
Our main contribution is a simple, new, mechanism for binary information elicitation for multiple
tasks when agents have endogenous proficiencies, with the following properties: (i) Exerting
maximum effort followed by truthful reporting of observations is a Nash equilibrium. (ii) This
is the equilibrium with maximum payoff to all agents, even when agents have different maximum proficiencies,
can use mixed strategies, and can choose a different strategy for each of their tasks. Our information
elicitation mechanism requires only minimal bounds on the priors, asks agents to only report their
own evaluations, and does not require any conditions on a diverging number of agent reports per task
to achieve its incentive properties. The main idea behind our mechanism is to use the presence of
multiple tasks and ratings to identify and penalize low-effort agreement: the mechanism rewards
agents for agreeing with a `reference' rater on a task but also penalizes for blind agreement by subtracting
out a statistic term designed so that agents obtain reward only when they put effort into their observations.
