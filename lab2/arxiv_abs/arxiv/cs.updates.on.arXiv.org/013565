Recent advances in video processing utilizing deep learning primitives achieved breakthroughs
in fundamental problems in video analysis such as frame classification and object detection enabling
an array of new applications. In this paper we study the problem of interactive declarative query
processing on video streams. In particular we introduce a set of approximate filters to speed up
queries that involve objects of specific type (e.g., cars, trucks, etc.) on video frames with associated
spatial relationships among them (e.g., car left of truck). The resulting filters are able to assess
quickly if the query predicates are true to proceed with further analysis of the frame or otherwise
not consider the frame further avoiding costly object detection operations. We propose two classes
of filters $IC$ and $OD$, that adapt principles from deep image classification and object detection.
The filters utilize extensible deep neural architectures and are easy to deploy and utilize. In
addition, we propose statistical query processing techniques to process aggregate queries involving
objects with spatial constraints on video streams and demonstrate experimentally the resulting
increased accuracy on the resulting aggregate estimation. Combined these techniques constitute
a robust set of video monitoring query processing techniques. We demonstrate that the application
of the techniques proposed in conjunction with declarative queries on video streams can dramatically
increase the frame processing rate and speed up query processing by at least two orders of magnitude.
We present the results of a thorough experimental study utilizing benchmark video data sets at scale
demonstrating the performance benefits and the practical relevance of our proposals. 