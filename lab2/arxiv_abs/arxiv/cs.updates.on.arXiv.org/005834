Artificial autonomous agents and robots interacting in complex environments are required to continually
acquire and fine-tune knowledge over sustained periods of time. The ability to learn from continuous
streams of information is referred to as lifelong learning and represents a long-standing challenge
for neural network models due to catastrophic forgetting. Computational models of lifelong learning
typically alleviate catastrophic forgetting in experimental scenarios with given datasets of
static images and limited complexity, thereby differing significantly from the conditions artificial
agents are exposed to. In more natural settings, sequential information may become progressively
available over time and access to previous experience may be restricted. In this paper, we propose
a dual-memory self-organizing architecture for lifelong learning scenarios. The architecture
comprises two growing recurrent networks with the complementary tasks of learning object instances
(episodic memory) and categories (semantic memory). Both growing networks can expand in response
to novel sensory experience: the episodic memory learns fine-grained spatiotemporal representations
of object instances in an unsupervised fashion while the semantic memory uses task-relevant signals
to regulate structural plasticity levels and develop more compact representations from episodic
experience. For the consolidation of knowledge in the absence of external sensory input, the episodic
memory periodically replays trajectories of neural reactivations. We evaluate the proposed model
on the CORe50 benchmark dataset for continuous object recognition, showing that we significantly
outperform current methods of lifelong learning in three different incremental learning scenarios
