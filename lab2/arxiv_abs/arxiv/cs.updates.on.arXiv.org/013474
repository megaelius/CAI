The stringent requirements of mobile edge computing (MEC) applications and functions fathom the
high capacity and dense deployment of MEC hosts to the upcoming wireless networks. However, operating
such high capacity MEC hosts can significantly increase energy consumption. Thus, a BS unit can
act as a self-powered BS. In this paper, an effective energy dispatch mechanism for self-powered
wireless networks with edge computing capabilities is studied. First, a two-stage linear stochastic
programming problem is formulated with the goal of minimizing the total energy consumption cost
of the system while fulfilling the energy demand. Second, a semi-distributed data-driven solution
is proposed by developing a novel multi-agent meta-reinforcement learning (MAMRL) framework
to solve the formulated problem. In particular, each BS plays the role of a local agent that explores
a Markovian behavior for both energy consumption and generation while each BS transfers time-varying
features to a meta-agent. Sequentially, the meta-agent optimizes (i.e., exploits) the energy
dispatch decision by accepting only the observations from each local agent with its own state information.
Meanwhile, each BS agent estimates its own energy dispatch policy by applying the learned parameters
from meta-agent. Finally, the proposed MAMRL framework is benchmarked by analyzing deterministic,
asymmetric, and stochastic environments in terms of non-renewable energy usages, energy cost,
and accuracy. Experimental results show that the proposed MAMRL model can reduce up to 11% non-renewable
energy usage and by 22.4% the energy cost (with 95.8% prediction accuracy), compared to other baseline
methods. 