Graph convolutional networks (GCNs), which generalize CNNs to more generic non-Euclidean structures,
have achieved remarkable performance for skeleton-based action recognition. However, there
still exist several issues in the previous GCN-based models. First, the topology of the graph is
set heuristically and fixed over all the model layers and input data. This may not be suitable for
the hierarchy of the GCN model and the diversity of the data in action recognition tasks. Second,
the second-order information of the skeleton data, i.e., the length and orientation of the bones,
is rarely investigated, which is naturally more informative and discriminative for the human action
recognition. In this work, we propose a novel multi-stream attention-enhanced adaptive graph
convolutional neural network (MS-AAGCN) for skeleton-based action recognition. The graph topology
in our model can be either uniformly or individually learned based on the input data in an end-to-end
manner. This data-driven approach increases the flexibility of the model for graph construction
and brings more generality to adapt to various data samples. Besides, the proposed adaptive graph
convolutional layer is further enhanced by a spatial-temporal-channel attention module, which
helps the model pay more attention to important joints, frames and features. Moreover, the information
of both the joints and bones, together with their motion information, are simultaneously modeled
in a multi-stream framework, which shows notable improvement for the recognition accuracy. Extensive
experiments on the two large-scale datasets, NTU-RGBD and Kinetics-Skeleton, demonstrate that
the performance of our model exceeds the state-of-the-art with a significant margin. 