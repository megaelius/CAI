Thermal imaging is a robust sensing technique but its consumer applicability is limited by the high
cost of thermal sensors. Nevertheless, low-resolution thermal cameras are relatively affordable
and are also usually accompanied by a high-resolution visible-range camera. This visible-range
image can be used as a guide to reconstruct a high-resolution thermal image using guided super-resolution(GSR)
techniques. However, the difference in wavelength-range of the input images makes this task challenging.
Improper processing can introduce artifacts such as blur and ghosting, mainly due to texture and
content mismatch. To this end, we propose a novel algorithm for guided super-resolution that explicitly
tackles the issue of texture-mismatch caused due to multimodality. We propose a two-stage network
that combines information from a low-resolution thermal and a high-resolution visible image with
the help of multi-level edge-extraction and integration. The first stage of our network extracts
edge-maps from the visual image at different pyramidal levels and the second stage integrates these
edge-maps into our proposed super-resolution network at appropriate layers. Extraction and integration
of edges belonging to different scales simplifies the task of GSR as it provides texture to object-level
information in a progressive manner. Using multi-level edges also allows us to adjust the contribution
of the visual image directly at the time of testing and thus provides controllability at test-time.
We perform multiple experiments and show that our method performs better than existing state-of-the-art
guided super-resolution methods both quantitatively and qualitatively. 