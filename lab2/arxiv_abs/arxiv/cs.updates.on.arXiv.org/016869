In many applications, Bayesian inverse problems can give rise to probability distributions which
contain complexities due to the Hessian varying greatly across parameter space. This complexity
often manifests itself as lower dimensional manifolds on which the likelihood function is invariant,
or varies very little. This can be due to trying to infer unobservable parameters, or due to sloppiness
in the model which is being used to describe the data. In such a situation, standard sampling methods
for characterising the posterior distribution, which do not incorporate information about this
structure, will be highly inefficient. In this paper, we seek to develop an approach to tackle this
problem when using adaptive importance sampling methods, by using optimal transport maps to simplify
posterior distributions which are concentrated on lower dimensional manifolds. This approach
is applicable to a whole range of problems for which Monte Carlo Markov chain (MCMC) methods mix slowly.
We demonstrate the approach by considering inverse problems arising from partially observed stochastic
reaction networks. In particular, we consider systems which exhibit multiscale behaviour, but
for which only the slow variables in the system are observable. We demonstrate that certain multiscale
approximations lead to more consistent approximations of the posterior than others. The use of
optimal transport maps stabilises the ensemble transform adaptive importance sampling (ETAIS)
method, and allows for efficient sampling with smaller ensemble sizes. This approach allows us
to take advantage of the large increases of efficiency when using adaptive importance sampling
methods for previously intractable Bayesian inverse problems with complex posterior structure.
