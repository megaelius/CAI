Recurrent Neural Networks (RNNs) are popular models of brain function. The typical training strategy
is to adjust their input-output behavior so that it matches that of the biological circuit of interest.
Even though this strategy ensures that the biological and artificial networks perform the same
computational task, it does not guarantee that their internal activity dynamics match. This suggests
that the trained RNNs might end up performing the task employing a different internal computational
mechanism, which would make them a suboptimal model of the biological circuit. In this work, we introduce
a novel training strategy that allows learning not only the input-output behavior of an RNN but also
its internal network dynamics, based on sparse neural recordings. We test the proposed method by
training an RNN to simultaneously reproduce internal dynamics and output signals of a physiologically-inspired
neural model. Specifically, this model generates the multiphasic muscle-like activity patterns
typically observed during the execution of reaching movements, based on the oscillatory activation
patterns concurrently observed in the motor cortex. Remarkably, we show that the reproduction
of the internal dynamics is successful even when the training algorithm relies on the activities
of a small subset of neurons sampled from the biological network. Furthermore, we show that training
the RNNs with this method significantly improves their generalization performance. Overall,
our results suggest that the proposed method is suitable for building powerful functional RNN models,
which automatically capture important computational properties of the biological circuit of
interest from sparse neural recordings. 