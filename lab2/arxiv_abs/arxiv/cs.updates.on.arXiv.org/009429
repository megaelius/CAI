Purpose: Surgical task-based metrics (rather than entire procedure metrics) can be used to improve
surgeon training and, ultimately, patient care through focused training interventions. Machine
learning models to automatically recognize individual tasks or activities are needed to overcome
the otherwise manual effort of video review. Traditionally, these models have been evaluated using
frame-level accuracy. Here, we propose evaluating surgical activity recognition models by their
effect on task-based efficiency metrics. In this way, we can determine when models have achieved
adequate performance for providing surgeon feedback via metrics from individual tasks. Methods:
We propose a new CNN-LSTM model, RP-Net-V2, to recognize the 12 steps of robotic-assisted radical
prostatectomies (RARP). We evaluated our model both in terms of conventional methods (e.g. Jaccard
Index, task boundary accuracy) as well as novel ways, such as the accuracy of efficiency metrics
computed from instrument movements and system events. Results: Our proposed model achieves a Jaccard
Index of 0.85 thereby outperforming previous models on robotic-assisted radical prostatectomies.
Additionally, we show that metrics computed from tasks automatically identified using RP-Net-V2
correlate well with metrics from tasks labeled by clinical experts. Conclusions: We demonstrate
that metrics-based evaluation of surgical activity recognition models is a viable approach to
determine when models can be used to quantify surgical efficiencies. We believe this approach and
our results illustrate the potential for fully automated, post-operative efficiency reports.
