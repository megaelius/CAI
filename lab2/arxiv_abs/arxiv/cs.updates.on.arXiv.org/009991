The presence of artificial agents in human social networks is growing. From chatbots to robots,
human experience in the developed world is moving towards a socio-technical system in which agents
can be technological or biological, with increasingly blurred distinctions between. Given that
emotion is a key element of human interaction, enabling artificial agents with the ability to reason
about affect is a key stepping stone towards a future in which technological agents and humans can
work together. This paper presents work on building intelligent computational agents that integrate
both emotion and cognition. These agents are grounded in the well-established social-psychological
Bayesian Affect Control Theory (BayesAct). The core idea of BayesAct is that humans are motivated
in their social interactions by affective alignment: they strive for their social experiences
to be coherent at a deep, emotional level with their sense of identity and general world views as constructed
through culturally shared symbols. This affective alignment creates cohesive bonds between group
members, and is instrumental for collaborations to solidify as relational group commitments.
BayesAct agents are motivated in their social interactions by a combination of affective alignment
and decision theoretic reasoning, trading the two off as a function of the uncertainty or unpredictability
of the situation. This paper provides a high-level view of dual process theories and advances BayesAct
as a plausible, computationally tractable model based in social-psychological theory. We introduce
a revised BayesAct model that more deeply integrates social-psychological theorising, and we
demonstrate a component of the model as being sufficient to account for cognitive biases about fairness,
dissonance and conformity. We show how the model can unify different exploration strategies in
reinforcement learning. 