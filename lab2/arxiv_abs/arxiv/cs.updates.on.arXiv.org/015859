With the recent advances in voice synthesis such as WaveNet, AI-synthesized fake voices are indistinguishable
to human ears and widely applied for producing realistic and natural DeepFakes which are real threats
to everyone. However, effective and robust detectors for synthesized fake voices are still in their
infancy and are not ready to fully tackle this emerging threat. In this paper, we devise a novel approach,
named DeepSonar, based on monitoring neuron behaviors of speaker recognition (SR) system, a deep
neural network (DNN), to discern AI-synthesized fake voices. Layer-wise neuron behaviors provide
an important insight to hunt the differences among inputs, which are widely employed for building
safety, robust and interpretable DNNs. In this work, we leverage the power of layer-wise neuron
activation patterns with a conjecture that they can capture the subtle differences between real
and AI-synthesized fake voices and provide a cleaner signal to classifiers than raw inputs. Experiments
are conducted in three datasets (including commercial products from Google, Baidu, etc.) containing
both English and Chinese languages to corroborate the high detection rates (98.1% average accuracy)
and low false alarm rates (0.02 equal error rate) of DeepSonar in discerning fake voices. Furthermore,
extensive experiment results show its robustness against manipulation attacks (e.g., voice conversion
and additive real-world noises). Our work also poses a new insight into adopting neuron behaviors
for effective and robust AI aided multimedia fakes forensics instead of motivated by various artifacts
introduced in fakes. 