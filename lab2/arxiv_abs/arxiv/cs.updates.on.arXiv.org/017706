Algorithmic decision making has proliferated and now impacts our daily lives in both mundane and
consequential ways. Machine learning practitioners make use of a myriad of algorithms for predictive
models in applications as diverse as movie recommendations, medical diagnoses, and parole recommendations
without delving into the reasons driving specific predictive decisions. Machine learning algorithms
in such applications are often chosen for their superior performance, however popular choices
such as random forest and deep neural networks fail to provide an interpretable understanding of
the predictive model. In recent years, rule-based algorithms have been used to address this issue.
Wang et al. (2017) presented an or-of-and (disjunctive normal form) based classification technique
that allows for classification rule mining of a single class in a binary classification; this method
is also shown to perform comparably to other modern algorithms. In this work, we extend this idea
to provide classification rules for both classes simultaneously. That is, we provide a distinct
set of rules for both positive and negative classes. In describing this approach, we also present
a novel and complete taxonomy of classifications that clearly capture and quantify the inherent
ambiguity in noisy binary classifications in the real world. We show that this approach leads to
a more granular formulation of the likelihood model and a simulated-annealing based optimization
achieves classification performance competitive with comparable techniques. We apply our method
to synthetic as well as real world data sets to compare with other related methods that demonstrate
the utility of our proposal. 