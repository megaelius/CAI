Deep Neural Network (DNN) has recently achieved outstanding performance in a variety of computer
vision tasks, including facial attribute classification. The great success of classifying facial
attributes with DNN often relies on a massive amount of labelled data. However, in real-world applications,
labelled data are only provided for some commonly used attributes (such as age, gender); whereas,
unlabelled data are available for other attributes (such as attraction, hairline). To address
the above problem, we propose a novel deep transfer neural network method based on multi-label learning
for facial attribute classification, termed FMTNet, which consists of three sub-networks: the
Face detection Network (FNet), the Multi-label learning Network (MNet) and the Transfer learning
Network (TNet). Firstly, based on the Faster Region-based Convolutional Neural Network (Faster
R-CNN), FNet is fine-tuned for face detection. Then, MNet is fine-tuned by FNet to predict multiple
attributes with labelled data, where an effective loss weight scheme is developed to explicitly
exploit the correlation between facial attributes based on attribute grouping. Finally, based
on MNet, TNet is trained by taking advantage of unsupervised domain adaptation for unlabelled facial
attribute classification. The three sub-networks are tightly coupled to perform effective facial
attribute classification. A distinguishing characteristic of the proposed FMTNet method is that
the three sub-networks (FNet, MNet and TNet) are constructed in a similar network structure. Extensive
experimental results on challenging face datasets demonstrate the effectiveness of our proposed
method compared with several state-of-the-art methods. 