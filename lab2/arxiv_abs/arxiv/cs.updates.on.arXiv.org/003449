Recently, dense connections have attracted substantial attention in computer vision because
they facilitate gradient flow and implicit deep supervision during training. Particularly, DenseNet,
which connects each layer to every other layer in a feed-forward fashion, has shown impressive performances
in natural image classification tasks. We propose HyperDenseNet, a 3D fully convolutional neural
network that extends the definition of dense connectivity to multi-modal segmentation problems.
Each imaging modality has a path, and dense connections occur not only between the pairs of layers
within the same path, but also between those across different paths. This contrasts with the existing
multi-modal CNN approaches, in which modeling several modalities relies entirely on a single joint
layer (or level of abstraction) for fusion, typically either at the input or at the output of the network.
Therefore, the proposed network has total freedom to learn more complex combinations between the
modalities, within and in-between all the levels of abstraction, which increases significantly
the learning representation. We report extensive evaluations over two different and highly competitive
multi-modal brain tissue segmentation challenges, iSEG 2017 and MRBrainS 2013, with the former
focusing on 6-month infant data and the latter on adult images. HyperDenseNet yielded significant
improvements over many state-of-the-art segmentation networks, ranking at the top on both benchmarks.
We further provide a comprehensive experimental analysis of features re-use, which confirms the
importance of hyper-dense connections in multi-modal representation learning. Our code is publicly
available at https://www.github.com/josedolz/HyperDenseNet. 