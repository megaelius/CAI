We are interested in the development of surrogate models for uncertainty quantification and propagation
in problems governed by stochastic PDEs using a deep convolutional encoder-decoder network in
a similar fashion to approaches considered in deep learning for image-to-image regression tasks.
Since normal neural networks are data intensive and cannot provide predictive uncertainty, we
propose a Bayesian approach to convolutional neural nets. A recently introduced variational gradient
descent algorithm based on Stein's method is scaled to deep convolutional networks to perform approximate
Bayesian inference on millions of uncertain network parameters. This approach achieves state
of the art performance in terms of predictive accuracy and uncertainty quantification in comparison
to other approaches in Bayesian neural networks as well as techniques that include Gaussian processes
and ensemble methods even when the training data size is relatively small. To evaluate the performance
of this approach, we consider standard uncertainty quantification benchmark problems including
flow in heterogeneous media defined in terms of limited data-driven permeability realizations.
The performance of the surrogate model developed is very good even though there is no underlying
structure shared between the input (permeability) and output (flow/pressure) fields as is often
the case in the image-to-image regression models used in computer vision problems. Studies are
performed with an underlying stochastic input dimensionality up to $4,225$ where most other uncertainty
quantification methods fail. Uncertainty propagation tasks are considered and the predictive
output Bayesian statistics are compared to those obtained with Monte Carlo estimates. 