There currently exists a gap between the theories proposed by the probability and uncertainty and
the needs of Artificial Intelligence research. These theories primarily address the needs of expert
systems, using knowledge structures which must be pre-compiled and remain static in structure
during runtime. Many Al systems require the ability to dynamically add and remove parts of the current
knowledge structure (e.g., in order to examine what the world would be like for different causal
theories). This requires more flexibility than existing uncertainty systems display. In addition,
many Al researchers are only interested in using "probabilities" as a means of obtaining an ordering,
rather than attempting to derive an accurate probabilistic account of a situation. This indicates
the need for systems which stress ease of use and don't require extensive probability information
when one cannot (or doesn't wish to) provide such information. This paper attempts to help reconcile
the gap between approaches to uncertainty and the needs of many AI systems by examining the control
issues which arise, independent of a particular uncertainty calculus. when one tries to satisfy
these needs. Truth Maintenance Systems have been used extensively in problem solving tasks to help
organize a set of facts and detect inconsistencies in the believed state of the world. These systems
maintain a set of true/false propositions and their associated dependencies. However, situations
often arise in which we are unsure of certain facts or in which the conclusions we can draw from available
information are somewhat uncertain. The non-monotonic TMS 12] was an attempt at reasoning when
all the facts are not known, but it fails to take into account degrees of belief and how available evidence
can combine to strengthen a particular belief. This paper addresses the problem of probabilistic
reasoning as it applies to Truth Maintenance Systems. It describes a belief Maintenance System
that manages a current set of beliefs in much the same way that a TMS manages a set of true/false propositions.
If the system knows that belief in fact is dependent in some way upon belief in fact2, then it automatically
modifies its belief in facts when new information causes a change in belief of fact2. It models the
behavior of a TMS, replacing its 3-valued logic (true, false, unknown) with an infinite valued logic,
in such a way as to reduce to a standard TMS if all statements are given in absolute true/false terms.
Belief Maintenance Systems can, therefore, be thought of as a generalization of Truth Maintenance
Systems, whose possible reasoning tasks are a superset of those for a TMS. 