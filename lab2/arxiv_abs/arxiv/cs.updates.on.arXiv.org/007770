The performance of person re-identification (Re-ID) has been seriously effected by the large cross-view
appearance variations caused by mutual occlusions and background clutters. Hence learning a feature
representation that can adaptively emphasize the foreground persons becomes very critical to
solve the person Re-ID problem. In this paper, we propose a simple yet effective foreground attentive
neural network (FANN) to learn a discriminative feature representation for person Re-ID, which
can adaptively enhance the positive side of foreground and weaken the negative side of background.
Specifically, a novel foreground attentive subnetwork is designed to drive the network's attention,
in which a decoder network is used to reconstruct the binary mask by using a novel local regression
loss function, and an encoder network is regularized by the decoder network to focus its attention
on the foreground persons. The resulting feature maps of encoder network are further fed into the
body part subnetwork and feature fusion subnetwork to learn discriminative features. Besides,
a novel symmetric triplet loss function is introduced to supervise feature learning, in which the
intra-class distance is minimized and the inter-class distance is maximized in each triplet unit,
simultaneously. Training our FANN in a multi-task learning framework, a discriminative feature
representation can be learned to find out the matched reference to each probe among various candidates
in the gallery. Extensive experimental results on several public benchmark datasets are evaluated,
which have shown clear improvements of our method over the state-of-the-art approaches. 