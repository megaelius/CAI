Automated pavement distresses detection using road images remains a challenging topic in the computer
vision research community. Recent developments in deep learning has led to considerable research
activity directed towards improving the efficacy of automated pavement distress identification
and rating. Deep learning models require a large ground truth data set, which is often not readily
available in the case of pavements. In this study, a labeled dataset approach is introduced as a first
step towards a more robust, easy-to-deploy pavement condition assessment system. The technique
is termed herein as the Pavement Image Dataset (PID) method. The dataset consists of images captured
from two camera views of an identical pavement segment, i.e., a wide-view and a top-down view. The
wide-view images were used to classify the distresses and to train the deep learning frameworks,
while the top-down view images allowed calculation of distress density, which will be used in future
studies aimed at automated pavement rating. For the wide view group dataset, 7,237 images were manually
annotated and distresses classified into nine categories. Images were extracted using the Google
Application Programming Interface (API), selecting street-view images using a python-based
code developed for this project. The new dataset was evaluated using two mainstream deep learning
frameworks: You Only Look Once (YOLO v2) and Faster Region Convolution Neural Network (Faster R-CNN).
Accuracy scores using the F1 index were found to be 0.84 for YOLOv2 and 0.65 for the Faster R-CNN model
runs; both quite acceptable considering the convenience of utilizing Google maps images. 