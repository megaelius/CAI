Affective computing and cognitive theory are widely used in modern human-computer interaction
scenarios. Human faces, as the most prominent and easily accessible features, have attracted great
attention from researchers. Since humans have rich emotions and developed musculature, there
exist a lot of fine-grained expressions in real-world applications. However, it is extremely time-consuming
to collect and annotate a large number of facial images, of which may even require psychologists
to correctly categorize them. To the best of our knowledge, the existing expression datasets are
only limited to several basic facial expressions, which are not sufficient to support our ambitions
in developing successful human-computer interaction systems. To this end, a novel Fine-grained
Facial Expression Database - F2ED is contributed in this paper, and it includes more than 200k images
with 54 facial expressions from 119 persons. Considering the phenomenon of uneven data distribution
and lack of samples is common in real-world scenarios, we further evaluate several tasks of few-shot
expression learning by virtue of our F2ED, which are to recognize the facial expressions given only
few training instances. These tasks mimic human performance to learn robust and general representation
from few examples. To address such few-shot tasks, we propose a unified task-driven framework -
Compositional Generative Adversarial Network (Comp-GAN) learning to synthesize facial images
and thus augmenting the instances of few-shot expression classes. Extensive experiments are conducted
on F2ED and existing facial expression datasets, i.e., JAFFE and FER2013, to validate the efficacy
of our F2ED in pre-training facial expression recognition network and the effectiveness of our
proposed approach Comp-GAN to improve the performance of few-shot recognition tasks. 