Transfer learning aims at improving the performance of target learners on target domains by transferring
the knowledge contained in different but related source domains. In this way, the dependence on
a large number of target domain data can be reduced for constructing target learners. Due to the wide
application prospects, transfer learning has become a popular and promising area in machine learning.
Although there are already some valuable and impressive surveys on transfer learning, these surveys
introduce approaches in a relatively isolated way and lack the recent advances in transfer learning.
As the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively
review the relevant studies. This survey attempts to connect and systematize the existing transfer
learning researches, as well as to summarize and interpret the mechanisms and the strategies in
a comprehensive way, which may help readers have a better understanding of the current research
status and ideas. Different from previous surveys, this survey paper reviews over forty representative
transfer learning approaches from the perspectives of data and model. The applications of transfer
learning are also briefly introduced. In order to show the performance of different transfer learning
models, twenty representative transfer learning models are used for experiments. The models are
performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and Office-31. And
the experimental results demonstrate the importance of selecting appropriate transfer learning
models for different applications in practice. 