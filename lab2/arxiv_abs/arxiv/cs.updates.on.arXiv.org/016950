The COVID-19 pandemic continues to severely undermine the prosperity of the global health system.
To combat this pandemic, effective screening techniques for infected patients are indispensable.
There is no doubt that the use of chest X-ray images for radiological assessment is one of the essential
screening techniques. Some of the early studies revealed that the patient's chest X-ray images
showed abnormalities, which is natural for patients infected with COVID-19. In this paper, we proposed
a parallel-dilated convolutional neural network (CNN) based COVID-19 detection system from chest
x-ray images, named as Parallel-Dilated COVIDNet (PDCOVIDNet). First, the publicly available
chest X-ray collection fully preloaded and enhanced, and then classified by the proposed method.
Differing convolution dilation rate in a parallel form demonstrates the proof-of-principle for
using PDCOVIDNet to extract radiological features for COVID-19 detection. Accordingly, we have
assisted our method with two visualization methods, which are specifically designed to increase
understanding of the key components associated with COVID-19 infection. Both visualization methods
compute gradients for a given image category related to feature maps of the last convolutional layer
to create a class-discriminative region. In our experiment, we used a total of 2,905 chest X-ray
images, comprising three cases (such as COVID-19, normal, and viral pneumonia), and empirical
evaluations revealed that the proposed method extracted more significant features expeditiously
related to the suspected disease. The experimental results demonstrate that our proposed method
significantly improves performance metrics: accuracy, precision, recall, and F1 scores reach
96.58%, 96.58%, 96.59%, and 96.58%, respectively, which is comparable or enhanced compared with
the state-of-the-art methods. 