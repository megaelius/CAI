A remarkable time of human promise has been ushered in by the convergence of the ever-expanding availability
of big data, the soaring speed and stretch of cloud computing platforms, and the advancement of increasingly
sophisticated machine learning algorithms. Innovations in AI are already leaving a mark on government
by improving the provision of essential social goods and services from healthcare, education,
and transportation to food supply, energy, and environmental management. These bounties are likely
just the start. The prospect that progress in AI will help government to confront some of its most
urgent challenges is exciting, but legitimate worries abound. As with any new and rapidly evolving
technology, a steep learning curve means that mistakes and miscalculations will be made and that
both unanticipated and harmful impacts will occur. This guide, written for department and delivery
leads in the UK public sector and adopted by the British Government in its publication, 'Using AI
in the Public Sector,' identifies the potential harms caused by AI systems and proposes concrete,
operationalisable measures to counteract them. It stresses that public sector organisations
can anticipate and prevent these potential harms by stewarding a culture of responsible innovation
and by putting in place governance processes that support the design and implementation of ethical,
fair, and safe AI systems. It also highlights the need for algorithmically supported outcomes to
be interpretable by their users and made understandable to decision subjects in clear, non-technical,
and accessible ways. Finally, it builds out a vision of human-centred and context-sensitive implementation
that gives a central role to communication, evidence-based reasoning, situational awareness,
and moral justifiability. 