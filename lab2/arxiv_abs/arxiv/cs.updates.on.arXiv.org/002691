Research on damage detection of road surfaces using image processing techniques has been actively
conducted, achieving considerably high detection accuracies. Many studies only focus on the detection
of the presence or absence of damage. However, in a real-world scenario, when the road managers from
a governing body need to repair such damage, they need to clearly understand the type of damage in
order to take effective action. In addition, in many of these previous studies, the researchers
acquire their own data using different methods. Hence, there is no uniform road damage dataset available
openly, leading to the absence of a benchmark for road damage detection. This study makes three contributions
to address these issues. First, to the best of our knowledge, for the first time, a large-scale road
damage dataset is prepared. This dataset is composed of 9,053 road damage images captured with a
smartphone installed on a car, with 15,435 instances of road surface damage included in these road
images. In order to generate this dataset, we cooperated with 7 municipalities in Japan and acquired
road images for more than 40 hours. These images were captured in a wide variety of weather and illuminance
conditions. In each image, we annotated the bounding box representing the location and type of damage.
Next, we used a state-of-the-art object detection method using convolutional neural networks
to train the damage detection model with our dataset, and compared the accuracy and runtime speed
on both, using a GPU server and a smartphone. Finally, we demonstrate that the type of damage can be
classified into eight types with high accuracy by applying the proposed object detection method.
The road damage dataset, our experimental results, and the developed smartphone application used
in this study are publicly available (https://github.com/sekilab/RoadDamageDetector/). 