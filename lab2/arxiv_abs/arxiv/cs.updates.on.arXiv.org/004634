An important challenge in reinforcement learning, including evolutionary robotics, is to solve
multimodal problems, where agents have to act in qualitatively different ways depending on the
circumstances. Because multimodal problems are often too difficult to solve directly, it is helpful
to take advantage of staging, where a difficult task is divided into simpler subtasks that can serve
as stepping stones for solving the overall problem. Unfortunately, choosing an effective ordering
for these subtasks is difficult, and a poor ordering can reduce the speed and performance of the learning
process. Here, we provide a thorough introduction and investigation of the Combinatorial Multi-Objective
Evolutionary Algorithm (CMOEA), which avoids ordering subtasks by allowing all combinations
of subtasks to be explored simultaneously. We compare CMOEA against two algorithms that can similarly
optimize on multiple subtasks simultaneously: NSGA-II and Lexicase Selection. The algorithms
are tested on a multimodal robotics problem with six subtasks as well as a maze navigation problem
with a hundred subtasks. On these problems, CMOEA either outperforms or is competitive with the
controls. Separately, we show that adding a linear combination over all objectives can improve
the ability of NSGA-II to solve these multimodal problems. Lastly, we show that, in contrast to NSGA-II
and Lexicase Selection, CMOEA can effectively leverage secondary objectives to achieve state-of-the-art
results on the robotics task. In general, our experiments suggest that CMOEA is a promising, state-of-the-art
algorithm for solving multimodal problems. 