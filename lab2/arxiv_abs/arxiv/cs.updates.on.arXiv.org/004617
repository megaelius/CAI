There are several reports available on affective electroencephalography-based personal identification
(affective EEG-based PI), one of which uses a small dataset and another reaching less than 90\% of
the mean correct recognition rate \emph{CRR},. Thus, the aim of this paper is to improve and evaluate
the performance of affective EEG-based PI using a deep learning approach. The state-of-the-art
EEG dataset DEAP was used as the standard for affective recognition. Thirty-two healthy participants
participated in the experiment. They were asked to watch affective elicited music videos and score
subjective ratings for forty video clips during the EEG measurement. An EEG amplifier with thirty-two
electrodes was used to record affective EEG measurements from the participants. To identify personal
EEG, a cascade of deep learning architectures was proposed, using a combination of Convolutional
Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). CNNs are used to handle the spatial
information from the EEG while RNNs extract the temporal information. There has been a cascade of
CNNs, with recurrent models known as Long Short-Term Memory (CNN-LSTM) and Gate Recurrent Unit
(CNN-GRU) for comparison. Experimental results indicate that CNN-GRU and CNN-LSTM can deal with
an EEG (4--40 Hz) rom different affective states and reach up to 99.90--100\% mean \emph{CRR}. On
the other hand, a traditional machine learning approach such as a support vector machine (SVM) using
power spectral density (PSD) as a feature does not reach 50\% mean \emph{CRR}. To reduce the number
of EEG electrodes from thirty-two to five for more practical application, $F_{3}$, $F_{4}$, $F_{z}$,
$F_{7}$ and $F_{8}$ were found to be the best five electrodes for application in similar scenarios
to those in this study. CNN-GRU and CNN-LSTM reached up to 99.17\% and 98.23\% mean \emph{CRR}, respectively.
