Mean-modulated flicker -- wherein luminance increments and decrements of equal magnitude are
applied, over time, to a test field -- is commonly used in both clinical assessment of vision and experimental
studies of visual systems. However, presenting mean-modulated flicker on computer-controlled
displays is problematic; displays typically introduce luminance artifacts to flickering stimuli,
especially at high flicker frequency or contrast, potentially interfering with the validity of
findings. Here, we present a battery of tests that we used to judge the suitability of displays for
presenting mean-modulated flicker. These tests revealed marked differences between a new high-performance
liquid-crystal display (LCD; EIZO ColorEdge CG247X) and a new consumer-grade LCD (Dell U2415b),
despite the displays' vendor-supplied specifications being almost identical. We measured displayed
luminance using a spot meter, and a linearized photodiode device to record displayed luminance
waveforms. We derived spatial uniformity, response times, Fourier amplitude spectra, cycle-averaged
luminance, and root-mean-squared luminance. We presented paired luminance pulses to quantify
the displays' nonlinear dynamics. The CG247X showed relatively good spatial uniformity. Fourier
transformation of nominally static test patches revealed spectra free of artifacts, with the exception
of a frame response (artifactual flicker related to the display refresh). The CG247X's response
times depended on both source and destination luminance. Despite this nonlinear behaviour, we
were able to define a contrast and frequency range wherein the CG247X was artifact-free, that is,
the relationship between nominal luminance and displayed luminance was accurately modelled using
a causal, linear time-invariant system. This range included contrasts up to 80%, and flicker frequencies
up to 30 Hz. 