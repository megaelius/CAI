Single stage deep learning algorithm for 2D object detection was made popular by Single Shot MultiBox
Detector (SSD) and it was heavily adopted in several embedded applications. PointPillars is a state
of the art 3D object detection algorithm that uses a Single Shot Detector adapted for 3D object detection.
The main downside of PointPillars is that it has a two stage approach with learned input representation
based on fully connected layers followed by the Single Shot Detector for 3D detection. In this paper
we present Single Shot 3D Object Detection (SS3D) - a single stage 3D object detection algorithm
which combines straight forward, statistically computed input representation and a Single Shot
Detector (based on PointPillars). Computing the input representation is straight forward, does
not involve learning and does not have much computational cost. We also extend our method to stereo
input and show that, aided by additional semantic segmentation input; our method produces similar
accuracy as state of the art stereo based detectors. Achieving the accuracy of two stage detectors
using a single stage approach is important as single stage approaches are simpler to implement in
embedded, real-time applications. With LiDAR as well as stereo input, our method outperforms PointPillars.
When using LiDAR input, our input representation is able to improve the AP3D of Cars objects in the
moderate category from 74.99 to 76.84. When using stereo input, our input representation is able
to improve the AP3D of Cars objects in the moderate category from 38.13 to 45.13. Our results are also
better than other popular 3D object detectors such as AVOD and F-PointNet. 