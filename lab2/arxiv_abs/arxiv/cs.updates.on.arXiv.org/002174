Colorectal cancer is the fourth leading cause of cancer deaths worldwide and the second leading
cause in the United States. The risk of colorectal cancer can be mitigated by the identification
and removal of premalignant lesions through optical colonoscopy. Unfortunately, conventional
colonoscopy misses more than 20% of the polyps that should be removed, due in part to poor contrast
of lesion topography. Imaging tissue topography during a colonoscopy is difficult because of the
size constraints of the endoscope and the deforming mucosa. Most existing methods make geometric
assumptions or incorporate a priori information, which limits accuracy and sensitivity. In this
paper, we present a method that avoids these restrictions, using a joint deep convolutional neural
network-conditional random field (CNN-CRF) framework. Estimated depth is used to reconstruct
the topography of the surface of the colon from a single image. We train the unary and pairwise potential
functions of a CRF in a CNN on synthetic data, generated by developing an endoscope camera model and
rendering over 100,000 images of an anatomically-realistic colon. We validate our approach with
real endoscopy images from a porcine colon, transferred to a synthetic-like domain, with ground
truth from registered computed tomography measurements. The CNN-CRF approach estimates depths
with a relative error of 0.152 for synthetic endoscopy images and 0.242 for real endoscopy images.
We show that the estimated depth maps can be used for reconstructing the topography of the mucosa
from conventional colonoscopy images. This approach can easily be integrated into existing endoscopy
systems and provides a foundation for improving computer-aided detection algorithms for detection,
segmentation and classification of lesions. 