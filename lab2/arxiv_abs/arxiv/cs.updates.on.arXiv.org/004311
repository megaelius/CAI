Matching for causal inference is a well-studied problem, but standard methods fail when the units
to match are text documents: the high-dimensional and rich nature of the data renders exact matching
infeasible, causes propensity scores to produce incomparable matches, and makes assessing match
quality difficult. In this paper, we characterize a framework for matching text documents that
decomposes existing methods into: (1) the choice of text representation, and (2) the choice of distance
metric. We investigate how different choices within this framework affect both the quantity and
quality of matches identified through a systematic multifactor evaluation experiment using human
subjects. Altogether we evaluate 84 unique text matching methods along with 5 comparison methods
taken from the literature. Our experimental results identify methods that generate matches with
higher subjective match quality than current state-of-the-art techniques. We enhance the precision
of these results by developing a predictive model to estimate the match quality of pairs of text documents
as a function of our 84 distance scores. This model, which we find successfully mimics human judgment,
also allows for approximate and unsupervised evaluation of new procedures. We then employ the identified
best method to engage with a substantive debate in the study of media bias using a data set of front-page
news articles from thirteen news sources. Media bias is composed of topic selection bias and presentation
bias; using text matching to control for topic selection, we find that both components contribute
to media bias, though some news sources rely on one component more than the other. 