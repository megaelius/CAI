Virtual reality has been gaining popularity in recent years caused by the proliferation of affordable
consumer-grade devices such as Oculus Rift, HTC Vive, and Samsung VR. Amongst the various VR applications,
360{\deg} video streaming is currently one of the most popular ones. It allows user to change their
field-of-view (FoV) based on head movement, which enables them to freely select an area anywhere
from the sphere the video is (virtually) projected to. While 360{\deg} video streaming offers new
exciting ways of consuming content for viewers, it poses a series of challenges to the systems that
are responsible for the distribution of such content from the origin to the viewer. One challenge
is the significantly increased bandwidth requirement for streaming such content in real time.
Recent research has shown that only streaming the content that is in the user's FoV in high quality
can lead to strong bandwidth savings. This can be achieved by analyzing the viewers head orientation
and movement based on sensor information. Alternatively, historic information from users that
watched the content in the past can be taken into account to prefetch 360{\deg} video data in high
quality assuming the viewer will direct the FoV to these areas. In this paper, we present a 360{\deg}
video streaming system that transitions between sensor- and content-based predictive mechanisms.
We evaluate the effects of this transition-based approach on the Quality of Experience (QoE) of
such a VR streaming system and show that the perceived quality can be increased between 50\% and 80\%
compared to systems that only apply either one of the two approaches. 