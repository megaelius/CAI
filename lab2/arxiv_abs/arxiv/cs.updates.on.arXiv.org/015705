The complex and computationally expensive nature of landscape evolution models pose significant
challenges in the inference and optimisation of unknown parameters. Bayesian inference provides
a methodology for estimation and uncertainty quantification of unknown model parameters. In our
previous work, we developed parallel tempering Bayeslands as a framework for parameter estimation
and uncertainty quantification for the Badlands landscape evolution model. Parallel tempering
Bayeslands features high-performance computing with dozens of processing cores running in parallel
to enhance computational efficiency. Although we use parallel computing, the procedure remains
computationally challenging since thousands of samples need to be drawn and evaluated. \textcolor{black}{In
large-scale landscape and basin evolution problems, a single model evaluation can take from several
minutes to hours, and in some instances, even days. Surrogate-assisted optimisation has been used
for several computationally expensive engineering problems which motivate its use in optimisation
and inference of complex geoscientific models.} The use of surrogate models can speed up parallel
tempering Bayeslands by developing computationally inexpensive models to mimic expensive ones.
In this paper, we apply surrogate-assisted parallel tempering where that surrogate mimics a landscape
evolution model by estimating the likelihood function from the model. \textcolor{black}{We employ
a neural network-based surrogate model that learns from the history of samples generated. } The
entire framework is developed in a parallel computing infrastructure to take advantage of parallelism.
The results show that the proposed methodology is effective in lowering the overall computational
cost significantly while retaining the quality of solutions. 