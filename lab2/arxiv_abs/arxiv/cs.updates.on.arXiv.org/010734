In stochastic control applications, typically only an ideal model (controlled transition kernel)
is assumed and the control design is based on the given model, raising the problem of performance
loss due to the mismatch between the assumed model and the actual model. Toward this end, we study
continuity properties of discrete-time stochastic control problems with respect to system models
(i.e., controlled transition kernels) and robustness of optimal control policies designed for
incorrect models applied to the true system. We study both fully observed and partially observed
setups under an infinite horizon discounted expected cost criterion. We show that continuity and
robustness cannot be established under weak and setwise convergences of transition kernels in
general, but that the expected induced cost is robust under total variation. By imposing further
assumptions on the measurement models and on the kernel itself (such as continuous convergence),
we show that the optimal cost can be made continuous under weak convergence of transition kernels
as well. Using these continuity properties, we establish convergence results and error bounds
due to mismatch that occurs by the application of a control policy which is designed for an incorrectly
estimated system model to a true model, thus establishing positive and negative results on robustness.Compared
to the existing literature, we obtain strictly refined robustness results that are applicable
even when the incorrect models can be investigated under weak convergence and setwise convergence
criteria (with respect to a true model), in addition to the total variation criteria. These entail
positive implications on empirical learning in (data-driven) stochastic control since often
system models are learned through empirical training data where typically weak convergence criterion
applies but stronger convergence criteria do not. 