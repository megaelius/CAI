Scientific applications are often irregular and characterized by large computationally-intensive
parallel loops. Dynamic loop scheduling (DLS) techniques improve the performance of computationally-intensive
scientific applications via load balancing of their execution on high-performance computing
(HPC) systems. Identifying the most suitable choices of data distribution strategies, system
sizes, and DLS techniques which improve the performance of a given application, requires intensive
assessment and a large number of exploratory native experiments (using real applications on real
systems), which may not always be feasible or practical due to associated time and costs. In such
cases, simulative experiments are more appropriate for studying the performance of applications.
This motivates the question of How realistic are the simulations of executions of scientific applications
using DLS on HPC platforms? In the present work, a methodology is devised to answer this question.
It involves the experimental verification and analysis of the performance of DLS in scientific
applications. The proposed methodology is employed for a computer vision application executing
using four DLS techniques on two different HPC plat- forms, both via native and simulative experiments.
The evaluation and analysis of the native and simulative results indicate that the accuracy of the
simulative experiments is strongly influenced by the approach used to extract the computational
effort of the application (FLOP- or time-based), the choice of application model representation
into simulation (data or task parallel), and the available HPC subsystem models in the simulator
(multi-core CPUs, memory hierarchy, and network topology). The minimum and the maximum percent
errors achieved between the native and the simulative experiments are 0.95% and 8.03%, respectively.
