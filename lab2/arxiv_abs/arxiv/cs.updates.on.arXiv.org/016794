Genetic and Evolutionary Algorithms (GEAs) rely on operators such as mutation and recombination
to introduce variation to the genotypes. Because of their crucial role and effect on GEA performance,
several studies have attempted to model and quantify the variation induced by different operators
on various genotypic representations and GEAs. In this paper we focus on the popular representations
of integers from bit strings, and ask how sensitive these particular representations are to variation
operators, and in particular to single-bit mutations. We approach this question from both theoretical
and experimental perspectives. First, we prove lower and upper bounds on the single-bit mutation
locality of any representation by reducing the problem to hypercube mappings. We also compute an
asymptotic limit for the distance distortion of any operator and any representation. Then, our
experiments replicate previous results on mutation-based GEAs and examine the predictive power
of the locality metrics we compute. We primarily experiment with four representations in particular,
two of which have been extensively studied: Gray and standard binary encoding. Our main result is
that the locality of standard binary encoding representation is no worse---and sometimes better---than
that of Gray encoding. This result appears to contradict several past studies that found Gray to
outperform standard binary encoding for a large class of GEA problems. We discuss various alternate
explanations to Gray's better performance, but conclude that single-bit mutation locality cannot
be one of those. It may, however, be useful for explaining the performance of GEAs during their exploration
phase. 