Background: Given the importance of relation or event extraction from biomedical research publications
to support knowledge capture and synthesis, and the strong dependency of approaches to this information
extraction task on syntactic information, it is valuable to understand which approaches to syntactic
processing of biomedical text have the highest performance. Results: We perform an empirical study
comparing state-of-the-art traditional feature-based and neural network-based models for two
core natural language processing tasks of part-of-speech (POS) tagging and dependency parsing
on two benchmark biomedical corpora, GENIA and CRAFT. To the best of our knowledge, there is no recent
work making such comparisons in the biomedical context; specifically no detailed analysis of neural
models on this data is available. Experimental results show that in general, the neural models outperform
the feature-based models on two benchmark biomedical corpora GENIA and CRAFT. We also perform a
task-oriented evaluation to investigate the influences of these models in a downstream application
on biomedical event extraction, and show that better intrinsic parsing performance does not always
imply better extrinsic event extraction performance. Conclusion: We have presented a detailed
empirical study comparing traditional feature-based and neural network-based models for POS
tagging and dependency parsing in the biomedical context, and also investigated the influence
of parser selection for a biomedical event extraction downstream task. Availability of data and
material: We make the retrained models available at https://github.com/datquocnguyen/BioPosDep
