The recent COVID-19 pandemic, which was first detected in Wuhan, China, has been linked to increased
anti-Chinese sentiment in the United States. Recently, Broniatowski et al. found that foreign
powers, and especially Russia, were implicated in information operations using public health
crises to promote discord -- including racial conflict -- in American society (Broniatowski, 2018).
This brief considers the problem of automatically detecting changes in overall attitudes, that
may be associated with emerging information operations, via artificial intelligence. Accurate
analysis of these emerging topics usually requires laborious, manual analysis by experts to annotate
millions of tweets to identify biases in new topics. We introduce extensions of the Word Embedding
Association Test from Caliskan et. al to a new domain (Caliskan, 2017). This practical and unsupervised
method is applied to quantify biases being promoted in information operations. Analyzing historical
information operations from Russia's interference in the 2016 U.S. presidential elections, we
quantify biased attitudes for presidential candidates, and sentiment toward Muslim groups. We
next apply this method to a corpus of tweets containing anti-Chinese hashtags. We find that roughly
1% of tweets in our corpus reference Russian-funded news sources and use anti-Chinese hashtags
and, beyond the expected anti-Chinese attitudes, we find that this corpus as a whole contains pro-Russian
attitudes, which are not present in a control Twitter corpus containing general tweets. Additionally,
4% of the users in this corpus were suspended within a week. These findings may indicate the presence
of abusive account activity associated with rapid changes in attitudes around the COVID-19 public
health crisis, suggesting potential information operations. 