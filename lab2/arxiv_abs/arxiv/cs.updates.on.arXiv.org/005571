Purpose: The fusion of transrectal ultrasound (TRUS) and magnetic resonance (MR) images for guiding
targeted prostate biopsy has significantly improved the biopsy yield of aggressive cancers. A
key component of MR-TRUS fusion is image registration. However, it is very challenging to obtain
a robust automatic MR-TRUS registration due to the large appearance difference between the two
imaging modalities. The work presented in this paper aims to tackle this problem by addressing two
challenges: (i) the definition of a suitable similarity metric and (ii) the determination of a suitable
optimization strategy. Methods: This work proposes the use of a deep convolutional neural network
to learn a similarity metric for MR-TRUS registration. We also use a composite optimization strategy
that explores the solution space in order to search for a suitable initialization for the second-order
optimization of the learned metric. Further, a multi-pass approach is used in order to smooth the
metric for optimization. Results: The learned similarity metric outperforms the classical mutual
information and also the state-of-the-art MIND feature based methods. The results indicate that
the overall registration framework has a large capture range. The proposed deep similarity metric
based approach obtained a mean TRE of 3.86mm (with an initial TRE of 16mm) for this challenging problem.
Conclusion: A similarity metric that is learned using a deep neural network can be used to assess
the quality of any given image registration and can be used in conjunction with the aforementioned
optimization framework to perform automatic registration that is robust to poor initialization.
