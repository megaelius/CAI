How secure automatic speaker verification (ASV) technology is? More concretely, given a specific
target speaker, how likely is it to find another person who gets falsely accepted as that target?
This question may be addressed empirically by studying naturally confusable pairs of speakers
within a large enough corpus. To this end, one might expect to find at least some speaker pairs that
are indistinguishable from each other in terms of ASV. To a certain extent, such aim is mirrored in
the standardized ASV evaluation benchmarks. However, the number of speakers in such evaluation
benchmarks represents only a small fraction of all possible human voices, making it challenging
to extrapolate performance beyond a given corpus. Furthermore, the impostors used in performance
evaluation are usually selected randomly. A potentially more meaningful definition of an impostor
- at least in the context of security-driven ASV applications - would be closest (most confusable)
other speaker to a given target. We put forward a novel performance assessment framework to address
both the inadequacy of the random-impostor evaluation model and the size limitation of evaluation
corpora by addressing ASV security against closest impostors on arbitrarily large datasets. The
framework allows one to make a prediction of the safety of given ASV technology, in its current state,
for arbitrarily large speaker database size consisting of virtual (sampled) speakers. As a proof-of-concept,
we analyze the performance of two state-of-the-art ASV systems, based on i-vector and x-vector
speaker embeddings (as implemented in the popular Kaldi toolkit), on the recent VoxCeleb 1 & 2 corpora.
We found that neither the i-vector or x-vector system is immune to increased false alarm rate at increased
impostor database size. 