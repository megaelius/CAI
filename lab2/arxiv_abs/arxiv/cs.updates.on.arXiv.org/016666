Bobkov, Houdr\'e, and the last author introduced a Poincar\'e-type functional parameter, $\lambda_\infty$,
of a graph $G$. They related $\lambda_\infty$ to the {\em vertex expansion} of the graph via a Cheeger-type
inequality, analogous to the inequality relating the spectral gap of the graph, $\lambda_2$, to
its {\em edge expansion}. While $\lambda_2$ can be computed efficiently, the computational complexity
of $\lambda_\infty$ has remained an open question. Following the work of the second author with
Raghavendra and Vempala, wherein the complexity of $\lambda_\infty$ was related to the so-called
small-set expansion (SSE) problem, it has been believed that computing $\lambda_\infty$ is a hard
problem. We confirm this conjecture by proving that computing $\lambda_\infty$ is indeed NP-hard,
even for weighted trees. Our gadget further proves NP-hardness of computing \emph{spread constant}
of a weighted tree; i.e., a geometric measure of the graph, introduced by Alon, Boppana, and Spencer,
in the context of deriving an asymptotic isoperimetric inequality of Cartesian products of graphs.
We conclude this case by providing a fully polynomial time approximation scheme. We further study
a generalization of spread constant in machine learning literature, namely the {\em maximum variance
embedding} problem. For trees, we provide fast combinatorial algorithms that avoid solving a semidefinite
relaxation of the problem. On the other hand, for general graphs, we propose a randomized projection
method that can outperform the optimal orthogonal projection, i.e., PCA, classically used for
rounding of the optimum lifted solution (to SDP relaxation) of the problem. 