Making a good decision involves considering the likely outcomes under each possible action. For
example, would drug A or drug B lead to a better outcome for this patient? Ideally, we answer these
questions using an experiment, but this is not always possible (e.g., it may be unethical). As an
alternative, we can use non-experimental data to learn models that make counterfactual predictions
of what we would observe had we run an experiment. To learn such models for decision-making problems,
we propose the use of counterfactual objectives in lieu of classical supervised learning objectives.
We implement this idea in a challenging and frequently occurring context, and propose the counterfactual
GP (CGP), a counterfactual model of continuous-time trajectories (time series) under sequences
of actions taken in continuous-time. We develop our model within the potential outcomes framework
of Neyman and Rubin. The counterfactual GP is trained using a joint maximum likelihood objective
that adjusts for dependencies between observed actions and outcomes in the training data. We report
two sets of experimental results. First, we show that the CGP's predictions are reliable; they are
stable to changes in certain characteristics of the training data that are not relevant to the decision-making
problem. Predictive models trained using classical supervised learning objectives, however,
are not stable to such perturbations. In the second experiment, we use data from a real intensive
care unit (ICU) and qualitatively demonstrate how the CGP's ability to answer "What if?" questions
offers medical decision-makers a powerful new tool for planning treatment. 