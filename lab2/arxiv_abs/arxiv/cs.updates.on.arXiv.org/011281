Virtual borders are employed to allow humans the interactive and flexible restriction of their
mobile robots' workspaces in human-centered environments, e.g. to exclude privacy zones from
the workspace or to indicate certain areas for working. They have been successfully specified in
interaction processes using methods from human-robot interaction. However, these methods often
lack an expressive feedback system, are restricted to robot's on-board interaction capabilities
and require a direct line of sight between human and robot. This negatively affects the user experience
and interaction time. Therefore, we investigate the effect of a smart environment on the teaching
of virtual borders with the objective to enhance the perceptual and interaction capabilities of
a robot. For this purpose, we propose a novel interaction method based on a laser pointer, that leverages
a smart home environment in the interaction process. This interaction method comprises an architecture
for a smart home environment designed to support the interaction process, the cooperation of human,
robot and smart environment in the interaction process, a cooperative perception including stationary
and mobile cameras to perceive laser spots and an algorithm to extract virtual borders from multiple
camera observations. The results of an experimental evaluation support our hypotheses that our
novel interaction method features a significantly shorter interaction time and a better user experience
compared to an approach without support of a smart environment. Moreover, the interaction method
does not negatively affect other user requirements concerning completeness and accuracy. 