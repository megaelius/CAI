Breast cancer is the second leading cause of cancer death among women worldwide. Nevertheless,
it is also one of the most treatable malignances if detected early. Screening for breast cancer with
digital mammography (DM) has been widely used. However it demonstrates limited sensitivity for
women with dense breasts. An emerging technology in the field is contrast-enhanced digital mammography
(CEDM), which includes a low energy (LE) image similar to DM, and a recombined image leveraging tumor
neoangiogenesis similar to breast magnetic resonance imaging (MRI). CEDM has shown better diagnostic
accuracy than DM. While promising, CEDM is not yet widely available across medical centers. In this
research, we propose a Shallow-Deep Convolutional Neural Network (SD-CNN) where a shallow CNN
is developed to derive "virtual" recombined images from LE images, and a deep CNN is employed to extract
novel features from LE, recombined or "virtual" recombined images for ensemble models to classify
the cases as benign vs. cancer. To evaluate the validity of our approach, we first develop a deep-CNN
using 49 CEDM cases collected from Mayo Clinic to prove the contributions from recombined images
for improved breast cancer diagnosis (0.86 in accuracy using LE imaging vs. 0.90 in accuracy using
both LE and recombined imaging). We then develop a shallow-CNN using the same 49 CEDM cases to learn
the nonlinear mapping from LE to recombined images. Next, we use 69 DM cases collected from the hospital
located at Zhejiang University, China to generate "virtual" recombined images. Using DM alone
provides 0.91 in accuracy, whereas SD-CNN improves the diagnostic accuracy to 0.95. 