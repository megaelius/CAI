Humans excel at continually acquiring and fine-tuning knowledge over sustained time spans. This
ability, typically referred to as lifelong learning, is crucial for artificial agents interacting
in real-world, dynamic environments where i) the number of tasks to be learned is not pre-defined,
ii) training samples become progressively available over time, and iii) annotated samples may
be very sparse. In this paper, we propose a dual-memory self-organizing system that learns spatiotemporal
representations from videos. The architecture draws inspiration from the interplay of the hippocampal
and neocortical systems in the mammalian brain argued to mediate the complementary tasks of quickly
integrating specific experiences, i.e., episodic memory (EM), and slowly learning generalities
from episodic events, i.e., semantic memory (SM). The complementary memories are modeled as recurrent
self-organizing neural networks: The EM quickly adapts to incoming novel sensory observations
via competitive Hebbian Learning, whereas the SM progressively learns compact representations
by using task-relevant signals to regulate intrinsic levels of neurogenesis and neuroplasticity.
For the consolidation of knowledge, trajectories of neural reactivations are periodically replayed
to both networks. We analyze and evaluate the performance of our approach with the CORe50 benchmark
dataset for continuous object recognition from videos. We show that the proposed approach significantly
outperforms current (supervised) methods of lifelong learning in three different incremental
learning scenarios, and that due to the unsupervised nature of neural network self-organization,
our approach can be used in scenarios where sample annotations are sparse. 