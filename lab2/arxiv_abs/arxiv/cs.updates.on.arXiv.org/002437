Synaptic connections between neurons in the brain are dynamic because of continuously ongoing
spine dynamics, axonal sprouting, and other processes. In fact, it was recently shown that the spontaneous
synapse-autonomous component of spine dynamics is at least as large as the component that depends
on the history of pre- and postsynaptic neural activity. These data are inconsistent with common
models for network plasticity, and raise the questions how neural circuits can maintain a stable
computational function in spite of these continuously ongoing processes, and what functional
uses these ongoing processes might have. Here, we present a rigorous theoretical framework for
these seemingly stochastic spine dynamics and rewiring processes in the context of reward-based
learning tasks. We show that spontaneous synapse-autonomous processes, in combination with reward
signals such as dopamine, can explain the capability of networks of neurons in the brain to configure
themselves for specific computational tasks, and to compensate automatically for later changes
in the network or task. Furthermore we show theoretically and through computer simulations that
stable computational performance is compatible with continuously ongoing synapse-autonomous
changes. After reaching good computational performance it causes primarily a slow drift of network
architecture and dynamics in task-irrelevant dimensions, as observed for neural activity in motor
cortex and other areas. On the more abstract level of reinforcement learning the resulting model
gives rise to an understanding of reward-driven network plasticity as continuous sampling of network
configurations. 