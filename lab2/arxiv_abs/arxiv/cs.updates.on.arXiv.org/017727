The recent proliferation of numerous fashion e-commerce platforms has led to a surge in online shopping
of fashion products. Fashion being the dominant aspect in online retail sales, demands for efficient
and effective fashion products recommendation systems that could boost revenue, improve customer
experience and engagement. In this paper, we focus on the problem of similar fashion item recommendation
for multiple fashion items. Given a Product Display Page for a fashion item in an online e-commerce
platform, we identify the images with a full-shot look, i.e., the one with a full human model wearing
the fashion item. While the majority of existing works in this domain focus on retrieving similar
products corresponding to a single item present in a query, we focus on the retrieval of multiple
fashion items at once. This is an important problem because while a user might have searched for a
particular primary article type (e.g., men's shorts), the human model in the full-shot look image
would usually be wearing secondary fashion items as well (e.g., t-shirts, shoes etc). Upon looking
at the full-shot look image in the PDP, the user might also be interested in viewing similar items
for the secondary article types. To address this need, we use human keypoint detection to first identify
the fullshot images, from which we subsequently select the front facing ones. An article detection
and localisation module pretrained on a large-dataset is then used to identify different articles
in the image. The detected articles and the catalog database images are then represented in a common
embedding space, for the purpose of similarity based retrieval. We make use of a triplet-based neural
network to obtain the embeddings. Our embedding network by virtue of an active-learning component
achieves further improvements in the retrieval performance. 