Diabetic retinopathy (DR) grading is crucial in determining the patients' adequate treatment
and follow up, but the screening process can be tiresome and prone to errors. Deep learning approaches
have shown promising performance as computer-aided diagnosis(CAD) systems, but their black-box
behaviour hinders the clinical application. We propose DR$\vert$GRADUATE, a novel deep learning-based
DR grading CAD system that supports its decision by providing a medically interpretable explanation
and an estimation of how uncertain that prediction is, allowing the ophthalmologist to measure
how much that decision should be trusted. We designed DR$\vert$GRADUATE taking into account the
ordinal nature of the DR grading problem. A novel Gaussian-sampling approach built upon a Multiple
Instance Learning framework allow DR$\vert$GRADUATE to infer an image grade associated with an
explanation map and a prediction uncertainty while being trained only with image-wise labels.
DR$\vert$GRADUATE was trained on the Kaggle training set and evaluated across multiple datasets.
In DR grading, a quadratic-weighted Cohen's kappa (QWK) between 0.71 and 0.84 was achieved in five
different datasets. We show that high QWK values occur for images with low prediction uncertainty,
thus indicating that this uncertainty is a valid measure of the predictions' quality. Further,
bad quality images are generally associated with higher uncertainties, showing that images not
suitable for diagnosis indeed lead to less trustworthy predictions. Additionally, tests on unfamiliar
medical image data types suggest that DR$\vert$GRADUATE allows outlier detection. The attention
maps generally highlight regions of interest for diagnosis. These results show the great potential
of DR$\vert$GRADUATE as a second-opinion system in DR severity grading. 