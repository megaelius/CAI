Are existing object detection methods adequate for detecting text and visual elements in scientific
plots which are arguably different than the objects found in natural images? To answer this question,
we train and compare the accuracy of Fast/Faster R-CNN, SSD, YOLO and RetinaNet on the PlotQA dataset
with over 220,000 scientific plots. At the standard IOU setting of 0.5, most networks perform well
with mAP scores greater than 80% in detecting the relatively simple objects in plots. However, the
performance drops drastically when evaluated at a stricter IOU of 0.9 with the best model giving
a mAP of 35.70%. Note that such a stricter evaluation is essential when dealing with scientific plots
where even minor localisation errors can lead to large errors in downstream numerical inferences.
Given this poor performance, we propose minor modifications to existing models by combining ideas
from different object detection networks. While this significantly improves the performance,
there are still 2 main issues: (i) performance on text objects which are essential for reasoning
is very poor, and (ii) inference time is unacceptably large considering the simplicity of plots.
Based on these experiments and results, we identify the following considerations for improving
object detection on plots: (a) small inference time, (b) higher precision on text objects, and (c)
more accurate localisation with a custom loss function with non-negligible loss values at high
IOU (> 0.8). We propose a network which meets all these considerations: It is 16x faster than the best
performing competitor and significantly improves upon the accuracy of existing models with a mAP
of 93.44%@0.9 IOU. 