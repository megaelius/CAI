Our objective is to build machine learning based models that predict audiovisual quality directly
from a set of correlated parameters that are extracted from a target quality dataset. We have used
the bitstream version of the INRS audiovisual quality dataset that reflects contemporary real-time
configurations for video frame rate, video quantization, noise reduction parameters and network
packet loss rate. We have utilized this dataset to build bitstream perceived quality estimation
models based on the Random Forests, Bagging, Deep Learning and Genetic Programming methods. We
have taken an empirical approach and have generated models varying from very simple to the most complex
depending on the number of features used from the quality dataset. Random Forests and Bagging models
have overall generated the most accurate results in terms of RMSE and Pearson correlation coefficient
values. Deep Learning and Genetic Programming based bitstream models have also achieved good results
but that high performance was observed only with a limited range of features. We have also obtained
the epsilon-insensitive RMSE values for each model and have computed the significance of the difference
between the correlation coefficients. Overall we conclude that computing the bitstream information
is worth the effort it takes to generate and helps to build more accurate models for real-time communications.
However, it is useful only for the deployment of the right algorithms with the carefully selected
subset of the features. The dataset and tools that have been developed during this research are publicly
available for research and development purposes. 