Multi-label classification plays a momentous role in perceiving intricate contents of an aerial
image and triggers several related studies over the last years. However, most of them deploy few
efforts in exploiting label relations, while such dependencies are crucial for making accurate
predictions. Although an LSTM layer can be introduced to modeling such label dependencies in a chain
propagation manner, the efficiency might be questioned when certain labels are improperly inferred.
To address this, we propose a novel aerial image multi-label classification network, attention-aware
label relational reasoning network. Particularly, our network consists of three elemental modules:
1) a label-wise feature parcel learning module, 2) an attentional region extraction module, and
3) a label relational inference module. To be more specific, the label-wise feature parcel learning
module is designed for extracting high-level label-specific features. The attentional region
extraction module aims at localizing discriminative regions in these features and yielding attentional
label-specific features. The label relational inference module finally predicts label existences
using label relations reasoned from outputs of the previous module. The proposed network is characterized
by its capacities of extracting discriminative label-wise features in a proposal-free way and
reasoning about label relations naturally and interpretably. In our experiments, we evaluate
the proposed model on the UCM multi-label dataset and a newly produced dataset, AID multi-label
dataset. Quantitative and qualitative results on these two datasets demonstrate the effectiveness
of our model. To facilitate progress in the multi-label aerial image classification, the AID multi-label
dataset will be made publicly available. 