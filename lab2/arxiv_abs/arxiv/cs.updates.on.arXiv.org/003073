We introduce Chinese Text in the Wild, a very large dataset of Chinese text in street view images.
While optical character recognition (OCR) in document images is well studied and many commercial
tools are available, detection and recognition of text in natural images is still a challenging
problem, especially for more complicated character sets such as Chinese text. Lack of training
data has always been a problem, especially for deep learning methods which require massive training
data. In this paper we provide details of a newly created dataset of Chinese text with about 1 million
Chinese characters annotated by experts in over 30 thousand street view images. This is a challenging
dataset with good diversity. It contains planar text, raised text, text in cities, text in rural
areas, text under poor illumination, distant text, partially occluded text, etc. For each character
in the dataset, the annotation includes its underlying character, its bounding box, and 6 attributes.
The attributes indicate whether it has complex background, whether it is raised, whether it is handwritten
or printed, etc. The large size and diversity of this dataset make it suitable for training robust
neural networks for various tasks, particularly detection and recognition. We give baseline results
using several state-of-the-art networks, including AlexNet, OverFeat, Google Inception and
ResNet for character recognition, and YOLOv2 for character detection in images. Overall Google
Inception has the best performance on recognition with 80.5% top-1 accuracy, while YOLOv2 achieves
an mAP of 71.0% on detection. Dataset, source code and trained models will all be publicly available
on the website. 