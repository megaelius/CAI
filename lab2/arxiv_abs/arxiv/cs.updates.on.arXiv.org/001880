Developing image classification models often requires significant architecture engineering.
In this paper, we attempt to automate this engineering process by learning the model architectures
directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose
to learn an architectural building block on a small dataset that can be transferred to a large dataset.
In our experiments, we search for the best convolutional layer (or "cell") on the CIFAR-10 dataset
and then apply this learned cell to the ImageNet dataset by stacking together more copies of this
cell, each with their own parameters. Although the cell is not learned directly on ImageNet, an architecture
constructed from the best learned cell achieves, among the published work, state-of-the-art accuracy
of 82.7% top-1 and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than the best
human-invented architectures while having 9 billion fewer FLOPS -- a reduction of 28% from the previous
state of the art model. When evaluated at different levels of computational cost, accuracies of
networks constructed from the cells exceed those of the state-of-the-art human-designed models.
For instance, a smaller network constructed from the best cell also achieves 74% top-1 accuracy,
which is 3.1% better than equivalently-sized, state-of-the-art models for mobile platforms.
Finally, the image features learned from image classification are generically useful and can be
transferred to other computer vision problems. On the task of object detection, the learned features
used with Faster-RCNN framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO
dataset. 