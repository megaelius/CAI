Unsupervised domain adaptation aims at transferring knowledge from the labeled source domain
to the unlabeled target domain. Previous adversarial domain adaptation methods mostly adopt the
discriminator with binary or $K$-dimensional output to perform marginal or conditional alignment
independently. Recent experiments have shown that when the discriminator is provided with domain
information in both domains and label information in the source domain, it is able to preserve the
complex multimodal information and high semantic information in both domains. Following this
idea, we adopt a discriminator with $2K$-dimensional output to perform both domain-level and class-level
alignments simultaneously in a single discriminator. However, a single discriminator can not
capture all the useful information across domains and the relationships between the examples and
the decision boundary are rarely explored before. Inspired by multi-view learning and latest advances
in domain adaptation, besides the adversarial process between the discriminator and the feature
extractor, we also design a novel mechanism to make two discriminators pit against each other, so
that they can provide diverse information for each other and avoid generating target features outside
the support of the source domain. To the best of our knowledge, it is the first time to explore a dual
adversarial strategy in domain adaptation. Moreover, we also use the semi-supervised learning
regularization to make the representations more discriminative. Comprehensive experiments
on two real-world datasets verify that our method outperforms several state-of-the-art domain
adaptation methods. 