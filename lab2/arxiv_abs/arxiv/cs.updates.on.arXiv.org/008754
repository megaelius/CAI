In this paper, we focus on model generalization and adaptation for cross-domain person re-identification
(Re-ID). Unlike existing cross-domain Re-ID methods, leveraging the auxiliary information of
those unlabeled target-domain data, we aim at enhancing the model generalization and adaptation
by discriminative feature learning, and directly exploiting a pre-trained model to new domains
(datasets) without any utilization of the information from target domains. To address the discriminative
feature learning problem, we surprisingly find that simply introducing the attention mechanism
to adaptively extract the person features for every domain is of great effectiveness. We adopt two
popular type of attention mechanisms, long-range dependency based attention and direct generation
based attention. Both of them can perform the attention via spatial or channel dimensions alone,
even the combination of spatial and channel dimensions. The outline of different attentions are
well illustrated. Moreover, we also incorporate the attention results into the final output of
model through skip-connection to improve the features with both high and middle level semantic
visual information. In the manner of directly exploiting a pre-trained model to new domains, the
attention incorporation method truly could enhance the model generalization and adaptation to
perform the cross-domain person Re-ID. We conduct extensive experiments between three large datasets,
Market-1501, DukeMTMC-reID and MSMT17. Surprisingly, introducing only attention can achieve
state-of-the-art performance, even much better than those cross-domain Re-ID methods utilizing
auxiliary information from the target domain. 