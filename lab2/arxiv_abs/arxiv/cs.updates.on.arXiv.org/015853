Finding and identifying scatteredly-distributed, small, and critically important objects in
3D oncology images is very challenging. We focus on the detection and segmentation of oncology-significant
(or suspicious cancer metastasized) lymph nodes (OSLNs), which has not been studied before as a
computational task. Determining and delineating the spread of OSLNs is essential in defining the
corresponding resection/irradiating regions for the downstream workflows of surgical resection
and radiotherapy of various cancers. For patients who are treated with radiotherapy, this task
is performed by experienced radiation oncologists that involves high-level reasoning on whether
LNs are metastasized, which is subject to high inter-observer variations. In this work, we propose
a divide-and-conquer decision stratification approach that divides OSLNs into tumor-proximal
and tumor-distal categories. This is motivated by the observation that each category has its own
different underlying distributions in appearance, size and other characteristics. Two separate
detection-by-segmentation networks are trained per category and fused. To further reduce false
positives (FP), we present a novel global-local network (GLNet) that combines high-level lesion
characteristics with features learned from localized 3D image patches. Our method is evaluated
on a dataset of 141 esophageal cancer patients with PET and CT modalities (the largest to-date).
Our results significantly improve the recall from $45\%$ to $67\%$ at $3$ FPs per patient as compared
to previous state-of-the-art methods. The highest achieved OSLN recall of $0.828$ is clinically
relevant and valuable. 