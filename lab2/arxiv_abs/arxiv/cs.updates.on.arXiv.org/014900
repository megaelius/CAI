Context: The effectiveness of data selection approaches in improving the performance of cross
project defect prediction(CPDP) has been shown in multiple previous studies. Beside that, replication
studies play an important role in the support of any valid study. Repeating a study using the same
or different subjects can lead to better understandings of the nature of the problem. Objective:
We use an iterative dataset selection (IDS) approach to generate training datasets and evaluate
them on a set of randomly created validation datasets in the context of CPDP while considering a higher
range of flexibility which makes the approach more feasible in practice. Method: We replicate an
earlier study and present some insights into the achieved results while pointing out some of the
shortcomings of the original study. Using the lessons learned, we propose to use an alternative
training/validation dataset generation approaches which not only is more feasible in practice,
but also achieves slightly better performances. We compare the results of our experiments to those
from scenarios A, B, C and D from the original study. Results:Our experiments reveal that IDS is heavily
recall based. The average recall performance for all test sets is 0.933 which is significantly higher
than that from the replicated method. This in turn comes with a loss in precision. IDS has the lowest
precision among the compared scenarios that use Decision Table learner. IDS however, achieves
comparable or better F-measure performances. IDS achieves higher mean, median and min F-measure
values while being more stable generally, in comparison with the replicated method. Conclusions:
We conclude that datasets obtained from iterative/search-based approaches is a promising way
to tackle CPDP. Especially, the performance increase in terms of both time and performance encourages
further investigation of our approach. 