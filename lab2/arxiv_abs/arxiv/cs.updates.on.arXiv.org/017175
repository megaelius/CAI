Convolutional neural networks (CNNs) have been attracting increasing attention in hyperspectral
(HS) image classification, owing to their ability to capture spatial-spectral feature representations.
Nevertheless, their ability in modeling relations between samples remains limited. Beyond the
limitations of grid sampling, graph convolutional networks (GCNs) have been recently proposed
and successfully applied in irregular (or non-grid) data representation and analysis. In this
paper, we thoroughly investigate CNNs and GCNs (qualitatively and quantitatively) in terms of
HS image classification. Due to the construction of the adjacency matrix on all the data, traditional
GCNs usually suffer from a huge computational cost, particularly in large-scale remote sensing
(RS) problems. To this end, we develop a new mini-batch GCN (called miniGCN hereinafter) which allows
to train large-scale GCNs in a mini-batch fashion. More significantly, our miniGCN is capable of
inferring out-of-sample data without re-training networks and improving classification performance.
Furthermore, as CNNs and GCNs can extract different types of HS features, an intuitive solution
to break the performance bottleneck of a single model is to fuse them. Since miniGCNs can perform
batch-wise network training (enabling the combination of CNNs and GCNs) we explore three fusion
strategies: additive fusion, element-wise multiplicative fusion, and concatenation fusion
to measure the obtained performance gain. Extensive experiments, conducted on three HS datasets,
demonstrate the advantages of miniGCNs over GCNs and the superiority of the tested fusion strategies
with regards to the single CNN or GCN models. The codes of this work will be available at https://github.com/danfenghong/IEEE_TGRS_GCN
for the sake of reproducibility. 