With the growing complexity of deep learning methods adopted in practical applications, there
is an increasing and stringent need to explain and interpret the decisions of such methods. In this
work, we focus on explainable AI and propose a novel generic and model-agnostic framework for synthesizing
input exemplars that maximize a desired response from a machine learning model. To this end, we use
a generative model, which acts as a prior for generating data, and traverse its latent space using
a novel evolutionary strategy with momentum updates. Our framework is generic because (i) it can
employ any underlying generator, e.g. Variational Auto-Encoders (VAEs) or Generative Adversarial
Networks (GANs), and (ii) it can be applied to any input data, e.g. images, text samples or tabular
data. Since we use a zero-order optimization method, our framework is model-agnostic, in the sense
that the machine learning model that we aim to explain is a black-box. We stress out that our novel
framework does not require access or knowledge of the internal structure or the training data of
the black-box model. We conduct experiments with two generative models, VAEs and GANs, and synthesize
exemplars for various data formats, image, text and tabular, demonstrating that our framework
is generic. We also employ our prototype synthetization framework on various black-box models,
for which we only know the input and the output formats, showing that it is model-agnostic. Moreover,
we compare our framework (available at https://github.com/antoniobarbalau/exemplar) with
a model-dependent approach based on gradient descent, proving that our framework obtains equally-good
exemplars in a shorter computational time. 