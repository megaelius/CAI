Image-to-image translation is considered a next frontier in the field of medical image analysis,
with numerous potential applications. However, recent advances in this field offer individualized
solutions by utilizing specialized architectures which are task specific or by suffering from
limited capacities and thus requiring refinement through non end-to-end training. In this paper,
we propose a novel general purpose framework for medical image-to-image translation, titled MedGAN,
which operates in an end-to-end manner on the image level. MedGAN builds upon recent advances in
the field of generative adversarial networks(GANs) by combining the adversarial framework with
a unique combination of non-adversarial losses which captures the high and low frequency components
of the desired target modality. Namely, we utilize a discriminator network as a trainable feature
extractor which penalizes the discrepancy between the translated medical images and the desired
modalities in the pixel and perceptual sense. Moreover, style-transfer losses are utilized to
match the textures and fine-structures of the desired target images to the outputs. Additionally,
we present a novel generator architecture, titled CasNet, which enhances the sharpness of the translated
medical outputs through progressive refinement via encoder decoder pairs. To demonstrate the
effectiveness of our approach, we apply MedGAN on three novel and challenging applications: PET-CT
translation, correction of MR motion artefacts and PET image denoising. Qualitative and quantitative
comparisons with state-of-the-art techniques have emphasized the superior performance of the
proposed framework. MedGAN can be directly applied as a general framework for future medical translation
tasks. 