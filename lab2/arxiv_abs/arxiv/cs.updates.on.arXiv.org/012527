Resource allocation and transceivers in wireless networks are usually designed by solving optimization
problems subject to specific constraints, which can be formulated as variable or functional optimization.
If the objective and constraint functions of a variable optimization problem can be derived, standard
numerical algorithms can be applied for finding the optimal solution, which however incur high
computational cost when the dimension of the variable is high. To reduce the on-line computational
complexity, learning the optimal solution as a function of the environment's status by deep neural
networks (DNNs) is an effective approach. DNNs can be trained under the supervision of optimal solutions,
which however, is not applicable to the scenarios without models or for functional optimization
where the optimal solutions are hard to obtain. If the objective and constraint functions are unavailable,
reinforcement learning can be applied to find the solution of a functional optimization problem,
which is however not tailored to optimization problems in wireless networks. In this article, we
introduce unsupervised and reinforced-unsupervised learning frameworks for solving both variable
and functional optimization problems without the supervision of the optimal solutions. When the
mathematical model of the environment is completely known and the distribution of environment's
status is known or unknown, we can invoke unsupervised learning algorithm. When the mathematical
model of the environment is incomplete, we introduce reinforced-unsupervised learning algorithms
that learn the model by interacting with the environment. Our simulation results confirm the applicability
of these learning frameworks by taking a user association problem as an example. 