Wearable devices enable theoretically continuous, longitudinal monitoring of physiological
measurements like step count, energy expenditure, and heart rate. Although the classification
of abnormal cardiac rhythms such as atrial fibrillation from wearable devices has great potential,
commercial algorithms remain proprietary and tend to focus on heart rate variability derived from
green spectrum LED sensors placed on the wrist where noise remains an unsolved problem. Here, we
develop a multi-task deep learning method to assess signal quality and arrhythmia event detection
in wearable photoplethysmography devices for real-time detection of atrial fibrillation (AF).
We train our algorithm on over one million simulated unlabeled physiological signals and fine-tune
on a curated dataset of over 500K labeled signals from over 100 individuals from 3 different wearable
devices. We demonstrate that in comparison with a traditional random forest-based approach (precision:0.24,
recall:0.58, f1:0.34, auPRC:0.44) and a single task CNN (precision:0.59, recall:0.69, f1:0.64,
auPRC:0.68) our architecture using unsupervised transfer learning through convolutional denoising
autoencoders dramatically improves the performance of AF detection in participants at rest (pr:0.94,
rc:0.98, f1:0.96, auPRC:0.96). In addition, we validate algorithm performance on a prospectively
derived replication cohort of ambulatory subjects using data derived from an independently engineered
device. We show that two-stage training can help address the unbalanced data problem common to biomedical
applications where large well-annotated datasets are scarce. In conclusion, though a combination
of simulation and transfer learning and we develop and apply a multitask architecture to the problem
of AF detection from wearable wrist sensors demonstrating high levels of accuracy and a solution
for the vexing challenge of mechanical noise. 