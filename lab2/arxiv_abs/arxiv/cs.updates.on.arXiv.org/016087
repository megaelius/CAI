Skin cancer is among the most common cancer types. Dermoscopic image analysis improves the diagnostic
accuracy for detection of malignant melanoma and other pigmented skin lesions when compared to
unaided visual inspection. Hence, computer-based methods to support medical experts in the diagnostic
procedure are of great interest. Fine-tuning pre-trained convolutional neural networks (CNNs)
has been shown to work well for skin lesion classification. Pre-trained CNNs are usually trained
with natural images of a fixed image size which is typically significantly smaller than captured
skin lesion images and consequently dermoscopic images are downsampled for fine-tuning. However,
useful medical information may be lost during this transformation. In this paper, we explore the
effect of input image size on skin lesion classification performance of fine-tuned CNNs. For this,
we resize dermoscopic images to different resolutions, ranging from 64x64 to 768x768 pixels and
investigate the resulting classification performance of three well-established CNNs, namely
DenseNet-121, ResNet-18, and ResNet-50. Our results show that using very small images (of size
64x64 pixels) degrades the classification performance, while images of size 128x128 pixels and
above support good performance with larger image sizes leading to slightly improved classification.
We further propose a novel fusion approach based on a three-level ensemble strategy that exploits
multiple fine-tuned networks trained with dermoscopic images at various sizes. When applied on
the ISIC 2017 skin lesion classification challenge, our fusion approach yields an area under the
receiver operating characteristic curve of 89.2% and 96.6% for melanoma classification and seborrheic
keratosis classification, respectively, outperforming state-of-the-art algorithms. 