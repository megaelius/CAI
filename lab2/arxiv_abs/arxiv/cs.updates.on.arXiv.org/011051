Predicting patient mortality is an important and challenging problem in the healthcare domain,
especially for intensive care unit (ICU) patients. Electronic health notes serve as a rich source
for learning patient representations, that can facilitate effective risk assessment. However,
a large portion of clinical notes are unstructured and also contain domain specific terminologies,
from which we need to extract structured information. In this paper, we introduce an embedding framework
to learn semantically-plausible distributed representations of clinical notes that exploits
the semantic correspondence between the unstructured texts and their corresponding structured
knowledge, known as semantic frame, in a hierarchical fashion. Our approach integrates text modeling
and semantic correspondence learning into a single model that comprises 1) an unstructured embedding
module that makes use of self-similarity matrix representations in order to inject structural
regularities of different segments inherent in clinical texts to promote local coherence, 2) a
structured embedding module to embed the semantic frames (e.g., UMLS semantic types) with deep
ConvNet and 3) a hierarchical semantic correspondence module that embeds by enhancing the interactions
between text-semantic frame embedding pairs at multiple levels (i.e., words, sentence, note).
Evaluations on multiple embedding benchmarks on post discharge intensive care patient mortality
prediction tasks demonstrate its effectiveness compared to approaches that do not exploit the
semantic interactions between structured and unstructured information present in clinical notes.
