Recently, self-driving vehicles have been introduced with several automated features including
lane-keep assistance, queuing assistance in traffic-jam, parking assistance and crash avoidance.
These self-driving vehicles and intelligent visual traffic surveillance systems mainly depend
on cameras and sensors fusion systems. Adverse weather conditions such as heavy fog, rain, snow,
and sandstorms are considered dangerous restrictions of the functionality of cameras impacting
seriously the performance of adopted computer vision algorithms for scene understanding (i.e.,
vehicle detection, tracking, and recognition in traffic scenes). For example, reflection coming
from rain flow and ice over roads could cause massive detection errors which will affect the performance
of intelligent visual traffic systems. Additionally, scene understanding and vehicle detection
algorithms are mostly evaluated using datasets contain certain types of synthetic images plus
a few real-world images. Thus, it is uncertain how these algorithms would perform on unclear images
acquired in the wild and how the progress of these algorithms is standardized in the field. To this
end, we present a new dataset (benchmark) consisting of real-world images collected under various
adverse weather conditions called DAWN. This dataset emphasizes a diverse traffic environment
(urban, highway and freeway) as well as a rich variety of traffic flow. The DAWN dataset comprises
a collection of 1000 images from real-traffic environments, which are divided into four sets of
weather conditions: fog, snow, rain and sandstorms. The dataset is annotated with object bounding
boxes for autonomous driving and video surveillance scenarios. This data helps interpreting effects
caused by the adverse weather conditions on the performance of vehicle detection systems. 