Probability theory, epistemically interpreted, provides an excellent, if not the best available
account of inductive reasoning. This is so because there are general and definite rules for the change
of subjective probabilities through information or experience; induction and belief change are
one and same topic, after all. The most basic of these rules is simply to conditionalize with respect
to the information received; and there are similar and more general rules. 1 Hence, a fundamental
reason for the epistemological success of probability theory is that there at all exists a well-behaved
concept of conditional probability. Still, people have, and have reasons for, various concerns
over probability theory. One of these is my starting point: Intuitively, we have the notion of plain
belief; we believe propositions2 to be true (or to be false or neither). Probability theory, however,
offers no formal counterpart to this notion. Believing A is not the same as having probability 1 for
A, because probability 1 is incorrigible3; but plain belief is clearly corrigible. And believing
A is not the same as giving A a probability larger than some 1 - c, because believing A and believing
B is usually taken to be equivalent to believing A & B.4 Thus, it seems that the formal representation
of plain belief has to take a non-probabilistic route. Indeed, representing plain belief seems
easy enough: simply represent an epistemic state by the set of all propositions believed true in
it or, since I make the common assumption that plain belief is deductively closed, by the conjunction
of all propositions believed true in it. But this does not yet provide a theory of induction, i.e.
an answer to the question how epistemic states so represented are changed tbrough information or
experience. There is a convincing partial answer: if the new information is compatible with the
old epistemic state, then the new epistemic state is simply represented by the conjunction of the
new information and the old beliefs. This answer is partial because it does not cover the quite common
case where the new information is incompatible with the old beliefs. It is, however, important to
complete the answer and to cover this case, too; otherwise, we would not represent plain belief as
conigible. The crucial problem is that there is no good completion. When epistemic states are represented
simply by the conjunction of all propositions believed true in it, the answer cannot be completed;
and though there is a lot of fruitful work, no other representation of epistemic states has been proposed,
as far as I know, which provides a complete solution to this problem. In this paper, I want to suggest
such a solution. In [4], I have more fully argued that this is the only solution, if certain plausible
desiderata are to be satisfied. Here, in section 2, I will be content with formally defining and intuitively
explaining my proposal. I will compare my proposal with probability theory in section 3. It will
turn out that the theory I am proposing is structurally homomorphic to probability theory in important
respects and that it is thus equally easily implementable, but moreover computationally simpler.
Section 4 contains a very brief comparison with various kinds of logics, in particular conditional
logic, with Shackle's functions of potential surprise and related theories, and with the Dempster
- Shafer theory of belief functions. 