Despite being very successful within the pattern recognition and machine learning community,
graph-based methods are often unusable with many machine learning tools. This is because of the
incompatibility of most of the mathematical operations in graph domain. Graph embedding has been
proposed as a way to tackle these difficulties, which maps graphs to a vector space and makes the standard
machine learning techniques applicable for them. However, it is well known that graph embedding
techniques usually suffer from the loss of structural information. In this paper, given a graph,
we consider its hierarchical structure for mapping it into a vector space. The hierarchical structure
is constructed by topologically clustering the graph nodes, and considering each cluster as a node
in the upper hierarchical level. Once this hierarchical structure of graph is constructed, we consider
its various configurations of its parts, and use stochastic graphlet embedding (SGE) for mapping
them into vector space. Broadly speaking, SGE produces a distribution of uniformly sampled low
to high order graphlets as a way to embed graphs into the vector space. In what follows, the coarse-to-fine
structure of a graph hierarchy and the statistics fetched through the distribution of low to high
order stochastic graphlets complements each other and include important structural information
with varied contexts. Altogether, these two techniques substantially cope with the usual information
loss involved in graph embedding techniques, and it is not a surprise that we obtain more robust vector
space embedding of graphs. This fact has been corroborated through a detailed experimental evaluation
on various benchmark graph datasets, where we outperform the state-of-the-art methods. 