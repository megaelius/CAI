In systems of programmable matter, we are given a collection of simple computation elements (or
particles) with limited (constant-size) memory. We are interested in when they can self-organize
to solve system-wide problems of movement, configuration and coordination. Here, we initiate
a stochastic approach to developing robust distributed algorithms for programmable matter systems
using Markov chains. We are able to leverage the wealth of prior work in Markov chains and related
areas to design and rigorously analyze our distributed algorithms and show that they have several
desirable properties. We study the compression problem, in which a particle system must gather
as tightly together as possible, as in a sphere or its equivalent in the presence of some underlying
geometry. More specifically, we seek fully distributed, local, and asynchronous algorithms that
lead the system to converge to a configuration with small boundary. We present a Markov chain-based
algorithm that solves the compression problem under the geometric amoebot model, for particle
systems that begin in a connected configuration. The algorithm takes as input a bias parameter $\lambda$,
where $\lambda > 1$ corresponds to particles favoring having more neighbors. We show that for all
$\lambda > 2+\sqrt{2}$, there is a constant $\alpha > 1$ such that eventually with all but exponentially
small probability the particles are $\alpha$-compressed, meaning the perimeter of the system
configuration is at most $\alpha \cdot p_{min}$, where $p_{min}$ is the minimum possible perimeter
of the particle system. Surprisingly, the same algorithm can also be used for expansion when $0 <
\lambda < 2.17$, and we prove similar results about expansion for values of $\lambda$ in this range.
This is counterintuitive as it shows that particles preferring to be next to each other ($\lambda
> 1$) is not sufficient to guarantee compression. 