Due to the complexity of the natural world, a programmer cannot foresee all possible situations
a connected and autonomous vehicle (CAV) will face during its operation, and hence, CAVs will need
to learn to make decisions autonomously. Due to the sensing of its surroundings and information
exchanged with other vehicles and road infrastructure a CAV will have access to large amounts of
useful data. While different control algorithms have been proposed for CAVs, the benefits brought
about by connectedness of autonomous vehicles to other vehicles and to the infrastructure, and
its implications on policy learning has not been investigated in literature. This paper investigates
a data driven driving policy learning framework through an agent-based modelling approaches.
The contributions of the paper are two-fold. A dynamic programming framework is proposed for in-vehicle
policy learning with and without connectivity to neighboring vehicles. The simulation results
indicate that while a CAV can learn to make autonomous decisions, vehicle-to-vehicle (V2V) communication
of information improves this capability. Furthermore, to overcome the limitations of sensing
in a CAV, the paper proposes a novel concept for infrastructure-led policy learning and communication
with autonomous vehicles. In infrastructure-led policy learning, road-side infrastructure
senses and captures successful vehicle maneuvers and learns an optimal policy from those temporal
sequences, and when a vehicle approaches the road-side unit, the policy is communicated to the CAV.
Deep-imitation learning methodology is proposed to develop such an infrastructure-led policy
learning framework. 