The sharp and recent increase in the availability of data captured by different sensors combined
with their considerably heterogeneous natures poses a serious challenge for the effective and
efficient processing of remotely sensed data. Such an increase in remote sensing and ancillary
datasets, however, opens up the possibility of utilizing multimodal datasets in a joint manner
to further improve the performance of the processing approaches with respect to the application
at hand. Multisource data fusion has, therefore, received enormous attention from researchers
worldwide for a wide variety of applications. Moreover, thanks to the revisit capability of several
spaceborne sensors, the integration of the temporal information with the spatial and/or spectral/backscattering
information of the remotely sensed data is possible and helps to move from a representation of 2D/3D
data to 4D data structures, where the time variable adds new information as well as challenges for
the information extraction algorithms. There are a huge number of research works dedicated to multisource
and multitemporal data fusion, but the methods for the fusion of different modalities have expanded
in different paths according to each research community. This paper brings together the advances
of multisource and multitemporal data fusion approaches with respect to different research communities
and provides a thorough and discipline-specific starting point for researchers at different levels
(i.e., students, researchers, and senior researchers) willing to conduct novel investigations
on this challenging topic by supplying sufficient detail and references. 