We present an active learning architecture that allows a robot to actively learn which data collection
strategy is most efficient for acquiring motor skills to achieve multiple outcomes, and generalise
over its experience to achieve new outcomes. The robot explores its environment both via interactive
learning and goal-babbling. It learns at the same time when, who and what to actively imitate from
several available teachers, and learns when not to use social guidance but use active goal-oriented
self-exploration. This is formalised in the framework of life-long strategic learning. The proposed
architecture, called Socially Guided Intrinsic Motivation with Active Choice of Teacher and Strategy
(SGIM-ACTS), relies on hierarchical active decisions of what and how to learn driven by empirical
evaluation of learning progress for each learning strategy. We illustrate with an experiment where
a simulated robot learns to control its arm for realising two kinds of different outcomes. It has
to choose actively and hierarchically at each learning episode: 1) what to learn: which outcome
is most interesting to select as a goal to focus on for goal-directed exploration; 2) how to learn:
which data collection strategy to use among self-exploration, mimicry and emulation; 3) once he
has decided when and what to imitate by choosing mimicry or emulation, then he has to choose who to
imitate, from a set of different teachers. We show that SGIM-ACTS learns significantly more efficiently
than using single learning strategies, and coherently selects the best strategy with respect to
the chosen outcome, taking advantage of the available teachers (with different levels of skills).
