Online marketplaces often witness opinion spam in the form of reviews. People are often hired to
target specific brands for promoting or impeding them by writing highly positive or negative reviews.
This often is done collectively in groups. Although some previous studies attempted to identify
and analyze such opinion spam groups, little has been explored to spot those groups who target a brand
as a whole, instead of just products. In this paper, we collected reviews from the Amazon product
review site and manually labelled a set of 923 candidate reviewer groups. The groups are extracted
using frequent itemset mining over brand similarities such that users are clustered together if
they have mutually reviewed (products of) a lot of brands. We hypothesize that the nature of the reviewer
groups is dependent on 8 features specific to a (group, brand) pair. We develop a feature-based supervised
model to classify candidate groups as extremist entities. We run multiple classifiers for the task
of classifying a group based on the reviews written by the users of that group, to determine if the
group shows signs of extremity. A 3-layer Perceptron based classifier turns out to be the best classifier.
We further study the behaviours of such groups in detail to understand the dynamics of brand-level
opinion fraud better. These behaviours include consistency in ratings, review sentiment, verified
purchase, review dates and helpful votes received on reviews. Surprisingly, we observe that there
are a lot of verified reviewers showing extreme sentiment, which on further investigation leads
to ways to circumvent existing mechanisms in place to prevent unofficial incentives on Amazon.
