Due to its potential wide applications in video surveillance and other computer vision tasks like
tracking, person re-identification (ReID) has become popular and been widely investigated. However,
conventional person re-identification can only handle RGB color images, which will fail at dark
conditions. Thus RGB-infrared ReID (also known as Infrared-Visible ReID or Visible-Thermal ReID)
is proposed. Apart from appearance discrepancy in traditional ReID caused by illumination, pose
variations and viewpoint changes, modality discrepancy produced by cameras of the different spectrum
also exists, which makes RGB-infrared ReID more difficult. To address this problem, we focus on
extracting the shared cross-spectrum features of different modalities. In this paper, a novel
multi-spectrum image generation method is proposed and the generated samples are utilized to help
the network to find discriminative information for re-identifying the same person across modalities.
Another challenge of RGB-infrared ReID is that the intra-person (images from the same person) discrepancy
is often larger than the inter-person (images from different persons) discrepancy, so a dual-subspace
pairing strategy is proposed to alleviate this problem. Combining those two parts together, we
also design a one-stream neural network combining the aforementioned methods to extract compact
representations of person images, called Cross-spectrum Dual-subspace Pairing (CDP) model.
Furthermore, during the training process, we also propose a Dynamic Hard Spectrum Mining method
to automatically mine more hard samples from hard spectrum based on the current model state to further
boost the performance. Extensive experimental results on two public datasets, SYSU-MM01 with
RGB + near-infrared images and RegDB with RGB + far-infrared images, have demonstrated the efficiency
and generality of our proposed method. 