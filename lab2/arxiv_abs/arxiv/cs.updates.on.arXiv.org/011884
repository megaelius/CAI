Achieving robust multi-person 2D body landmark localization and pose estimation is essential
for human behavior and interaction understanding as encountered for instance in HRI settings.
Accurate methods have been proposed recently, but they usually rely on rather deep Convolutional
Neural Network (CNN) architecture, thus requiring large computational and training resources.
In this paper, we investigate different architectures and methodologies to address these issues
and achieve fast and accurate multi-person 2D pose estimation. To foster speed, we propose to work
with depth images, whose structure contains sufficient information about body landmarks while
being simpler than textured color images and thus potentially requiring less complex CNNs for processing.
In this context, we make the following contributions. i) we study several CNN architecture designs
combining pose machines relying on the cascade of detectors concept with lightweight and efficient
CNN structures; ii) to address the need for large training datasets with high variability, we rely
on semi-synthetic data combining multi-person synthetic depth data with real sensor backgrounds;
iii) we explore domain adaptation techniques to address the performance gap introduced by testing
on real depth images; iv) to increase the accuracy of our fast lightweight CNN models, we investigate
knowledge distillation at several architecture levels which effectively enhance performance.
Experiments and results on synthetic and real data highlight the impact of our design choices, providing
insights into methods addressing standard issues normally faced in practical applications, and
resulting in architectures effectively matching our goal in both performance and speed. 