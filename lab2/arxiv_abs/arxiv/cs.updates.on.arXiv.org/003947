Spatial misalignment caused by variations in poses and viewpoints is one of the most critical issues
that hinders the performance improvement in existing person re-identification (Re-ID) algorithms.
To address this problem, in this paper, we present a robust and efficient graph correspondence transfer
(REGCT) approach for explicit spatial alignment in Re-ID. Specifically, we propose to establish
the patch-wise correspondences of positive training pairs via graph matching. By exploiting both
spatial and visual contexts of human appearance in graph matching, meaningful semantic correspondences
can be obtained. To circumvent the cumbersome \emph{on-line} graph matching in testing phase,
we propose to transfer the \emph{off-line} learned patch-wise correspondences from the positive
training pairs to test pairs. In detail, for each test pair, the training pairs with similar pose-pair
configurations are selected as references. The matching patterns (i.e., the correspondences)
of the selected references are then utilized to calculate the patch-wise feature distances of this
test pair. To enhance the robustness of correspondence transfer, we design a novel pose context
descriptor to accurately model human body configurations, and present an approach to measure the
similarity between a pair of pose context descriptors. Meanwhile, to improve testing efficiency,
we propose a correspondence template ensemble method using the voting mechanism, which significantly
reduces the amount of patch-wise matchings involved in distance calculation. With aforementioned
strategies, the REGCT model can effectively and efficiently handle the spatial misalignment problem
in Re-ID. Extensive experiments on five challenging benchmarks, including VIPeR, Road, PRID450S,
3DPES and CUHK01, evidence the superior performance of REGCT over other state-of-the-art approaches.
