Edge computing and distributed machine learning have advanced to a level that can revolutionize
a particular organization. Distributed devices such as the Internet of Things (IoT) often produce
a large amount of data, eventually resulting in big data that can be vital in uncovering hidden patterns,
and other insights in numerous fields such as healthcare, banking, and policing. Data related to
areas such as healthcare and banking can contain potentially sensitive data that can become public
if they are not appropriately sanitized. Federated learning (FedML) is a recently developed distributed
machine learning (DML) approach that tries to preserve privacy by bringing the learning of an ML
model to data owners'. However, literature shows different attack methods such as membership inference
that exploit the vulnerabilities of ML models as well as the coordinating servers to retrieve private
data. Hence, FedML needs additional measures to guarantee data privacy. Furthermore, big data
often requires more resources than available in a standard computer. This paper addresses these
issues by proposing a distributed perturbation algorithm named as DISTPAB, for privacy preservation
of horizontally partitioned data. DISTPAB alleviates computational bottlenecks by distributing
the task of privacy preservation utilizing the asymmetry of resources of a distributed environment,
which can have resource-constrained devices as well as high-performance computers. Experiments
show that DISTPAB provides high accuracy, high efficiency, high scalability, and high attack resistance.
Further experiments on privacy-preserving FedML show that DISTPAB is an excellent solution to
stop privacy leaks in DML while preserving high data utility. 