Person re-identification (re-id) aims to match pedestrians observed by disjoint camera views.
It attracts increasing attention in computer vision due to its importance to surveillance system.
To combat the major challenge of cross-view visual variations, deep embedding approaches are proposed
by learning a compact feature space from images such that the Euclidean distances correspond to
their cross-view similarity metric. However, the global Euclidean distance cannot faithfully
characterize the ideal similarity in a complex visual feature space because features of pedestrian
images exhibit unknown distributions due to large variations in poses, illumination and occlusion.
Moreover, intra-personal training samples within a local range are robust to guide deep embedding
against uncontrolled variations, which however, cannot be captured by a global Euclidean distance.
In this paper, we study the problem of person re-id by proposing a novel sampling to mine suitable
\textit{positives} (i.e. intra-class) within a local range to improve the deep embedding in the
context of large intra-class variations. Our method is capable of learning a deep similarity metric
adaptive to local sample structure by minimizing each sample's local distances while propagating
through the relationship between samples to attain the whole intra-class minimization. To this
end, a novel objective function is proposed to jointly optimize similarity metric learning, local
positive mining and robust deep embedding. This yields local discriminations by selecting local-ranged
positive samples, and the learned features are robust to dramatic intra-class variations. Experiments
on benchmarks show state-of-the-art results achieved by our method. 