Deep learning based models have excelled in many computer vision task and appear to surpass humans
performance. However, these models require an avalanche of expensive human labeled training data
and many iterations to train their large number of parameters. This severely limits their scalability
to the real-world long-tail distributed categories. Learning from such extremely limited labeled
examples is known as Few-shot learning. Different to prior arts that leverage meta-learning or
data augmentation strategies to alleviate this extremely data-scarce problem, this paper presents
a statistical approach, dubbed Instance Credibility Inference to exploit the support of unlabeled
instances for few-shot visual recognition. Typically, we repurpose the self-taught learning
paradigm. To do so, we construct a (Generalized) Linear Model (LM/GLM) with incidental parameters
to model the mapping from (un-)labeled features to their (pseudo-)labels, in which the sparsity
of the incidental parameters indicates the credibility of corresponding pseudo-labeled instance.
We rank the credibility of pseudo-labels of unlabeled instances along the regularization path
of their corresponding incidental parameters, and the most trustworthy pseudo-labeled examples
are preserved as the augmented labeled instances.This process is repeated until all the unlabeled
samples are iteratively included in the expanded training set. Theoretically, under mild conditions
of restricted eigenvalue, irrepresentability, and large error, our approach is guaranteed to
collect all the correctly-predicted pseudo-labeled instances from the noisy pseudo-labeled
set. Extensive experiments under two few-shot settings show that our approach can establish new
state of the art on four widely used few-shot visual recognition benchmark datasets including miniImageNet,
tieredImageNet, CIFAR-FS, and CUB. 