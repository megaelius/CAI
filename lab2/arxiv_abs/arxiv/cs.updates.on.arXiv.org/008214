We introduce REPRISE, a REtrospective and PRospective Inference SchEme, which learns temporal
event-predictive models of dynamical systems. REPRISE infers the unobservable contextual event
state and accompanying temporal predictive models that best explain the recently encountered
sensorimotor experiences retrospectively. Meanwhile, it optimizes upcoming motor activities
prospectively in a goal-directed manner. Here, REPRISE is implemented by a recurrent neural network
(RNN), which learns temporal forward models of the sensorimotor contingencies generated by different
simulated dynamic vehicles. The RNN is augmented with contextual neurons, which enable the encoding
of distinct, but related, sensorimotor dynamics as compact event codes. We show that REPRISE concurrently
learns to separate and approximate the encountered sensorimotor dynamics: it analyzes sensorimotor
error signals adapting both internal contextual neural activities and connection weight values.
Moreover, we show that REPRISE can exploit the learned model to induce goal-directed, model-predictive
control, that is, approximate active inference: Given a goal state, the system imagines a motor
command sequence optimizing it with the prospective objective to minimize the distance to the goal.
The RNN activities thus continuously imagine the upcoming future and reflect on the recent past,
optimizing the predictive model, the hidden neural state activities, and the upcoming motor activities.
As a result, event-predictive neural encodings develop, which allow the invocation of highly effective
and adaptive goal-directed sensorimotor control. 