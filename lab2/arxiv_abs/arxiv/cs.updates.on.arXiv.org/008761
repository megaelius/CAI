Auto-encoders are among the most popular neural network architecture for dimension reduction.
They are composed of two parts: the encoder which maps the model distribution to a latent manifold
and the decoder which maps the latent manifold to a reconstructed distribution. However, auto-encoders
are known to provoke chaotically scattered data distribution in the latent manifold resulting
in an incomplete reconstructed distribution. Current distance measures fail to detect this problem
because they are not able to acknowledge the shape of the data manifolds, i.e. their topological
features, and the scale at which the manifolds should be analyzed. We propose Persistent Homology
for Wasserstein Auto-Encoders, called PHom-WAE, a new methodology to assess and measure the data
distribution of a generative model. PHom-WAE minimizes the Wasserstein distance between the true
distribution and the reconstructed distribution and uses persistent homology, the study of the
topological features of a space at different spatial resolutions, to compare the nature of the latent
manifold and the reconstructed distribution. Our experiments underline the potential of persistent
homology for Wasserstein Auto-Encoders in comparison to Variational Auto-Encoders, another
type of generative model. The experiments are conducted on a real-world data set particularly challenging
for traditional distance measures and auto-encoders. PHom-WAE is the first methodology to propose
a topological distance measure, the bottleneck distance, for Wasserstein Auto-Encoders used
to compare decoded samples of high quality in the context of credit card transactions. 