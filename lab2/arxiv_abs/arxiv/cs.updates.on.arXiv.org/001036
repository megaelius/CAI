There is an increasing demand to make data "open" to third parties, as data sharing has great benefits
in data-driven decision making. However, with a wide variety of sensitive data collected, protecting
privacy of individuals, communities and organizations, is an essential factor in making data "open".
The approaches currently adopted by industry in releasing private data are often ad hoc and prone
to a number of attacks, including re-identification attacks, as they do not provide adequate privacy
guarantees. While differential privacy has attracted significant interest from academia and
industry by providing rigorous and reliable privacy guarantees, the reduced utility and inflexibility
of current differentially private algorithms for data release is a barrier to their use in real-life.
This paper aims to address these two challenges. First, we propose a novel mechanism to augment the
conventional utility of differential privacy by fusing two Laplace or geometric distributions
together. We derive closed form expressions for entropy, variance of added noise, and absolute
expectation of noise for the proposed piecewise mixtures. Then the relevant distributions are
utilised to theoretically prove the privacy and accuracy guarantees of the proposed mechanisms.
Second, we show that our proposed mechanisms have greater flexibility, with three parameters to
adjust, giving better utility in bounding noise, and mitigating larger inaccuracy, in comparison
to typical one-parameter differentially private mechanisms. We then empirically evaluate the
performance of piecewise mixture distributions with extensive simulations and with a real-world
dataset for both linear count queries and histogram queries. The empirical results show an increase
in all utility measures considered, while maintaining privacy, for the piecewise mixture mechanisms
compared to standard Laplace or geometric mechanisms. 