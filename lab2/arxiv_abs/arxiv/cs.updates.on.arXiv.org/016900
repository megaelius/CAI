A practical deep neural network's (DNN) evaluation involves thousands of multiply-and-accumulate
(MAC) operations. To extend DNN's superior inference capabilities to energy constrained devices,
architectures and circuits that minimize energy-per-MAC must be developed. In this respect, analog
delay-based MAC is advantageous due to reasons both extrinsic and intrinsic to the MAC implementation
$-$ (1) lower fixed-point precision (1-8 bits) requirement in a DNN's evaluation, (2) better dynamic
range than charge-based accumulation for smaller technology nodes and (3) simpler analog-digital
interfaces. Implementing DNNs using delay-based MAC requires mixed-signal delay multipliers
that accept digitally stored weights and analog voltages as arguments. To this end, a novel, linearly
tune-able delay-cell is proposed, wherein, the delay is realized with an inverted MOS capacitor
($C^*$) steadily discharged from a linearly input-voltage dependent initial charge. The cell
is analytically modeled, constraints for its functional validity are determined, and jitter-models
are developed. Multiple cells with scaled delays, corresponding to each bit of the digital argument,
must be cascaded to form the multiplier. To realize such bit-wise delay-scaling of the cells, a biasing
circuit is proposed that generates sub-threshold gate-voltages to scale $C^*$'s discharging
rate, and thus area-expensive transistor width-scaling is avoided. On applying the constraints
and jitter models to 130nm technology, the minimum optimal $C^*$ was found to be 2 fF and maximum number
of bits to be 5. Schematic-level simulations show a worst case energy-consumption close to the state-of-art,
and thus, feasibility of the cell. 