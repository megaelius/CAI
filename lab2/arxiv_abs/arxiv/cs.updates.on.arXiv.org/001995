Traffic prediction plays an important role in evaluating the performance of telecommunication
networks and attracts intense research interests. A significant number of algorithms and models
have been proposed to learn knowledge from traffic data and improve the prediction accuracy. In
the recent big data era, the relevant research enthusiasm remains and deep learning has been exploited
to extract the useful information in depth. In particular, Long Short-Term Memory (LSTM), one kind
of Recurrent Neural Network (RNN) schemes, has attracted significant attentions due to the long-range
dependency embedded in the sequential traffic data. However, LSTM has considerable computational
cost, which can not be tolerated in tasks with stringent latency requirement. In this paper, we propose
a deep learning model based on LSTM, called Random Connectivity LSTM (RCLSTM). Compared to the conventional
LSTM, RCLSTM achieves a significant breakthrough in the architecture formation of neural network,
whose connectivity is determined in a stochastic manner rather than full connected. So, the neural
network in RCLSTM can exhibit certain sparsity, which means many neural connections are absent
(distinguished from the full connectivity) and thus the number of parameters to be trained is reduced
and much fewer computations are required. We apply the RCLSTM solution to predict traffic and validate
that the RCLSTM with even 35% neural connectivity still shows a strong capability in traffic prediction.
Also, along with increasing the number of training samples, the performance of RCLSTM becomes closer
to the conventional LSTM. Moreover, the RCLSTM exhibits even superior prediction accuracy than
the conventional LSTM when the length of input traffic sequences increases. 