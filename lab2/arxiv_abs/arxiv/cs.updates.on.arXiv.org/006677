In this paper, a spintronic neuromorphic reconfigurable Array (SNRA) is developed to fuse together
power-efficient probabilistic and in-field programmable deterministic computing during both
training and evaluation phases of restricted Boltzmann machines (RBMs). First, probabilistic
spin logic devices are used to develop an RBM realization which is adapted to construct deep belief
networks (DBNs) having one to three hidden layers of size 10 to 800 neurons each. Second, we design
a hardware implementation for the contrastive divergence (CD) algorithm using a four-state finite
state machine capable of unsupervised training in N+3 clocks where N denotes the number of neurons
in each RBM. The functionality of our proposed CD hardware implementation is validated using ModelSim
simulations. We synthesize the developed Verilog HDL implementation of our proposed test/train
control circuitry for various DBN topologies where the maximal RBM dimensions yield resource utilization
ranging from 51 to 2,421 lookup tables (LUTs). Next, we leverage spin Hall effect (SHE)-magnetic
tunnel junction (MTJ) based non-volatile LUTs circuits as an alternative for static random access
memory (SRAM)-based LUTs storing the deterministic logic configuration to form a reconfigurable
fabric. Finally, we compare the performance of our proposed SNRA with SRAM-based configurable
fabrics focusing on the area and power consumption induced by the LUTs used to implement both CD and
evaluation modes. The results obtained indicate more than 80% reduction in combined dynamic and
static power dissipation, while achieving at least 50% reduction in device count. 