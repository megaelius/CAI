Building natural language interfaces for databases has been a long-standing challenge for several
decades. The major advantage of these so-called text-to-SQL systems is that end-users can query
complex databases without the need to know SQL or the underlying database schema. Due to significant
advancements in machine learning, the recent focus of research has been on neural networks to tackle
this challenge on complex datasets like Spider. Several recent text-to-SQL systems achieve promising
results on this dataset. However, none of them extracts and incorporates values from the user questions
for generating SQL statements. Thus, the practical use of these systems in a real-world scenario
has not been sufficiently demonstrated yet. In this paper we propose ValueNet light and ValueNet
-- the first end-to-end text-to-SQL system incorporating values on the challenging Spider dataset.
The main idea of our approach is to use not only metadata information about the underlying database
but also information on the base data as input for our neural network architecture. In particular,
we propose a novel architecture sketch to extract values from a user question and come up with possible
value candidates which are not explicitly mentioned in the question. We then use a neural model based
on an encoder-decoder architecture to synthesize the SQL query. Finally, we evaluate our model
on the Spider challenge using the Execution Accuracy metric, a more difficult metric than used by
most participants of the challenge. Our experimental evaluation demonstrates that ValueNet light
and ValueNet reach state-of-the-art results of 64% and 60% accuracy, respectively, for translating
from text to SQL, even when applying this more difficult metric than used by previous work. 