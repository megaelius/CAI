Refractive error, one of the leading cause of visual impairment, can be corrected by simple interventions
like prescribing eyeglasses. We trained a deep learning algorithm to predict refractive error
from the fundus photographs from participants in the UK Biobank cohort, which were 45 degree field
of view images and the AREDS clinical trial, which contained 30 degree field of view images. Our model
use the "attention" method to identify features that are correlated with refractive error. Mean
absolute error (MAE) of the algorithm's prediction compared to the refractive error obtained in
the AREDS and UK Biobank. The resulting algorithm had a MAE of 0.56 diopters (95% CI: 0.55-0.56) for
estimating spherical equivalent on the UK Biobank dataset and 0.91 diopters (95% CI: 0.89-0.92)
for the AREDS dataset. The baseline expected MAE (obtained by simply predicting the mean of this
population) was 1.81 diopters (95% CI: 1.79-1.84) for UK Biobank and 1.63 (95% CI: 1.60-1.67) for
AREDS. Attention maps suggested that the foveal region was one of the most important areas used by
the algorithm to make this prediction, though other regions also contribute to the prediction.
The ability to estimate refractive error with high accuracy from retinal fundus photos has not been
previously known and demonstrates that deep learning can be applied to make novel predictions from
medical images. Given that several groups have recently shown that it is feasible to obtain retinal
fundus photos using mobile phones and inexpensive attachments, this work may be particularly relevant
in regions of the world where autorefractors may not be readily available. 