Convolutional Neural Networks (CNNs) have been used successfully across a broad range of areas
including data mining, object detection, and in business. The dominance of CNNs follows a breakthrough
by Alex Krizhevsky which showed improvements by dramatically reducing the error rate obtained
in a general image classification task from 26.2% to 15.4%. In road safety, CNNs have been applied
widely to the detection of traffic signs, obstacle detection, and lane departure checking. In addition,
CNNs have been used in data mining systems that monitor driving patterns and recommend rest breaks
when appropriate. This paper presents a driver drowsiness detection system and shows that there
are potential social challenges regarding the application of these techniques, by highlighting
problems in detecting dark-skinned driver's faces. This is a particularly important challenge
in African contexts, where there are more dark-skinned drivers. Unfortunately, publicly available
datasets are often captured in different cultural contexts, and therefore do not cover all ethnicities,
which can lead to false detections or racially biased models. This work evaluates the performance
obtained when training convolutional neural network models on commonly used driver drowsiness
detection datasets and testing on datasets specifically chosen for broader representation. Results
show that models trained using publicly available datasets suffer extensively from over-fitting,
and can exhibit racial bias, as shown by testing on a more representative dataset. We propose a novel
visualisation technique that can assist in identifying groups of people where there might be the
potential of discrimination, using Principal Component Analysis (PCA) to produce a grid of faces
sorted by similarity, and combining these with a model accuracy overlay. 