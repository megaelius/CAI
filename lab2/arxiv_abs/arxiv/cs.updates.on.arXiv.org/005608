There has been renewed recent interest in developing effective lower bounds for Dynamic Time Warping
(DTW) distance between time series. These have many applications in time series indexing, clustering,
forecasting, regression and classification. One of the key time series classification algorithms,
the nearest neighbor algorithm with DTW distance (NN-DTW) is very expensive to compute, due to the
quadratic complexity of DTW. Lower bound search can speed up NN-DTW substantially. An effective
and tight lower bound quickly prunes off unpromising nearest neighbor candidates from the search
space and minimises the number of the costly DTW computations. The speed up provided by lower bound
search becomes increasingly critical as training set size increases. Different lower bounds provide
different trade-offs between computation time and tightness. Most existing lower bounds interact
with DTW warping window sizes. They are very tight and effective at smaller warping window sizes,
but become looser as the warping window increases, thus reducing the pruning effectiveness for
NN-DTW. In this work, we present a new class of lower bounds that are tighter than the popular Keogh
lower bound, while requiring similar computation time. Our new lower bounds take advantage of the
DTW boundary condition, monotonicity and continuity constraints to create a tighter lower bound.
Of particular significance, they remain relatively tight even for large windows. A single parameter
to these new lower bounds controls the speed-tightness trade-off. We demonstrate that these new
lower bounds provide an exceptional balance between computation time and tightness for the NN-DTW
time series classification task, resulting in greatly improved efficiency for NN-DTW lower bound
search. 