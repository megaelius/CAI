On the morning of November 9th 2016, the world woke up to the shocking outcome of the US Presidential
elections: Donald Trump was the 45th President of the United States of America. An unexpected event
that still has tremendous consequences all over the world. Today, we know that a minority of social
bots, automated social media accounts mimicking humans, played a central role in spreading divisive
messages and disinformation, possibly contributing to Trump's victory. In the aftermath of the
2016 US elections, the world started to realize the gravity of widespread deception in social media.
Following Trump's exploit, we witnessed to the emergence of a strident dissonance between the multitude
of efforts for detecting and removing bots, and the increasing effects that these malicious actors
seem to have on our societies. This paradox opens a burning question: What strategies should we enforce
in order to stop this social bot pandemic? In these times, during the run-up to the 2020 US elections,
the question appears as more crucial than ever. What stroke social, political and economic analysts
after 2016, deception and automation, has been however a matter of study for computer scientists
since at least 2010. In this work, we briefly survey the first decade of research in social bot detection.
Via a longitudinal analysis, we discuss the main trends of research in the fight against bots, the
major results that were achieved, and the factors that make this never-ending battle so challenging.
Capitalizing on lessons learned from our extensive analysis, we suggest possible innovations
that could give us the upper hand against deception and manipulation. Studying a decade of endeavours
at social bot detection can also inform strategies for detecting and mitigating the effects of other,
more recent, forms of online deception, such as strategic information operations and political
trolls. 