Artificial Intelligence (AI) has an increasing impact on all areas of people's livelihoods. A detailed
look at existing interdisciplinary and transdisciplinary metrics frameworks could bring new
insights and enable practitioners to navigate the challenge of understanding and assessing the
impact of Autonomous and Intelligent Systems (A/IS). There has been emerging consensus on fundamental
ethical and rights-based AI principles proposed by scholars, governments, civil rights organizations,
and technology companies. In order to move from principles to real-world implementation, we adopt
a lens motivated by regulatory impact assessments and the well-being movement in public policy.
Similar to public policy interventions, outcomes of AI systems implementation may have far-reaching
complex impacts. In public policy, indicators are only part of a broader toolbox, as metrics inherently
lead to gaming and dissolution of incentives and objectives. Similarly, in the case of A/IS, there's
a need for a larger toolbox that allows for the iterative assessment of identified impacts, inclusion
of new impacts in the analysis, and identification of emerging trade-offs. In this paper, we propose
the practical application of an enhanced well-being impact assessment framework for A/IS that
could be employed to address ethical and rights-based normative principles in AI. This process
could enable a human-centered algorithmically-supported approach to the understanding of the
impacts of AI systems. Finally, we propose a new testing infrastructure which would allow for governments,
civil rights organizations, and others, to engage in cooperating with A/IS developers towards
implementation of enhanced well-being impact assessments. 