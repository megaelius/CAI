We study delay of jobs that consist of multiple parallel tasks, which is a critical performance metric
in a wide range of applications such as data file retrieval in coded storage systems and parallel
computing. In this problem, each job is completed only when all of its tasks are completed, so the
delay of a job is the maximum of the delays of its tasks. Despite the wide attention this problem has
received, tight analysis is still largely unknown since analyzing job delay requires characterizing
the complicated correlation among task delays, which is hard to do. We first consider an asymptotic
regime where the number of servers, $n$, goes to infinity, and the number of tasks in a job, $k^{(n)}$,
is allowed to increase with $n$. We establish the asymptotic independence of any $k^{(n)}$ queues
under the condition $k^{(n)} = o(n^{1/4})$. This greatly generalizes the asymptotic-independence
type of results in the literature where asymptotic independence is shown only for a fixed constant
number of queues. As a consequence of our independence result, the job delay converges to the maximum
of independent task delays. We next consider the non-asymptotic regime. Here we prove that independence
yields a stochastic upper bound on job delay for any $n$ and any $k^{(n)}$ with $k^{(n)}\le n$. The
key component of our proof is a new technique we develop, called "Poisson oversampling". Our approach
converts the job delay problem into a corresponding balls-and-bins problem. However, in contrast
with typical balls-and-bins problems where there is a negative correlation among bins, we prove
that our variant exhibits positive correlation. 