People readily generalise prior knowledge to novel situations and stimuli. Advances in machine
learning and artificial intelligence have begun to approximate and even surpass human performance
in specific domains, but machine learning systems struggle to generalise information to untrained
situations. We present and model that demonstrates human-like extrapolatory generalisation
by learning and explicitly representing an open-ended set of relations characterising regularities
within the domains it is exposed to. First, when trained to play one video game (e.g., Breakout).
the model generalises to a new game (e.g., Pong) with different rules, dimensions, and characteristics
in a single shot. Second, the model can learn representations from a different domain (e.g., 3D shape
images) that support learning a video game and generalising to a new game in one shot. By exploiting
well-established principles from cognitive psychology and neuroscience, the model learns structured
representations without feedback, and without requiring knowledge of the relevant relations
to be given a priori. We present additional simulations showing that the representations that the
model learns support cross-domain generalisation. The model's ability to generalise between
different games demonstrates the flexible generalisation afforded by a capacity to learn not only
statistical relations, but also other relations that are useful for characterising the domain
to be learned. In turn, this kind of flexible, relational generalisation is only possible because
the model is capable of representing relations explicitly, a capacity that is notably absent in
extant statistical machine learning algorithms. 