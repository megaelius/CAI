While the strength of Topological Data Analysis has been explored in many studies on high dimensional
numeric data, it is still a challenging task to apply it to text. As the primary goal in topological
data analysis is to define and quantify the shapes in numeric data, defining shapes in the text is
much more challenging, even though the geometries of vector spaces and conceptual spaces are clearly
relevant for information retrieval and semantics. In this paper, we examine two different methods
of extraction of topological features from text, using as the underlying representations of words
the two most popular methods, namely word embeddings and TF-IDF vectors. To extract topological
features from the word embedding space, we interpret the embedding of a text document as high dimensional
time series, and we analyze the topology of the underlying graph where the vertices correspond to
different embedding dimensions. For topological data analysis with the TF-IDF representations,
we analyze the topology of the graph whose vertices come from the TF-IDF vectors of different blocks
in the textual document. In both cases, we apply homological persistence to reveal the geometric
structures under different distance resolutions. Our results show that these topological features
carry some exclusive information that is not captured by conventional text mining methods. In our
experiments we observe adding topological features to the conventional features in ensemble models
improves the classification results (up to 5\%). On the other hand, as expected, topological features
by themselves may be not sufficient for effective classification. It is an open problem to see whether
TDA features from word embeddings might be sufficient, as they seem to perform within a range of few
points from top results obtained with a linear support vector classifier. 