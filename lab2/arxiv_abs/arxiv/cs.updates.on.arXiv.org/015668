Next generation of embedded Information and Communication Technology (ICT) systems are collaborative
systems able to perform autonomous tasks. The remarkable expansion of the embedded ICT market,
together with the rise and breakthroughs of Artificial Intelligence (AI), have put the focus on
the Edge as it stands as one of the keys for the next technological revolution: the seamless integration
of AI in our daily life. However, training and deployment of custom AI solutions on embedded devices
require a fine-grained integration of data, algorithms, and tools to achieve high accuracy. Such
integration requires a high level of expertise that becomes a real bottleneck for small and medium
enterprises wanting to deploy AI solutions on the Edge which, ultimately, slows down the adoption
of AI on daily-life applications. In this work, we present a modular AI pipeline as an integrating
framework to bring data, algorithms, and deployment tools together. By removing the integration
barriers and lowering the required expertise, we can interconnect the different stages of tools
and provide a modular end-to-end development of AI products for embedded devices. Our AI pipeline
consists of four modular main steps: i) data ingestion, ii) model training, iii) deployment optimization
and, iv) the IoT hub integration. To show the effectiveness of our pipeline, we provide examples
of different AI applications during each of the steps. Besides, we integrate our deployment framework,
LPDNN, into the AI pipeline and present its lightweight architecture and deployment capabilities
for embedded devices. Finally, we demonstrate the results of the AI pipeline by showing the deployment
of several AI applications such as keyword spotting, image classification and object detection
on a set of well-known embedded platforms, where LPDNN consistently outperforms all other popular
deployment frameworks. 