In assessing the severity of age-related macular degeneration (AMD), the Age-Related Eye Disease
Study (AREDS) Simplified Severity Scale predicts the risk of progression to late AMD. However,
its manual use requires the time-consuming participation of expert practitioners. While several
automated deep learning (DL) systems have been developed for classifying color fundus photographs
of individual eyes by AREDS severity score, none to date has utilized a patient-based scoring system
that employs images from both eyes to assign a severity score. DeepSeeNet, a DL model, was developed
to classify patients automatically by the AREDS Simplified Severity Scale (score 0-5) using bilateral
color fundus images. DeepSeeNet was trained on 58,402 and tested on 900 images from the longitudinal
follow up of 4,549 participants from AREDS. Gold standard labels were obtained using reading center
grades. DeepSeeNet simulates the human grading process by first detecting individual AMD risk
factors (drusen size; pigmentary abnormalities) for each eye and then calculating a patient-based
AMD severity score using the AREDS Simplified Severity Scale. DeepSeeNet performed better on patient-based,
multi-class classification (accuracy=0.671; kappa=0.558) than retinal specialists (accuracy=0.599;
kappa=0.467) with high AUCs in the detection of large drusen (0.94), pigmentary abnormalities
(0.93) and late AMD (0.97), respectively. DeepSeeNet demonstrated high accuracy with increased
transparency in the automated assignment of individual patients to AMD risk categories based on
the AREDS Simplified Severity Scale. These results highlight the potential of deep learning systems
to assist and enhance clinical decision-making processes in AMD patients such as early AMD detection
and risk prediction for developing late AMD. DeepSeeNet is publicly available on https://github.com/ncbi-nlp/DeepSeeNet.
