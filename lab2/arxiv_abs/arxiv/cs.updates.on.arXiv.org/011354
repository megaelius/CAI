The performance of face recognition (FR) systems applied in video surveillance has been shown to
improve when the design data is augmented through synthetic face generation. This is true, for instance,
with pair-wise matchers (e.g., deep Siamese networks) that typically rely on a reference gallery
with one still image per individual. However, generating synthetic images in the source domain
may not improve the performance during operations due to the domain shift w.r.t. the target domain.
Moreover, despite the emergence of Generative Adversarial Networks (GANs) for realistic synthetic
generation, it is often difficult to control the conditions under which synthetic faces are generated.
In this paper, a cross-domain face synthesis approach is proposed that integrates a new Controllable
GAN (C-GAN). It employs an off-the-shelf 3D face model as a simulator to generate face images under
various poses. The simulated images and noise are input to the C-GAN for realism refinement which
employs an additional adversarial game as a third player to preserve the identity and specific facial
attributes of the refined images. This allows generating realistic synthetic face images that
reflects capture conditions in the target domain while controlling the GAN output to generate faces
under desired pose conditions. Experiments were performed using videos from the Chokepoint and
COX-S2V datasets, and a deep Siamese network for FR with a single reference still per person. Results
indicate that the proposed approach can provide a higher level of accuracy compared to the current
state-of-the-art approaches for synthetic data augmentation. 