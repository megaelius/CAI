We study the connections between network structure, opinion dynamics, and an adversary's power
to artificially induce disagreements. We approach these questions by extending models of opinion
formation in the social sciences to represent scenarios, familiar from recent events, in which
external actors seek to destabilize communities through sophisticated information warfare tactics
via fake news and bots. In many instances, the intrinsic goals of these efforts are not necessarily
to shift the overall sentiment of the network, but rather to induce discord. These perturbations
diffuse via opinion dynamics on the underlying network, through mechanisms that have been analyzed
and abstracted through work in computer science and the social sciences. We investigate the properties
of such attacks, considering optimal strategies both for the adversary seeking to create disagreement
and for the entities tasked with defending the network from attack. We show that for different formulations
of these types of objectives, different regimes of the spectral structure of the network will limit
the adversary's capacity to sow discord; this enables us to qualitatively describe which networks
are most vulnerable against these perturbations. We then consider the algorithmic task of a network
defender to mitigate these sorts of adversarial attacks by insulating nodes heterogeneously;
we show that, by considering the geometry of this problem, this optimization task can be efficiently
solved via convex programming. Finally, we generalize these results to allow for two network structures,
where the opinion dynamics process and the measurement of disagreement become uncoupled, and determine
how the adversary's power changes; for instance, this may arise when opinion dynamics are controlled
an online community via social media, while disagreement is measured along "real-world" connections.
