Deep learning and convolutional neural networks (CNNs) have made progress in polarimetric synthetic
aperture radar (PolSAR) image classification over the past few years. However, a crucial issue
has not been addressed, i.e., the requirement of CNNs for abundant labeled samples versus the insufficient
human annotations of PolSAR images. It is well-known that following the supervised learning paradigm
may lead to the overfitting of training data, and the lack of supervision information of PolSAR images
undoubtedly aggravates this problem, which greatly affects the generalization performance of
CNN-based classifiers in large-scale applications. To handle this problem, in this paper, learning
transferrable representations from unlabeled PolSAR data through convolutional architectures
is explored for the first time. Specifically, a PolSAR-tailored contrastive learning network
(PCLNet) is proposed for unsupervised deep PolSAR representation learning and few-shot classification.
Different from the utilization of optical processing methods, a diversity stimulation mechanism
is constructed to narrow the application gap between optics and PolSAR. Beyond the conventional
supervised methods, PCLNet develops an auxiliary pre-training phase based on the proxy objective
of contrastive instance discrimination to learn useful representations from unlabeled PolSAR
data. The acquired representations are transferred to the downstream task, i.e., few-shot PolSAR
classification. Experiments on two widely used PolSAR benchmark datasets confirm the validity
of PCLNet. Besides, this work may enlighten how to efficiently utilize the massive unlabeled PolSAR
data to alleviate the greedy demands of CNN-based methods for human annotations. 