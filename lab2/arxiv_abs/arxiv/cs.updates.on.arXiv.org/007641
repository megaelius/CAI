Artificial Intelligence represents many things: a new market to conquer or a quality label for tech
companies, a threat for traditional industries, a menace for democracy, or a blessing for our busy
everyday life. The press abounds in examples illustrating these aspects, but one should draw not
hasty and premature conclusions. The first successes in AI have been a surprise for society at large-including
researchers in the field. Today, after the initial stupefaction, we have examples of the system
reactions: traditional companies are heavily investing in AI, social platforms are monitored
during elections, data collection is more and more regulated, etc. The resilience of an organization
(i.e. its capacity to resist to a shock) relies deeply on the perception of its environment. Future
problems have to be anticipated, while unforeseen events occurring have to be quickly identified
in order to be mitigated as fast as possible. The author states that this clear perception starts
with a common definition of AI in terms of capacities and limits. AI practitioners should make notions
and concepts accessible to the general public and the impacted fields (e.g. industries, law, education).
It is a truism that only law experts would have the potential to estimate IA impacts on judicial system.
However, questions remain on how to connect different kind of expertise and what is the appropriate
level of detail required for the knowledge exchanges. And the same consideration is true for dissemination
towards society. Ultimately, society will live with decisions made by the "experts". It sounds
wise to involve society in the decision process rather than risking to pay consequences later. Therefore,
society also needs the key concepts to understand AI impact on their life. This was the purpose of
the trial of an IA that took place in October 2018 at the Court of Appeal of Paris: gathering experts
from various fields to expose challenges in law and science towards a general public. 