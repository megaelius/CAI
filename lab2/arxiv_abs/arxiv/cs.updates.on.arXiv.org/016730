Computing at the edge offers intriguing possibilities for the development of autonomy and artificial
intelligence. The advancements in autonomous technologies and the resurgence of computer vision
have led to a rise in demand for fast and reliable deep learning applications. In recent years, the
industry has introduced devices with impressive processing power to perform various object detection
tasks. However, with real-time detection, devices are constrained in memory, computational capacity,
and power, which may compromise the overall performance. This could be solved either by optimizing
the object detector or modifying the images. In this paper, we investigate the performance of CNN-based
object detectors on constrained devices when applying different image compression techniques.
We examine the capabilities of a NVIDIA Jetson Nano; a low-power, high-performance computer, with
an integrated GPU, small enough to fit on-board a CubeSat. We take a closer look at the Single Shot
MultiBox Detector (SSD) and Region-based Fully Convolutional Network (R-FCN) that are pre-trained
on DOTA - a Large Scale Dataset for Object Detection in Aerial Images. The performance is measured
in terms of inference time, memory consumption, and accuracy. By applying image compression techniques,
we are able to optimize performance. The two techniques applied, lossless compression and image
scaling, improves speed and memory consumption with no or little change in accuracy. The image scaling
technique achieves a 100% runnable dataset and we suggest combining both techniques in order to
optimize the speed/memory/accuracy trade-off. 