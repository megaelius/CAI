Designing problems using matrices is very important in Computer Science. Fields like graph computer,
graphs theory, and machine learning use matrices very often to solve their own problems. The most
often matrix operation is the multiplication. It may be time-consuming if the matrices to be multiplied
are large. For this reason, the parallel computer became a must to tackle this problem. In this report,
it is presented a comparison between sequential and parallel approaches to computing the matrix
multiplication using CUDA and openMP. The results show the importance of parallelizing mainly
when the matrices are large. A modelagem de problemas utilizando matrizes \'e de extrema import\^ancia
para Ci\^encia da Computa\c{c}\~ao. \'Areas como computa\c{c}\~ao gr\'afica, grafos e aprendizado
de m\'aquina utilizam matrizes com alta frequ\^encia para solucionar seus respectivos problemas.
Dessa forma, operar matrizes de maneira eficiente \'e muito importante para o desempenho de algoritmos.
Uma das opera\c{c}\~oes de matrizes mais utilizadas \'e a multiplica\c{c}\~ao, que se torna um
empecilho para o desempenho computacional de algoritmos na medida que o tamanho das matrizes a serem
multiplicadas aumentam. Por conta disso, a computa\c{c}\~ao paralela se tornou uma solu\c{c}\~ao
padr\~ao para abordar tal problema. Neste trabalho \'e apresentado uma compara\c{c}\~ao entre
as abordagens sequencial e paralela para multiplica\c{c}\~ao de matrizes utilizando CUDA e OpenMP.
O resultado da an\'alise realizada entre o tamanho da matriz e o desempenho da multiplica\c{c}\~ao
mostra a import\^ancia da paraleliza\c{c}\~ao principalmente para matrizes de ordem elevada.
