Fundamental frequency is one of the most important characteristics of speech and audio signals.
Harmonic model-based fundamental frequency estimators offer a higher estimation accuracy and
robustness against noise than the widely used autocorrelation-based methods. However, the traditional
harmonic model-based estimators do not take the temporal smoothness of the fundamental frequency,
the model order, and the voicing into account as they process each data segment independently. In
this paper, a fully Bayesian fundamental frequency tracking algorithm based on the harmonic model
and a first-order Markov process model is proposed. Smoothness priors are imposed on the fundamental
frequencies, model orders, and voicing using first-order Markov process models. Using these Markov
models, fundamental frequency estimation and voicing detection errors can be reduced. Using the
harmonic model, the proposed fundamental frequency tracker has an improved robustness to noise.
An analytical form of the likelihood function, which can be computed efficiently, is derived. Compared
to the state-of-the-art neural network and non-parametric approaches, the proposed fundamental
frequency tracking algorithm reduces the mean absolute errors and gross errors by 15\% and 20\%
on the Keele pitch database and 36\% and 26\% on sustained /a/ sounds from a database of Parkinson's
disease voices under 0 dB white Gaussian noise. A MATLAB version of the proposed algorithm is made
freely available for reproduction of the results\footnote{An implementation of the proposed
algorithm using MATLAB may be found in \url{https://tinyurl.com/yxn4a543} 