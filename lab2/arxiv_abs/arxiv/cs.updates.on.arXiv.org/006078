Solving analytics inside the database is of great practical importance as it avoids the costly repeated
loop data scientists have to deal with on a daily basis: select features from data residing in relational
databases using feature extraction queries involving joins, projections, and aggregations;
export the training dataset defined by such queries; convert this dataset into the format of an external
learning tool; and train the desired model using this tool. These in-database analytics problems
are also a fertile ground of theoretically fundamental and challenging problems at the intersection
of relational and statistical data models. This article introduces a unified framework for training
and evaluating a class of statistical learning models inside a relational database. This class
includes ridge linear regression, polynomial regression, factorization machines, and principal
component analysis. We show that, by synergizing key tools from relational database theory such
as schema information, query structure, functional dependencies, recent advances in query evaluation
algorithms, and from linear algebra such as various tensor and matrix operations, one can formulate
in-database analytics problems and design efficient algorithms to solve them. This theoretical
development informed the design and implementation of the AC/DC system for in-database learning.
We benchmark the performance of AC/DC against R, MADlib, libFM, and TensorFlow. For typical retail
forecasting and advertisement planning applications, AC/DC can learn polynomial regression
models and factorization machines up to three orders of magnitude faster than its competitors whenever
they do not run out of memory, exceed 24-hour timeout, or encounter internal design limitations.
