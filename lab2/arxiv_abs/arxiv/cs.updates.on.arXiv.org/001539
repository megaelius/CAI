We propose an automatic unsupervised cell event detection and classification method, which expands
convolutional Long Short-Term Memory (LSTM) neural networks, for cellular events in cell video
sequences. Cells in images that are captured from various biomedical applications usually have
different shapes and motility, which pose difficulties for the automated event detection in cell
videos. Current methods to detect cellular events are based on supervised machine learning and
rely on tedious manual annotation from investigators with specific expertise. So that our LSTM
network could be trained in an unsupervised manner, we designed it with a branched structure where
one branch learns the frequent, regular appearance and movements of objects and the second learns
the stochastic events, which occur rarely and without warning in a cell video sequence. We tested
our network on a publicly available dataset of densely packed stem cell phase-contrast microscopy
images undergoing cell division. This dataset is considered to be more challenging that a dataset
with sparse cells. We compared our method to several published supervised methods evaluated on
the same dataset and to a supervised LSTM method with a similar design and configuration to our unsupervised
method. We used an F1-score, which is a balanced measure for both precision and recall. Our results
show that our unsupervised method has a higher or similar F1-score when compared to two fully supervised
methods that are based on Hidden Conditional Random Fields (HCRF), and has comparable accuracy
with the current best supervised HCRF-based method. Our method was generalizable as after being
trained on one video it could be applied to videos where the cells were in different conditions. The
accuracy of our unsupervised method approached that of its supervised counterpart. 