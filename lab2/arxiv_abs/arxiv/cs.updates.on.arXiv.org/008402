Urban wastewater sector is being pushed to optimize processes in order to reduce energy consumption
without compromising its quality standards. Energy costs can represent a significant share of
the global operational costs (between 50% and 60%) in an intensive energy consumer. Pumping is the
largest consumer of electrical energy in a wastewater treatment plant. Thus, the optimal control
of pump units can help the utilities to decrease operational costs. This work describes an innovative
predictive control policy for wastewater variable-frequency pumps that minimize electrical
energy consumption, considering uncertainty forecasts for wastewater intake rate and information
collected by sensors accessible through the Supervisory Control and Data Acquisition system.
The proposed control method combines statistical learning (regression and predictive models)
and deep reinforcement learning (Proximal Policy Optimization). The following main original
contributions are produced: i) model-free and data-driven predictive control; ii) control philosophy
focused on operating the tank with a variable wastewater set-point level; iii) use of supervised
learning to generate synthetic data for pre-training the reinforcement learning policy, without
the need to physically interact with the system. The results for a real case-study during 90 days
show a 16.7% decrease in electrical energy consumption while still achieving a 97% reduction in
the number of alarms (tank level above 7.2 meters) when compared with the current operating scenario
(operating with a fixed set-point level). The numerical analysis showed that the proposed data-driven
method is able to explore the trade-off between number of alarms and consumption minimization,
offering different options to decision-makers. 