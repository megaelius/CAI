Current `dry lab' surgical phantom simulators are a valuable tool for surgeons which allows them
to improve their dexterity and skill with surgical instruments. These phantoms mimic the haptic
and shape of organs of interest, but lack a realistic visual appearance. In this work, we present
an innovative application in which representations learned from real intraoperative endoscopic
sequences are transferred to a surgical phantom scenario. The term hyperrealism is introduced
in this field, which we regard as a novel subform of surgical augmented reality for approaches that
involve real-time object transfigurations. For related tasks in the computer vision community,
unpaired cycle-consistent Generative Adversarial Networks (GANs) have shown excellent results
on still RGB images. Though, application of this approach to continuous video frames can result
in flickering, which turned out to be especially prominent for this application. Therefore, we
propose an extension of cycle-consistent GANs, named tempCycleGAN, to improve temporal consistency.The
novel method is evaluated on captures of a silicone phantom for training endoscopic reconstructive
mitral valve procedures. Synthesized videos show highly realistic results with regard to 1) replacement
of the silicone appearance of the phantom valve by intraoperative tissue texture, while 2) explicitly
keeping crucial features in the scene, such as instruments, sutures and prostheses. Compared to
the original CycleGAN approach, tempCycleGAN efficiently removes flickering between frames.
The overall approach is expected to change the future design of surgical training simulators since
the generated sequences clearly demonstrate the feasibility to enable a considerably more realistic
training experience for minimally-invasive procedures. 