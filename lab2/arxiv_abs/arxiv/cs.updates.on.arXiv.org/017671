Accurate and automated tumor segmentation is highly desired since it has the great potential to
increase the efficiency and reproducibility of computing more complete tumor measurements and
imaging biomarkers, comparing to (often partial) human measurements. This is probably the only
viable means to enable the large-scale clinical oncology patient studies that utilize medical
imaging. Deep learning approaches have shown robust segmentation performances for certain types
of tumors, e.g., brain tumors in MRI imaging, when a training dataset with plenty of pixel-level
fully-annotated tumor images is available. However, more than often, we are facing the challenge
that only (very) limited annotations are feasible to acquire, especially for hard tumors. Pancreatic
ductal adenocarcinoma (PDAC) segmentation is one of the most challenging tumor segmentation tasks,
yet critically important for clinical needs. Previous work on PDAC segmentation is limited to the
moderate amounts of annotated patient images (n<300) from venous or venous+arterial phase CT scans.
Based on a new self-learning framework, we propose to train the PDAC segmentation model using a much
larger quantity of patients (n~=1,000), with a mix of annotated and un-annotated venous or multi-phase
CT images. Pseudo annotations are generated by combining two teacher models with different PDAC
segmentation specialties on unannotated images, and can be further refined by a teaching assistant
model that identifies associated vessels around the pancreas. A student model is trained on both
manual and pseudo annotated multi-phase images. Experiment results show that our proposed method
provides an absolute improvement of 6.3% Dice score over the strong baseline of nnUNet trained on
annotated images, achieving the performance (Dice = 0.71) similar to the inter-observer variability
between radiologists. 