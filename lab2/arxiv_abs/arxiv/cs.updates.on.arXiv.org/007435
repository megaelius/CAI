Images today are increasingly shared online on social networking sites such as Facebook, Flickr,
Foursquare, and Instagram. Despite that current social networking sites allow users to change
their privacy preferences, this is often a cumbersome task for the vast majority of users on the Web,
who face difficulties in assigning and managing privacy settings. Thus, automatically predicting
images' privacy to warn users about private or sensitive content before uploading these images
on social networking sites has become a necessity in our current interconnected world. In this paper,
we explore learning models to automatically predict appropriate images' privacy as private or
public using carefully identified image-specific features. We study deep visual semantic features
that are derived from various layers of Convolutional Neural Networks (CNNs) as well as textual
features such as user tags and deep tags generated from deep CNNs. Particularly, we extract deep
(visual and tag) features from four pre-trained CNN architectures for object recognition, i.e.,
AlexNet, GoogLeNet, VGG-16, and ResNet, and compare their performance for image privacy prediction.
Results of our experiments on a Flickr dataset of over thirty thousand images show that the learning
models trained on features extracted from ResNet outperform the state-of-the-art models for image
privacy prediction. We further investigate the combination of user tags and deep tags derived from
CNN architectures using two settings: (1) SVM on the bag-of-tags features; and (2) text-based CNN.
Our results show that even though the models trained on the visual features perform better than those
trained on the tag features, the combination of deep visual features with image tags shows improvements
in performance over the individual feature sets. 