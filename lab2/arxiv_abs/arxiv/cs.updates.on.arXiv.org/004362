Decreasing costs of vision sensors and advances in embedded hardware boosted lane related research
detection, estimation, and tracking in the past two decades. The interest in this topic has increased
even more with the demand for advanced driver assistance systems (ADAS) and self-driving cars.
Although extensively studied independently, there is still need for studies that propose a combined
solution for the multiple problems related to the ego-lane, such as lane departure warning (LDW),
lane change detection, lane marking type (LMT) classification, road markings detection and classification,
and detection of adjacent lanes (i.e., immediate left and right lanes) presence. In this paper,
we propose a real-time Ego-Lane Analysis System (ELAS) capable of estimating ego-lane position,
classifying LMTs and road markings, performing LDW and detecting lane change events. The proposed
vision-based system works on a temporal sequence of images. Lane marking features are extracted
in perspective and Inverse Perspective Mapping (IPM) images that are combined to increase robustness.
The final estimated lane is modeled as a spline using a combination of methods (Hough lines with Kalman
filter and spline with particle filter). Based on the estimated lane, all other events are detected.
To validate ELAS and cover the lack of lane datasets in the literature, a new dataset with more than
20 different scenes (in more than 15,000 frames) and considering a variety of scenarios (urban road,
highways, traffic, shadows, etc.) was created. The dataset was manually annotated and made publicly
available to enable evaluation of several events that are of interest for the research community
(i.e., lane estimation, change, and centering; road markings; intersections; LMTs; crosswalks
and adjacent lanes). ELAS achieved high detection rates in all real-world events and proved to be
ready for real-time applications. 