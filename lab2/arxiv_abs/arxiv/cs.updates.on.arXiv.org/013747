Background and Objective: Object detection is a primary research interest in computer vision.
Sperm-cell detection in a densely populated bull semen microscopic observation video presents
challenges such as partial occlusion, vast number of objects in a single video frame, tiny size of
the object, artifacts, low contrast, and blurry objects because of the rapid movement of the sperm
cells. This study proposes an architecture, called DeepSperm, that solves the aforementioned
challenges and is more accurate and faster than state-of-the-art architectures. Methods: In the
proposed architecture, we use only one detection layer, which is specific for small object detection.
For handling overfitting and increasing accuracy, we set a higher network resolution, use a dropout
layer, and perform data augmentation on hue, saturation, and exposure. Several hyper-parameters
are tuned to achieve better performance. We compare our proposed method with those of a conventional
image processing-based object-detection method, you only look once (YOLOv3), and mask region-based
convolutional neural network (Mask R-CNN). Results: In our experiment, we achieve 86.91 mAP on
the test dataset and a processing speed of 50.3 fps. In comparison with YOLOv3, we achieve an increase
of 16.66 mAP point, 3.26 x faster on testing, and 1.4 x faster on training with a small training dataset,
which contains 40 video frames. The weights file size was also reduced significantly, with 16.94
x smaller than that of YOLOv3. Moreover, it requires 1.3 x less graphical processing unit (GPU) memory
than YOLOv3. Conclusions: This study proposes DeepSperm, which is a simple, effective, and efficient
architecture with its hyper-parameters and configuration to detect bull sperm cells robustly
in real time. In our experiment, we surpass the state of the art in terms of accuracy, speed, and resource
needs. 