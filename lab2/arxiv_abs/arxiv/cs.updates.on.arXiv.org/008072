While there are well-developed tools for maximizing a submodular function subject to a matroid
constraint, there is much less work on the corresponding supermodular maximization problems.
We develop new techniques for attacking these problems inspired by the continuous greedy method
applied to the multi-linear extension of a submodular function. We first adapt the continuous greedy
algorithm to work for general twice-continuously differentiable functions. The performance
of the adapted algorithm depends on a new smoothness parameter. If $F:[0,1]^n\rightarrow\mathbb{R}$
is one-sided $\sigma$-smooth, then the approximation factor only depends on $\sigma$. We apply
the new algorithm to a broad class of quadratic supermodular functions arising in diversity maximization.
This captures metric diversity maximization ($\sigma=2$) and negative-type diversity ($\sigma=4$).
We also develop new methods (inspired by swap rounding and approximate integer decomposition)
for rounding quadratics over a matroid polytope. Together with the adapted continuous greedy this
leads to a $O(\sigma^{3/2})$-approximation. This is the best asymptotic approximation known
for this class of quadratics and the evidence suggests that it may be tight. We then consider general
(non-quadratic) functions. We give a broad parameterized family of monotone functions which include
submodular functions and the just-discussed supermodular family of discrete quadratics. Such
set functions are called $\gamma$-meta-submodular. We develop local search algorithms with approximation
factors that depend only on $\gamma$. We show that the $\gamma$-meta-submodular families include
well-known function classes including meta-submodular functions ($\gamma=0$), proportionally
submodular ($\gamma=1$), and diversity functions based on negative-type distances or Jensen-Shannon
divergence (both $\gamma=2$) and (semi-)metric diversity functions. 