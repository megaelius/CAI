Deep Convolutional Neural Networks (CNNs) are a special type of Neural Networks, which have shown
state-of-the-art results on various competitive benchmarks. The powerful learning ability of
deep CNN is largely achieved with the use of multiple non-linear feature extraction stages that
can automatically learn hierarchical representation from the data. Availability of a large amount
of data and improvements in the hardware processing units have accelerated the research in CNNs
and recently very interesting deep CNN architectures are reported. The recent race in deep CNN architectures
for achieving high performance on the challenging benchmarks has shown that the innovative architectural
ideas, as well as parameter optimization, can improve the CNN performance on various vision-related
tasks. In this regard, different ideas in the CNN design have been explored such as use of different
activation and loss functions, parameter optimization, regularization, and restructuring of
processing units. However, the major improvement in representational capacity is achieved by
the restructuring of the processing units. Especially, the idea of using a block as a structural
unit instead of a layer is gaining substantial appreciation. This survey thus focuses on the intrinsic
taxonomy present in the recently reported CNN architectures and consequently, classifies the
recent innovations in CNN architectures into seven different categories. These seven categories
are based on spatial exploitation, depth, multi-path, width, feature map exploitation, channel
boosting and attention. Additionally, it covers the elementary understanding of the CNN components
and sheds light on the current challenges and applications of CNNs. 