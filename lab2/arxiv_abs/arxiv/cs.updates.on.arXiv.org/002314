Robotic and animal mapping systems share many challenges and characteristics: they must function
in a wide variety of environmental conditions, enable the robot or animal to navigate effectively
to find food or shelter, and be computationally tractable from both a speed and storage perspective.
With regards to map storage, the mammalian brain appears to take a diametrically opposed approach
to all current robotic mapping systems. Where robotic mapping systems attempt to solve the data
association problem to minimise representational aliasing, neurons in the brain intentionally
break data association by encoding large (potentially unlimited) numbers of places with a single
neuron. In this paper, we propose a novel method based on supervised learning techniques that seeks
out regularly repeating visual patterns in the environment with mutually complementary co-prime
frequencies, and an encoding scheme that enables storage requirements to grow sub-linearly with
the size of the environment being mapped. To improve robustness in challenging real-world environments
while maintaining storage growth sub-linearity, we incorporate both multi-exemplar learning
and data augmentation techniques. Using large benchmark robotic mapping datasets, we demonstrate
the combined system achieving high-performance place recognition with sub-linear storage requirements,
and characterize the performance-storage growth trade-off curve. The work serves as the first
robotic mapping system with sub-linear storage scaling properties, as well as the first large-scale
demonstration in real-world environments of one of the proposed memory benefits of these neurons.
