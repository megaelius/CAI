In the setting where information cannot be verified, we propose a simple yet powerful information
theoretical framework---the Mutual Information Paradigm---for information elicitation mechanisms.
Our framework pays every agent a measure of mutual information between her signal and a peer's signal.
We require that the mutual information measurement has the key property that any "data processing"
on the two random variables will decrease the mutual information between them. We identify such
information measures that generalize Shannon mutual information. Our Mutual Information Paradigm
overcomes the two main challenges in information elicitation without verification: (1) how to
incentivize effort and avoid agents colluding to report random or identical responses (2) how to
motivate agents who believe they are in the minority to report truthfully. Aided by the information
measures we found, (1) we use the paradigm to design a family of novel mechanisms where truth-telling
is a dominant strategy and any other strategy will decrease every agent's expected payment (in the
multi-question, detail free, minimal setting where the number of questions is large); (2) we show
the versatility of our framework by providing a unified theoretical understanding of existing
mechanisms---Peer Prediction [Miller 2005], Bayesian Truth Serum [Prelec 2004], and Dasgupta
and Ghosh [2013]---by mapping them into our framework such that theoretical results of those existing
mechanisms can be reconstructed easily. We also give an impossibility result which illustrates,
in a certain sense, the the optimality of our framework. 