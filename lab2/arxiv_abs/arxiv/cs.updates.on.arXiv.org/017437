Innovations in data science and AI/ML have a central role to play in supporting global efforts to
combat COVID-19. The versatility of AI/ML technologies enables scientists and technologists
to address an impressively broad range of biomedical, epidemiological, and socioeconomic challenges.
This wide-reaching scientific capacity, however, also raises a diverse array of ethical challenges.
The need for researchers to act quickly and globally in tackling SARS-CoV-2 demands unprecedented
practices of open research and responsible data sharing at a time when innovation ecosystems are
hobbled by proprietary protectionism, inequality, and a lack of public trust. Moreover, societally
impactful interventions like digital contact tracing are raising fears of surveillance creep
and are challenging widely held commitments to privacy, autonomy, and civil liberties. Prepandemic
concerns that data-driven innovations may function to reinforce entrenched dynamics of societal
inequity have likewise intensified given the disparate impact of the virus on vulnerable social
groups and the life-and-death consequences of biased and discriminatory public health outcomes.
To address these concerns, I offer five steps that need to be taken to encourage responsible research
and innovation. These provide a practice-based path to responsible AI/ML design and discovery
centered on open, accountable, equitable, and democratically governed processes and products.
When taken from the start, these steps will not only enhance the capacity of innovators to tackle
COVID-19 responsibly, they will, more broadly, help to better equip the data science and AI/ML community
to cope with future pandemics and to support a more humane, rational, and just society. 