The young infant explores its body, its sensorimotor system, and the immediately accessible parts
of its environment, over the course of a few months creating a model of peripersonal space useful
for reaching and grasping objects around it. Drawing on constraints from the empirical literature
on infant behavior, we present a preliminary computational model of this learning process, implemented
and evaluated on a physical robot. The learning agent explores the relationship between the configuration
space of the arm, sensing joint angles through proprioception, and its visual perceptions of the
hand and grippers. The resulting knowledge is represented as the peripersonal space (PPS) graph,
where nodes represent states of the arm, edges represent safe movements, and paths represent safe
trajectories from one pose to another. In our model, the learning process is driven by intrinsic
motivation. When repeatedly performing an action, the agent learns the typical result, but also
detects unusual outcomes, and is motivated to learn how to make those unusual results reliable.
Arm motions typically leave the static background unchanged, but occasionally bump an object,
changing its static position. The reach action is learned as a reliable way to bump and move an object
in the environment. Similarly, once a reliable reach action is learned, it typically makes a quasi-static
change in the environment, moving an object from one static position to another. The unusual outcome
is that the object is accidentally grasped (thanks to the innate Palmar reflex), and thereafter
moves dynamically with the hand. Learning to make grasps reliable is more complex than for reaches,
but we demonstrate significant progress. Our current results are steps toward autonomous sensorimotor
learning of motion, reaching, and grasping in peripersonal space, based on unguided exploration
and intrinsic motivation. 