Visual data collected from Unmanned Aerial Vehicles (UAVs) has opened a new frontier of computer
vision that requires automated analysis of aerial images/videos. However, the existing UAV datasets
primarily focus on object detection. An object detector does not differentiate between the moving
and non-moving objects. Given a real-time UAV video stream, how can we both localize and classify
the moving objects, i.e. perform moving object recognition (MOR)? The MOR is one of the essential
tasks to support various UAV vision-based applications including aerial surveillance, search
and rescue, event recognition, urban and rural scene understanding.To the best of our knowledge,
no labeled dataset is available for MOR evaluation in UAV videos. Therefore, in this paper, we introduce
MOR-UAV, a large-scale video dataset for MOR in aerial videos. We achieve this by labeling axis-aligned
bounding boxes for moving objects which requires less computational resources than producing
pixel-level estimates. We annotate 89,783 moving object instances collected from 30 UAV videos,
consisting of 10,948 frames in various scenarios such as weather conditions, occlusion, changing
flying altitude and multiple camera views. We assigned the labels for two categories of vehicles
(car and heavy vehicle). Furthermore, we propose a deep unified framework MOR-UAVNet for MOR in
UAV videos. Since, this is a first attempt for MOR in UAV videos, we present 16 baseline results based
on the proposed framework over the MOR-UAV dataset through quantitative and qualitative experiments.
We also analyze the motion-salient regions in the network through multiple layer visualizations.
The MOR-UAVNet works online at inference as it requires only few past frames. Moreover, it doesn't
require predefined target initialization from user. Experiments also demonstrate that the MOR-UAV
dataset is quite challenging. 