Machine learning models are extensively being used in decision making, especially for prediction
tasks. These models could be biased or unfair towards a specific sensitive group either of a specific
race, gender or age. Researchers have put efforts into characterizing a particular definition
of fairness and enforcing them into the models. In this work, mainly we are concerned with the following
three definitions, Disparate Impact, Demographic Parity and Equalized Odds. Researchers have
shown that Equalized Odds cannot be satisfied in calibrated classifiers unless the classifier
is perfect. Hence the primary challenge is to ensure a degree of fairness while guaranteeing as much
accuracy as possible. Fairness constraints are complex and need not be convex. Incorporating them
into a machine learning algorithm is a significant challenge. Hence, many researchers have tried
to come up with a surrogate loss which is convex in order to build fair classifiers. Besides, certain
papers try to build fair representations by preprocessing the data, irrespective of the classifier
used. Such methods, not only require a lot of unrealistic assumptions but also require human engineered
analytical solutions to build a machine learning model. We instead propose an automated solution
which is generalizable over any fairness constraint. We use a neural network which is trained on
batches and directly enforces the fairness constraint as the loss function without modifying it
further. We have also experimented with other complex performance measures such as H-mean loss,
Q-mean-loss, F-measure; without the need for any surrogate loss functions. Our experiments prove
that the network achieves similar performance as state of the art. Thus, one can just plug-in appropriate
loss function as per required fairness constraint and performance measure of the classifier and
train a neural network to achieve that. 