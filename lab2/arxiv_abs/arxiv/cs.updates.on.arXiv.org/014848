Airborne light detection and ranging (LiDAR) plays an increasingly significant role in urban planning,
topographic mapping, environmental monitoring, power line detection and other fields thanks
to its capability to quickly acquire large-scale and high-precision ground information. To achieve
point cloud classification, previous studies proposed point cloud deep learning models that can
directly process raw point clouds based on PointNet-like architectures. And some recent works
proposed graph convolution neural network based on the inherent topology of point clouds. However,
the above point cloud deep learning models only pay attention to exploring local geometric structures,
yet ignore global contextual relationships among all points. In this paper, we present a graph attention
convolution neural network (GACNN) that can be directly applied to the classification of unstructured
3D point clouds obtained by airborne LiDAR. Specifically, we first introduce a graph attention
convolution module that incorporates global contextual information and local structural features.
Based on the proposed graph attention convolution module, we further design an end-to-end encoder-decoder
network, named GACNN, to capture multiscale features of the point clouds and therefore enable more
accurate airborne point cloud classification. Experiments on the ISPRS 3D labeling dataset show
that the proposed model achieves a new state-of-the-art performance in terms of average F1 score
(71.5\%) and a satisfying overall accuracy (83.2\%). Additionally, experiments further conducted
on the 2019 Data Fusion Contest Dataset by comparing with other prevalent point cloud deep learning
models demonstrate the favorable generalization capability of the proposed model. 