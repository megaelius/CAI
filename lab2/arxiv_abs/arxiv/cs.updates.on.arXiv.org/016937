Voice Assistants (VA) such as Amazon Alexa and Google Assistant are quickly and seamlessly integrating
into people's daily lives. The increased reliance on VA services raises privacy concerns such as
the leakage of private conversations and sensitive information. Privacy policies play an important
role in addressing users' privacy concerns and informing them about the data collection, storage,
and sharing practices. VA platforms (both Amazon Alexa and Google Assistant) allow third-party
developers to build new voice-apps and publish them to the app store. Voice-app developers are required
to provide privacy policies to disclose their apps' data practices. However, little is known whether
these privacy policies are informative and trustworthy or not on emerging VA platforms. On the other
hand, many users invoke voice-apps through voice and thus there exists a usability challenge for
users to access these privacy policies. In this paper, we conduct the first large-scale data analytics
to systematically measure the effectiveness of privacy policies provided by voice-app developers
on two mainstream VA platforms. We seek to understand the quality and usability issues of privacy
policies provided by developers in the current app stores. We analyzed 64,720 Amazon Alexa skills
and 2,201 Google Assistant actions. Our work also includes a user study to understand users' perspectives
on VA's privacy policies. Our findings reveal a worrisome reality of privacy policies in two mainstream
voice-app stores, where there exists a substantial number of problematic privacy policies. Surprisingly,
Google and Amazon even have official voice-apps violating their own requirements regarding the
privacy policy. 