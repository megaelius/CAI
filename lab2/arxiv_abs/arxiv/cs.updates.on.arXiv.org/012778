Federated edge learning (FEEL) is a popular framework for model training at an edge server using
data distributed at edge devices (e.g., smart-phones and sensors) without compromising their
privacy. In the FEEL framework, edge devices periodically transmit high-dimensional stochastic
gradients to the edge server, where these gradients are aggregated and used to update a global model.
When the edge devices share the same communication medium, the multiple access channel from the
devices to the edge server induces a communication bottleneck. To overcome this bottleneck, an
efficient broadband analog transmission scheme has been recently proposed, featuring the aggregation
of analog modulated gradients (or local models) via the waveform-superposition property of the
wireless medium. However, the assumed linear analog modulation makes it difficult to deploy this
technique in modern wireless systems that exclusively use digital modulation. To address this
issue, we propose in this work a novel digital version of broadband over-the-air aggregation, called
one-bit broadband digital aggregation (OBDA). The new scheme features one-bit gradient quantization
followed by digital modulation at the edge devices and a majority-voting based decoding at the edge
server. We develop a comprehensive analysis framework for quantifying the effects of wireless
channel hostilities (channel noise, fading, and channel estimation errors) on the convergence
rate. The analysis shows that the hostilities slow down the convergence of the learning process
by introducing a scaling factor and a bias term into the gradient norm. However, we show that all the
negative effects vanish as the number of participating devices grows, but at a different rate for
each type of channel hostility. 