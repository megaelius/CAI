AI algorithms are being used with increased frequency in SE research and practice. Such algorithms
are usually commissioned and certified using data from outside the SE domain. Can we assume that
such algorithms can be used ''off-the-shelf'' (i.e. with no modifications)? To say that another
way, are there special features of SE problems that suggest a different and better way to use AI tools?
To answer these questions, this paper reports experiments with TimeLIME, a variant of the LIME explanation
algorithm from KDD'16. LIME can offer recommendations on how to change static code attributes in
order to reduce the number of defects in the next software release. That version of LIME used an internal
weighting tool to decide what attributes to include/exclude in those recommendations. TimeLIME
improves on that weighting scheme using the following SE knowledge: software comes in releases;
an implausible change to software is something that has never been changed in prior releases; so
it is better to use plausible changes, i.e. changes with some precedent in the prior releases. By
restricting recommendations to just the frequently changed attributes, TimeLIME can produce
(a)~dramatically better explanations of what causes defects and (b)~much better recommendations
on how to fix buggy code. Apart from these specific results about defect reduction and TimeLIME,
the more general point of this paper is that our community should be more careful about using off-the-shelf
AI tools, without first applying SE knowledge. As shown here, it may not be a complex matter to apply
that knowledge. Further, once that SE knowledge is applied, this can result in dramatically better
systems. 