Food recognition has received more and more attention in the multimedia community for its various
real-world applications, such as diet management and self-service restaurants. A large-scale
ontology of food images is urgently needed for developing advanced large-scale food recognition
algorithms, as well as for providing the benchmark dataset for such algorithms. To encourage further
progress in food recognition, we introduce the dataset ISIA Food- 500 with 500 categories from the
list in the Wikipedia and 399,726 images, a more comprehensive food dataset that surpasses existing
popular benchmark datasets by category coverage and data volume. Furthermore, we propose a stacked
global-local attention network, which consists of two sub-networks for food recognition. One
subnetwork first utilizes hybrid spatial-channel attention to extract more discriminative features,
and then aggregates these multi-scale discriminative features from multiple layers into global-level
representation (e.g., texture and shape information about food). The other one generates attentional
regions (e.g., ingredient relevant regions) from different regions via cascaded spatial transformers,
and further aggregates these multi-scale regional features from different layers into local-level
representation. These two types of features are finally fused as comprehensive representation
for food recognition. Extensive experiments on ISIA Food-500 and other two popular benchmark datasets
demonstrate the effectiveness of our proposed method, and thus can be considered as one strong baseline.
The dataset, code and models can be found at this http URL 