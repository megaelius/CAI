In Compressive Sensing theory and its applications, quantization of signal measurements, as integrated
into any realistic sensing model, impacts the quality of signal reconstruction. In fact, there
even exist incompatible combinations of quantization functions (e.g., the 1-bit sign function)
and sensing matrices (e.g., Bernoulli) that cannot lead to an arbitrarily low reconstruction error
when the number of observations increases. This work shows that, for a scalar and uniform quantization,
provided that a uniform random vector, or "random dithering", is added to the compressive measurements
of a low-complexity signal (e.g., a sparse or compressible signal, or a low-rank matrix) before
quantization, a large class of random matrix constructions known to respect the restricted isometry
property (RIP) are made "compatible" with this quantizer. This compatibility is demonstrated
by the existence of (at least) one signal reconstruction method, the "projected back projection"
(PBP), whose reconstruction error is proved to decay when the number of quantized measurements
increases. Despite the simplicity of PBP, which amounts to projecting the back projection of the
compressive observations (obtained from their multiplication by the adjoint sensing matrix)
onto the low-complexity set containing the observed signal, we also prove that given a RIP matrix
and for a single realization of the dithering, this reconstruction error decay is also achievable
uniformly for the sensing of all signals in the considered low-complexity set. We finally confirm
empirically these observations in several sensing contexts involving sparse signals, low-rank
matrices, and compressible signals, with various RIP matrix constructions such as sub-Gaussian
random matrices and random partial Discrete Cosine Transform (DCT) matrices. 