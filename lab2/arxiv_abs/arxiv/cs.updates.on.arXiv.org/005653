We present a medical crowdsourcing visual analytics platform called C{$^2$}A to visualize, classify
and filter crowdsourced clinical data. More specifically, C$^2$A is used to build consensus on
a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing
medical applications have recently shown promise where the non-expert users (the crowd) were able
to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading
time and possibly improve accuracy by building a consensus on the findings beforehand and letting
the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC)
application with the clinical technicians as our target users, and the radiologists acting as consultants
and classifying segments as benign or malignant. In particular, C$^2$A is used to analyze and explore
crowd responses on video segments, created from fly-throughs in the virtual colon. C$^2$A provides
several interactive visualization components to build crowd consensus on video segments, to detect
anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user's
work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific
parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework
in improving workers' output quality, the potential to reduce the radiologists' interpretation
time, and hence, the potential to improve the traditional clinical workflow by marking the majority
of the video segments as benign based on the crowd consensus. 