The brain performs intelligent tasks with extremely low energy consumption. This work takes inspiration
from two strategies used by the brain to achieve this energy efficiency: the absence of separation
between computing and memory functions, and the reliance on low precision computation. The emergence
of resistive memory technologies indeed provides an opportunity to co-integrate tightly logic
and memory in hardware. In parallel, the recently proposed concept of Binarized Neural Network,
where multiplications are replaced by exclusive NOR (XNOR) logic gates, offers a way to implement
artificial intelligence using very low precision computation. In this work, we therefore propose
a strategy to implement low energy Binarized Neural Networks, which employs brain-inspired concepts,
while retaining energy benefits from digital electronics. We design, fabricate and test a memory
array, including periphery and sensing circuits, optimized for this in-memory computing scheme.
Our circuit employs hafnium oxide resistive memory integrated in the back end of line of a 130 nanometer
CMOS process, in a two transistors - two resistors cell, which allows performing the exclusive NOR
operations of the neural network directly within the sense amplifiers. We show, based on extensive
electrical measurements, that our design allows reducing the amount of bit errors on the synaptic
weights, without the use of formal error correcting codes. We design a whole system using this memory
array. We show on standard machine learning tasks (MNIST, CIFAR-10, ImageNet and an ECG task) that
the system has an inherent resilience to bit errors. We evidence that its energy consumption is attractive
compared to more standard approaches, and that it can use the memory devices in regimes where they
exhibit particularly low programming energy and high endurance. 