As we move towards the exascale era, the new architectures must be capable of running the massive
computational problems efficiently. Scientists and researchers are continuously investing
in tuning the performance of extreme-scale computational problems. These problems arise in almost
all areas of computing, ranging from big data analytics, artificial intelligence, search, machine
learning, virtual/augmented reality, computer vision, image/signal processing to computational
science and bioinformatics. With Moore's law driving the evolution of hardware platforms towards
exascale, the dominant performance metric (time efficiency) has now expanded to also incorporate
power/energy efficiency. Therefore, the major challenge that we face in computing systems research
is: "how to solve massive-scale computational problems in the most time/power/energy efficient
manner?" The architectures are constantly evolving making the current performance optimizing
strategies less applicable and new strategies to be invented. The solution is for the new architectures,
new programming models, and applications to go forward together. Doing this is, however, extremely
hard. There are too many design choices in too many dimensions. We propose the following strategy
to solve the problem: (i) Models - Develop accurate analytical models (e.g. execution time, energy,
silicon area) to predict the cost of executing a given program, and (ii) Complete System Design -
Simultaneously optimize all the cost models for the programs (computational problems) to obtain
the most time/area/power/energy efficient solution. Such an optimization problem evokes the
notion of codesign. 