We propose an intuitive generalization to the Generative Adversarial Networks (GANs) and its conditional
variants to address the well known mode collapse problem. Firstly, we propose a multi-agent GAN
architecture incorporating multiple generators and one discriminator. Secondly, to enforce
different generators to capture diverse high probability modes, we modify discriminator's objective
function where along with finding the real and fake samples, the discriminator has to identify the
generator that generated the fake sample. Intuitively, to succeed in this task, the discriminator
must learn to push different generators towards different identifiable modes. Our framework (MAD-GAN)
is generalizable in the sense that it can be easily combined with other existing variants of GANs
to produce diverse samples. We perform extensive experiments on synthetic and real datasets and
compare MAD-GAN with different variants of GAN. We show high quality diverse sample generations
for the challenging tasks such as image-to-image translation (known to learn delta distribution)
and face generation. In addition, we show that MAD-GAN is able to disentangle different modalities
even when trained using highly challenging multi-view dataset (mixture of forests, icebergs,
bedrooms etc). In the end, we also show its efficacy for the unsupervised feature representation
task. In the appendix we introduce a similarity based competing objective which encourages the
different generators to generate varied samples judged by a user defined similarity metric. We
show extensive evaluations on a 1-D setting of mixture of gaussians for non parametric density estimation.
The theoretical proofs back the efficacy of the framework and explains why various generators are
pushed towards distinct clusters of modes. 