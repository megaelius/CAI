Prostate cancer (PCa) is graded by pathologists by examining the architectural pattern of cancerous
epithelial tissue on hematoxylin and eosin (H&E) stained slides. Given the importance of gland
morphology, automatically differentiating between glandular epithelial tissue and other tissues
is an important prerequisite for the development of automated methods for detecting PCa. We propose
a new method, using deep learning, for automatically segmenting epithelial tissue in digitized
prostatectomy slides. We employed immunohistochemistry (IHC) to render the ground truth less
subjective and more precise compared to manual outlining on H&E slides, especially in areas with
high-grade and poorly differentiated PCa. Our dataset consisted of 102 tissue blocks, including
both low and high grade PCa. From each block a single new section was cut, stained with H&E, scanned,
restained using P63 and CK8/18 to highlight the epithelial structure, and scanned again. The H&E
slides were co-registered to the IHC slides. On a subset of the IHC slides we applied color deconvolution,
corrected stain errors manually, and trained a U-Net to perform segmentation of epithelial structures.
Whole-slide segmentation masks generated by the IHC U-Net were used to train a second U-Net on H&E.
Our system makes precise cell-level segmentations and segments both intact glands as well as individual
(tumor) epithelial cells. We achieved an F1-score of 0.895 on a hold-out test set and 0.827 on an external
reference set from a different center. We envision this segmentation as being the first part of a
fully automated prostate cancer detection and grading pipeline. 