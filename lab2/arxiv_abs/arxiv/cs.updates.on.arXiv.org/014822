Measurements in Liquid Argon Time Projection Chamber (LArTPC) neutrino detectors, such as the
MicroBooNE detector at Fermilab, feature large, high fidelity event images. Deep learning techniques
have been extremely successful in classification tasks of photographs, but their application
to LArTPC event images is challenging, due to the large size of the events. Events in these detectors
are typically two orders of magnitude larger than images found in classical challenges, like recognition
of handwritten digits contained in the MNIST database or object recognition in the ImageNet database.
Ideally, training would occur on many instances of the entire event data, instead of many instances
of cropped regions of interest from the event data. However, such efforts lead to extremely long
training cycles, which slow down the exploration of new network architectures and hyperparameter
scans to improve the classification performance. We present studies of scaling a LArTPC classification
problem on multiple architectures, spanning multiple nodes. The studies are carried out on simulated
events in the MicroBooNE detector. We emphasize that it is beyond the scope of this study to optimize
networks or extract the physics from any results here. Institutional computing at Pacific Northwest
National Laboratory and the SummitDev machine at Oak Ridge National Laboratory's Leadership Computing
Facility have been used. To our knowledge, this is the first use of state-of-the-art Convolutional
Neural Networks for particle physics and their attendant compute techniques onto the DOE Leadership
Class Facilities. We expect benefits to accrue particularly to the Deep Underground Neutrino Experiment
(DUNE) LArTPC program, the flagship US High Energy Physics (HEP) program for the coming decades.
