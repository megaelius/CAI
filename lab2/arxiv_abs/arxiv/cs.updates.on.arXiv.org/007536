The prevalence of new technologies and social media has amplified the effects of misinformation
on our societies. Thus, it is necessary to create computational tools to mitigate their effects
effectively. This study aims to provide a critical overview of computational approaches concerned
with combating misinformation. To this aim, I offer an overview of scholarly definitions of misinformation.
I adopt a framework for studying misinformation that suggests paying attention to the source, content,
and consumers as the three main elements involved in the process of misinformation and I provide
an overview of literature from disciplines of psychology, media studies, and cognitive sciences
that deal with each of these elements. Using the framework, I overview the existing computational
methods that deal with 1) misinformation detection and fact-checking using Content 2) Identifying
untrustworthy Sources and social bots, and 3) Consumer-facing tools and methods aiming to make
humans resilient to misinformation. I find that the vast majority of works in computer science and
information technology is concerned with the crucial tasks of detection and verification of content
and sources of misinformation. Moreover, I find that computational research focusing on Consumers
of Misinformation in Human-Computer Interaction (HCI) and related fields are very sparse and often
do not deal with the subtleties of this process. The majority of existing interfaces and systems
are less concerned with the usability of the tools rather than the robustness and accuracy of the
detection methods. Using this survey, I call for an interdisciplinary approach towards human-misinformation
interaction that focuses on building methods and tools that robustly deal with such complex psychological/social
phenomena. 