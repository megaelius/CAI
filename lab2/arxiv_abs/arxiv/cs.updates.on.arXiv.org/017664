A large portion of passenger requests is reportedly unserviced, partially due to vacant for-hire
drivers' cruising behavior during the passenger seeking process. This paper aims to model the multi-driver
repositioning task through a mean field multi-agent reinforcement learning (MARL) approach that
captures competition among multiple agents. Because the direct application of MARL to the multi-driver
system under a given reward mechanism will likely yield a suboptimal equilibrium due to the selfishness
of drivers, this study proposes a reward design scheme with which a more desired equilibrium can
be reached. To effectively solve the bilevel optimization problem with upper level as the reward
design and the lower level as a multi-agent system, a Bayesian optimization (BO) algorithm is adopted
to speed up the learning process. We then apply the bilevel optimization model to two case studies,
namely, e-hailing driver repositioning under service charge and multiclass taxi driver repositioning
under NYC congestion pricing. In the first case study, the model is validated by the agreement between
the derived optimal control from BO and that from an analytical solution. With a simple piecewise
linear service charge, the objective of the e-hailing platform can be increased by 8.4%. In the second
case study, an optimal toll charge of $5.1 is solved using BO, which improves the objective of city
planners by 7.9%, compared to that without any toll charge. Under this optimal toll charge, the number
of taxis in the NYC central business district is decreased, indicating a better traffic condition,
without substantially increasing the crowdedness of the subway system. 