Recent successes of Deep Neural Networks (DNNs) in a variety of research tasks, however, heavily
rely on the large amounts of labeled samples. This may require considerable annotation cost in real-world
applications. Fortunately, active learning is a promising methodology to train high-performing
model with minimal annotation cost. In the deep learning context, the critical question of active
learning is how to precisely identify the informativeness of samples for DNN. In this paper, inspired
by piece-wise linear interpretability in DNN, we first introduce the linear separable regions
of samples to the problem of active learning, and propose a novel Deep Active learning approach by
Model Interpretability (DAMI). To keep the maximal representativeness of the entire unlabeled
data, DAMI tries to select and label samples on different linear separable regions introduced by
the piece-wise linear interpretability in DNN. We focus on two scenarios: 1) Multi-Layer Perception
(MLP) for modeling tabular data; 2) language models for modeling textual data. On tabular data,
we use the local piece-wise interpretation in DNN as the representation of each sample, and directly
run K-mediods clustering to select and label the central sample in each cluster. On textual data,
we propose a novel aggregator to find the most informative word in each sentence, and use its local
piece-wise interpretation as the representation of the sentence. To be noted, this whole process
of DAMI does not require any hyper-parameters to tune manually. To verify the effectiveness of our
approach, extensive experiments have been conducted on both tabular datasets and textual datasets.
The experimental results demonstrate that DAMI constantly outperforms several state-of-the-art
compared methods. 