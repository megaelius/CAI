Our previous works have demonstrated that visually realistic 3D meshes can be automatically reconstructed
with low-cost, off-the-shelf unmanned aerial systems (UAS) equipped with capable cameras, and
efficient photogrammetric software techniques. However, such generated data do not contain semantic
information/features of objects (i.e., man-made objects, vegetation, ground, object materials,
etc.) and cannot allow the sophisticated user-level and system-level interaction. Considering
the use case of the data in creating realistic virtual environments for training and simulations
(i.e., mission planning, rehearsal, threat detection, etc.), segmenting the data and extracting
object information are essential tasks. Thus, the objective of this research is to design and develop
a fully automated photogrammetric data segmentation and object information extraction framework.
To validate the proposed framework, the segmented data and extracted features were used to create
virtual environments in the authors previously designed simulation tool i.e., Aerial Terrain
Line of Sight Analysis System (ATLAS). The results showed that 3D mesh trees could be replaced with
geo-typical 3D tree models using the extracted individual tree locations. The extracted tree features
(i.e., color, width, height) are valuable for selecting the appropriate tree species and enhance
visual quality. Furthermore, the identified ground material information can be taken into consideration
for pathfinding. The shortest path can be computed not only considering the physical distance,
but also considering the off-road vehicle performance capabilities on different ground surface
materials. 