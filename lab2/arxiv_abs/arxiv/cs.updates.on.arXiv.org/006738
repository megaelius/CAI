Driven by recent computer vision and robotic applications, recovering 3D human poses has become
increasingly important and attracted growing interests. In fact, completing this task is quite
challenging due to the diverse appearances, viewpoints, occlusions and inherently geometric
ambiguities inside monocular images. Most of the existing methods focus on designing some elaborate
priors /constraints to directly regress 3D human poses based on the corresponding 2D human pose-aware
features or 2D pose predictions. However, due to the insufficient 3D pose data for training and the
domain gap between 2D space and 3D space, these methods have limited scalabilities for all practical
scenarios (e.g., outdoor scene). Attempt to address this issue, this paper proposes a simple yet
effective self-supervised correction mechanism to learn all intrinsic structures of human poses
from abundant images. Specifically, the proposed mechanism involves two dual learning tasks,
i.e., the 2D-to-3D pose transformation and 3D-to-2D pose projection, to serve as a bridge between
3D and 2D human poses in a type of "free" self-supervision for accurate 3D human pose estimation.
The 2D-to-3D pose implies to sequentially regress intermediate 3D poses by transforming the pose
representation from the 2D domain to the 3D domain under the sequence-dependent temporal context,
while the 3D-to-2D pose projection contributes to refining the intermediate 3D poses by maintaining
geometric consistency between the 2D projections of 3D poses and the estimated 2D poses. We further
apply our self-supervised correction mechanism to develop a 3D human pose machine, which jointly
integrates the 2D spatial relationship, temporal smoothness of predictions and 3D geometric knowledge.
Extensive evaluations demonstrate the superior performance and efficiency of our framework over
all the compared competing methods. 