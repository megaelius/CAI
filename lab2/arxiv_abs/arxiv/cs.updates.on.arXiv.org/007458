Visual modes of communication are ubiquitous in modern life. Here we investigate drawing, the most
basic form of visual communication. Communicative drawing poses a core challenge for theories
of how vision and social cognition interact, requiring a detailed understanding of how sensory
information and social context jointly determine what information is relevant to communicate.
Participants (N=192) were paired in an online environment to play a sketching-based reference
game. On each trial, both participants were shown the same four objects, but in different locations.
The sketcher's goal was to draw one of these objects - the target - so that the viewer could select it
from the array. There were two types of trials: close, where objects belonged to the same basic-level
category, and far, where objects belonged to different categories. We found that people exploited
information in common ground with their partner to efficiently communicate about the target: on
far trials, sketchers achieved high recognition accuracy while applying fewer strokes, using
less ink, and spending less time on their drawings than on close trials. We hypothesized that humans
succeed in this task by recruiting two core competencies: (1) visual abstraction, the capacity
to perceive the correspondence between an object and a drawing of it; and (2) pragmatic inference,
the ability to infer what information would help a viewer distinguish the target from distractors.
To evaluate this hypothesis, we developed a computational model of the sketcher that embodied both
competencies, instantiated as a deep convolutional neural network nested within a probabilistic
program. We found that this model fit human data well and outperformed lesioned variants, providing
an algorithmically explicit theory of how perception and social cognition jointly support contextual
flexibility in visual communication. 