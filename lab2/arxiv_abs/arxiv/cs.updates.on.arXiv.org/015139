Machine learning, particularly in the form of deep learning, has driven most of the recent fundamental
developments in artificial intelligence. Deep learning is based on computational models that
are, to a certain extent, bio-inspired, as they rely on networks of connected simple computing units
operating in parallel. Deep learning has been successfully applied in areas such as object/pattern
recognition, speech and natural language processing, self-driving vehicles, intelligent self-diagnostics
tools, autonomous robots, knowledgeable personal assistants, and monitoring. These successes
have been mostly supported by three factors: availability of vast amounts of data, continuous growth
in computing power, and algorithmic innovations. The approaching demise of Moore's law, and the
consequent expected modest improvements in computing power that can be achieved by scaling, raise
the question of whether the described progress will be slowed or halted due to hardware limitations.
This paper reviews the case for a novel beyond CMOS hardware technology, memristors, as a potential
solution for the implementation of power-efficient in-memory computing, deep learning accelerators,
and spiking neural networks. Central themes are the reliance on non-von-Neumann computing architectures
and the need for developing tailored learning and inference algorithms. To argue that lessons from
biology can be useful in providing directions for further progress in artificial intelligence,
we briefly discuss an example based reservoir computing. We conclude the review by speculating
on the big picture view of future neuromorphic and brain-inspired computing systems. 