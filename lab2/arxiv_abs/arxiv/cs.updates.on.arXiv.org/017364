Recently, convolutional neural networks (CNNs) have set latest state-of-the-art on various human
activity recognition (HAR) datasets. However, deep CNNs often require more computing resources,
which limits their applications in embedded HAR. Although many successful methods have been proposed
to reduce memory and FLOPs of CNNs, they often involve special network architectures designed for
visual tasks, which are not suitable for deep HAR tasks with time series sensor signals, due to remarkable
discrepancy. Therefore, it is necessary to develop lightweight deep models to perform HAR. As filter
is the basic unit in constructing CNNs, it deserves further research whether re-designing smaller
filters is applicable for deep HAR. In the paper, inspired by the idea, we proposed a lightweight
CNN using Lego filters for HAR. A set of lower-dimensional filters is used as Lego bricks to be stacked
for conventional filters, which does not rely on any special network structure. The local loss function
is used to train model. To our knowledge, this is the first paper that proposes lightweight CNN for
HAR in ubiquitous and wearable computing arena. The experiment results on five public HAR datasets,
UCI-HAR dataset, OPPORTUNITY dataset, UNIMIB-SHAR dataset, PAMAP2 dataset, and WISDM dataset
collected from either smartphones or multiple sensor nodes, indicate that our novel Lego CNN with
local loss can greatly reduce memory and computation cost over CNN, while achieving higher accuracy.
That is to say, the proposed model is smaller, faster and more accurate. Finally, we evaluate the
actual performance on an Android smartphone. 