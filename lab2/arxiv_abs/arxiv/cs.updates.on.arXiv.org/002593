Sufficient training data is normally required to train deeply learned models. However, the number
of pedestrian images per ID in person re-identification (re-ID) datasets is usually limited, since
manually annotations are required for multiple camera views. To produce more data for training
deeply learned models, generative adversarial network (GAN) can be leveraged to generate samples
for person re-ID. However, the samples generated by vanilla GAN usually do not have labels. So in
this paper, we propose a virtual label called Multi-pseudo Regularized Label (MpRL) and assign
it to the generated images. With MpRL, the generated samples will be used as supplementary of real
training data to train a deep model in a semi-supervised learning fashion. Considering data bias
between generated and real samples, MpRL utilizes different contributions from pre-defined training
classes. The contribution-based virtual labels are automatically assigned to generated samples
to reduce ambiguous prediction in training. Meanwhile, MpRL only relies on pre-defined training
classes without using extra classes. Furthermore, to reduce over-fitting, a regularized manner
is applied to MpRL to regularize the learning process. To verify the effectiveness of MpRL, two state-of-the-art
convolutional neural networks (CNNs) are adopted in our experiments. Experiments demonstrate
that by assigning MpRL to generated samples, we can further improve the person re-ID performance
on three datasets i.e., Market-1501, DukeMTMC-reID, and CUHK03. The proposed method obtains +6.29%,
+6.30% and +5.58% improvements in rank-1 accuracy over a strong CNN baseline respectively, and
outperforms the state-of-the-art methods. 