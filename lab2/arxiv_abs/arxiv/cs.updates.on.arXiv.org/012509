Explainable recommendation attempts to develop models that generate not only high-quality recommendations
but also intuitive explanations. The explanations may either be post-hoc or directly come from
an explainable model. Explainable recommendation tries to address the problem of why: by providing
explanations to users or system designers, it helps humans to understand why certain items are recommended
by the algorithm, where the human can either be users or system designers. Explainable recommendation
helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction
of recommendation systems. It also facilitates system designers for better system debugging.
In recent years, a large number of explainable recommendation approaches -- especially model-based
methods -- have been proposed and applied in real-world systems. In this survey, we provide a comprehensive
review for the explainable recommendation research. We highlight the position of explainable
recommendation in recommender system research by categorizing recommendation problems into
the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable
recommendation on three perspectives: 1) We provide a chronological research timeline of explainable
recommendation, including user study approaches in the early years and more recent model-based
approaches. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation
research: one dimension is the information source of the explanations, and the other dimension
is the algorithmic mechanism to generate explainable recommendations. 3) We summarize how explainable
recommendation applies to different recommendation tasks, such as product, social, and POI recommendations.
We also devote a section to discuss the future directions to promote the explainable recommendation
research. 