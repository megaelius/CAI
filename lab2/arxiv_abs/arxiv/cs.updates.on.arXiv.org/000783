We investigate the problem of continuous-time causal estimation under a minimax criterion. Let
$X^T = \{X_t,0\leq t\leq T\}$ be governed by the probability law $P_{\theta}$ from a class of possible
laws indexed by $\theta \in \Lambda$, and $Y^T$ be the noise corrupted observations of $X^T$ available
to the estimator. We characterize the estimator minimizing the worst case regret, where regret
is the difference between the causal estimation loss of the estimator and that of the optimum estimator.
One of the main contributions of this paper is characterizing the minimax estimator, showing that
it is in fact a Bayesian estimator. We then relate minimax regret to the channel capacity when the
channel is either Gaussian or Poisson. In this case, we characterize the minimax regret and the minimax
estimator more explicitly. If we further assume that the uncertainty set consists of deterministic
signals, the worst case regret is exactly equal to the corresponding channel capacity, namely the
maximal mutual information attainable across the channel among all possible distributions on
the uncertainty set of signals. The corresponding minimax estimator is the Bayesian estimator
assuming the capacity-achieving prior. Using this relation, we also show that the capacity achieving
prior coincides with the least favorable input. Moreover, we show that this minimax estimator is
not only minimizing the worst case regret but also essentially minimizing regret for "most" of the
other sources in the uncertainty set. We present a couple of examples for the construction of an minimax
filter via an approximation of the associated capacity achieving distribution. 