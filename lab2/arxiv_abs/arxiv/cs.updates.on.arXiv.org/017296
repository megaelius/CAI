Pedestrian detection through Computer Vision is a building block for a multitude of applications.
Recently, there was an increasing interest in Convolutional Neural Network-based architectures
for the execution of such a task. One of these supervised networks' critical goals is to generalize
the knowledge learned during the training phase to new scenarios with different characteristics.
A suitably labeled dataset is essential to achieve this purpose. The main problem is that manually
annotating a dataset usually requires a lot of human effort, and it is costly. To this end, we introduce
ViPeD (Virtual Pedestrian Dataset), a new synthetically generated set of images collected with
the highly photo-realistic graphical engine of the video game GTA V - Grand Theft Auto V, where annotations
are automatically acquired. However, when training solely on the synthetic dataset, the model
experiences a Synthetic2Real Domain Shift leading to a performance drop when applied to real-world
images. To mitigate this gap, we propose two different Domain Adaptation techniques suitable for
the pedestrian detection task, but possibly applicable to general object detection. Experiments
show that the network trained with ViPeD can generalize over unseen real-world scenarios better
than the detector trained over real-world data, exploiting the variety of our synthetic dataset.
Furthermore, we demonstrate that with our Domain Adaptation techniques, we can reduce the Synthetic2Real
Domain Shift, making closer the two domains and obtaining a performance improvement when testing
the network over the real-world images. The code, the models, and the dataset are made freely available
at https://ciampluca.github.io/viped/ 