Background: Accessing relevant data on the product, process, and usage perspectives of software
as well as integrating and analyzing such data is crucial for getting reliable and timely actionable
insights aimed at continuously managing software quality in Rapid Software Development (RSD).
In this context, several software analytics tools have been developed in recent years. However,
there is a lack of explainable software analytics that software practitioners trust. Aims: We aimed
at creating a quality model (called Q-Rapids quality model) for actionable analytics in RSD, implementing
it, and evaluating its understandability and relevance. Method: We performed workshops at four
companies in order to determine relevant metrics as well as product and process factors. We also
elicited how these metrics and factors are used and interpreted by practitioners when making decisions
in RSD. We specified the Q-Rapids quality model by comparing and integrating the results of the four
workshops. Then we implemented the Q-Rapids tool to support the usage of the Q-Rapids quality model
as well as the gathering, integration, and analysis of the required data. Afterwards we installed
the Q-Rapids tool in the four companies and performed semi-structured interviews with eight product
owners to evaluate the understandability and relevance of the Q-Rapids quality model. Results:
The participants of the evaluation perceived the metrics as well as the product and process factors
of the Q-Rapids quality model as understandable. Also, they considered the Q-Rapids quality model
relevant for identifying product and process deficiencies (e.g., blocking code situations).
Conclusions: By means of heterogeneous data sources, the Q-Rapids quality model enables detecting
problems that take more time to find manually and adds transparency among the perspectives of system,
process, and usage. 