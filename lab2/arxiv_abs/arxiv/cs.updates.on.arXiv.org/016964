Positive semidefinite matrix factorization (PSDMF) expresses each entry of a nonnegative matrix
as the inner product of two positive semidefinite (psd) matrices. When all these psd matrices are
constrained to be diagonal, this model is equivalent to nonnegative matrix factorization. Applications
include combinatorial optimization, quantum-based statistical models, and recommender systems,
among others. However, despite the increasing interest in PSDMF, only a few PSDMF algorithms were
proposed in the literature. In this paper, we show that PSDMF algorithms can be designed based on
phase retrieval (PR) and affine rank minimization (ARM) algorithms. This procedure allows a significant
shortcut in designing new PSDMF algorithms, as it allows to leverage some of the useful numerical
properties of existing PR and ARM methods to the PSDMF framework. Motivated by this idea, we introduce
a new family of PSDMF algorithms based on singular value projection (SVP) and iterative hard thresholding
(IHT). This family subsumes previously-proposed projected gradient PSDMF methods; additionally,
we show a new connection between SVP-based methods and majorization-minimization. Numerical
experiments show that our proposed methods outperform state-of-the-art coordinate descent algorithms
in terms of convergence speed and computational complexity, in certain scenarios. In certain cases,
our proposed normalized-IHT-based method is the only algorithm able to find a solution. These results
support our claim that the PSDMF framework can inherit desired numerical properties from PR and
ARM algorithms, leading to more efficient PSDMF algorithms, and motivate further study of the links
between these models. 