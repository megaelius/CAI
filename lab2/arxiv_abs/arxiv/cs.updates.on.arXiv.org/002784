Presence of missing values in a dataset can adversely affect the performance of a classifier; it
deteriorates rapidly as the missingness increases. Single and Multiple Imputation are normally
performed to fill in the missing values. In this paper, we present several variants of combining
multiple imputation and bootstrapping to create ensembles that can model uncertainty and diversity
in the data, and that are robust to high missingness in the data. We present three ensemble strategies:
bootstrapping on incomplete data followed by (i) single imputation and (ii) multiple imputation,
and (iii) multiple imputation ensemble without bootstrapping. We use mean imputation, Gaussian
random imputation and expectation maximization as the base imputation methods to be used in these
ensemble strategies. We perform an extensive evaluation of the performance of the proposed ensemble
strategies on $8$ datasets by varying the missingness ratio. Our results show that bootstrapping
followed by multiple imputation using expectation maximization is the most robust method that
prevents the classifier's performance from degrading, even at high missingness ratio (up to 30%).
For small missingness ratio (up to 10%) most of the ensemble methods perform equivalently but better
than their single imputation counterparts. Kappa-error plots suggest that accurate classifiers
with reasonable diversity is the reason for this behaviour. A consistent observation in all the
datasets suggests that for small missingness (up to 10%), bootstrapping on incomplete data without
any imputation produces equivalent results to other ensemble methods with single or multiple imputations.
