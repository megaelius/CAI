In multi-person videos, especially team sport videos, a semantic event is usually represented
as a confrontation between two teams of players, which can be represented as collective motion.
In broadcast basketball videos, specific camera motions are used to present specific events. Therefore,
a semantic event in broadcast basketball videos is closely related to both the global motion (camera
motion) and the collective motion. A semantic event in basketball videos can be generally divided
into three stages: pre-event, event occurrence (event-occ), and post-event. In this paper, we
propose an ontology-based global and collective motion pattern (On_GCMP) algorithm for basketball
event classification. First, a two-stage GCMP based event classification scheme is proposed.
The GCMP is extracted using optical flow. The two-stage scheme progressively combines a five-class
event classification algorithm on event-occs and a two-class event classification algorithm
on pre-events. Both algorithms utilize sequential convolutional neural networks (CNNs) and long
short-term memory (LSTM) networks to extract the spatial and temporal features of GCMP for event
classification. Second, we utilize post-event segments to predict success/failure using deep
features of images in the video frames (RGB_DF_VF) based algorithms. Finally the event classification
results and success/failure classification results are integrated to obtain the final results.
To evaluate the proposed scheme, we collected a new dataset called NCAA+, which is automatically
obtained from the NCAA dataset by extending the fixed length of video clips forward and backward
of the corresponding semantic events. The experimental results demonstrate that the proposed
scheme achieves the mean average precision of 59.22% on NCAA+. It is higher by 7.62% than state-of-the-art
on NCAA. 