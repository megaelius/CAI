The purpose of this study is to provide a detailed performance comparison of feature detector/descriptor
methods, particularly when their various combinations are used for image-matching. The localization
experiments of a mobile robot in an indoor environment are presented as a case study. In these experiments,
3090 query images and 127 dataset images were used. This study includes five methods for feature
detectors (features from accelerated segment test (FAST), oriented FAST and rotated binary robust
independent elementary features (BRIEF) (ORB), speeded-up robust features (SURF), scale invariant
feature transform (SIFT), and binary robust invariant scalable keypoints (BRISK)) and five other
methods for feature descriptors (BRIEF, BRISK, SIFT, SURF, and ORB). These methods were used in
23 different combinations and it was possible to obtain meaningful and consistent comparison results
using the performance criteria defined in this study. All of these methods were used independently
and separately from each other as either feature detector or descriptor. The performance analysis
shows the discriminative power of various combinations of detector and descriptor methods. The
analysis is completed using five parameters: (i) accuracy, (ii) time, (iii) angle difference between
keypoints, (iv) number of correct matches, and (v) distance between correctly matched keypoints.
In a range of 60{\deg}, covering five rotational pose points for our system, the FAST-SURF combination
had the lowest distance and angle difference values and the highest number of matched keypoints.
SIFT-SURF was the most accurate combination with a 98.41% correct classification rate. The fastest
algorithm was ORB-BRIEF, with a total running time of 21,303.30 s to match 560 images captured during
motion with 127 dataset images. 