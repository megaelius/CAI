Action Unit (AU) detection plays an important role for facial expression recognition. To the best
of our knowledge, there is little research about AU analysis for micro-expressions. In this paper,
we focus on AU detection in micro-expressions. Microexpression AU detection is challenging due
to the small quantity of micro-expression databases, low intensity, short duration of facial muscle
change, and class imbalance. In order to alleviate the problems, we propose a novel Spatio-Temporal
Adaptive Pooling (STAP) network for AU detection in micro-expressions. Firstly, STAP is aggregated
by a series of convolutional filters of different sizes. In this way, STAP can obtain multi-scale
information on spatial and temporal domains. On the other hand, STAP contains less parameters,
thus it has less computational cost and is suitable for micro-expression AU detection on very small
databases. Furthermore, STAP module is designed to pool discriminative information for micro-expression
AUs on spatial and temporal domains.Finally, Focal loss is employed to prevent the vast number of
negatives from overwhelming the microexpression AU detector. In experiments, we firstly polish
the AU annotations on three commonly used databases. We conduct intensive experiments on three
micro-expression databases, and provide several baseline results on micro-expression AU detection.
The results show that our proposed approach outperforms the basic Inflated inception-v1 (I3D)
in terms of an average of F1- score. We also evaluate the performance of our proposed method on cross-database
protocol. It demonstrates that our proposed approach is feasible for cross-database micro-expression
AU detection. Importantly, the results on three micro-expression databases and cross-database
protocol provide extensive baseline results for future research on micro-expression AU detection.
