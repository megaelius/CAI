Developing and selecting hearing aids is a time consuming process which could be simplified by using
objective models. The framework for auditory discrimination experiments (FADE) accurately simulated
the benefit of hearing aid algorithms. One simulation with FADE requires several hours of (un)processed
signals, which is obstructive when the signals have to be recorded. We propose and evaluate a real-time
optimized and data-reduced FADE version ("ROR-FADE") which enables simulations of speech recognition
thresholds (SRTs) with about 30 minutes of recorded and potentially processed signals of the (German)
matrix sentence test. SRTs were simulated for different noise maskers, degrees of hearing loss,
and with simulated hearing aids. At last, speech recognition with three pairs of real hearing aids
was simulated. The differences between ROR-FADE and FADE were small for stationary maskers (1 dB),
but larger with strongly fluctuating maskers (5 dB). Hearing impairment and hearing aid algorithms
seemed to reduced the differences. Hearing aid benefits were found in silence ($\geq$8 dB), in stationary
and fluctuating maskers in co-located (stat. 2 dB; fluct. 6 dB), and spatially separated speech
and noise signals (stat. $\geq$8 dB; fluct. 8 dB). The simulations were plausible in comparison
to data from literature, but a comparison with empirical data is still open. ROR-FADE simulates
SRTs in about 30 minutes in any setup that uses matrix sentences. Therefore, it facilitates objective
SRT simulations with real devices with unknown signal processing in real environments. Consequently,
ROR-FADE could be used for model-based hearing aid fitting or for the development of hearing aids.
