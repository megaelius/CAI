Dynamic nature of the cloud environment has made distributed resource management process a challenge
for cloud service providers. The importance of maintaining the quality of service in accordance
with customer expectations as well as the highly dynamic nature of cloud-hosted applications add
new levels of complexity to the process. Advances to the big data learning approaches have shifted
conventional static capacity planning solutions to complex performance-aware resource management
methods. It is shown that the process of decision making for resource adjustment is closely related
to the behaviour of the system including the utilization of resources and application components.
Therefore, a continuous monitoring of system attributes and performance metrics provide the raw
data for the analysis of problems affecting the performance of the application. Data analytic methods
such as statistical and machine learning approaches offer the required concepts, models and tools
to dig into the data, find general rules, patterns and characteristics that define the functionality
of the system. Obtained knowledge form the data analysis process helps to find out about the changes
in the workloads, faulty components or problems that can cause system performance to degrade. A
timely reaction to performance degradations can avoid violations of the service level agreements
by performing proper corrective actions including auto-scaling or other resource adjustment
solutions. In this paper, we investigate the main requirements and limitations in cloud resource
management including a study of the approaches in workload and anomaly analysis in the context of
the performance management in the cloud. A taxonomy of the works on this problem is presented which
identifies the main approaches in existing researches from data analysis side to resource adjustment
techniques. 