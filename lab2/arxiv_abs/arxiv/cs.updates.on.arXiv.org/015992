A lack of sufficient training data, both in terms of variety and quantity, is often the bottleneck
in the development of machine learning (ML) applications in any domain. For agricultural applications,
ML-based models designed to perform tasks such as autonomous plant classification will typically
be coupled to just one or perhaps a few plant species. As a consequence, each crop-specific task is
very likely to require its own specialized training data, and the question of how to serve this need
for data now often overshadows the more routine exercise of actually training such models. To tackle
this problem, we have developed an embedded robotic system to automatically generate and label
large datasets of plant images for ML applications in agriculture. The system can image plants from
virtually any angle, thereby ensuring a wide variety of data; and with an imaging rate of up to one
image per second, it can produce lableled datasets on the scale of thousands to tens of thousands
of images per day. As such, this system offers an important alternative to time- and cost-intensive
methods of manual generation and labeling. Furthermore, the use of a uniform background made of
blue keying fabric enables additional image processing techniques such as background replacement
and plant segmentation. It also helps in the training process, essentially forcing the model to
focus on the plant features and eliminating random correlations. To demonstrate the capabilities
of our system, we generated a dataset of over 34,000 labeled images, with which we trained an ML-model
to distinguish grasses from non-grasses in test data from a variety of sources. We now plan to generate
much larger datasets of Canadian crop plants and weeds that will be made publicly available in the
hope of further enabling ML applications in the agriculture sector. 