Performing ML computation on private data while maintaining data privacy aka Privacy-preserving
Machine Learning (PPML) is an emergent field of research. Recently, PPML has seen a visible shift
towards the adoption of Secure Outsourced Computation (SOC) paradigm, due to the heavy computation
that it entails. In the SOC paradigm, computation is outsourced to a set of powerful and specially
equipped servers that provide service on a pay-per-use basis. In this work, we propose SWIFT, a robust
PPML framework for a range of ML algorithms in SOC setting, that guarantees output delivery to the
users irrespective of any adversarial behaviour. Robustness, a highly desirable feature, evokes
user participation without the fear of denial of service. At the heart of our framework lies a highly-efficient,
maliciously-secure, three-party computation (3PC) over rings that provides guaranteed output
delivery (GOD) in the honest-majority setting. To the best of our knowledge, SWIFT is the first robust
and efficient PPML framework in the 3PC setting. SWIFT is as fast as the best-known 3PC framework
BLAZE (Patra et al. NDSS'20) which only achieves fairness. Fairness ensures either all or none receive
the output, whereas GOD ensures guaranteed output delivery no matter what. We extend our 3PC framework
for four parties (4PC). In this regime, SWIFT is as fast as the best known fair 4PC framework Trident
(Chaudhari et al. NDSS'20) and twice faster than the best-known robust 4PC framework FLASH (Byali
et al. PETS'20). We demonstrate the practical relevance of our framework by benchmarking two important
applications-- i) ML algorithms: Logistic Regression and Neural Network, and ii) Biometric matching,
both over a 64-bit ring in WAN setting. Our readings reflect our claims as above. 