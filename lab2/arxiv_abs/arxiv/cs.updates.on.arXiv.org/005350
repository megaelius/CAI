We further develop a new framework, called PDE Acceleration, by applying it to calculus of variations
problems defined for general functions on $\mathbb{R}^n$, obtaining efficient numerical algorithms
to solve the resulting class of optimization problems based on simple discretizations of their
corresponding accelerated PDE's. While the resulting family of PDE's and numerical schemes are
quite general, we give special attention to their application for regularized inversion problems,
with particular illustrative examples on some popular image processing applications. The method
is a generalization of momentum, or accelerated, gradient descent to the PDE setting. For elliptic
problems, the descent equations are a nonlinear damped wave equation, instead of a diffusion equation,
and the acceleration is realized as an improvement in the CFL condition from $\Delta t\sim \Delta
x^{2}$ (for diffusion) to $\Delta t\sim \Delta x$ (for wave equations). We work out several explicit
as well as a semi-implicit numerical schemes, together with their necessary stability constraints,
and include recursive update formulations which allow minimal-effort adaptation of existing
gradient descent PDE codes into the accelerated PDE framework. We explore these schemes more carefully
for a broad class of regularized inversion applications, with special attention to quadratic,
Beltrami, and Total Variation regularization, where the accelerated PDE takes the form of a nonlinear
wave equation. Experimental examples demonstrate the application of these schemes for image denoising,
deblurring, and inpainting, including comparisons against Primal Dual, Split Bregman, and ADMM
algorithms. 