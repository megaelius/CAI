Facial landmark detection is an important preprocessing task for most applications related to
face analysis. In recent years, the performance of facial landmark detection has been significantly
improved by using deep Convolutional Neural Networks (CNNs), especially the Heatmap Regression
Models (HRMs). Although their performance on common benchmark datasets have reached a high level,
the robustness of these models still remains a challenging problem in the practical use under more
noisy conditions of realistic environments. Contrary to most existing work focusing on the design
of new models, we argue that improving the robustness requires rethinking many other aspects, including
the use of datasets, the format of landmark annotation, the evaluation metric as well as the training
and detection algorithm itself. In this paper, we propose a novel method for robust facial landmark
detection using a loss function based on the 2D Wasserstein distance combined with a new landmark
coordinate sampling relying on the barycenter of the individual propability distributions. The
most intriguing fact of our method is that it can be plugged-and-play on most state-of-the-art HRMs
with neither additional complexity nor structural modifications of the models. Further, with
the large performance increase of state-of-the-art deep CNN models, we found that current evaluation
metrics can no longer fully reflect the robustness of these models. Therefore, we propose several
improvements on the standard evaluation protocol. Extensive experimental results on both traditional
evaluation metrics and our evaluation metrics demonstrate that our approach significantly improves
the robustness of state-of-the-art facial landmark detection models. 