Silicon-based Static Random Access Memories (SRAM) and digital Boolean logic have been the workhorse
of the state-of-art computing platforms. Despite tremendous strides in scaling the ubiquitous
metal-oxide-semiconductor transistor, the underlying \textit{von-Neumann} computing architecture
has remained unchanged. The limited throughput and energy-efficiency of the state-of-art computing
systems, to a large extent, results from the well-known \textit{von-Neumann bottleneck}. The
energy and throughput inefficiency of the von-Neumann machines have been accentuated in recent
times due to the present emphasis on data-intensive applications like artificial intelligence,
machine learning \textit{etc}. A possible approach towards mitigating the overhead associated
with the von-Neumann bottleneck is to enable \textit{in-memory} Boolean computations. In this
manuscript, we present an augmented version of the conventional SRAM bit-cells, called \textit{the
X-SRAM}, with the ability to perform in-memory, vector Boolean computations, in addition to the
usual memory storage operations. We propose at least six different schemes for enabling in-memory
vector computations including NAND, NOR, IMP (implication), XOR logic gates with respect to different
bit-cell topologies $-$ the 8T cell and the 8$^+$T Differential cell. In addition, we also present
a novel \textit{`read-compute-store'} scheme, wherein the computed Boolean function can be directly
stored in the memory without the need of latching the data and carrying out a subsequent write operation.
The feasibility of the proposed schemes has been verified using predictive transistor models and
Monte-Carlo variation analysis. 