Mobile phones pervade our daily lives and play ever expanding roles in many contexts. Their ubiquitousness
makes them pivotal in empowering disabled people. However, if no inclusive approaches are provided,
it becomes a strong vehicle of exclusion. Even though current solutions try to compensate for the
lack of sight, not all information reaches the blind user. Good spatial ability is still required
to make sense of the device and its interface, as well as the need to memorize positions on screen or
keys and associated actions in a keypad. Those problems are compounded by many individual attributes
such as age, age of blindness onset or tactile sensitivity which often are forgotten by designers.
Worse, the entire blind population is recurrently thought of as homogeneous (often stereotypically
so). Thus all users face the same solutions, ignoring their specific capabilities and needs. We
usually ignore this diversity as we have the ability to adapt and become experts in interfaces that
were probably maladjusted to begin with. This adaptation is not always within reach. Interaction
with mobile devices is highly visually demanding which widens this gap amongst blind people. It
is paramount to understand the impact of individual differences and their relationship with demands
to enable the deployment of more inclusive solutions. We explore individual differences among
blind people and assess how they are related with mobile interface demands, both at low (e.g. performing
an on-screen gesture) and high level (text-entry) tasks. Results confirmed that different ability
levels have significant impact on the performance attained by a blind person. Particularly, otherwise
ignored attributes like tactile acuity, pressure sensitivity, spatial ability or verbal IQ have
shown to be matched with specific mobile demands and parametrizations. 