The boosting on the need of security notably increased the amount of possible facial recognition
applications, especially due to the success of the Internet of Things (IoT) paradigm. However,
although handcrafted and deep learning-inspired facial features reached a significant level
of compactness and expressive power, the facial recognition performance still suffers from intra-class
variations such as ageing, facial expressions, lighting changes, and pose. These variations cannot
be captured in a single acquisition and require multiple acquisitions of long duration, which are
expensive and need a high level of collaboration from the users. Among others, self-update algorithms
have been proposed in order to mitigate these problems. Self-updating aims to add novel templates
to the users' gallery among the inputs submitted during system operations. Consequently, computational
complexity and storage space tend to be among the critical requirements of these algorithms. The
present paper deals with the above problems by a novel template-based self-update algorithm, able
to keep over time the expressive power of a limited set of templates stored in the system database.
The rationale behind the proposed approach is in the working hypothesis that a dominating mode characterises
the features' distribution given the client. Therefore, the key point is to select the best templates
around that mode. We propose two methods, which are tested on systems based on handcrafted features
and deep-learning-inspired autoencoders at the state-of-the-art. Three benchmark data sets
are used. Experimental results confirm that, by effective and compact feature sets which can support
our working hypothesis, the proposed classification-selection approaches overcome the problem
of manual updating and, in case, stringent computational requirements. 