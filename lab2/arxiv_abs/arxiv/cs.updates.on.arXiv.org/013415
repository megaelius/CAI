Random access schemes in modern wireless communications are generally based on the framed-ALOHA
(f-ALOHA), which can be optimized by flexibly organizing devices' transmission and re-transmission.
However, this optimization is generally intractable due to the lack of information about complex
traffic generation statistics and the occurrence of the random collision. In this article, we first
summarize the general structure of access control optimization for different random access schemes,
and then review the existing access control optimization based on Machine Learning (ML) and non-ML
techniques. We demonstrate that the ML-based methods can better optimize the access control problem
compared with non-ML based methods, due to their capability in solving high complexity long-term
optimization problem and learning experiential knowledge from reality. To further improve the
random access performance, we propose two-step learning optimizers for access control optimization,
which individually execute the traffic prediction and the access control configuration. In detail,
our traffic prediction method relies on online supervised learning adopting Recurrent Neural
Networks (RNNs) that can accurately capture traffic statistics over consecutive frames, and the
access control configuration can use either a non-ML based controller or a cooperatively trained
Deep Reinforcement Learning (DRL) based controller depending on the complexity of different random
access schemes. Numerical results show that the proposed two-step cooperative learning optimizer
considerably outperforms the conventional Deep Q-Network (DQN) in terms of higher training efficiency
and better access performance. 