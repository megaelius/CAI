In this paper, we propose a convolutional recurrent neural network for joint sound event localization
and detection (SELD) of multiple overlapping sound events in three-dimensional (3D) space. The
proposed network takes a sequence of consecutive spectrogram time-frames as input and maps it to
two outputs in parallel. As the first output, the sound event detection (SED) is performed as a multi-label
multi-class classification task on each time-frame producing temporal activity for all the sound
event classes. As the second output, localization is performed by estimating the 3D Cartesian coordinates
of the direction-of-arrival (DOA) for each sound event class using multi-class regression. The
proposed method is able to associate multiple DOAs with respective sound event labels and further
track this association with respect to time. The proposed method uses separately the phase and magnitude
component of the spectrogram calculated on each audio channel as the feature, thereby avoiding
any method- and array-specific feature extraction. The method is evaluated on five Ambisonic and
two circular array format datasets with different overlapping sound events in anechoic, reverberant
and real-life scenarios. The proposed method is compared with two SED, three DOA estimation, and
one SELD baselines. The results show that the proposed method is generic to array structures, robust
to unseen DOA labels, reverberation, and low SNR scenarios. The proposed joint estimation of DOA
and SED in comparison to the respective standalone baselines resulted in a consistently higher
recall of the estimated number of DOAs across datasets. 