We study online resource allocation problems with a diseconomy of scale. In these problems, there
are certain requests, each demanding a set of resources, that arrive in an online manner. The cost
of each resource is semi-convex and grows superlinearly in the total load on the resource. An irrevocable
allocation decision has to be made directly after the arrival of each request with the goal to minimize
the total cost on the resources. We focus on two simple greedy online policies that provide very fast
and easy approximation algorithms. The first policy is to minimize the individual cost of the current
online request with respect to all previous requests that have been allocated before. The second
policy is to minimize the marginal total cost over all requests that have arrived up to this point.
In the literature, these type of algorithms is also considered as one-round walks in congestion
games starting from the empty state. We consider the weighted and unweighted version of the problem.
In the weighted variant, and for cost functions that are polynomials with maximal degree $d$ and
positive coefficients, we proof a tight competitive ratio of $\left(\sqrt[d]{2}-1\right)^{-(d+1)}$
for the marginal total cost policy. This interestingly exactly matches the approximation factor
for the corresponding \emph{multiple}-round walk algorithm. Our work indicates that one-round
walks that start in an empty starting state are exactly as efficient as multiple-round walks. We
also show that this does not carry over to the unweighted version of the problem. For unweighted instances,
we provide lower bounds for both policies that are significantly larger than the corresponding
multiple-round walks. We complement our results with an upper and lower bound on the solution quality
of the personal cost policy for weighted and unweighted instances. 