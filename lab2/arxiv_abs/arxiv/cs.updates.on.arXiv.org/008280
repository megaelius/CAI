Differential privacy has seen remarkable success as a rigorous and practical formalization of
data privacy in the past decade. But it also has some well known weaknesses: notably, it does not tightly
handle composition. This weakness has inspired several recent relaxations of differential privacy
based on Renyi divergences. We propose an alternative relaxation of differential privacy, which
we term "$f$-differential privacy", which has a number of appealing properties and avoids some
of the difficulties associated with divergence based relaxations. First, it preserves the hypothesis
testing interpretation of differential privacy, which makes its guarantees easily interpretable.
It allows for lossless reasoning about composition and post-processing, and notably, a direct
way to import existing tools from differential privacy, including privacy amplification by subsampling.
We define a canonical single parameter family of definitions within our class which we call "Gaussian
Differential Privacy", defined based on the hypothesis testing of two shifted Gaussian distributions.
We show that this family is focal by proving a central limit theorem, which shows that the privacy
guarantees of \emph{any} hypothesis-testing based definition of privacy (including differential
privacy) converges to Gaussian differential privacy in the limit under composition. We also prove
a finite (Berry-Esseen style) version of the central limit theorem, which gives a useful tool for
tractably analyzing the exact composition of potentially complicated expressions. We demonstrate
the use of the tools we develop by giving an improved analysis of the privacy guarantees of noisy stochastic
gradient descent. 