Arbitrary style transfer is the task of synthesis of an image that has never been seen before, using
two given images: content image and style image. The content image forms the structure, the basic
geometric lines and shapes of the resulting image, while the style image sets the color and texture
of the result. The word "arbitrary" in this context means the absence of any one pre-learned style.
So, for example, convolutional neural networks capable of transferring a new style only after training
or retraining on a new amount of data are not con-sidered to solve such a problem, while networks based
on the attention mech-anism that are capable of performing such a transformation without retraining
- yes. An original image can be, for example, a photograph, and a style image can be a painting of a famous
artist. The resulting image in this case will be the scene depicted in the original photograph, made
in the stylie of this picture. Recent arbitrary style transfer algorithms make it possible to achieve
good re-sults in this task, however, in processing portrait images of people, the result of such
algorithms is either unacceptable due to excessive distortion of facial features, or weakly expressed,
not bearing the characteristic features of a style image. In this paper, we consider an approach
to solving this problem using the combined architecture of deep neural networks with a attention
mechanism that transfers style based on the contents of a particular image segment: with a clear
predominance of style over the form for the background part of the im-age, and with the prevalence
of content over the form in the image part con-taining directly the image of a person. 