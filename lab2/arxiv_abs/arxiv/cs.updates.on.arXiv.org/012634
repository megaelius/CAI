Two of the most significant challenges in uncertainty propagation pertain to the high computational
cost for the simulation of complex physical models and the high dimension of the random inputs. In
applications of practical interest both of these problems are encountered and standard methods
for uncertainty quantification either fail or are not feasible. To overcome the current limitations,
we propose a probabilistic multi-fidelity framework that can exploit lower-fidelity model versions
of the original problem in a small data regime. The approach circumvents the curse of dimensionality
by learning dependencies between the outputs of high-fidelity models and lower-fidelity models
instead of explicitly accounting for the high-dimensional inputs. We complement the information
provided by a low-fidelity model with a low-dimensional set of informative features of the stochastic
input, which are discovered by employing a combination of supervised and unsupervised dimensionality
reduction techniques. The goal of our analysis is an efficient and accurate estimation of the full
probabilistic response for a high-fidelity model. Despite the incomplete and noisy information
that low-fidelity predictors provide, we demonstrate that accurate and certifiable estimates
for the quantities of interest can be obtained in the small data regime, i.e., with significantly
fewer high-fidelity model runs than state-of-the-art methods for uncertainty propagation. We
illustrate our approach by applying it to challenging numerical examples such as Navier-Stokes
flow simulations and monolithic fluid-structure interaction problems. 