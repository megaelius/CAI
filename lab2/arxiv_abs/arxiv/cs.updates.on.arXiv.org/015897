Few-shot learning can find the latent structure information between the prior knowledge and the
queried data by the similarity metric of meta-learning to construct the discriminative model for
recognizing the new categories with the rare labeled samples. Most existing methods try to model
the similarity relationship of the samples in the intra tasks, and generalize the model to identify
the new categories. However, the relationship of samples between the separated tasks is difficultly
considered because of the different metric criterion in the respective tasks. In contrast, the
proposed high-order structure preserving graph neural network(HOSP-GNN) can further explore
the rich structure of the samples to predict the label of the queried data on graph that enables the
structure evolution to explicitly discriminate the categories by iteratively updating the high-order
structure relationship (the relative metric in multi-samples,instead of pairwise sample metric)
with the manifold structure constraints. HOSP-GNN can not only mine the high-order structure for
complementing the relevance between samples that may be divided into the different task in meta-learning,
and but also generate the rule of the structure updating by manifold constraint. Furthermore, HOSP-GNN
doesn't need retrain the learning model for recognizing the new classes, and HOSP-GNN has the well-generalizable
high-order structure for model adaptability. Experiments show that HOSP-GNN outperforms the
state-of-the-art methods on supervised and semi-supervised few-shot learning in three benchmark
datasets that are miniImageNet, tieredImageNet and FC100. 