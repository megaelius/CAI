The tremendous potential exhibited by deep learning is often offset by architectural and computational
complexity, making widespread deployment a challenge for edge scenarios such as mobile and other
consumer devices. To tackle this challenge, we explore the following idea: Can we learn generative
machines to automatically generate deep neural networks with efficient network architectures?
In this study, we introduce the idea of generative synthesis, which is premised on the intricate
interplay between a generator-inquisitor pair that work in tandem to garner insights and learn
to generate highly efficient deep neural networks that best satisfies operational requirements.
What is most interesting is that, once a generator has been learned through generative synthesis,
it can be used to generate not just one but a large variety of different, unique highly efficient deep
neural networks that satisfy operational requirements. Experimental results for image classification,
semantic segmentation, and object detection tasks illustrate the efficacy of generative synthesis
in producing generators that automatically generate highly efficient deep neural networks (which
we nickname FermiNets) with higher model efficiency and lower computational costs (reaching >10x
more efficient and fewer multiply-accumulate operations than several tested state-of-the-art
networks), as well as higher energy efficiency (reaching >4x improvements in image inferences
per joule consumed on a Nvidia Tegra X2 mobile processor). As such, generative synthesis can be a
powerful, generalized approach for accelerating and improving the building of deep neural networks
for on-device edge scenarios. 