A total of twenty paired CT and MR images were used in this study to investigate two conditional generative
adversarial networks, Pix2Pix, and Cycle GAN, for generating synthetic CT images for Headand Neck
cancer cases. Ten of the patient cases were used for training and included such common artifacts
as dental implants; the remaining ten testing cases were used for testing and included a larger range
of image features commonly found in clinical head and neck cases. These features included strong
metal artifacts from dental implants, one case with a metal implant, and one case with abnormal anatomy.
The original CT images were deformably registered to the mDixon FFE MR images to minimize the effects
of processing the MR images. The sCT generation accuracy and robustness were evaluated using Mean
Absolute Error (MAE) based on the Hounsfield Units (HU) for three regions (whole body, bone, and
air within the body), Mean Error (ME) to observe systematic average offset errors in the sCT generation,
and dosimetric evaluation of all clinically relevant structures. For the test set the MAE for the
Pix2Pix and Cycle GAN models were 92.4 $\pm$ 13.5 HU, and 100.7 $\pm$ 14.6 HU, respectively, for the
body region, 166.3 $\pm$ 31.8 HU, and 184 $\pm$ 31.9 HU, respectively, for the bone region, and 183.7
$\pm$ 41.3 HU and 185.4 $\pm$ 37.9 HU for the air regions. The ME for Pix2Pix and Cycle GAN were 21.0
$\pm$ 11.8 HU and 37.5 $\pm$ 14.9 HU, respectively. Absolute Percent Mean/Max Dose Errors were less
than 2% for the PTV and all critical structures for both models, and DRRs generated from these models
looked qualitatively similar to CT generated DRRs showing these methods are promising for MR-only
planning. 