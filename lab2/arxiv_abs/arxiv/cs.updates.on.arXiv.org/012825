Traditional online maps, widely used on Internet such as Google map and Baidu map, are rendered from
vector data. Timely updating online maps from vector data, of which the generating is time-consuming,
is a difficult mission. It is a shortcut to generate online maps in time from remote sensing images,
which can be acquired timely without vector data. However, this mission used to be challenging or
even impossible. Inspired by image-to-image translation (img2img) techniques based on generative
adversarial network (GAN), we propose a semi-supervised structure-augmented online map GAN (S$^{2}$OMGAN)
model to generate online maps directly from remote sensing images. In this model, we designed a semi-supervised
learning strategy to pre-train S$^{2}$OMGAN on rich unpaired samples and finetune it on limited
paired samples in reality. We also designed image gradient L1 loss and image gradient structure
loss to generate an online map with global topological relationship and detailed edge curves of
objects, which are important in cartography. Moreover, we propose edge structural similarity
index (ESSI) as a metric to evaluate the quality of topological consistency between generated online
maps and ground truths. Experimental results present that S$^{2}$OMGAN outperforms state-of-the-art
(SOTA) works according to mean squared error, structural similarity index and ESSI. Also, S$^{2}$OMGAN
wins more approval than SOTA in the human perceptual test on visual realism of cartography. Our work
shows that S$^{2}$OMGAN is potentially a new paradigm to produce online maps. Our implementation
of the S$^{2}$OMGAN is available at \url{https://github.com/imcsq/S2OMGAN}. 