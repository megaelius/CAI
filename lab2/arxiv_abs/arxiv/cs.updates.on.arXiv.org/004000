Scientific applications are complex, large, and often exhibit irregular and stochastic behavior.
The use of efficient loop scheduling techniques is crucial for improving their performance, often
degraded by load imbalance, on high-performance computing (HPC) platforms. A number of dynamic
loop scheduling (DLS) techniques have been proposed between the late 1980s and early 2000s, and
efficiently used in scientific applications. In most cases, the computing systems on which they
have been tested and validated are no longer available. To minimize performance degradation due
to load imbalance on modern HPC platforms, it is important to ensure that the DLS techniques employed
in scientific applications today adhere to their original design goals and specifications. The
goal of this work is to reproduce and predict the performance of a selection of scheduling experiments
from the 1992 original work that introduced factoring, an efficient DLS technique proposed for
shared-memory systems, both, via simulative and native experimentation. The selected scheduling
experiments involve two computational kernels and four loop scheduling techniques. The experiments
show that the simulation reproduces the performance achieved on the past computing platform and
accurately predicts the performance achieved on the present computing platform. The performance
reproduction and prediction confirm that the present implementation of these DLS techniques both,
in simulation and natively, adheres to their original description. Moreover, the simulative and
native experiments follow the expected performance behavior for the considered scheduling scenarios.
This work paves the way towards additional simulative and native experimentation using further
DLS techniques in the future. 