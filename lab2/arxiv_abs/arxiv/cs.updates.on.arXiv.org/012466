String data are often disseminated to support applications such as location-based service provision
or DNA sequence analysis. This dissemination, however, may expose sensitive patterns that model
confidential knowledge. In this paper, we consider the problem of sanitizing a string by concealing
the occurrences of sensitive patterns, while maintaining data utility, in two settings that are
relevant to many common string processing tasks. In the first setting, we aim to generate the minimal-length
string that preserves the order of appearance and frequency of all non-sensitive patterns. Such
a string allows accurately performing tasks based on the sequential nature and pattern frequencies
of the string. To construct such a string, we propose a time-optimal algorithm, TFS-ALGO. We also
propose another time-optimal algorithm, PFS-ALGO, which preserves a partial order of appearance
of non-sensitive patterns but produces a much shorter string that can be analyzed more efficiently.
The strings produced by either of these algorithms are constructed by concatenating non-sensitive
parts of the input string. However, it is possible to detect the sensitive patterns by ``reversing''
the concatenation operations. In response, we propose a heuristic, MCSR-ALGO, which replaces
letters in the strings output by the algorithms with carefully selected letters, so that sensitive
patterns are not reinstated, implausible patterns are not introduced, and occurrences of spurious
patterns are prevented. In the second setting, we aim to generate a string that is at minimal edit
distance from the original string, in addition to preserving the order of appearance and frequency
of all non-sensitive patterns. To construct such a string, we propose an algorithm, ETFS-ALGO,
based on solving specific instances of approximate regular expression matching. 