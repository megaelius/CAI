Medical imaging is an essential tool in many areas of medical applications, used for both diagnosis
and treatment. However, reading medical images and making diagnosis or treatment recommendations
require specially trained medical specialists. The current practice of reading medical images
is labor-intensive, time-consuming, costly, and error-prone. It would be more desirable to have
a computer-aided system that can automatically make diagnosis and treatment recommendations.
Recent advances in deep learning enable us to rethink the ways of clinician diagnosis based on medical
images. In this thesis, we will introduce 1) mammograms for detecting breast cancers, the most frequently
diagnosed solid cancer for U.S. women, 2) lung CT images for detecting lung cancers, the most frequently
diagnosed malignant cancer, and 3) head and neck CT images for automated delineation of organs at
risk in radiotherapy. First, we will show how to employ the adversarial concept to generate the hard
examples improving mammogram mass segmentation. Second, we will demonstrate how to use the weakly
labeled data for the mammogram breast cancer diagnosis by efficiently design deep learning for
multi-instance learning. Third, the thesis will walk through DeepLung system which combines deep
3D ConvNets and GBM for automated lung nodule detection and classification. Fourth, we will show
how to use weakly labeled data to improve existing lung nodule detection system by integrating deep
learning with a probabilistic graphic model. Lastly, we will demonstrate the AnatomyNet which
is thousands of times faster and more accurate than previous methods on automated anatomy segmentation.
