There has been a wave of interest in applying machine learning to study dynamical systems. In particular,
neural networks have been applied to solve the equations of motion, and therefore, track the evolution
of a system. In contrast to other applications of neural networks and machine learning, dynamical
systems -- depending on their underlying symmetries -- possess invariants such as energy, momentum,
and angular momentum. Traditional numerical iteration methods usually violate these conservation
laws, propagating errors in time, and reducing the predictability of the method. We present a Hamiltonian
neural network that solves the differential equations that govern dynamical systems. This unsupervised
model is learning solutions that satisfy identically, up to an arbitrarily small error, Hamilton's
equations and, therefore, conserve the Hamiltonian invariants. Once it is optimized, the proposed
architecture is considered a symplectic unit due to the introduction of an efficient parametric
form of solutions. In addition, by sharing the network parameters and the choice of an appropriate
activation function drastically improve the predictability of the network. An error analysis
is derived and states that the numerical errors depend on the overall network performance. The symplectic
architecture is then employed to solve the equations for the nonlinear oscillator and the chaotic
Henon-Heiles dynamical system. In both systems, the symplectic Euler integrator requires two
orders more evaluation points than the Hamiltonian network in order to achieve the same order of
the numerical error in the predicted phase space trajectories. 