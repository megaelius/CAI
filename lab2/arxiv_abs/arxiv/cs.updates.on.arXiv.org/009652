Knee osteoarthritis (OA) is the most common musculoskeletal disease in the world. In primary healthcare,
knee OA is diagnosed using clinical examination and radiographic assessment. Osteoarthritis
Research Society International (OARSI) atlas of OA radiographic features allows to perform independent
assessment of knee osteophytes, joint space narrowing and other knee features. This provides a
fine-grained OA severity assessment of the knee, compared to the gold standard and most commonly
used Kellgren-Lawrence (KL) composite score. However, both OARSI and KL grading systems suffer
from moderate inter-rater agreement, and therefore, the use of computer-aided methods could help
to improve the reliability of the process. In this study, we developed a robust, automatic method
to simultaneously predict KL and OARSI grades in knee radiographs. Our method is based on Deep Learning
and leverages an ensemble of deep residual networks with 50 layers, squeeze-excitation and ResNeXt
blocks. Here, we used transfer learning from ImageNet with a fine-tuning on the whole Osteoarthritis
Initiative (OAI) dataset. An independent testing of our model was performed on the whole Multicenter
Osteoarthritis Study (MOST) dataset. Our multi-task method yielded Cohen's kappa coefficients
of 0.82 for KL-grade and 0.79, 0.84, 0.94, 0.83, 0.84, 0.90 for femoral osteophytes, tibial osteophytes
and joint space narrowing for lateral and medial compartments respectively. Furthermore, our
method yielded area under the ROC curve of 0.98 and average precision of 0.98 for detecting the presence
of radiographic OA (KL $\geq 2$), which is better than the current state-of-the-art. 