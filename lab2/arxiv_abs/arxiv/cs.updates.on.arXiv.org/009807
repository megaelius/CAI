Relational data in its most basic form is a static collection of known facts. However, by learning
to infer and deduct additional information and structure, we can massively increase the usefulness
of the underlying data. One common form of inferential reasoning in knowledge bases is implication
discovery. Here, by learning when one relation implies another, we can extend our knowledge representation.
There are several existing models for relational implication, however we argue they are motivated
but not principled. To this end, we define a formal probabilistic model of relational implication.
By using estimators based on the empirical distribution of our dataset, we demonstrate that our
model outperforms existing approaches. While previous work achieves a best score of 0.7812 AUC
on an evaluatory dataset, our ProbE model improves this to 0.7915. Furthermore, we demonstrate
that our model can be improved substantially through the use of link prediction models and dense
latent representations of the underlying argument and relations. This variant, denoted ProbL,
improves the state of the art on our evaluation dataset to 0.8143. In addition to developing a new
framework and providing novel scores of relational implication, we provide two pragmatic resources
to assist future research. First, we motivate and develop an improved crowd framework for constructing
labelled datasets of relational implication. Using this, we reannotate and make public a dataset
comprised of 17,848 instances of labelled relational implication. We demonstrate that precision
(as evaluated by expert consensus with the crowd labels) on the resulting dataset improves from
53% to 95%. 