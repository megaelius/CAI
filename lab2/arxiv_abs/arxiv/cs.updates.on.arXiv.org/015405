Histopathologic diagnosis relies on integration of simultaneous information from a broad range
of scales, ranging from nuclear aberrations ($\approx \mathcal{O}(0.1\ \rm{\mu m})$) through
cellular structures ($\approx \mathcal{O}(10\ \rm{\mu m})$) to the global tissue architecture
($\gtrapprox \mathcal{O}(1\ \rm{mm})$). To explicitly mimic how human pathologists combine
multi-scale information, we introduce a family of multi-encoder fully-convolutional neural
networks with deep fusion. We present a simple block for merging model paths with differing spatial
scales in a spatial relationship-preserving fashion, which can readily be included in standard
encoder-decoder networks and at various levels. Additionally, a context classification gate
block is suggested as an alternative for the incorporation of solely global context. Furthermore,
deep guidance by an additional classification loss is studied. Our experiments on whole-slide
images of hepatocellular carcinoma show that the multi-scale architectures outperform a baseline
U-Net by a large margin. The setups benefit from both local as well as global context and particularly
from a combination of both. If feature maps from different scales are fused, doing so in a spatial
relationship preserving manner is found to be beneficial. Deep guidance seems to speed up and stabilize
model training. Additional path fusions are shown to be possible at low computational cost which
considerably increases the set of possible multi-scale architectures. The findings demonstrate
the potential of the introduced family of human-inspired, end-to-end trainable, multi-scale
multi-encoder fully-convolutional neural networks to improve deep histopathologic diagnosis
by extensive integration of largely different spatial scales. 