We consider the problem of cross-view geo-localization. The primary challenge of this task is to
learn the robust feature against large viewpoint changes. Existing benchmarks can help, but are
limited in the number of viewpoints. Image pairs, containing two viewpoints, e.g., satellite and
ground, are usually provided, which may compromise the feature learning. Besides phone cameras
and satellites, in this paper, we argue that drones could serve as the third platform to deal with
the geo-localization problem. In contrast to the traditional ground-view images, drone-view
images meet fewer obstacles, e.g., trees, and could provide a comprehensive view when flying around
the target place. To verify the effectiveness of the drone platform, we introduce a new multi-view
multi-source benchmark for drone-based geo-localization, named University-1652. University-1652
contains data from three platforms, i.e., synthetic drones, satellites and ground cameras of 1,652
university buildings around the world. To our knowledge, University-1652 is the first drone-based
geo-localization dataset and enables two new tasks, i.e., drone-view target localization and
drone navigation. As the name implies, drone-view target localization intends to predict the location
of the target place via drone-view images. On the other hand, given a satellite-view query image,
drone navigation is to drive the drone to the area of interest in the query. We use this dataset to analyze
a variety of off-the-shelf CNN features and propose a strong CNN baseline on this challenging dataset.
The experiments show that University-1652 helps the model to learn the viewpoint-invariant features
and also has good generalization ability in the real-world scenario. 