The penalized least squares (PLS) is a classic method to solve inverse problems, where a regularization
term is added to stabilize the solution. Optimal transport (OT) is another mathematical framework
that has recently received significant attention by computer vision community, for it provides
means to transport one distribution to another in an unsupervised manner. The cycle-consistent
generative adversarial network (cycleGAN) is a recent extension of GAN to learn target distributions
with less mode collapsing behavior. Although similar in that no supervised training is required,
the algorithms look different, so the mathematical relationship between these approaches is not
clear. In this article, we provide an important advance to unveil the missing link. Specifically,
we propose a novel PLS cost by imposing a deep learning-based inverse path as a regularization term.
When used as a transportation cost for optimal transport formulation, we show that this new PLS formulation
leads to a novel cycleGAN architecture as a Kantorovich dual OT formulation. One of the most important
advantages of this formulation is that depending on the knowledge of the forward problem, distinct
variations of cycleGAN architecture can be derived: for example, one with two pairs of generators
and discriminators, and the other with only a single pair of generator and discriminator. Even for
the two generator cases, we show that the structural knowledge of the forward operator can lead to
a simpler generator architecture which significantly simplifies the neural network training.
The new cycleGAN formulation, what we call the OT-cycleGAN, have been applied for various biomedical
imaging problems, such as accelerated magnetic resonance imaging (MRI), super-resolution microscopy,
and low-dose x-ray computed tomography (CT). Experimental results confirm the efficacy and flexibility
of the theory. 