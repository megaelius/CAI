Contrast-enhanced computed tomography angiograms (CTAs) are widely used in cardiovascular imaging
to obtain a non-invasive view of arterial structures. However, contrast agents are associated
with complications at the injection site as well as renal toxicity leading to contrast-induced
nephropathy (CIN) and renal failure. We hypothesised that the raw data acquired from a non-contrast
CT contains sufficient information to differentiate blood and other soft tissue components. We
utilised deep learning methods to define the subtleties between soft tissue components in order
to simulate contrast enhanced CTAs without contrast agents. Twenty-six patients with paired non-contrast
and CTA images were randomly selected from an approved clinical study. Non-contrast axial slices
within the AAA from 10 patients (n = 100) were sampled for the underlying Hounsfield unit (HU) distribution
at the lumen, intra-luminal thrombus and interface locations. Sampling of HUs in these regions
revealed significant differences between all regions (p<0.001 for all comparisons), confirming
the intrinsic differences in the radiomic signatures between these regions. To generate a large
training dataset, paired axial slices from the training set (n=13) were augmented to produce a total
of 23,551 2-D images. We trained a 2-D Cycle Generative Adversarial Network (cycleGAN) for this
non-contrast to contrast (NC2C) transformation task. The accuracy of the cycleGAN output was assessed
by comparison to the contrast image. This pipeline is able to differentiate between visually incoherent
soft tissue regions in non-contrast CT images. The CTAs generated from the non-contrast images
bear strong resemblance to the ground truth. Here we describe a novel application of Generative
Adversarial Network for CT image processing. This is poised to disrupt clinical pathways requiring
contrast enhanced CT imaging. 