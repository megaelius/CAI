Deep learning based task systems normally rely on a large amount of manually labeled training data,
which is expensive to obtain and subject to operator variations. Moreover, it does not always hold
that the manually labeled data and the unlabeled data are sitting in the same distribution. In this
paper, we alleviate these problems by proposing a discriminative consistent domain generation
(DCDG) approach to achieve a semi-supervised learning. The discriminative consistent domain
is achieved by a double-sided domain adaptation. The double-sided domain adaptation aims to make
a fusion of the feature spaces of labeled data and unlabeled data. In this way, we can fit the differences
of various distributions between labeled data and unlabeled data. In order to keep the discriminativeness
of generated consistent domain for the task learning, we apply an indirect learning for the double-sided
domain adaptation. Based on the generated discriminative consistent domain, we can use the unlabeled
data to learn the task model along with the labeled data via a consistent image generation. We demonstrate
the performance of our proposed DCDG on the late gadolinium enhancement cardiac MRI (LGE-CMRI)
images acquired from patients with atrial fibrillation in two clinical centers for the segmentation
of the left atrium anatomy (LA) and proximal pulmonary veins (PVs). The experiments show that our
semi-supervised approach achieves compelling segmentation results, which can prove the robustness
of DCDG for the semi-supervised learning using the unlabeled data along with labeled data acquired
from a single center or multicenter studies. 