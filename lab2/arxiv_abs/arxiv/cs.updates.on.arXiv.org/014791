Current cloud computing frameworks host millions of physical servers that utilize cloud computing
resources in the form of different virtual machines (VM). Cloud Data Center (CDC) infrastructures
require significant amounts of energy to deliver large scale computational services. Computing
nodes generate large volumes of heat, requiring cooling units in turn to eliminate the effect of
this heat. Thus, the overall energy consumption of the CDC increases tremendously for servers as
well as for cooling units. However, current workload allocation policies do not take into account
the effect on temperature and it is challenging to simulate the thermal behavior of CDCs. There is
a need for a thermal-aware framework to simulate and model the behavior of nodes and measure the important
performance parameters which can be affected by its temperature. In this paper, we propose a lightweight
framework, ThermoSim, for modeling and simulation of thermal-aware resource management for cloud
computing environments. This work presents a Recurrent Neural Network based deep learning temperature
predictor for CDCs which is utilized by ThermoSim for lightweight resource management in constrained
cloud environments. ThermoSim extends the CloudSim toolkit helping to analyze the performance
of various key parameters such as energy consumption, SLA violation rate, number of VM migrations
and temperature during the management of cloud resources for execution of workloads. Further,
different energy-aware and thermal-aware resource management techniques are tested using the
proposed ThermoSim framework in order to validate it against the existing framework. The experimental
results demonstrate the proposed framework is capable of modeling and simulating the thermal behavior
of a CDC and the ThermoSim framework is better than Thas in terms of energy consumption, cost, time,
memory usage & prediction accuracy. 