In this paper, a real-time Internet of Things (IoT) monitoring system is considered in which the
IoT devices are scheduled to sample underlying physical processes and send the status updates to
a common destination. In a real-world IoT, due to the possibly different dynamics of each physical
process, the sizes of the status updates for different devices are often different and each status
update typically requires multiple transmission slots. By taking into account such multi-time
slot transmissions with non-uniform sizes of the status updates under noisy channels, the problem
of joint device scheduling and status sampling is studied in order to minimize the average age of
information (AoI) at the destination. This stochastic problem is formulated as an infinite horizon
average cost Markov decision process (MDP). The monotonicity of the value function of the MDP is
characterized and then used to show that the optimal scheduling and sampling policy is threshold-based
with respect to the AoI at each device. To overcome the curse of dimensionality, a low-complexity
suboptimal policy is proposed through a semi-randomized base policy and linear approximated value
functions. The proposed suboptimal policy is shown to exhibit a similar structure to the optimal
policy, which provides a structural base for its effective performance. A structure-aware algorithm
is then developed to obtain the suboptimal policy. The analytical results are further extended
to the IoT monitoring system with random status update arrivals, for which, the optimal scheduling
and sampling policy is also shown to be threshold-based with the AoI at each device. Simulation results
illustrate the structures of the optimal policy and show a near-optimal AoI performance resulting
from the proposed suboptimal solution approach. 