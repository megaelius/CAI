This paper attempts to answer a central question in unsupervised learning: what does it mean to "make
sense" of a sensory sequence? In our formalization, making sense involves constructing a symbolic
causal theory that explains the sensory sequence and satisfies a set of unity conditions. This model
was inspired by Kant's discussion of the synthetic unity of apperception in the Critique of Pure
Reason. On our account, making sense of sensory input is a type of program synthesis, but it is unsupervised
program synthesis. Our second contribution is a computer implementation, the Apperception Engine,
that was designed to satisfy the above requirements. Our system is able to produce interpretable
human-readable causal theories from very small amounts of data, because of the strong inductive
bias provided by the Kantian unity constraints. A causal theory produced by our system is able to
predict future sensor readings, as well as retrodict earlier readings, and "impute" (fill in the
blanks of) missing sensory readings, in any combination. We tested the engine in a diverse variety
of domains, including cellular automata, rhythms and simple nursery tunes, multi-modal binding
problems, occlusion tasks, and sequence induction IQ tests. In each domain, we test our engine's
ability to predict future sensor values, retrodict earlier sensor values, and impute missing sensory
data. The Apperception Engine performs well in all these domains, significantly out-performing
neural net baselines. We note in particular that in the sequence induction IQ tasks, our system achieved
human-level performance. This is notable because our system is not a bespoke system designed specifically
to solve IQ tasks, but a general purpose apperception system that was designed to make sense of any
sensory sequence. 