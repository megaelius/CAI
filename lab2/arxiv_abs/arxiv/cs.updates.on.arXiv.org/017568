Video anomaly detection under video-level labels is currently a challenging task. Previous works
have made progresses on discriminating whether a video sequencecontains anomalies. However,
most of them fail to accurately localize the anomalous events within videos in the temporal domain.
In this paper, we propose a Weakly Supervised Anomaly Localization (WSAL) method focusing on temporally
localizing anomalous segments within anomalous videos. Inspired by the appearance difference
in anomalous videos, the evolution of adjacent temporal segments is evaluated for the localization
of anomalous segments. To this end, a high-order context encoding model is proposed to not only extract
semantic representations but also measure the dynamic variations so that the temporal context
could be effectively utilized. In addition, in order to fully utilize the spatial context information,
the immediate semantics are directly derived from the segment representations. The dynamic variations
as well as the immediate semantics, are efficiently aggregated to obtain the final anomaly scores.
An enhancement strategy is further proposed to deal with noise interference and the absence of localization
guidance in anomaly detection. Moreover, to facilitate the diversity requirement for anomaly
detection benchmarks, we also collect a new traffic anomaly (TAD) dataset which specifies in the
traffic conditions, differing greatly from the current popular anomaly detection evaluation
benchmarks.Extensive experiments are conducted to verify the effectiveness of different components,
and our proposed method achieves new state-of-the-art performance on the UCF-Crime and TAD datasets.
