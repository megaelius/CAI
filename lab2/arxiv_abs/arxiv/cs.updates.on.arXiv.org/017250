The design of building heating, ventilation, and air conditioning (HVAC) system is critically
important, as it accounts for around half of building energy consumption and directly affects occupant
comfort, productivity, and health. Traditional HVAC control methods are typically based on creating
explicit physical models for building thermal dynamics, which often require significant effort
to develop and are difficult to achieve sufficient accuracy and efficiency for runtime building
control and scalability for field implementations. Recently, deep reinforcement learning (DRL)
has emerged as a promising data-driven method that provides good control performance without analyzing
physical models at runtime. However, a major challenge to DRL (and many other data-driven learning
methods) is the long training time it takes to reach the desired performance. In this work, we present
a novel transfer learning based approach to overcome this challenge. Our approach can effectively
transfer a DRL-based HVAC controller trained for the source building to a controller for the target
building with minimal effort and improved performance, by decomposing the design of neural network
controller into a transferable front-end network that captures building-agnostic behavior and
a back-end network that can be efficiently trained for each specific building. We conducted experiments
on a variety of transfer scenarios between buildings with different sizes, numbers of thermal zones,
materials and layouts, air conditioner types, and ambient weather conditions. The experimental
results demonstrated the effectiveness of our approach in significantly reducing the training
time, energy cost, and temperature violations. 