In this paper, we propose a novel robocentric formulation of the visual-inertial navigation system
(VINS) within a sliding-window filtering framework and design an efficient, lightweight, robocentric
visual-inertial odometry (R-VIO) algorithm for consistent motion tracking even in challenging
environments using only a monocular camera and a 6-axis IMU. The key idea is to deliberately reformulate
the VINS with respect to a moving local frame, rather than a fixed global frame of reference as in the
standard world-centric VINS, in order to obtain relative motion estimates of higher accuracy for
updating global poses. As an immediate advantage of this robocentric formulation, the proposed
R-VIO can start from an arbitrary pose, without the need to align the initial orientation with the
global gravitational direction. More importantly, we analytically show that the linearized robocentric
VINS does not undergo the observability mismatch issue as in the standard world-centric counterpart
which was identified in the literature as the main cause of estimation inconsistency. Additionally,
we investigate in-depth the special motions that degrade the performance in the world-centric
formulation and show that such degenerate cases can be easily compensated in the proposed robocentric
formulation, without resorting to additional sensors as in the world-centric formulation, thus
leading to better robustness. The proposed R-VIO algorithm has been extensively tested through
both Monte Carlo simulations and real-world experiments with different sensor platforms navigating
in different environments, and shown to achieve better (or competitive at least) performance than
the state-of-the-art VINS, in terms of consistency, accuracy and efficiency. 