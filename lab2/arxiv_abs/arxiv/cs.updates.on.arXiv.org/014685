Over-the-air computation (AirComp)-based federated learning (FL) enables low-latency uploads
and the aggregation of machine learning models by exploiting simultaneous co-channel transmission
and the resultant waveform superposition. This study aims at realizing secure AirComp-based FL
against various privacy attacks where malicious central servers infer clients' private data from
aggregated global models. To this end, a differentially private AirComp-based FL is designed in
this study, where the key idea is to harness receiver noise perturbation injected to aggregated
global models inherently, thereby preventing the inference of clients' private data. However,
the variance of the inherent receiver noise is often uncontrollable, which renders the process
of injecting an appropriate noise perturbation to achieve a desired privacy level quite challenging.
Hence, this study designs transmit power control across clients, wherein the received signal level
is adjusted intentionally to control the noise perturbation levels effectively, thereby achieving
the desired privacy level. It is observed that a higher privacy level requires lower transmit power,
which indicates the tradeoff between the privacy level and signal-to-noise ratio (SNR). To understand
this tradeoff more fully, the closed-form expressions of SNR (with respect to the privacy level)
are derived, and the tradeoff is analytically demonstrated. The analytical results also demonstrate
that among the configurable parameters, the number of participating clients is a key parameter
that enhances the received SNR under the aforementioned tradeoff. The analytical results are validated
through numerical evaluations. 