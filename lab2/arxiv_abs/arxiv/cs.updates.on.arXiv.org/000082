The study of inter-human communication requires a more complex framework than Shannon's (1948)
mathematical theory of communication because "information" is defined in the latter case as meaningless
uncertainty. Assuming that meaning cannot be communicated, we extend Shannon's theory by defining
mutual redundancy as a positional counterpart of the relational communication of information.
Mutual redundancy indicates the surplus of meanings that can be provided to the exchanges in reflexive
communications. The information is redundant because based on "pure sets," that is, without subtraction
of mutual information in the overlaps. We show that in the three-dimensional case (e.g., of a Triple
Helix of university-industry-government relations), mutual redundancy is equal to mutual information
(Rxyz = Txyz); but when the dimensionality is even, the sign is different. We generalize to the measurement
in N dimensions and proceed to the interpretation. Using Luhmann's social-systems theory and/or
Giddens' structuration theory, mutual redundancy can be provided with an interpretation in the
sociological case: different meaning-processing structures code and decode with other algorithms.
A surplus of ("absent") options can then be generated that add to the redundancy. Luhmann's "functional
(sub)systems" of expectations or Giddens' "rule-resource sets" are positioned mutually, but
coupled operationally in events or "instantiated" in actions. Shannon-type information is generated
by the mediation, but the "structures" are (re-)positioned towards one another as sets of (potentially
counterfactual) expectations. The structural differences among the coding and decoding algorithms
provide a source of additional options in reflexive and anticipatory communications. 