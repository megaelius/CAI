Automatic quantification of human interaction behaviors based on language information has been
shown to be effective in psychotherapy research domains such as marital therapy and cancer care.
Existing systems typically use a moving-window approach where the target behavior construct is
first quantified based on observations inside a window, such as a fixed number of words or turns,
and then integrated over all the windows in that interaction. Given a behavior of interest, it is
important to employ the appropriate length of observation, since too short a window might not contain
sufficient information. Unfortunately, the link between behavior and observation length for
lexical cues has not been well studied and it is not clear how these requirements relate to the characteristics
of the target behavior construct. Therefore, in this paper, we investigate how the choice of window
length affects the efficacy of language-based behavior quantification, by analyzing (a) the similarity
between system predictions and human expert assessments for the same behavior construct and (b)
the consistency in relations between predictions of related behavior constructs. We apply our
analysis to a large and diverse set of behavior codes that are used to annotate real-life interactions
and find that behaviors related to negative affect can be quantified from just a few words whereas
those related to positive traits and problem solving require much longer observation windows.
On the other hand, constructs that describe dysphoric affect do not appear to be quantifiable from
language information alone, regardless of how long they are observed. We compare our findings with
related work on behavior quantification based on acoustic vocal cues as well as with prior work on
thin slices and human personality predictions and find that, in general, they are in agreement.
