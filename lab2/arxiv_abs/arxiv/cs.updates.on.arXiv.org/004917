Consider a set of agents that wish to estimate a vector of parameters of their mutual interest. For
this estimation goal, agents can sense and communicate. When sensing, an agent measures (in additive
gaussian noise) linear combinations of the unknown vector of parameters. When communicating,
an agent can broadcast information to a few other agents, by using the channels that happen to be randomly
at its disposal at the time. To coordinate the agents towards their estimation goal, we propose a
novel algorithm called FADE (Fast and Asymptotically efficient Distributed Estimator), in which
agents collaborate at discrete time-steps; at each time-step, agents sense and communicate just
once, while also updating their own estimate of the unknown vector of parameters. FADE enjoys five
attractive features: first, it is an intuitive estimator, simple to derive; second, it withstands
dynamic networks, that is, networks whose communication channels change randomly over time; third,
it is strongly consistent in that, as time-steps play out, each agent's local estimate converges
(almost surely) to the true vector of parameters; fourth, it is both asymptotically unbiased and
efficient, which means that, across time, each agent's estimate becomes unbiased and the mean-square
error (MSE) of each agent's estimate vanishes to zero at the same rate of the MSE of the optimal estimator
at an almighty central node; fifth, and most importantly, when compared with a state-of-art consensus+innovation
(CI) algorithm, it yields estimates with outstandingly lower mean-square errors, for the same
number of communications -- for example, in a sparsely connected network model with 50 agents, we
find through numerical simulations that the reduction can be dramatic, reaching several orders
of magnitude. 