A widely used method for solving SOS (Sum Of Squares) decomposition problem is to reduce it to the
problem of semi-definite programs (SDPs) which can be efficiently solved in theory. In practice,
although many SDP solvers can work out some problems of big scale, the efficiency and reliability
of such method decrease greatly while the input size increases. Recently, by exploiting the sparsity
of the input SOS decomposition problem, some preprocessing algorithms were proposed [5,17], which
first divide the input problem satisfying special definitions or properties into smaller SDP problems
and then pass the smaller ones to SDP solvers to obtain reliable results efficiently. A natural question
is that to what extent the above mentioned preprocessing algorithms work. That is, how many polynomials
satisfying those definitions or properties are there in the SOS polynomials? In this paper, we define
a concept of block SOS decomposable polynomials which is a generalization of those special classes
in [5] and [17]. Roughly speaking, it is a class of polynomials whose SOS decomposition problem can
be transformed into smaller ones (in other words, the corresponding SDP matrices can be block-diagnolized)
by considering their supports only (coefficients are not considered). Then we prove that the set
of block SOS decomposable polynomials has measure zero in the set of SOS polynomials. That means
if we only consider supports (not with coefficients) of polynomials, such algorithms decreasing
the size of SDPs for those SDP-based SOS solvers can only work on very few polynomials. As a result,
this shows that the SOS decomposition problems that can be optimized by the above mentioned preprocessing
algorithms are very few. 