Information dissemination is a fundamental problem in parallel and distributed computing. In
its simplest variant, the broadcasting problem, a message has to be spread among all nodes of a graph.
A prominent communication protocol for this problem is based on the random phone call model (Karp
et al., FOCS 2000). In each step, every node opens a communication channel to a randomly chosen neighbor
for bi-directional communication. Motivated by replicated databases and peer-to-peer networks,
Berenbrink et al., ICALP 2010, considered the gossiping problem in the random phone call model.
There, each node starts with its own message and all messages have to be disseminated to all nodes
in the network. They showed that any $O(\log n)$-time algorithm in complete graphs requires $\Omega(\log
n)$ message transmissions per node to complete gossiping, w.h.p, while for broadcasting the average
number of transmissions per node is $O(\log\log n)$. It is known that the $O(n\log\log n)$ bound
on the number of transmissions required for randomized broadcasting in complete graphs cannot
be achieved in sparse graphs even if they have best expansion and connectivity properties. In this
paper, we analyze whether a similar influence of the graph density also holds w.r.t. the performance
of gossiping. We study analytically and empirically the communication overhead generated by randomized
gossiping in random graphs and consider simple modifications of the random phone call model in these
graphs. Our results indicate that, unlike in broadcasting, there is no significant difference
between the performance of randomized gossiping in complete graphs and sparse random graphs. Furthermore,
our simulations indicate that by tuning the parameters of our algorithms, we can significantly
reduce the communication overhead compared to the traditional push-pull approach in the graphs
we consider. 