Quantification of anatomical shape changes still relies on scalar global indexes which are largely
insensitive to regional or asymmetric modifications. Accurate assessment of pathology-driven
anatomical remodeling is a crucial step for the diagnosis and treatment of heart conditions. Deep
learning approaches have recently achieved wide success in the analysis of medical images, but
they lack interpretability in the feature extraction and decision processes. In this work, we propose
a new interpretable deep learning model for shape analysis. In particular, we exploit deep generative
networks to model a population of anatomical segmentations through a hierarchy of conditional
latent variables. At the highest level of this hierarchy, a two-dimensional latent space is simultaneously
optimised to discriminate distinct clinical conditions, enabling the direct visualisation of
the classification space. Moreover, the anatomical variability encoded by this discriminative
latent space can be visualised in the segmentation space thanks to the generative properties of
the model, making the classification task transparent. This approach yielded high accuracy in
the categorisation of healthy and remodelled hearts when tested on unseen segmentations from our
own multi-centre dataset as well as in an external validation set. More importantly, it enabled
the visualisation in three-dimensions of the most discriminative anatomical features between
the two conditions. The proposed approach scales effectively to large populations, facilitating
high-throughput analysis of normal anatomy and pathology in large-scale studies of volumetric
imaging. 