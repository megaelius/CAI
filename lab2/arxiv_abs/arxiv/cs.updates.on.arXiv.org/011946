Many scientific applications consist of large and computationally-intensive loops. Dynamic
loop self-scheduling (DLS) techniques are used to parallelize and to balance the load during the
execution of such applications. Load imbalance arises from variations in the loop iteration (or
tasks) execution times, caused by problem, algorithmic, or systemic characteristics. The variations
in systemic characteristics are referred to as perturbations, and can be caused by other applications
or processes that share the same resources, or a temporary system fault or malfunction. Therefore,
the selection of the most efficient DLS technique is critical to achieve the best application performance.
The following question motivates this work: Given an application, an HPC system, and their characteristics
and interplay, which DLS technique will achieve improved performance under unpredictable perturbations?
Existing studies focus on variations in the delivered computational speed only as the source of
perturbations in the system. However, perturbations in available network bandwidth or latency
are inevitable on production HPC systems. A Simulator-assisted scheduling (SimAS) is introduced
as a new control-theoretic-inspired approach to dynamically select DLS techniques that improve
the performance of applications executing on heterogeneous HPC systems under perturbations.
The present work examines the performance of seven applications on a heterogeneous system under
all the above system perturbations. SimAS is evaluated as a proof of concept using native and simulative
experiments. The performance results confirm the original hypothesis that no single DLS technique
can deliver the absolute best performance in all scenarios, whereas the SimAS-based DLS selection
resulted in improved application performance in most experiments. 