In this paper, we propose a new estimation procedure for discovering the structure of Gaussian Markov
random fields (MRFs) with false discovery rate (FDR) control, making use of the sorted l1-norm (SL1)
regularization. A Gaussian MRF is an acyclic graph representing a multivariate Gaussian distribution,
where nodes are random variables and edges represent the conditional dependence between the connected
nodes. Since it is possible to learn the edge structure of Gaussian MRFs directly from data, Gaussian
MRFs provide an excellent way to understand complex data by revealing the dependence structure
among many inputs features, such as genes, sensors, users, documents, etc. In learning the graphical
structure of Gaussian MRFs, it is desired to discover the actual edges of the underlying but unknown
probabilistic graphical model-it becomes more complicated when the number of random variables
(features) p increases, compared to the number of data points n. In particular, when p >> n, it is statistically
unavoidable for any estimation procedure to include false edges. Therefore, there have been many
trials to reduce the false detection of edges, in particular, using different types of regularization
on the learning parameters. Our method makes use of the SL1 regularization, introduced recently
for model selection in linear regression. We focus on the benefit of SL1 regularization that it can
be used to control the FDR of detecting important random variables. Adapting SL1 for probabilistic
graphical models, we show that SL1 can be used for the structure learning of Gaussian MRFs using our
suggested procedure nsSLOPE (neighborhood selection Sorted L-One Penalized Estimation), controlling
the FDR of detecting edges. 