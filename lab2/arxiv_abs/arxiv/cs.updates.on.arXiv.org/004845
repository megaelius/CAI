We introduce the Riemannian Motion Policy (RMP), a new mathematical object for modular motion generation.
An RMP is a second-order dynamical system (acceleration field or motion policy) coupled with a corresponding
Riemannian metric. The motion policy maps positions and velocities to accelerations, while the
metric captures the directions in the space important to the policy. We show that RMPs provide a straightforward
and convenient method for combining multiple motion policies and transforming such policies from
one space (such as the task space) to another (such as the configuration space) in geometrically
consistent ways. The operators we derive for these combinations and transformations are provably
optimal, have linearity properties making them agnostic to the order of application, and are strongly
analogous to the covariant transformations of natural gradients popular in the machine learning
literature. The RMP framework enables the fusion of motion policies from different motion generation
paradigms, such as dynamical systems, dynamic movement primitives (DMPs), optimal control, operational
space control, nonlinear reactive controllers, motion optimization, and model predictive control
(MPC), thus unifying these disparate techniques from the literature. RMPs are easy to implement
and manipulate, facilitate controller design, simplify handling of joint limits, and clarify
a number of open questions regarding the proper fusion of motion generation methods (such as incorporating
local reactive policies into long-horizon optimizers). We demonstrate the effectiveness of RMPs
on both simulation and real robots, including their ability to naturally and efficiently solve
complicated collision avoidance problems previously handled by more complex planners. 