During the recent years, correlation filters have shown dominant and spectacular results for visual
object tracking. The types of the features that are employed in these family of trackers significantly
affect the performance of visual tracking. The ultimate goal is to utilize robust features invariant
to any kind of appearance change of the object, while predicting the object location as properly
as in the case of no appearance change. As the deep learning based methods have emerged, the study
of learning features for specific tasks has accelerated. For instance, discriminative visual
tracking methods based on deep architectures have been studied with promising performance. Nevertheless,
correlation filter based (CFB) trackers confine themselves to use the pre-trained networks which
are trained for object classification problem. To this end, in this manuscript the problem of learning
deep fully convolutional features for the CFB visual tracking is formulated. In order to learn the
proposed model, a novel and efficient backpropagation algorithm is presented based on the loss
function of the network. The proposed learning framework enables the network model to be flexible
for a custom design. Moreover, it alleviates the dependency on the network trained for classification.
Extensive performance analysis shows the efficacy of the proposed custom design in the CFB tracking
framework. By fine-tuning the convolutional parts of a state-of-the-art network and integrating
this model to a CFB tracker, which is the top performing one of VOT2016, 18% increase is achieved in
terms of expected average overlap, and tracking failures are decreased by 25%, while maintaining
the superiority over the state-of-the-art methods in OTB-2013 and OTB-2015 tracking datasets.
