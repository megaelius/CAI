With an aim to increase the capture range and accelerate the performance of state-of-the-art inter-subject
and subject-to-template 3D registration, we propose deep learning-based methods that are trained
to find the 3D position of arbitrarily oriented subjects or anatomy based on slices or volumes of
medical images. For this, we propose regression CNNs that learn to predict the angle-axis representation
of 3D rotations and translations using image features. We use and compare mean square error and geodesic
loss to train regression CNNs for 3D pose estimation used in two different scenarios: slice-to-volume
registration and volume-to-volume registration. Our results show that in such registration applications
that are amendable to learning, the proposed deep learning methods with geodesic loss minimization
can achieve accurate results with a wide capture range in real-time (<100ms). We also tested the
generalization capability of the trained CNNs on an expanded age range and on images of newborn subjects
with similar and different MR image contrasts. We trained our models on T2-weighted fetal brain
MRI scans and used them to predict the 3D pose of newborn brains based on T1-weighted MRI scans. We
showed that the trained models generalized well for the new domain when we performed image contrast
transfer through a conditional generative adversarial network. This indicates that the domain
of application of the trained deep regression CNNs can be further expanded to image modalities and
contrasts other than those used in training. A combination of our proposed methods with accelerated
optimization-based registration algorithms can dramatically enhance the performance of automatic
imaging devices and image processing methods of the future. 