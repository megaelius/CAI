Designing a lightweight and robust portrait segmentation algorithm is an important task for a wide
range of face applications. However, the problem has been considered as a subset of the object segmentation
problem and less handled in the semantic segmentation field. Obviously, portrait segmentation
has its unique requirements. First, because the portrait segmentation is performed in the middle
of a whole process of many real-world applications, it requires extremely lightweight models.
Second, there has not been any public datasets in this domain that contain a sufficient number of
images with unbiased statistics. To solve the first problem, we introduce the new extremely lightweight
portrait segmentation model SINet, containing an information blocking decoder and spatial squeeze
modules. The information blocking decoder uses confidence estimates to recover local spatial
information without spoiling global consistency. The spatial squeeze module uses multiple receptive
fields to cope with various sizes of consistency in the image. To tackle the second problem, we propose
a simple method to create additional portrait segmentation data which can improve accuracy on the
EG1800 dataset. In our qualitative and quantitative analysis on the EG1800 dataset, we show that
our method outperforms various existing lightweight segmentation models. Our method reduces
the number of parameters from2.1Mto86.9K(around 95.9% reduction), while maintaining the accuracy
under an 1% margin from the state-of-the-art portrait segmentation method. We also show our model
is successfully executed on a real mobile device with 100.6 FPS. In addition, we demonstrate that
our method can be used for general semantic segmentation on the Cityscape dataset. The code is available
inhttps://github.com/HYOJINPARK/ExtPortraitSeg 