Scientific applications often contain large, computationally-intensive, and irregular parallel
loops or tasks that exhibit stochastic characteristics. Applications may suffer from load imbalance
during their execution on high-performance computing (HPC) systems due to such characteristics.
Dynamic loop self-scheduling (DLS) techniques are instrumental in improving the performance
of scientific applications on HPC systems via load balancing. Selecting a DLS technique that results
in the best performance for different problems and system sizes requires a large number of exploratory
experiments. A theoretical model that can be used to predict the scheduling technique that yields
the best performance for a given problem and system has not yet been identified. Therefore, simulation
is the most appropriate approach for conducting such exploratory experiments with reasonable
costs. This work devises an approach to realistically simulate computationally-intensive scientific
applications that employ DLS and execute on HPC systems. Several approaches to represent the application
tasks (or loop iterations) are compared to establish their influence on the simulative application
performance. A novel simulation strategy is introduced, which transforms a native application
code into a simulative code. The native and simulative performance of two computationally-intensive
scientific applications are compared to evaluate the realism of the proposed simulation approach.
The comparison of the performance characteristics extracted from the native and simulative performance
shows that the proposed simulation approach fully captured most of the performance characteristics
of interest. This work shows and establishes the importance of simulations that realistically
predict the performance of DLS techniques for different applications and system configurations.
