Several municipalities have recently installed wireless 'smart' water meters that allow functionalities
such as demand response, leak alerts, identification of characteristic demand patterns, and detailed
consumption analysis. To achieve these benefits, the meter data needs to be error-free, which is
not necessarily available in practice, due to 'dirtiness' or 'uncertainty' of data, which is mostly
unavoidable. The focus of this paper is to investigate practical solutions to mine uncertain data
for reliable results and to evaluate the impact of dirty data on filters. This evaluation would eventually
lead to valuable information, which can be used for educated decision making on water planning strategies.
We perform a systematic study of the errors existing in a large-scale smart water meter deployments,
which is helpful to better understand the nature of errors. Identifying customers contributing
to a load peak is used as the main filter. The filter outputs are then combined with the domain expert
knowledge to evaluate their accuracy and validity and also to look for potential errors. After discovering
each error, we analyze its trails in the data and track back its source, which would eventually lead
to the removal of the error or dealing with it accordingly. This procedure is applied progressively
to ensure that all detectable errors are discovered and characterized in the data model. We evaluate
the performance of the proposed approach using the smart water meter consumption data obtained
from the City of Abbotsford, British Columbia, Canada. We present the results of both unprocessed
and cleaned data and analyze, in detail, the sensitivity of the selected filter to the errors. 