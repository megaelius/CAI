Deep convolutional neural networks have achieved remarkable progress on a variety of medical image
computing tasks. A common problem when applying supervised deep learning methods to medical images
is the lack of labeled data, which is very expensive and time-consuming to be collected. In this paper,
we present a novel semi-supervised method for medical image segmentation, where the network is
optimized by the weighted combination of a common supervised loss for labeled inputs only and a regularization
loss for both labeled and unlabeled data. To utilize the unlabeled data, our method encourages the
consistent predictions of the network-in-training for the same input under different regularizations.
Aiming for the semi-supervised segmentation problem, we enhance the effect of regularization
for pixel-level predictions by introducing a transformation, including rotation and flipping,
consistent scheme in our self-ensembling model. With the aim of semi-supervised segmentation
tasks, we introduce a transformation consistent strategy in our self-ensembling model to enhance
the regularization effect for pixel-level predictions. We have extensively validated the proposed
semi-supervised method on three typical yet challenging medical image segmentation tasks: (i)
skin lesion segmentation from dermoscopy images on International Skin Imaging Collaboration
(ISIC) 2017 dataset, (ii) optic disc segmentation from fundus images on Retinal Fundus Glaucoma
Challenge (REFUGE) dataset, and (iii) liver segmentation from volumetric CT scans on Liver Tumor
Segmentation Challenge (LiTS) dataset. Compared to the state-of-the-arts, our proposed method
shows superior segmentation performance on challenging 2D/3D medical images, demonstrating
the effectiveness of our semi-supervised method for medical image segmentation. 