Polar coding gives rise to the first explicit family of codes that provably achieve capacity with
efficient encoding and decoding for a wide range of channels. However, its performance at short
block lengths is far from optimal. Arikan has recently presented a new polar coding scheme, which
he called polarization-adjusted convolutional (PAC) codes. Such PAC codes provide dramatic improvement
in performance as compared to both standard successive-cancellation decoding as well as CRC-aided
list decoding. Arikan's PAC codes are based primarily upon the following ideas: replacing CRC precoding
with convolutional precoding (under appropriate rate profiling) and replacing list decoding
by sequential decoding. His simulations show that PAC codes, resulting from the combination of
these ideas, are close to finite-length bounds on the performance of any code under ML decoding.
One of our main goals in this paper is to answer the following question: is sequential decoding essential
for the superior performance of PAC codes? We show that similar performance can be achieved using
list decoding when the list size $L$ is moderately large (say, $L \ge 128$). List decoding has distinct
advantages over sequential decoding is certain scenarios, such as low-SNR regimes or situations
where the worst-case complexity/latency is the primary constraint. Another objective is to provide
some insights into the remarkable performance of PAC codes. We first observe that both sequential
decoding and list decoding of PAC codes closely match ML decoding thereof. We then estimate the number
of low weight codewords in PAC codes, using these estimates to approximate the union bound on their
performance under ML decoding. These results indicate that PAC codes are superior to both polar
codes and Reed-Muller codes, and suggest that the goal of rate-profiling may be to optimize the weight
distribution at low weights. 