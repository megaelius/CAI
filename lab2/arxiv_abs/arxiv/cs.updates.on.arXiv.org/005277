Artificial autonomous agents interacting in complex environments are required to continually
acquire and fine-tune knowledge over sustained periods of time. The ability to learn from continuous
streams of information is referred to lifelong learning and represents a long-standing challenge
for neural network models due to catastrophic forgetting in which novel sensory experience interferes
with existing representations and leads to abrupt decreases in the performance on previously acquired
knowledge. Computational models of lifelong learning typically alleviate catastrophic forgetting
in experimental scenarios with given datasets of static images and limited complexity, thereby
differing significantly from the conditions artificial agents are exposed to. In more natural
settings, sequential information may become progressively available over time and access to previous
experience may be restricted. We propose a dual-memory self-organizing architecture for lifelong
learning scenarios. The architecture comprises two growing recurrent networks with the complementary
tasks of learning object instances (episodic memory) and categories (semantic memory). Both growing
networks can expand in response to novel sensory experience: the episodic memory learns fine-grained
representations of object instances in an unsupervised fashion while the semantic memory uses
task-relevant signals to regulate levels of structural plasticity and develop more compact representations
from episodic experience. For the consolidation of knowledge in the absence of external sensory
input, the episodic memory periodically replays trajectories of neural reactivations. We evaluate
the performance of the proposed model on the CORe50 benchmark dataset for continuous object recognition,
showing that we significantly outperform current methods of lifelong learning in three different
incremental learning scenarios. 