High-density object counting in surveillance scenes is challenging mainly due to the drastic variation
of object scales. The prevalence of deep learning has largely boosted the object counting accuracy
on several benchmark datasets. However, does the global counts really count? Armed with this question
we dive into the predicted density map whose summation over the whole regions reports the global
counts for more in-depth analysis. We observe that the object density map generated by most existing
methods usually lacks of local consistency, i.e., counting errors in local regions exist unexpectedly
even though the global count seems to well match with the ground-truth. Towards this problem, in
this paper we propose a constrained multi-stage Convolutional Neural Networks (CNNs) to jointly
pursue locally consistent density map from two aspects. Different from most existing methods that
mainly rely on the multi-column architectures of plain CNNs, we exploit a stacking formulation
of plain CNNs. Benefited from the internal multi-stage learning process, the feature map could
be repeatedly refined, allowing the density map to approach the ground-truth density distribution.
For further refinement of the density map, we also propose a grid loss function. With finer local-region-based
supervisions, the underlying model is constrained to generate locally consistent density values
to minimize the training errors considering both the global and local counts accuracy. Experiments
on two widely-tested object counting benchmarks with overall significant results compared with
state-of-the-art methods demonstrate the effectiveness of our approach. 