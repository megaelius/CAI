Single Image Super Resolution (SISR) is the task of producing a high resolution (HR) image from a
given low-resolution (LR) image. It is a well researched problem with extensive commercial applications
such as digital camera, video compression, medical imaging and so on. Most super resolution works
focus on the features learning architecture, which can recover the texture details as close as possible.
However, these works suffer from the following challenges: (1) The low-resolution (LR) training
images are artificially synthesized using HR images with bicubic downsampling, which have much
richer-information than real demosaic-upscaled mobile images. The mismatch between training
and inference mobile data heavily blocks the improvement of practical super resolution algorithms.
(2) These methods cannot effectively handle the blind distortions during super resolution in practical
applications. In this work, an end-to-end novel framework, including high-to-low network and
low-to-high network, is proposed to solve the above problems with dual Generative Adversarial
Networks (GAN). First, the above mismatch problems are well explored with the high-to-low network,
where clear high-resolution image and the corresponding realistic low-resolution image pairs
can be generated. Moreover, a large-scale General Mobile Super Resolution Dataset, GMSR, is proposed,
which can be utilized for training or as a fair comparison benchmark for super resolution methods.
Second, an effective low-to-high network (super resolution network) is proposed in the framework.
Benefiting from the GMSR dataset and novel training strategies, the super resolution model can
effectively handle detail recovery and denoising at the same time. 