State-of-the-art computer codes for simulating real physical systems are often characterized
by a vast number of input parameters. Performing uncertainty quantification (UQ) tasks with Monte
Carlo (MC) methods is almost always infeasible because of the need to perform hundreds of thousands
or even millions of forward model evaluations in order to obtain convergent statistics. One, thus,
tries to construct a cheap-to-evaluate surrogate model to replace the forward model solver. For
systems with large numbers of input parameters, one has to deal with the curse of dimensionality
- the exponential increase in the volume of the input space, as the number of parameters increases
linearly. In this work, we demonstrate the use of deep neural networks (DNN) to construct surrogate
models for numerical simulators. We parameterize the structure of the DNN in a manner that lends
the DNN surrogate the interpretation of recovering a low dimensional nonlinear manifold. The model
response is a parameterized nonlinear function of the low dimensional projections of the input.
We think of this low dimensional manifold as a nonlinear generalization of the notion of the active
subspace. Our approach is demonstrated with a problem on uncertainty propagation in a stochastic
elliptic partial differential equation (SPDE) with uncertain diffusion coefficient. We deviate
from traditional formulations of the SPDE problem by not imposing a specific covariance structure
on the random diffusion coefficient. Instead, we attempt to solve a more challenging problem of
learning a map between an arbitrary snapshot of the diffusion field and the response. 