Purpose: To improve the image quality of highly accelerated multi-channel MRI data by learning
a joint variational network that reconstructs multiple clinical contrasts jointly. Methods:
Data from our multi-contrast acquisition was embedded into the variational network architecture
where shared anatomical information is exchanged by mixing the input contrasts. Complementary
k-space sampling across imaging contrasts and Bunch-Phase/Wave-Encoding were used for data acquisition
to improve the reconstruction at high accelerations. At 3T, our joint variational network approach
across T1w, T2w and T2-FLAIR-weighted brain scans was tested for retrospective under-sampling
at R=6 (2D) and R=4x4 (3D) acceleration. Prospective acceleration was also performed for 3D data
where the combined acquisition time for whole brain coverage at 1 mm isotropic resolution across
three contrasts was less than three minutes. Results: Across all test datasets, our joint multi-contrast
network better preserved fine anatomical details with reduced image-blurring when compared to
the corresponding single-contrast reconstructions. Improvement in image quality was also obtained
through complementary k-space sampling and Bunch-Phase/Wave-Encoding where the synergistic
combination yielded the overall best performance as evidenced by exemplarily slices and quantitative
error metrics. Conclusion: By leveraging shared anatomical structures across the jointly reconstructed
scans, our joint multi-contrast approach learnt more efficient regularizers which helped to retain
natural image appearance and avoid over-smoothing. When synergistically combined with advanced
encoding techniques, the performance was further improved, enabling up to R=16-fold acceleration
with good image quality. This should help pave the way to very rapid high-resolution brain exams.
