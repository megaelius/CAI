Machine learning is becoming increasingly important in scientific and technological progress,
due to its ability to create models that describe complex data and generalize well. The wealth of
publicly-available seismic data nowadays requires automated, fast, and reliable tools to carry
out a multitude of tasks, such as the detection of small, local earthquakes in areas characterized
by sparsity of receivers. A similar application of machine learning, however, should be built on
a large amount of labeled seismograms, which is neither immediate to obtain nor to compile. In this
study we present a large dataset of seismograms recorded along the vertical, north, and east components
of 1487 broad-band or very broad-band receivers distributed worldwide; this includes 629,095
3-component seismograms generated by 304,878 local earthquakes and labeled as EQ, and 615,847
ones labeled as noise (AN). Application of machine learning to this dataset shows that a simple Convolutional
Neural Network of 67,939 parameters allows discriminating between earthquakes and noise single-station
recordings, even if applied in regions not represented in the training set. Achieving an accuracy
of 96.7, 95.3, and 93.2% on training, validation, and test set, respectively, we prove that the large
variety of geological and tectonic settings covered by our data supports the generalization capabilities
of the algorithm, and makes it applicable to real-time detection of local events. We make the database
publicly available, intending to provide the seismological and broader scientific community
with a benchmark for time-series to be used as a testing ground in signal processing. 