Optical trapping techniques are an efficient way to probe limited quantities of rare isotopes.
In order to achieve the highest possible measurement precision, it is critical to optimize the optical
trapping efficiency. This work presents the development of a three-dimensional semi-classical
Monte Carlo simulation of the optical trapping process and its application to optimizing the optical
trapping efficiency of Radium for use in the search of the permanent electric dipole moment of $^{225}$Ra.
The simulation includes an effusive-oven atomic beam source, transverse cooling and Zeeman slowing
of an atomic beam, a three-dimensional magneto-optical trap, and additional processes such as
collisions with residual gas molecules. We benchmark the simulation against a well-characterized
$^{88}$Sr optical trap before applying it to the $^{225}$Ra optical trap. The simulation reproduces
the relative gains in optical trapping efficiency measured in both the $^{88}$Sr and $^{225}$Ra
optical traps. The measured and simulated values of the overall optical trapping efficiencies
for $^{88}$Sr are in agreement; however, they differ by a factor of $30$ for $^{225}$Ra. Studies
of several potential imperfections in the apparatus or systematic effects, such as atomic beam
source misalignment and laser frequency noise, show only limited effects on the simulated trapping
efficiency for $^{225}$Ra. We rule out any one systematic effect as the sole cause of the discrepancy
between the simulated and measured $^{225}$Ra optical trapping efficiencies; but, we do expect
that a combination of systematic effects contribute to this discrepancy. The accurate relative
gains predicted by the simulation prove that it is useful for testing planned upgrades to the apparatus.
