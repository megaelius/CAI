We report the Earth's rate of radiogenic heat production and (anti)neutrino luminosity from geologically
relevant short-lived radionuclides (SLR) and long-lived radionuclides (LLR) using decay constants
from the geological community, updated nuclear physics parameters, and calculations of the $\beta$
spectra. We track the time evolution of the radiogenic power and luminosity of the Earth over the
last 4.57 billion years, assuming an absolute abundance for the refractory elements in the silicate
Earth and key volatile/refractory element ratios (e.g., Fe/Al, K/U, and Rb/Sr) to set the abundance
levels for the moderately volatile elements. The relevant decays for the present-day heat production
in the Earth ($19.9\pm3.0$ TW) are from $^{40}$K, $^{87}$Rb, $^{147}$Sm, $^{232}$Th, $^{235}$U,
and $^{238}$U. Given element concentrations in kg-element/kg-rock and density $\rho$ in kg/m$^3$,
a simplified equation to calculate the present day heat production in a rock is: $$ h \, [\mu \text{W
m}^{-3}] = \rho \left( 3.387 \times 10^{-3}\,\text{K} + 0.01139 \,\text{Rb} + 0.04595\,\text{Sm}
+ 26.18\,\text{Th} + 98.29\,\text{U} \right) $$ The radiogenic heating rate of Earth-like material
at Solar System formation was some 10$^3$ to 10$^4$ times greater than present-day values, largely
due to decay of $^{26}$Al in the silicate fraction, which was the dominant radiogenic heat source
for the first $\sim10$ Ma. Assuming instantaneous Earth formation, the upper bound on radiogenic
energy supplied by the most powerful short-lived radionuclide $^{26}$Al ($t_{1/2}$ = 0.7 Ma) is
5.5$\;\times\;$10$^{31}$ J, which is comparable (within a factor of a few) to the planet's gravitational
binding energy. 