Due to the inter- and intra- variation of respiratory motion, it is highly desired to provide real-time
volumetric images during the treatment delivery of lung stereotactic body radiation therapy (SBRT)
for accurate and active motion management. In this proof-of-concept study, we propose a novel generative
adversarial network integrated with perceptual supervision to derive instantaneous volumetric
images from a single 2D projection. Our proposed network, named TransNet, consists of three modules,
i.e., encoding, transformation and decoding modules. Rather than only using image distance loss
between the generated 3D images and the ground truth 3D CT images to supervise the network, perceptual
loss in feature space is integrated into loss function to force the TransNet to yield accurate lung
boundary. Adversarial supervision is also used to improve the realism of generated 3D images. We
conducted a simulation study on 20 patient cases, who had received lung SBRT treatments in our institution
and undergone 4D-CT simulation, and evaluated the efficacy and consistency of our method for four
different projection angles, i.e., 0, 30, 60 and 90 degree. For each 3D CT image set of a breathing
phase, we simulated its 2D projections at these angles.Then for each projection angle, a patient's
3D CT images of 9 phases and the corresponding 2D projection data were used for training, with the
remaining phase used for testing. The mean absolute error, normalized MAE, peak signal-to-noise
ratio and structural similarity index metric achieved by our method are 99.3 HU, 0.032, 23.4 dB and
0.949, respectively. These results demonstrate the feasibility and efficacy of our 2D-to-3D method
for lung cancer patients, which provides a potential solution for in-treatment real-time on-board
volumetric imaging for accurate dose delivery to ensure the effectiveness of lung SBRT treatment.
