Bayesian methods have been very successful in quantifying uncertainty in physics-based problems
in parameter estimation and prediction. In these cases, physical measurements y are modeled as
the best fit of a physics-based model $\eta(\theta)$ where $\theta$ denotes the uncertain, best
input setting. Hence the statistical model is of the form $y = \eta(\theta) + \epsilon$, where $\epsilon$
accounts for measurement, and possibly other error sources. When non-linearity is present in $\eta(\cdot)$,
the resulting posterior distribution for the unknown parameters in the Bayesian formulation is
typically complex and non-standard, requiring computationally demanding computational approaches
such as Markov chain Monte Carlo (MCMC) to produce multivariate draws from the posterior. While
quite generally applicable, MCMC requires thousands, or even millions of evaluations of the physics
model $\eta(\cdot)$. This is problematic if the model takes hours or days to evaluate. To overcome
this computational bottleneck, we present an approach adapted from Bayesian model calibration.
This approach combines output from an ensemble of computational model runs with physical measurements,
within a statistical formulation, to carry out inference. A key component of this approach is a statistical
response surface, or emulator, estimated from the ensemble of model runs. We demonstrate this approach
with a case study in estimating parameters for a density functional theory (DFT) model, using experimental
mass/binding energy measurements from a collection of atomic nuclei. We also demonstrate how this
approach produces uncertainties in predictions for recent mass measurements obtained at Argonne
National Laboratory (ANL). 