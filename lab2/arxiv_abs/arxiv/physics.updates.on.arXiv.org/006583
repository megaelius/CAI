Traditional methods for black box optimization require a considerable number of evaluations which
can be time consuming, unpractical, and often unfeasible for many engineering applications that
rely on accurate representations and expensive models to evaluate. Bayesian Optimization (BO)
methods search for the global optimum by progressively (actively) learning a surrogate model of
the objective function along the search path. Bayesian optimization can be accelerated through
multifidelity approaches which leverage multiple black-box approximations of the objective
functions that can be computationally cheaper to evaluate, but still provide relevant information
to the search task. Further computational benefits are offered by the availability of parallel
and distributed computing architectures whose optimal usage is an open opportunity within the
context of active learning. This paper introduces the Resource Aware Active Learning (RAAL) strategy,
a multifidelity Bayesian scheme to accelerate the optimization of black box functions. At each
optimization step, the RAAL procedure computes the set of best sample locations and the associated
fidelity sources that maximize the information gain to acquire during the parallel/distributed
evaluation of the objective function, while accounting for the limited computational budget.
The scheme is demonstrated for a variety of benchmark problems and results are discussed for both
single fidelity and multifidelity settings. In particular we observe that the RAAL strategy optimally
seeds multiple points at each iteration allowing for a major speed up of the optimization task. 