Resource allocation systems provide the fundamental support for the normal functioning and well
being of the modern society, and can be modeled as minority games. A ubiquitous dynamical phenomenon
is the emergence of herding, where a vast majority of the users concentrate on a small number of resources,
leading to a low efficiency in resource allocation. To devise strategies to prevent herding is thus
of high interest. Previous works focused on control strategies that rely on external interventions,
such as pinning control where a fraction of users are forced to choose a certain action. Is it possible
to eliminate herding without any external control? The main point of this paper is to provide an affirmative
answer through exploiting artificial intelligence (AI). In particular, we demonstrate that,
when agents are empowered with reinforced learning in that they get familiar with the unknown game
environment gradually and attempt to deliver the optimal actions to maximize the payoff, herding
can effectively be eliminated. Computations reveal the striking phenomenon that, regardless
of the initial state, the system evolves persistently and relentlessly toward the optimal state
in which all resources are used efficiently. However, the evolution process is not without interruptions:
there are large fluctuations that occur but only intermittently in time. The statistical distribution
of the time between two successive fluctuating events is found to depend on the parity of the evolution,
i.e., whether the number of time steps in between is odd or even. We develop a physical analysis and
derive mean-field equations to gain an understanding of these phenomena. As minority game dynamics
and the phenomenon of herding are common in social, economic, and political systems, and since AI
is becoming increasingly widespread, we expect our AI empowered minority game system to have broad
applications. 