The detection of objects in the presence of significant background noise is a problem of fundamental
interest in sensing. In this work, we theoretically analyze a prototype target detection protocol,
the quantum temporal correlation (QTC) detection protocol, which is implemented in this work utilizing
spontaneous parametric down-converted photon-pair sources. The QTC detection protocol only
requires time-resolved photon-counting detection, which is phase-insensitive and therefore
suitable for optical target detection. As a comparison to the QTC detection protocol, we also consider
a classical phase-insensitive target detection protocol based on intensity detection that is
practical in the optical regime. We formulated the target detection problem as a total probe photon
transmission estimation problem and obtain an analytical expression of the receiver operating
characteristic (ROC) curves. We carry out experiments using a semiconductor waveguide source,
which we developed and previously reported. The experimental results agree very well with the theoretical
prediction. In particular, we find that in a high-level environment noise and loss, the QTC detection
protocol can achieve performance comparable to that of the classical protocol (that is practical
in the optical regime) but with \(\simeq 57\) times lower detection time in terms of ROC curve metric.
The performance of the QTC detection protocol experiment setup could be further improved with a
higher transmission of the reference photon and better detector time uncertainty. Furthermore,
the probe photons in the QTC detection protocol are completely indistinguishable from the background
noise and therefore useful for covert ranging applications. Finally, our technological platform
is highly scalable as well as tunable and thus amenable to large scale integration, which is necessary
for practical applications. 