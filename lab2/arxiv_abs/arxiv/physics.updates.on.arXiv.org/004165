Many relativistic plasma environments in high-energy astrophysics, including pulsar wind nebulae,
hot accretion flows onto black holes, relativistic jets in active galactic nuclei and gamma-ray
bursts, and giant radio lobes, are naturally turbulent. The plasma in these environments is often
so hot that synchrotron and inverse-Compton (IC) radiative cooling becomes important. In this
paper we investigate the general thermodynamic and radiative properties (and hence the observational
appearance) of an optically thin relativistically hot plasma stirred by driven magnetohydrodynamic
(MHD) turbulence and cooled by radiation. We find that if the system reaches a statistical equilibrium
where turbulent heating is balanced by radiative cooling, the effective electron temperature
tends to attain a universal value $\theta = kT_e/m_e c^2 \sim 1/\sqrt{\tau_T}$, where $\tau_T=n_e\sigma_T
L \ll 1$ is the system's Thomson optical depth, essentially independent of the strength of turbulent
driving or magnetic field. This is because both MHD turbulent dissipation and synchrotron cooling
are proportional to the magnetic energy density. We also find that synchrotron self-Compton (SSC)
cooling and perhaps a few higher-order IC components are automatically comparable to synchrotron
in this regime. The overall broadband radiation spectrum then consists of several distinct components
(synchrotron, SSC, etc.), well separated in photon energy (by a factor $\sim \tau_T^{-1}$) and
roughly equal in power. The number of IC peaks is checked by Klein-Nishina effects and depends logarithmically
on $\tau_T$ and the magnetic field. We also examine the limitations due to synchrotron self-absorption,
explore applications to Crab PWN and blazar jets, and discuss links to radiative magnetic reconnection.
