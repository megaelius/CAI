Reynolds-averaged Navier-Stokes (RANS) equations are widely used in engineering turbulent flow
simulations. However, the mean flow fields predicted by RANS solvers could come with large discrepancies
due to the uncertainties in modeled Reynolds stresses. Recently, Wang et al. demonstrated that
machine learning can be used to improve the RANS modeled Reynolds stresses by leveraging data from
high fidelity simulations (Physics informed machine learning approach for reconstructing Reynolds
stress modeling discrepancies based on DNS data. Physical Review Fluids. 2, 034603, 2017). However,
solving for mean flows from the machine-learning predicted Reynolds stresses still poses significant
challenges. The present work is a critical extension of (Wang et al. 2017), and it enables the machine
learning model to yield improved predictions of not only Reynolds stresses but also mean velocities
therefrom. Such a development is of profound practical importance, because often the velocities
and the derived quantities (e.g., drag, lift, surface friction), and not the Reynolds stresses
per se, are the ultimate quantities of interest in RANS simulations. The present work has two innovations.
First, we demonstrate a systematic procedure to generate mean flow features based on the integrity
basis for a set of mean flow tensors, which is in contrast to the ad hoc choices features in (Wang et
al. 2017). Second, we propose using machine learning to predict linear and nonlinear parts of the
Reynolds stress tensor separately. Inspired by the finite polynomial representation of tensors
in classical turbulence modeling, such a decomposition is instrumental in overcoming the instability
of RANS equations. Several test cases are used to demonstrate the merits of the proposed approach.
