Machine-intelligence has become a driving factor in modern society. However, its demand outpaces
the underlying electronic technology due to limitations given by fundamental physics such as capacitive
charging of wires, but also by system architecture of storing and handling data, both driving recent
trends towards processor heterogeneity. Here we introduce a novel amplitude-only Fourier-optical
processor paradigm capable of processing large-scale ~(1,000 x 1,000) matrices in a single time-step
and 100 microsecond-short latency. Conceptually, the information-flow direction is orthogonal
to the two-dimensional programmable-network, which leverages 10^6-parallel channels of display
technology, and enables a prototype demonstration performing convolutions as pixel-wise multiplications
in the Fourier domain reaching peta operations per second throughputs. The required real-to-Fourier
domain transformations are performed passively by optical lenses at zero-static power. We exemplary
realize a convolutional neural network (CNN) performing classification tasks on 2-Megapixel
large matrices at 10 kHz rates, which latency-outperforms current GPU and phase-based display
technology by one and two orders of magnitude, respectively. Training this optical convolutional
layer on image classification tasks and utilizing it in a hybrid optical-electronic CNN, shows
classification accuracy of 98% (MNIST) and 54% (CIFAR-10). Interestingly, the amplitude-only
CNN is inherently robust against coherence noise in contrast to phase-based paradigms and features
an over 2 orders of magnitude lower delay than liquid crystal-based systems. Beyond contributing
to novel accelerator technology, scientifically this amplitude-only massively-parallel optical
compute-paradigm can be far-reaching as it de-validates the assumption that phase-information
outweighs amplitude in optical processors for machine-intelligence. 