We present novel approaches for the development, evaluation and interpretation of artificial
neural networks (ANNs) for subfilter closures and demonstrate their usage in the context of large-eddy
simulations (LES) of a passive scalar in homogeneous isotropic turbulence. Exact subfilter fluxes
obtained by filtering direct numerical simulations (DNS) are used both to train deep ANN models
as a function of filtered variables, and to optimise the coefficients of common spatio-temporally
local LES closures. \textit{A-priori} analysis with respect to important dynamical features
such as backscatter and subfilter scalar variance transfer rate, reveals that learnt ANN models
out-perform optimised, turbulent Prandtl number closure models and gradient models. Next, \textit{a-posteriori}
solutions are obtained with each model over several integral timescales. These solutions are obtained
by explicitly filtering DNS-resolved velocity to isolate sources of error to subfilter flux closure.
These experiments reveal that ANN models temporally track resolved scalar variance with greater
accuracy compared to other subfilter flux models for a given filter length scale. Similarly, moments
of scalar two-point structure functions reveal that trained neural network models reproduce statistics
of ground-truth DNS with greater fidelity compared to common algebraic closure models. Finally,
we interpret the artificial neural networks statistically with differential sensitivity analysis
to show that the ANN models learn dynamics reminiscent of so-called "mixed models", where mixed
models are understood as comprising both a structural and functional component. Besides enabling
enhanced-accuracy LES of passive scalars henceforth, we anticipate this work to contribute to
utilising well-performing neural network models as a tool in interpretability, robustness and
model discovery. 