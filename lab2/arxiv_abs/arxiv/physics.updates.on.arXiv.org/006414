With the emergence and rapid proliferation of social media platforms and social networking sites,
recent years have witnessed a surge of misinformation spreading in our daily life. Drawing on a large-scale
dataset which covers more than 1.4M posts and 18M comments, we investigate the propagation of two
distinct narratives--(i) conspiracy information, whose claims are generally unsubstantiated
and thus referred as misinformation to some extent, and (ii) scientific information, whose origins
are generally readily identifiable and verifiable--in an online social media platform. We find
that conspiracy cascades tend to propagate in a multigenerational branching process while science
cascades are more likely to grow in a breadth-first manner. Specifically, conspiracy information
triggers larger cascades, involves more users and generations, persists longer, is more viral
and bursty than science information. Content analysis reveals that conspiracy cascades contain
more negative words and emotional words which convey anger, fear, disgust, surprise and trust.
We also find that conspiracy cascades are more concerned with political and controversial topics.
After applying machine learning models, we achieve an AUC score of nearly 90% in discriminating
conspiracy from science narratives using the constructed features. We also find that conspiracy
cascades are more likely to be controlled by a broader set of users than science cascades. Although
political affinity is thought to affect the consumption of misinformation, there is very few evidence
that political orientation of the information source plays a role during the propagation of conspiracy
information. Our study provides complementing evidence to current misinformation research and
has practical policy implications to stem the propagation and mitigate the influence of misinformation
online. 