Deep learning (DL) has shown unprecedented performance for many image analysis and image enhancement
tasks. Yet, solving large-scale inverse problems like tomographic reconstruction remains challenging
for DL. These problems involve non-local and space-variant integral transforms between the input
and output domains, for which no efficient neural network models have been found. A prior attempt
to solve such problems with supervised learning relied on a brute-force fully connected network
and applied it to reconstruction for a $128^4$ system matrix size. This cannot practically scale
to realistic data sizes such as $512^4$ and $512^6$ for three-dimensional data sets. Here we present
a novel framework to solve such problems with deep learning by casting the original problem as a continuum
of intermediate representations between the input and output data. The original problem is broken
down into a sequence of simpler transformations that can be well mapped onto an efficient hierarchical
network architecture, with exponentially fewer parameters than a generic network would need.
We applied the approach to computed tomography (CT) image reconstruction for a $512^4$ system matrix
size. To our knowledge, this enabled the first data-driven DL solver for full-size CT reconstruction
without relying on the structure of direct (analytical) or iterative (numerical) inversion techniques.
The proposed approach is applicable to other imaging problems such as emission and magnetic resonance
reconstruction. More broadly, hierarchical DL opens the door to a new class of solvers for general
inverse problems, which could potentially lead to improved signal-to-noise ratio, spatial resolution
and computational efficiency in various areas. 