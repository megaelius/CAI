According to a recent information-theoretical proposal, the problem of defining and identifying
communities in networks can be interpreted as a classical communication task over a noisy channel:
memberships of nodes are information bits erased by the channel, edges and non-edges in the network
are parity bits introduced by the encoder but degraded through the channel, and a community identification
algorithm is a decoder. The interpretation is perfectly equivalent to the one at the basis of well-known
statistical inference algorithms for community detection. The only difference in the interpretation
is that a noisy channel replaces a stochastic network model. However, the different perspective
gives the opportunity to take advantage of the rich set of tools of coding theory to generate novel
insights on the problem of community detection. In this paper, we illustrate two main applications
of standard coding-theoretical methods to community detection. First, we leverage a state-of-the-art
decoding technique to generate a family of quasi-optimal community detection algorithms. Second
and more important, we show that the Shannon's noisy-channel coding theorem can be invoked to establish
a lower bound, here named as decodability bound, for the maximum amount of noise tolerable by an ideal
decoder to achieve perfect detection of communities. When computed for well-established synthetic
benchmarks, the decodability bound explains accurately the performance achieved by the best community
detection algorithms existing on the market, telling us that only little room for their improvement
is still potentially left. 