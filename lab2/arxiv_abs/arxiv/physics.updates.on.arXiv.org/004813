Deep learning (DL) methods have in recent years yielded impressive results in medical imaging,
with the potential to function as clinical aid to radiologists. However, DL models in medical imaging
are often trained on public research cohorts with images acquired with a single scanner or with strict
protocol harmonization, which is not representative of a clinical setting. The aim of this study
was to investigate how well a DL model performs in unseen clinical data sets---collected with different
scanners, protocols and disease populations---and whether more heterogeneous training data
improves generalization. In total, 3117 MRI scans of brains from multiple dementia research cohorts
and memory clinics, that had been visually rated by a neuroradiologist according to Scheltens'
scale of medial temporal atrophy (MTA), were included in this study. By training multiple versions
of a convolutional neural network on different subsets of this data to predict MTA ratings, we assessed
the impact of including images from a wider distribution during training had on performance in external
memory clinic data. Our results showed that our model generalized well to data sets acquired with
similar protocols as the training data, but substantially worse in clinical cohorts with visibly
different tissue contrasts in the images. This implies that future DL studies investigating performance
in out-of-distribution (OOD) MRI data need to assess multiple external cohorts for reliable results.
Further, by including data from a wider range of scanners and protocols the performance improved
in OOD data, which suggests that more heterogeneous training data makes the model generalize better.
To conclude, this is the most comprehensive study to date investigating the domain shift in deep
learning on MRI data, and we advocate rigorous evaluation of DL models on clinical data prior to being
certified for deployment. 