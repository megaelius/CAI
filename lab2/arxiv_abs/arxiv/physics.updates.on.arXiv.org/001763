A basic systems question concerns the concept of closure, meaning autonomomy (closed) in the sense
of describing the (sub)system as fully consistent within itself. Alternatively, the system may
be nonautonomous (open) meaning it receives influence from an outside coupling subsystem. Information
flow, and related causation inference, are tenant on this simple concept. We take the perspective
of Weiner-Granger causality, descriptive of a subsystem forecast quality dependence on considering
states of another subsystem. Here we develop a new direct analytic discussion, rather than a data
oriented approach. That is, we refer to the underlying Frobenius-Perron transfer operator that
moderates evolution of densities of ensembles of orbits, and two alternative forms of the restricted
Frobenius-Perron (FP) operator, interpreted as if either closed (determinstic FP) or not closed
(the unaccounted outside influence seems stochastic and correspondingly the stochastic FP operator).
From this follows contrasting the kernels of the variants of the operators, as if densities in their
own rights. However, the corresponding differential entropy to compare by Kulback-Leibler divergence,
as one would when leading to transfer entropy, becomes ill-defined. Instead we build our Forecastability
Quality Metric (FQM) upon the "symmetrized" variant known as Jensen-Shanon divergence, and also
we are able to point out several useful resulting properties that result. We illustrate the FQM by
a simple coupled chaotic system. For now, this analysis is a new theoretical direction, but we describe
data oriented directions for the future. 