Imaging through scattering is an important, yet challenging problem. Tremendous progress has
been made by exploiting the deterministic input-output relation for a static medium. However,
this approach is highly susceptible to speckle decorrelations - small perturbations to the scattering
medium lead to model errors and severe degradation of the imaging performance. In addition, this
is complicated by the large number of phase-sensitive measurements required for characterizing
the input-output `transmission matrix'. Our goal here is to develop a new framework that is highly
scalable to both medium perturbations and measurement requirement. To do so, we abandon the traditional
deterministic approach, instead propose a statistical framework that permits higher representation
power to encapsulate a wide range of statistical variations needed for model generalization. Specifically,
we develop a convolutional neural network (CNN) that takes intensity-only speckle patterns as
input and predicts unscattered object as output. Importantly, instead of characterizing a single
input-output relation of a fixed medium, we train our CNN to learn statistical information contained
in several scattering media of the same class. We then show that the CNN is able to generalize over
a completely different set of scattering media from the same class, demonstrating its superior
adaptability to medium perturbations. In our proof of concept experiment, we first train our CNN
using speckle patterns captured on diffusers having the same macroscopic parameter (e.g. grits);
the trained CNN is then able to make high-quality reconstruction from speckle patterns that were
captured from an entirely different set of diffusers of the same grits. Our work paves the way to a
highly scalable deep learning approach for imaging through scattering media. 