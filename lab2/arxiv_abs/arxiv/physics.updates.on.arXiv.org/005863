We present a comprehensive analysis of electronic recoil vs. nuclear recoil discrimination in
liquid/gas xenon time projection chambers, using calibration data from the 2013 and 2014-16 runs
of the Large Underground Xenon (LUX) experiment. We observe strong charge-to-light discrimination
enhancement with increased event energy. For events with S1 = 120 detected photons, i.e. equivalent
to a nuclear recoil energy of $\sim$100 keV, we observe an electronic recoil background acceptance
of $<10^{-5}$ at a nuclear recoil signal acceptance of 50%. We also observe modest electric field
dependence of the discrimination power, which peaks at a field of around 300 V/cm over the range of
fields explored in this study (50-500 V/cm). In the WIMP search region of S1 = 1-80 phd, the minimum
electronic recoil leakage we observe is ${(7.3\pm0.6)\times10^{-4}}$, which is obtained for
a drift field of 240-290 V/cm. Pulse shape discrimination is utilized to improve our results, and
we find that, at low energies and low fields, there is an additional reduction in background leakage
by a factor of up to 3. We develop an empirical model for recombination fluctuations which, when used
alongside the Noble Element Scintillation Technique (NEST) simulation package, correctly reproduces
the skewness of the electronic recoil data. We use this updated simulation to study the width of the
electronic recoil band, finding that its dominant contribution comes from electron-ion recombination
fluctuations, followed in magnitude of contribution by fluctuations in the S1 signal, fluctuations
in the S2 signal, and fluctuations in the total number of quanta produced for a given energy deposition.
