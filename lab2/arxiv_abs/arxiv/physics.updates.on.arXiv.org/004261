Turbulence simulations play a key role in advancing the general understanding of the physical properties
turbulence and in interpreting astrophysical observations of turbulent plasmas. For the sake
of simplicity, however, turbulence simulations are often conducted in the isothermal limit. Given
that the majority of astrophysical systems are not governed by isothermal dynamics, we aim to quantify
the impact of thermodynamics on the physics of turbulence, through varying adiabatic index, $\gamma$,
combined with a range of optically thin cooling functions. In this paper, we present a suite of ideal
magnetohydrodynamics simulations of thermally balanced stationary turbulence in the subsonic,
super-Alfv\'enic, high beta (ratio of thermal to magnetic pressure) regime, where turbulent dissipation
is balanced by two idealized cooling functions (approximating linear cooling and free-free emission)
and examine the impact of the equation of state by considering cases that correspond to isothermal,
monatomic and diatomic gases. We find a strong anticorrelation between thermal and magnetic pressure
independent of thermodynamics, whereas the strong anticorrelation between density and magnetic
field found in the isothermal case weakens with increasing $\gamma$. Similarly, with the linear
relation between variations in density and thermal pressure with sonic Mach number becomes steeper
with increasing $\gamma$. This suggests that there exists a degeneracy in these relations with
respect to thermodynamics and Mach number in this regime, which is dominated by slow magnetosonic
modes. These results have implications for attempts to infer (e.g.) Mach numbers from (e.g.) Faraday
rotation measurements, without additional information regarding the thermodynamics of the plasma.
However, our results suggest that this degeneracy can be broken by utilizing higher-order moments
of observable distribution functions. 