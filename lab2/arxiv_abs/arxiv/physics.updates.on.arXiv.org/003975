Optical machine learning offers advantages in terms of power efficiency, scalability and computation
speed. Recently, an optical machine learning method based on Diffractive Deep Neural Networks
(D2NNs) has been introduced to execute a function as the input light diffracts through passive layers,
designed by deep learning using a computer. Here we introduce improvements to D2NNs by changing
the training loss function and reducing the impact of vanishing gradients in the error back-propagation
step. Using five phase-only diffractive layers, we numerically achieved a classification accuracy
of 97.18% and 89.13% for optical recognition of handwritten digits and fashion products, respectively;
using both phase and amplitude modulation (complex-valued) at each layer, our inference performance
improved to 97.81% and 89.32%, respectively. Furthermore, we report the integration of D2NNs with
electronic neural networks to create hybrid-classifiers that significantly reduce the number
of input pixels into an electronic network using an ultra-compact front-end D2NN with a layer-to-layer
distance of a few wavelengths, also reducing the complexity of the successive electronic network.
Using a 5-layer phase-only D2NN jointly-optimized with a single fully-connected electronic layer,
we achieved a classification accuracy of 98.71% and 90.04% for the recognition of handwritten digits
and fashion products, respectively. Moreover, the input to the electronic network was compressed
by >7.8 times down to 10x10 pixels. Beyond creating low-power and high-frame rate machine learning
platforms, D2NN-based hybrid neural networks will find applications in smart optical imager and
sensor design. 