Noble liquid radiation detectors have long been afflicted by spurious electron emission from their
cathodic electrodes. This phenomenon must be understood and mitigated in the next generation of
liquid xenon (LXe) experiments searching for WIMP dark matter or neutrinoless double beta decay,
and in the large liquid argon (LAr) detectors for the long-baseline neutrino programme. We present
a systematic study of this spurious emission involving a series of slow voltage-ramping tests on
fine metal wires immersed in a two-phase xenon time projection chamber with single electron sensitivity.
Emission currents as low as $10^{-18}$ A can thus be detected by electron counting, a vast improvement
over previous dedicated measurements. Emission episodes were recorded at surface fields as low
as $\sim$10 kV/cm in some wires and observed to have complex emission patterns, with average rates
of 10-200 c/s and outbreaks as high as $\sim$10$^6$ c/s. A fainter, less variable type of emission
was also present in all untreated samples. There is evidence of a partial conditioning effect, with
subsequent tests yielding on average fewer emitters occurring at different fields for the same
wire. We find no evidence for an intrinsic threshold particular to the metal-LXe interface which
might have limited previous experiments up to fields of at least 160 kV/cm. The general phenomenology
is not consistent with enhanced field emission from microscopic filaments, but it appears instead
to be related to the quality of the wire surface in terms of corrosion and the nature of its oxide layer.
This study concludes that some surface treatments, in particular nitric acid cleaning for stainless
steel wires, can bringing about at least order-of-magnitude improvements in overall electron
emission rates, and this should help the next generation of detectors achieve the required electrostatic
performance. 