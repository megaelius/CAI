The representation of nonlinear sub-grid processes, especially clouds, has been a major source
of uncertainty in climate models for decades. Cloud-resolving models better represent many of
these processes and can now be run globally but only for short-term simulations of at most a few years
because of computational limitations. Here we demonstrate that deep learning can be used to capture
many advantages of cloud-resolving modeling at a fraction of the computational cost. We train a
deep neural network to represent all atmospheric sub-grid processes in a climate model by learning
from a multi-scale model in which convection is treated explicitly. The trained neural network
then replaces the traditional sub-grid parameterizations in a global general circulation model
in which it freely interacts with the resolved dynamics and the surface-flux scheme. The prognostic
multi-year simulations are stable and closely reproduce not only the mean climate of the cloud-resolving
simulation but also key aspects of variability, including precipitation extremes and the equatorial
wave spectrum. Furthermore, the neural network approximately conserves energy despite not being
explicitly instructed to. Finally, we show that the neural network parameterization generalizes
to new surface forcing patterns but struggles to cope with temperatures far outside its training
manifold. Our results show the feasibility of using deep learning for climate model parameterization.
In a broader context, we anticipate that data-driven Earth System Model development could play
a key role in reducing climate prediction uncertainty in the coming decade. 