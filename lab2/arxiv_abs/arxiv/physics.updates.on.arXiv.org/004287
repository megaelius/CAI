Deep generative models, such as Generative Adversarial Networks (GANs) or Variational Autoencoders
have been demonstrated to produce images of high visual quality. However, the existing hardware
on which these models are trained severely limits the size of the images that can be generated. The
rapid growth of high dimensional data in many fields of science therefore poses a significant challenge
for generative models. In cosmology, the large-scale, 3D matter distribution, modeled with N-body
simulations, plays a crucial role in understanding of evolution of structures in the universe.
As these simulations are computationally very expensive, GANs have recently generated interest
as a possible method to emulate these datasets, but they have been, so far, mostly limited to 2D data.
In this work, we introduce a new benchmark for the generation of 3D N-body simulations, in order to
stimulate new ideas in the machine learning community and move closer to the practical use of generative
models in cosmology. As a first benchmark result, we propose a scalable GAN approach for training
a generator of N-body 3D cubes. Our technique relies on two key building blocks, (i) splitting the
generation of the high-dimensional data into smaller parts, and (ii) using a multi-scale approach
that efficiently captures global image features that might otherwise be lost in the splitting process.
We evaluate the performance of our model for the generation of N-body samples using various statistical
measures commonly used in cosmology. Our results show that the proposed model produces samples
of high visual quality, although the statistical analysis reveals that capturing rare features
in the data poses significant problems for the generative models. We make the data, quality evaluation
routines, and the proposed GAN architecture publicly available at https://github.com/nperraud/3DcosmoGAN
