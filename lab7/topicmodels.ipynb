{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim\n",
    "from nltk.stem import LancasterStemmer\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load newsgroups corpus and preprocess.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DOCS = 5000\n",
    "\n",
    "# Reads csv file and generates an index operation for each line\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "\n",
    "# Convert to list and sample...\n",
    "data = random.sample(df.content.values.tolist(), min(MAX_DOCS, len(df)))\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "# To lowercase\n",
    "data = [sent.lower() for sent in data]\n",
    "\n",
    "# filter out stop words & tokenize\n",
    "data = [gensim.utils.simple_preprocess(str(remove_stopwords(sent)), deacc=True) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem\n",
    "data = [[LancasterStemmer().stem(x) for x in sent] for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'kenne', 'alvin', 'subject', 're', 'ass', 'hel', 'org', 'univers', 'colorado', 'bould', 'lin', 'artic', 'writ', 'hav', 'acceiv', 'jes', 'savy', 'yo', 'tak', 'aw', 'chant', 'jehovah', 'wit', 'who', 'long', 'frequ', 'door', 'you', 'right', 'wrong', 'liv', 'good', 'lif', 'die', 'and', 'ceas', 'ex', 'right', 'wrong', 'die', 'suff', 'etern', 'damn', 'dont', 'mean', 'fun', 'point', 'lik', 'dirty', 'harry', 'said', 'youv', 'got', 'ask', 'yourself', 'feel', 'lucky', 'you', 'man', 'got', 'know', 'limit', 'dont', 'whosoev', 'wont', 'ridic', 'argu', 'christian', 'then', 'consid', 'switch', 'christianity', 'relig', 'off', 'fright', 'describ', 'hel', 'christians', 'think', 'view', 'strictly', 'ins', 'policy', 'know', 'believ', 'mess', 'lov', 'compass', 'oth', 'fai', 'bas', 'fear', 'hel', 'sound', 'lik', 'dysfunct', 'rel', 'god', 'lik', 'child', 'cring', 'fear', 'par', 'phys', 'viol', 'relig', 'concret', 'view', 'heav', 'hel', 'threats', 'persuas', 'wher', 'competit', 'envison', 'worst', 'hel', 'hard', 'nurt', 'ide', 'lov', 'neighb', 'yourself', 'rex', 'com', 'crit', 'welcom', 'ken']\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'scot', 'wood', 'subject', 're', 'western', 'digit', 'hd', 'info', 'nee', 'org', 'oakland', 'univers', 'rochest', 'michig', 'lin', 'nntp', 'post', 'host', 'vel', 'ac', 'oakland', 'edu', 'hol', 'ks', 'writ', 'my', 'western', 'digit', 'set', 'pin', 'back', 'anoth', 'hard', 'driv', 'set', 'jump', 'writ', 'right', 'on', 'circuit', 'board', 'wd', 'driv', 'ma', 'sl', 'wel', 'fig', 'jump', 'go', 'diff', 'problem', 'perplex', 'lik', 'wouldnt', 'know', 'driv', 'work', 'format', 'hardw', 'instal', 'problem', 'is', 'boot', 'sequ', 'want', 'pass', 'look', 'driv', 'goe', 'fin', 'bio', 'config', 'necess', 'driv', 'test', 'work', 'thing', 'com', 'driv', 'disk', 'pres', 'spin', 'insert', 'disk', 'driv', 'howev', 'work', 'fin', 'boot', 'ie', 'instal', 'softw', 'addit', 'help', 'welcom', 'swood', 'hunt', 'michig', 'dont', 'despair', 'clos', 'season', 'on', 'oposs', 'porcupin', 'weasel', 'red', 'squirrel', 'skunk', 'starl', 'fer', 'pigeon', 'engl', 'sparrow', 'ground', 'squirrel', 'woodchuck', 'trout', 'season', 'op', 'saturday', 'mon']\n"
     ]
    }
   ],
   "source": [
    "print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare corpus using GenSim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary of words\n",
    "id2word = corpora.Dictionary(data)\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 5), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 2), (57, 1), (58, 3), (59, 1), (60, 1), (61, 1), (62, 1), (63, 2), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 2), (81, 1), (82, 1), (83, 2), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 2), (107, 1), (108, 2), (109, 2), (110, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])   # this shows a list of word,freq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 36538 words and 5000 documents\n"
     ]
    }
   ],
   "source": [
    "M = len(id2word)\n",
    "N = len(corpus)\n",
    "print(f\"there are {len(id2word)} words and {len(corpus)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show some words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first words: acceiv\n",
      "first words: alvin\n",
      "first words: and\n",
      "first words: argu\n",
      "first words: artic\n",
      "first words: ask\n",
      "first words: ass\n",
      "first words: aw\n",
      "first words: bas\n",
      "first words: believ\n",
      "last words: hakim\n",
      "last words: jhsegal\n",
      "last words: midl\n",
      "last words: molotov\n",
      "last words: raajid\n",
      "last words: ramadh\n",
      "last words: riyad\n",
      "last words: rouhy\n",
      "last words: saamud\n",
      "last words: wiscon\n"
     ]
    }
   ],
   "source": [
    "for w in range(10):\n",
    "    print(f\"first words: {id2word[w]}\")\n",
    "for w in range(M-10,M):\n",
    "    print(f\"last words: {id2word[w]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros([N,M])\n",
    "for d, doc in enumerate(corpus):\n",
    "    for (j, f) in doc:\n",
    "        X[d,j] = f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run SVD on matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "U,sigma,V = linalg.svd(X, full_matrices=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2) (2, 2) (2, 36538)\n"
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "U2 = U[:, 0:K]\n",
    "V2 = V[0:K, :]\n",
    "sigma2 = np.diag(sigma[0:K])\n",
    "print(U2.shape, sigma2.shape, V2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f96b2d90940>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import pylab\n",
    "from random import sample\n",
    "\n",
    "pyplot.title(\"LSA\")\n",
    "pyplot.xlabel(u'x')\n",
    "pyplot.ylabel(u'y')\n",
    "\n",
    "for i in sample(range(len(U2)), 20):\n",
    "    pylab.text(U2[i][0], U2[i][1],  id2word[i], fontsize=10)\n",
    "x = U2.T[0]\n",
    "y = U2.T[1]\n",
    "pylab.plot(x, y, '.')\n",
    "\n",
    "for i in sample(range(len(V2[0])), 20):\n",
    "    pylab.text(V2[0][i], V2[1][i], ('D%d' %(i+1)), fontsize=10)\n",
    "x = V[0]\n",
    "y = V[1]\n",
    "pylab.plot(x, y, 'x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pLSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = np.zeros([N])   # counts per document\n",
    "n = np.zeros([N,M])  # counts per document, word\n",
    "for d, doc in enumerate(corpus):\n",
    "    for (j,f) in doc:\n",
    "        n[d,j] = f\n",
    "        nd[d] += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize parameters randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rand():\n",
    "    # theta[d, k] : p(z=k|d)\n",
    "    theta = np.random.rand(N, K)\n",
    "    d_sums = theta.sum(axis = 1)\n",
    "    theta /= d_sums[:, np.newaxis]\n",
    "\n",
    "    # beta[k, w] : p(w|z=k)\n",
    "    beta = np.random.rand(K, M)\n",
    "    w_sums = beta.sum(axis = 1)\n",
    "    beta /= w_sums[:, np.newaxis]\n",
    "\n",
    "    return theta, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EStep(theta, beta):\n",
    "    \n",
    "    # post[k,d,w] : p(z=k|d,w) posterior of latent z!    \n",
    "    _post = np.full((K,N,M), 1/K)\n",
    "    \n",
    "    for d, doc in enumerate(corpus):\n",
    "        for j,_ in doc:\n",
    "            for k in range(0, K):\n",
    "                _post[k, d, j] =  theta[d, k]*beta[k, j]\n",
    "    # now, we normalize using first axis..\n",
    "    k_sums = _post.sum(axis = 0)\n",
    "    _post /= k_sums[np.newaxis,:,:]\n",
    "\n",
    "    return _post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MStep(post):\n",
    "    \n",
    "    # re-estimate theta\n",
    "    _theta = np.zeros([N, K])\n",
    "    for k in range(0, K):\n",
    "        for d, doc in enumerate(corpus):\n",
    "            for j, f in doc:\n",
    "                _theta[d,k] += f * post[k,d,j]\n",
    "        for d in range(0,N):\n",
    "            _theta[d,k] /= nd[d]\n",
    "\n",
    "    # re-estimate beta\n",
    "    _beta = np.zeros([K, M])\n",
    "    for k in range(0,K):\n",
    "        for d, doc in enumerate(corpus):\n",
    "            for j, f in doc:\n",
    "                _beta[k,j] += f * post[k,d,j]\n",
    "    # now normalize by axis = 1\n",
    "    w_sums = _beta.sum(axis = 1)\n",
    "    _beta /= w_sums[:, np.newaxis]\n",
    "    \n",
    "    return _theta, _beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLikelihood(theta, beta):\n",
    "    tmp = 0\n",
    "    for d, doc in enumerate(corpus):\n",
    "        for j, f in doc:\n",
    "            tmp += f * np.log(theta[d,:].dot(beta[:,j]))\n",
    "    print(f'loglikelihood: {tmp:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood: -8118683.6\n",
      "iteration 0 took 1049.18 s.\n",
      "loglikelihood: -6223760.8\n",
      "iteration 1 took 1422.91 s.\n",
      "loglikelihood: -6194849.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "theta, beta = init_rand()\n",
    "LogLikelihood(theta,beta)\n",
    "start = time.time()\n",
    "for i in range(0, 10):\n",
    "    t = time.time()\n",
    "    post = EStep(theta,beta)\n",
    "    theta,beta = MStep(post)\n",
    "    elapsed = time.time() - t\n",
    "    \n",
    "    print(f\"iteration {i} took {elapsed:.2f} s.\")\n",
    "    LogLikelihood(theta,beta)\n",
    "print(f\"EM took {time.time()-start:.2f} s.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = []\n",
    "for k in range(K):\n",
    "    topic = []\n",
    "    ids = (-beta[k, :]).argsort()\n",
    "    topic = [(id2word[j], beta[k,j]) for j in ids]\n",
    "    all_topics.append(topic[:20])\n",
    "\n",
    "# print out topics:\n",
    "for k, topic in enumerate(all_topics):\n",
    "    print()\n",
    "    print(f'topic {k+1}: {topic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
